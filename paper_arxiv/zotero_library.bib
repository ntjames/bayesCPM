
@online{center_for_history_and_new_media_zotero_nodate,
	title = {Zotero Quick Start Guide},
	url = {http://zotero.org/support/quick_start_guide},
	author = {{Center for History and New Media}}
}

@article{dai_discriminative_2012,
	title = {Discriminative analysis of early Alzheimer's disease using multi-modal imaging and multi-level characterization with multi-classifier (M3)},
	volume = {59},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811911011645},
	doi = {10.1016/j.neuroimage.2011.10.003},
	pages = {2187--2195},
	number = {3},
	journaltitle = {{NeuroImage}},
	author = {Dai, Zhengjia and Yan, Chaogan and Wang, Zhiqun and Wang, Jinhui and Xia, Mingrui and Li, Kuncheng and He, Yong},
	urldate = {2017-06-27},
	date = {2012-02},
	langid = {english},
	file = {dai_et_al_2012_discriminative_analysis_of_early_alzheimer's_disease_using_multi-modal_imaging.pdf:/home/nathan/Dropbox/njames/zotero_sync/dai_et_al_2012_discriminative_analysis_of_early_alzheimer's_disease_using_multi-modal_imaging.pdf:application/pdf}
}

@article{kang_bayesian_2017,
	title = {A Bayesian Double Fusion Model for Resting-State Brain Connectivity Using Joint Functional and Structural Data},
	volume = {7},
	issn = {2158-0014, 2158-0022},
	url = {http://online.liebertpub.com/doi/10.1089/brain.2016.0447},
	doi = {10.1089/brain.2016.0447},
	pages = {219--227},
	number = {4},
	journaltitle = {Brain Connectivity},
	author = {Kang, Hakmook and Ombao, Hernando and Fonnesbeck, Christopher and Ding, Zhaohua and Morgan, Victoria L.},
	urldate = {2017-06-27},
	date = {2017-05},
	langid = {english},
	file = {kang_et_al_2017_a_bayesian_double_fusion_model_for_resting-state_brain_connectivity_using_joint.pdf:/home/nathan/Dropbox/njames/zotero_sync/kang_et_al_2017_a_bayesian_double_fusion_model_for_resting-state_brain_connectivity_using_joint.pdf:application/pdf}
}

@article{bowman_brain_2014,
	title = {Brain Imaging Analysis},
	volume = {1},
	issn = {2326-8298, 2326-831X},
	url = {http://www.annualreviews.org/doi/10.1146/annurev-statistics-022513-115611},
	doi = {10.1146/annurev-statistics-022513-115611},
	pages = {61--85},
	number = {1},
	journaltitle = {Annual Review of Statistics and Its Application},
	author = {Bowman, F. {DuBois}},
	urldate = {2017-06-27},
	date = {2014-01-03},
	langid = {english},
	file = {bowman_2014_brain_imaging_analysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/bowman_2014_brain_imaging_analysis.pdf:application/pdf}
}

@article{bunea_penalized_2011,
	title = {Penalized least squares regression methods and applications to neuroimaging},
	volume = {55},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811910016113},
	doi = {10.1016/j.neuroimage.2010.12.028},
	pages = {1519--1527},
	number = {4},
	journaltitle = {{NeuroImage}},
	author = {Bunea, Florentina and She, Yiyuan and Ombao, Hernando and Gongvatana, Assawin and Devlin, Kate and Cohen, Ronald},
	urldate = {2017-06-27},
	date = {2011-04},
	langid = {english},
	file = {bunea_et_al_2011_penalized_least_squares_regression_methods_and_applications_to_neuroimaging.pdf:/home/nathan/Dropbox/njames/zotero_sync/bunea_et_al_2011_penalized_least_squares_regression_methods_and_applications_to_neuroimaging.pdf:application/pdf}
}

@article{kang_simultaneous_2015,
	title = {Simultaneous control of error rates in {fMRI} data analysis},
	volume = {123},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S105381191500717X},
	doi = {10.1016/j.neuroimage.2015.08.009},
	pages = {102--113},
	journaltitle = {{NeuroImage}},
	author = {Kang, Hakmook and Blume, Jeffrey and Ombao, Hernando and Badre, David},
	urldate = {2017-06-27},
	date = {2015-12},
	langid = {english},
	file = {kang_et_al_2015_simultaneous_control_of_error_rates_in_fmri_data_analysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/kang_et_al_2015_simultaneous_control_of_error_rates_in_fmri_data_analysis.pdf:application/pdf}
}

@article{wong_fiber_2016,
	title = {Fiber direction estimation, smoothing and tracking in diffusion {MRI}},
	volume = {10},
	issn = {1932-6157},
	url = {http://projecteuclid.org/euclid.aoas/1475069599},
	doi = {10.1214/15-AOAS880},
	pages = {1137--1156},
	number = {3},
	journaltitle = {The Annals of Applied Statistics},
	author = {Wong, Raymond K. W. and Lee, Thomas C. M. and Paul, Debashis and Peng, Jie and Disease Neuroimaging Initiative, Alzheimer?s},
	urldate = {2017-06-27},
	date = {2016-09},
	langid = {english},
	file = {wong_et_al_2016_fiber_direction_estimation,_smoothing_and_tracking_in_diffusion_mri.pdf:/home/nathan/Dropbox/njames/zotero_sync/wong_et_al_2016_fiber_direction_estimation,_smoothing_and_tracking_in_diffusion_mri.pdf:application/pdf}
}

@article{lindquist_statistical_2008,
	title = {The Statistical Analysis of {fMRI} Data},
	volume = {23},
	issn = {0883-4237},
	url = {http://projecteuclid.org/euclid.ss/1242049389},
	doi = {10.1214/09-STS282},
	pages = {439--464},
	number = {4},
	journaltitle = {Statistical Science},
	author = {Lindquist, Martin A.},
	urldate = {2017-06-27},
	date = {2008-11},
	langid = {english},
	file = {lindquist_2008_the_statistical_analysis_of_fmri_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/lindquist_2008_the_statistical_analysis_of_fmri_data.pdf:application/pdf}
}

@article{hernan_observational_2008,
	title = {Observational Studies Analyzed Like Randomized Experiments: An Application to Postmenopausal Hormone Therapy and Coronary Heart Disease},
	volume = {19},
	issn = {1044-3983},
	url = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00001648-200811000-00002},
	doi = {10.1097/EDE.0b013e3181875e61},
	shorttitle = {Observational Studies Analyzed Like Randomized Experiments},
	pages = {766--779},
	number = {6},
	journaltitle = {Epidemiology},
	author = {Hernán, Miguel A. and Alonso, Alvaro and Logan, Roger and Grodstein, Francine and Michels, Karin B. and Willett, Walter C. and Manson, {JoAnn} E. and Robins, James M.},
	urldate = {2017-06-27},
	date = {2008-11},
	langid = {english},
	file = {hernán_et_al_2008_observational_studies_analyzed_like_randomized_experiments.pdf:/home/nathan/Dropbox/njames/zotero_sync/hernán_et_al_2008_observational_studies_analyzed_like_randomized_experiments.pdf:application/pdf}
}

@article{paul_multiple_1997,
	title = {Multiple risk factor intervention trial-Risk factor changes and mortality results (Reprinted from {JAMA}, vol 248, pg 1465-1477, 1982)},
	volume = {277},
	pages = {582--594},
	number = {7},
	journaltitle = {{JAMA}-{JOURNAL} {OF} {THE} {AMERICAN} {MEDICAL} {ASSOCIATION}},
	author = {Paul, O. and Arnold, C. B. and Mandriota, R. and Ames, R. P. and Eisenbach, J. R. and Bohn, E. and Thomas, H. E. and Kannel, W. B. and Rotondo, R. and Connors, J. and {others}},
	date = {1997},
	file = {paul_et_al_1997_multiple_risk_factor_intervention_trial-risk_factor_changes_and_mortality.pdf:/home/nathan/Dropbox/njames/zotero_sync/paul_et_al_1997_multiple_risk_factor_intervention_trial-risk_factor_changes_and_mortality.pdf:application/pdf}
}

@article{mitra_generalized_nodate,
	title = {A generalized p-value approach to inference on common mean running title: generalized p-value approach for common mean},
	url = {http://www.math.umbc.edu/~kogan/technical_papers/2006/Mitra_Sinha.pdf},
	shorttitle = {A generalized p-value approach to inference on common mean running title},
	author = {Mitra, Pranab K. and Sinha, Bimal K.},
	urldate = {2017-06-27},
	file = {mitra_sinha_a_generalized_p-value_approach_to_inference_on_common_mean_running_title.pdf:/home/nathan/Dropbox/njames/zotero_sync/mitra_sinha_a_generalized_p-value_approach_to_inference_on_common_mean_running_title.pdf:application/pdf}
}

@article{agresti_approximate_1998,
	title = {Approximate Is Better than "Exact" for Interval Estimation of Binomial Proportions},
	volume = {52},
	issn = {00031305},
	url = {http://www.jstor.org/stable/2685469?origin=crossref},
	doi = {10.2307/2685469},
	pages = {119},
	number = {2},
	journaltitle = {The American Statistician},
	author = {Agresti, Alan and Coull, Brent A.},
	urldate = {2017-06-27},
	date = {1998-05},
	file = {agresti_coull_1998_approximate_is_better_than_exact_for_interval_estimation_of_binomial.pdf:/home/nathan/Dropbox/njames/zotero_sync/agresti_coull_1998_approximate_is_better_than_exact_for_interval_estimation_of_binomial.pdf:application/pdf}
}

@article{agresti_simple_2000,
	title = {Simple and Effective Confidence Intervals for Proportions and Differences of Proportions Result from Adding Two Successes and Two Failures},
	volume = {54},
	issn = {00031305},
	url = {http://www.jstor.org/stable/2685779?origin=crossref},
	doi = {10.2307/2685779},
	pages = {280},
	number = {4},
	journaltitle = {The American Statistician},
	author = {Agresti, Alan and Caffo, Brian},
	urldate = {2017-06-27},
	date = {2000-11},
	file = {agresti_caffo_2000_simple_and_effective_confidence_intervals_for_proportions_and_differences_of.pdf:/home/nathan/Dropbox/njames/zotero_sync/agresti_caffo_2000_simple_and_effective_confidence_intervals_for_proportions_and_differences_of.pdf:application/pdf}
}

@article{schall_baseball_2000,
	title = {Do Baseball Players Regress Toward the Mean?},
	volume = {54},
	issn = {00031305},
	url = {http://www.jstor.org/stable/2685772?origin=crossref},
	doi = {10.2307/2685772},
	pages = {231},
	number = {4},
	journaltitle = {The American Statistician},
	author = {Schall, Teddy and Smith, Gary},
	urldate = {2017-06-27},
	date = {2000-11},
	file = {schall_smith_2000_do_baseball_players_regress_toward_the_mean.pdf:/home/nathan/Dropbox/njames/zotero_sync/schall_smith_2000_do_baseball_players_regress_toward_the_mean.pdf:application/pdf}
}

@article{berger_case_2006,
	title = {The case for objective Bayesian analysis},
	volume = {1},
	url = {http://projecteuclid.org/euclid.ba/1340371035},
	pages = {385--402},
	number = {3},
	journaltitle = {Bayesian analysis},
	author = {Berger, James and {others}},
	urldate = {2017-06-27},
	date = {2006},
	file = {berger_others_2006_the_case_for_objective_bayesian_analysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/berger_others_2006_the_case_for_objective_bayesian_analysis.pdf:application/pdf}
}

@article{rosenbaum_central_1983,
	title = {The Central Role of the Propensity Score in Observational Studies for Causal Effects},
	volume = {70},
	issn = {00063444},
	url = {http://www.jstor.org/stable/2335942?origin=crossref},
	doi = {10.2307/2335942},
	pages = {41},
	number = {1},
	journaltitle = {Biometrika},
	author = {Rosenbaum, Paul R. and Rubin, Donald B.},
	urldate = {2017-06-27},
	date = {1983-04},
	file = {rosenbaum_rubin_1983_the_central_role_of_the_propensity_score_in_observational_studies_for_causal.pdf:/home/nathan/Dropbox/njames/zotero_sync/rosenbaum_rubin_1983_the_central_role_of_the_propensity_score_in_observational_studies_for_causal.pdf:application/pdf}
}

@article{press_choosing_1978,
	title = {Choosing Between Logistic Regression and Discriminant Analysis},
	volume = {73},
	issn = {01621459},
	url = {http://www.jstor.org/stable/2286261?origin=crossref},
	doi = {10.2307/2286261},
	pages = {699},
	number = {364},
	journaltitle = {Journal of the American Statistical Association},
	author = {Press, S. James and Wilson, Sandra},
	urldate = {2017-06-27},
	date = {1978-12},
	file = {press_wilson_1978_choosing_between_logistic_regression_and_discriminant_analysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/press_wilson_1978_choosing_between_logistic_regression_and_discriminant_analysis.pdf:application/pdf}
}

@article{newcombe_two-sided_1998,
	title = {Two-sided confidence intervals for the single proportion: comparison of seven methods},
	volume = {17},
	url = {https://www.researchgate.net/profile/Robert_Newcombe2/publication/13687789_Two-Sided_Confidence_Intervals_for_the_Single_Proportion_Comparison_of_Seven_Methods/links/02bfe50f467c883370000000.pdf},
	shorttitle = {Two-sided confidence intervals for the single proportion},
	pages = {857--872},
	number = {8},
	journaltitle = {Statistics in medicine},
	author = {Newcombe, Robert G.},
	urldate = {2017-06-27},
	date = {1998},
	file = {newcombe_1998_two-sided_confidence_intervals_for_the_single_proportion.pdf:/home/nathan/Dropbox/njames/zotero_sync/newcombe_1998_two-sided_confidence_intervals_for_the_single_proportion.pdf:application/pdf}
}

@article{mandel_estimating_2013,
	title = {Estimating Time to Disease Progression Comparing Transition Models and Survival Methods-An Analysis of Multiple Sclerosis Data: An Analysis of Multiple Sclerosis Data},
	volume = {69},
	issn = {0006341X},
	url = {http://doi.wiley.com/10.1111/biom.12002},
	doi = {10.1111/biom.12002},
	shorttitle = {Estimating Time to Disease Progression Comparing Transition Models and Survival Methods-An Analysis of Multiple Sclerosis Data},
	pages = {225--234},
	number = {1},
	journaltitle = {Biometrics},
	author = {Mandel, Micha and Mercier, Francois and Eckert, Benjamin and Chin, Peter and Betensky, Rebecca A.},
	urldate = {2017-06-27},
	date = {2013-03},
	langid = {english},
	file = {mandel_et_al_2013_estimating_time_to_disease_progression_comparing_transition_models_and_survival.pdf:/home/nathan/Dropbox/njames/zotero_sync/mandel_et_al_2013_estimating_time_to_disease_progression_comparing_transition_models_and_survival.pdf:application/pdf}
}

@article{lafaye_de_micheaux_understanding_2009,
	title = {Understanding Convergence Concepts: A Visual-Minded and Graphical Simulation-Based Approach},
	volume = {63},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1198/tas.2009.0032},
	doi = {10.1198/tas.2009.0032},
	shorttitle = {Understanding Convergence Concepts},
	pages = {173--178},
	number = {2},
	journaltitle = {The American Statistician},
	author = {Lafaye de Micheaux, Pierre and Liquet, Benoit},
	urldate = {2017-06-27},
	date = {2009-05},
	langid = {english},
	file = {lafaye_de_micheaux_liquet_2009_understanding_convergence_concepts.pdf:/home/nathan/Dropbox/njames/zotero_sync/lafaye_de_micheaux_liquet_2009_understanding_convergence_concepts.pdf:application/pdf}
}

@article{cooper_factor_1983,
	title = {Factor Analysis: An Overview},
	volume = {37},
	issn = {00031305},
	url = {http://www.jstor.org/stable/2685875?origin=crossref},
	doi = {10.2307/2685875},
	shorttitle = {Factor Analysis},
	pages = {141},
	number = {2},
	journaltitle = {The American Statistician},
	author = {Cooper, John C. B.},
	urldate = {2017-06-27},
	date = {1983-05},
	file = {cooper_1983_factor_analysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/cooper_1983_factor_analysis.pdf:application/pdf}
}

@article{parker_criteria_1998,
	title = {Criteria for authorship for statisticians in medical papers},
	volume = {17},
	url = {http://hal.case.edu/~robrien/Parker89Criteria%20for%20authorship%20for%20statisticians%20in%20medical%20papers.pdf},
	pages = {2289--2299},
	number = {20},
	journaltitle = {Statistics in medicine},
	author = {Parker, Robert A. and Berman, Nancy G.},
	urldate = {2017-06-27},
	date = {1998},
	file = {parker_berman_1998_criteria_for_authorship_for_statisticians_in_medical_papers.pdf:/home/nathan/Dropbox/njames/zotero_sync/parker_berman_1998_criteria_for_authorship_for_statisticians_in_medical_papers.pdf:application/pdf}
}

@article{fernandez-delgado_we_2014,
	title = {Do we need hundreds of classifiers to solve real world classification problems},
	volume = {15},
	url = {http://www.jmlr.org/papers/volume15/delgado14a/source/delgado14a.pdf},
	pages = {3133--3181},
	number = {1},
	journaltitle = {J. Mach. Learn. Res},
	author = {Fernández-Delgado, Manuel and Cernadas, Eva and Barro, Senén and Amorim, Dinani},
	urldate = {2017-06-27},
	date = {2014},
	file = {fernández-delgado_et_al_2014_do_we_need_hundreds_of_classifiers_to_solve_real_world_classification_problems.pdf:/home/nathan/Dropbox/njames/zotero_sync/fernández-delgado_et_al_2014_do_we_need_hundreds_of_classifiers_to_solve_real_world_classification_problems.pdf:application/pdf}
}

@article{cedilnik_distribution_2004,
	title = {The distribution of the ratio of jointly normal variables},
	volume = {1},
	url = {http://search.proquest.com/openview/9ae38f7adffb06cf84c80fb911a4dac5/1?pq-origsite=gscholar&cbl=1396367},
	pages = {99},
	number = {1},
	journaltitle = {Metodoloski zvezki},
	author = {Cedilnik, Anton and Kosmelj, Katarina and Blejec, Andrej},
	urldate = {2017-06-27},
	date = {2004},
	file = {cedilnik_et_al_2004_the_distribution_of_the_ratio_of_jointly_normal_variables.pdf:/home/nathan/Dropbox/njames/zotero_sync/cedilnik_et_al_2004_the_distribution_of_the_ratio_of_jointly_normal_variables.pdf:application/pdf}
}

@article{dupont_power_1988,
	title = {Power Calculations for Matched Case-Control Studies},
	volume = {44},
	issn = {0006341X},
	url = {http://www.jstor.org/stable/2531743?origin=crossref},
	doi = {10.2307/2531743},
	pages = {1157},
	number = {4},
	journaltitle = {Biometrics},
	author = {Dupont, William D.},
	urldate = {2017-06-27},
	date = {1988-12},
	file = {dupont_1988_power_calculations_for_matched_case-control_studies.pdf:/home/nathan/Dropbox/njames/zotero_sync/dupont_1988_power_calculations_for_matched_case-control_studies.pdf:application/pdf}
}

@article{ehrenberg_writing_1982,
	title = {Writing Technical Papers or Reports},
	volume = {36},
	issn = {00031305},
	url = {http://www.jstor.org/stable/2683079?origin=crossref},
	doi = {10.2307/2683079},
	pages = {326},
	number = {4},
	journaltitle = {The American Statistician},
	author = {Ehrenberg, A. S. C.},
	urldate = {2017-06-27},
	date = {1982-11},
	file = {ehrenberg_1982_writing_technical_papers_or_reports.pdf:/home/nathan/Dropbox/njames/zotero_sync/ehrenberg_1982_writing_technical_papers_or_reports.pdf:application/pdf}
}

@article{casella_explaining_1992,
	title = {Explaining the Gibbs Sampler},
	volume = {46},
	issn = {00031305},
	url = {http://www.jstor.org/stable/2685208?origin=crossref},
	doi = {10.2307/2685208},
	pages = {167},
	number = {3},
	journaltitle = {The American Statistician},
	author = {Casella, George and George, Edward I.},
	urldate = {2017-06-27},
	date = {1992-08},
	file = {casella_george_1992_explaining_the_gibbs_sampler.pdf:/home/nathan/Dropbox/njames/zotero_sync/casella_george_1992_explaining_the_gibbs_sampler.pdf:application/pdf}
}

@article{gelman_why_2011,
	title = {Why Tables Are Really Much Better Than Graphs},
	volume = {20},
	issn = {1061-8600, 1537-2715},
	url = {http://www.tandfonline.com/doi/abs/10.1198/jcgs.2011.09166},
	doi = {10.1198/jcgs.2011.09166},
	pages = {3--7},
	number = {1},
	journaltitle = {Journal of Computational and Graphical Statistics},
	author = {Gelman, Andrew},
	urldate = {2017-06-27},
	date = {2011-01},
	langid = {english},
	file = {gelman_2011_why_tables_are_really_much_better_than_graphs.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_2011_why_tables_are_really_much_better_than_graphs.pdf:application/pdf}
}

@article{goodman_toward_1999,
	title = {Toward evidence-based medical statistics. 1: The P value fallacy},
	volume = {130},
	url = {http://annals.org/aim/article/712762/toward-evidence-based-medical-statistics-1-p-value-fallacy},
	shorttitle = {Toward evidence-based medical statistics. 1},
	pages = {995--1004},
	number = {12},
	journaltitle = {Annals of internal medicine},
	author = {Goodman, Steven N.},
	urldate = {2017-06-27},
	date = {1999},
	file = {goodman_1999_toward_evidence-based_medical_statistics.pdf:/home/nathan/Dropbox/njames/zotero_sync/goodman_1999_toward_evidence-based_medical_statistics.pdf:application/pdf}
}

@article{goodman_use_1994,
	title = {The use of predicted confidence intervals when planning experiments and the misuse of power when interpreting results},
	volume = {121},
	url = {http://annals.org/aim/article/707593/use-predicted-confidence-intervals-when-planning-experiments-misuse-power-when},
	pages = {200--206},
	number = {3},
	journaltitle = {Annals of internal medicine},
	author = {Goodman, Steven N. and Berlin, Jesse A.},
	urldate = {2017-06-27},
	date = {1994},
	file = {goodman_berlin_1994_the_use_of_predicted_confidence_intervals_when_planning_experiments_and_the.pdf:/home/nathan/Dropbox/njames/zotero_sync/goodman_berlin_1994_the_use_of_predicted_confidence_intervals_when_planning_experiments_and_the.pdf:application/pdf}
}

@article{greenland_confounding_1999,
	title = {Confounding and collapsibility in causal inference},
	url = {http://www.jstor.org/stable/2676645},
	pages = {29--46},
	journaltitle = {Statistical science},
	author = {Greenland, Sander and Robins, James M. and Pearl, Judea},
	urldate = {2017-06-27},
	date = {1999},
	file = {greenland_et_al_1999_confounding_and_collapsibility_in_causal_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/greenland_et_al_1999_confounding_and_collapsibility_in_causal_inference.pdf:application/pdf}
}

@article{hoenig_abuse_2001,
	title = {The abuse of power: the pervasive fallacy of power calculations for data analysis},
	volume = {55},
	url = {http://amstat.tandfonline.com/doi/abs/10.1198/000313001300339897},
	shorttitle = {The abuse of power},
	pages = {19--24},
	number = {1},
	journaltitle = {The American Statistician},
	author = {Hoenig, John M. and Heisey, Dennis M.},
	urldate = {2017-06-27},
	date = {2001},
	file = {hoenig_heisey_2001_the_abuse_of_power.pdf:/home/nathan/Dropbox/njames/zotero_sync/hoenig_heisey_2001_the_abuse_of_power.pdf:application/pdf}
}

@article{lenth_practical_2001,
	title = {Some practical guidelines for effective sample size determination},
	volume = {55},
	url = {http://www.tandfonline.com/doi/abs/10.1198/000313001317098149},
	pages = {187--193},
	number = {3},
	journaltitle = {The American Statistician},
	author = {Lenth, Russell V.},
	urldate = {2017-06-27},
	date = {2001},
	file = {lenth_2001_some_practical_guidelines_for_effective_sample_size_determination.pdf:/home/nathan/Dropbox/njames/zotero_sync/lenth_2001_some_practical_guidelines_for_effective_sample_size_determination.pdf:application/pdf}
}

@article{levine_post_2001,
	title = {Post hoc power analysis: an idea whose time has passed?},
	volume = {21},
	url = {http://onlinelibrary.wiley.com/doi/10.1592/phco.21.5.405.34503/full},
	shorttitle = {Post hoc power analysis},
	pages = {405--409},
	number = {4},
	journaltitle = {Pharmacotherapy: The Journal of Human Pharmacology and Drug Therapy},
	author = {Levine, Marc and Ensom, Mary {HH}},
	urldate = {2017-06-27},
	date = {2001},
	file = {levine_ensom_2001_post_hoc_power_analysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/levine_ensom_2001_post_hoc_power_analysis.pdf:application/pdf}
}

@article{miller_maximally_1982,
	title = {Maximally Selected Chi Square Statistics},
	volume = {38},
	issn = {0006341X},
	url = {http://www.jstor.org/stable/2529881?origin=crossref},
	doi = {10.2307/2529881},
	pages = {1011},
	number = {4},
	journaltitle = {Biometrics},
	author = {Miller, Rupert and Siegmund, David},
	urldate = {2017-06-27},
	date = {1982-12},
	file = {miller_siegmund_1982_maximally_selected_chi_square_statistics.pdf:/home/nathan/Dropbox/njames/zotero_sync/miller_siegmund_1982_maximally_selected_chi_square_statistics.pdf:application/pdf}
}

@article{wittes_sample_2002,
	title = {Sample size calculations for randomized controlled trials},
	volume = {24},
	url = {https://pdfs.semanticscholar.org/7f7a/5347088aa8e01f4258d15a672ec9cb8d80df.pdf},
	pages = {39--53},
	number = {1},
	journaltitle = {Epidemiologic Reviews},
	author = {Wittes, Janet},
	urldate = {2017-06-27},
	date = {2002},
	file = {wittes_2002_sample_size_calculations_for_randomized_controlled_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/wittes_2002_sample_size_calculations_for_randomized_controlled_trials.pdf:application/pdf}
}

@article{schell_identifying_2010,
	title = {Identifying Key Statistical Papers From 1985 to 2002 Using Citation Data for Applied Biostatisticians},
	volume = {64},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1198/tast.2010.08250},
	doi = {10.1198/tast.2010.08250},
	pages = {310--317},
	number = {4},
	journaltitle = {The American Statistician},
	author = {Schell, Michael J.},
	urldate = {2017-06-27},
	date = {2010-11},
	langid = {english},
	file = {schell_2010_identifying_key_statistical_papers_from_1985_to_2002_using_citation_data_for.pdf:/home/nathan/Dropbox/njames/zotero_sync/schell_2010_identifying_key_statistical_papers_from_1985_to_2002_using_citation_data_for.pdf:application/pdf}
}

@article{senn_mastering_2016,
	title = {Mastering variation: variance components and personalised medicine},
	volume = {35},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.6739},
	doi = {10.1002/sim.6739},
	shorttitle = {Mastering variation},
	pages = {966--977},
	number = {7},
	journaltitle = {Statistics in Medicine},
	author = {Senn, Stephen},
	urldate = {2017-06-27},
	date = {2016-03-30},
	langid = {english},
	file = {senn_2016_mastering_variation.pdf:/home/nathan/Dropbox/njames/zotero_sync/senn_2016_mastering_variation.pdf:application/pdf}
}

@article{moineddin_simulation_2007,
	title = {A simulation study of sample size for multilevel logistic regression models},
	volume = {7},
	issn = {1471-2288},
	url = {http://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-7-34},
	doi = {10.1186/1471-2288-7-34},
	number = {1},
	journaltitle = {{BMC} Medical Research Methodology},
	author = {Moineddin, Rahim and Matheson, Flora I and Glazier, Richard H},
	urldate = {2017-06-27},
	date = {2007-12},
	langid = {english},
	file = {moineddin_et_al_2007_a_simulation_study_of_sample_size_for_multilevel_logistic_regression_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/moineddin_et_al_2007_a_simulation_study_of_sample_size_for_multilevel_logistic_regression_models.pdf:application/pdf}
}

@article{stanley_could_2010,
	title = {Could It Be Better to Discard 90\% of the Data? A Statistical Paradox},
	volume = {64},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1198/tast.2009.08205},
	doi = {10.1198/tast.2009.08205},
	shorttitle = {Could It Be Better to Discard 90\% of the Data?},
	pages = {70--77},
	number = {1},
	journaltitle = {The American Statistician},
	author = {Stanley, T. D. and Jarrell, Stephen B. and Doucouliagos, Hristos},
	urldate = {2017-06-27},
	date = {2010-02},
	langid = {english},
	file = {stanley_et_al_2010_could_it_be_better_to_discard_90%_of_the_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/stanley_et_al_2010_could_it_be_better_to_discard_90%_of_the_data.pdf:application/pdf}
}

@article{hanley_statistical_2003,
	title = {Statistical Analysis of Correlated Data Using Generalized Estimating Equations: An Orientation},
	volume = {157},
	issn = {00029262},
	url = {https://academic.oup.com/aje/article-lookup/doi/10.1093/aje/kwf215},
	doi = {10.1093/aje/kwf215},
	shorttitle = {Statistical Analysis of Correlated Data Using Generalized Estimating Equations},
	pages = {364--375},
	number = {4},
	journaltitle = {American Journal of Epidemiology},
	author = {Hanley, J. A.},
	urldate = {2017-06-27},
	date = {2003-02-15},
	file = {hanley_2003_statistical_analysis_of_correlated_data_using_generalized_estimating_equations.pdf:/home/nathan/Dropbox/njames/zotero_sync/hanley_2003_statistical_analysis_of_correlated_data_using_generalized_estimating_equations.pdf:application/pdf}
}

@article{strobl_introduction_2009,
	title = {An introduction to recursive partitioning: Rationale, application, and characteristics of classification and regression trees, bagging, and random forests.},
	volume = {14},
	issn = {1939-1463, 1082-989X},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0016973},
	doi = {10.1037/a0016973},
	shorttitle = {An introduction to recursive partitioning},
	pages = {323--348},
	number = {4},
	journaltitle = {Psychological Methods},
	author = {Strobl, Carolin and Malley, James and Tutz, Gerhard},
	urldate = {2017-06-27},
	date = {2009},
	langid = {english},
	file = {strobl_et_al_2009_an_introduction_to_recursive_partitioning.pdf:/home/nathan/Dropbox/njames/zotero_sync/strobl_et_al_2009_an_introduction_to_recursive_partitioning.pdf:application/pdf}
}

@article{chib_understanding_1995,
	title = {Understanding the Metropolis-Hastings Algorithm},
	volume = {49},
	issn = {00031305},
	url = {http://www.jstor.org/stable/2684568?origin=crossref},
	doi = {10.2307/2684568},
	pages = {327},
	number = {4},
	journaltitle = {The American Statistician},
	author = {Chib, Siddhartha and Greenberg, Edward},
	urldate = {2017-06-27},
	date = {1995-11},
	file = {chib_greenberg_1995_understanding_the_metropolis-hastings_algorithm.pdf:/home/nathan/Dropbox/njames/zotero_sync/chib_greenberg_1995_understanding_the_metropolis-hastings_algorithm.pdf:application/pdf}
}

@article{vanderweele_mediation_2014,
	title = {Mediation Analysis with Multiple Mediators},
	volume = {2},
	issn = {2194-9263, 2161-962X},
	url = {https://www.degruyter.com/view/j/em.2013.2.issue-1/em-2012-0010/em-2012-0010.xml},
	doi = {10.1515/em-2012-0010},
	number = {1},
	journaltitle = {Epidemiologic Methods},
	author = {{VanderWeele}, Tyler and Vansteelandt, Stijn},
	urldate = {2017-06-27},
	date = {2014-01-03},
	file = {vanderweele_vansteelandt_2014_mediation_analysis_with_multiple_mediators.pdf:/home/nathan/Dropbox/njames/zotero_sync/vanderweele_vansteelandt_2014_mediation_analysis_with_multiple_mediators.pdf:application/pdf}
}

@article{ver_hoef_moving_2010,
	title = {A Moving Average Approach for Spatial Statistical Models of Stream Networks},
	volume = {105},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1198/jasa.2009.ap08248},
	doi = {10.1198/jasa.2009.ap08248},
	pages = {6--18},
	number = {489},
	journaltitle = {Journal of the American Statistical Association},
	author = {Ver Hoef, Jay M. and Peterson, Erin E.},
	urldate = {2017-06-27},
	date = {2010-03},
	langid = {english},
	file = {ver_hoef_peterson_2010_a_moving_average_approach_for_spatial_statistical_models_of_stream_networks.pdf:/home/nathan/Dropbox/njames/zotero_sync/ver_hoef_peterson_2010_a_moving_average_approach_for_spatial_statistical_models_of_stream_networks.pdf:application/pdf}
}

@article{white_multiple_2011,
	title = {Multiple imputation using chained equations: Issues and guidance for practice},
	volume = {30},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.4067},
	doi = {10.1002/sim.4067},
	shorttitle = {Multiple imputation using chained equations},
	pages = {377--399},
	number = {4},
	journaltitle = {Statistics in Medicine},
	author = {White, Ian R. and Royston, Patrick and Wood, Angela M.},
	urldate = {2017-06-27},
	date = {2011-02-20},
	langid = {english},
	file = {white_et_al_2011_multiple_imputation_using_chained_equations.pdf:/home/nathan/Dropbox/njames/zotero_sync/white_et_al_2011_multiple_imputation_using_chained_equations.pdf:application/pdf}
}

@article{epstein_why_2008,
	title = {Why model?},
	volume = {11},
	url = {http://jasss.soc.surrey.ac.uk/11/4/12.html},
	pages = {12},
	number = {4},
	journaltitle = {Journal of Artificial Societies and Social Simulation},
	author = {Epstein, Joshua M.},
	urldate = {2017-06-27},
	date = {2008},
	file = {epstein_2008_why_model.pdf:/home/nathan/Dropbox/njames/zotero_sync/epstein_2008_why_model.pdf:application/pdf}
}

@article{ryan_most-cited_2005,
	title = {The most-cited statistical papers},
	volume = {32},
	url = {http://www.tandfonline.com/doi/abs/10.1080/02664760500079373},
	pages = {461--474},
	number = {5},
	journaltitle = {Journal of Applied Statistics},
	author = {Ryan, Thomas P. and Woodall, William H.},
	urldate = {2017-06-27},
	date = {2005},
	file = {ryan_woodall_2005_the_most-cited_statistical_papers.pdf:/home/nathan/Dropbox/njames/zotero_sync/ryan_woodall_2005_the_most-cited_statistical_papers.pdf:application/pdf}
}

@article{goldstein_multilevel_2002,
	title = {Multilevel modelling of medical data},
	volume = {21},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/sim.1264/full},
	pages = {3291--3315},
	number = {21},
	journaltitle = {Statistics in medicine},
	author = {Goldstein, Harvey and Browne, William and Rasbash, Jon},
	urldate = {2017-06-27},
	date = {2002},
	file = {goldstein_et_al_2002_multilevel_modelling_of_medical_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/goldstein_et_al_2002_multilevel_modelling_of_medical_data.pdf:application/pdf}
}

@article{murphy_how_1997,
	title = {How to Read the Statistical Methods Literature: A Guide for Students},
	volume = {51},
	issn = {00031305},
	url = {http://www.jstor.org/stable/2685409?origin=crossref},
	doi = {10.2307/2685409},
	shorttitle = {How to Read the Statistical Methods Literature},
	pages = {155},
	number = {2},
	journaltitle = {The American Statistician},
	author = {Murphy, James R.},
	urldate = {2017-06-27},
	date = {1997-05},
	file = {murphy_1997_how_to_read_the_statistical_methods_literature.pdf:/home/nathan/Dropbox/njames/zotero_sync/murphy_1997_how_to_read_the_statistical_methods_literature.pdf:application/pdf}
}

@article{normand_what_2010,
	title = {What is evidence?},
	volume = {29},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.3933},
	doi = {10.1002/sim.3933},
	pages = {1985--1988},
	number = {19},
	journaltitle = {Statistics in Medicine},
	author = {Normand, Sharon-Lise T. and {McNeil}, Barbara J.},
	urldate = {2017-06-27},
	date = {2010-07-29},
	langid = {english},
	file = {normand_mcneil_2010_what_is_evidence.pdf:/home/nathan/Dropbox/njames/zotero_sync/normand_mcneil_2010_what_is_evidence.pdf:application/pdf}
}

@article{pearl_causal_2009,
	title = {Causal inference in statistics: An overview},
	volume = {3},
	issn = {1935-7516},
	url = {http://projecteuclid.org/euclid.ssu/1255440554},
	doi = {10.1214/09-SS057},
	shorttitle = {Causal inference in statistics},
	pages = {96--146},
	number = {0},
	journaltitle = {Statistics Surveys},
	author = {Pearl, Judea},
	urldate = {2017-06-27},
	date = {2009},
	langid = {english},
	file = {pearl_2009_causal_inference_in_statistics.pdf:/home/nathan/Dropbox/njames/zotero_sync/pearl_2009_causal_inference_in_statistics.pdf:application/pdf}
}

@article{peng_method_2008,
	title = {A method for visualizing multivariate time series data},
	url = {http://biostats.bepress.com/jhubiostat/paper166/},
	author = {Peng, Roger D.},
	urldate = {2017-06-27},
	date = {2008},
	file = {peng_2008_a_method_for_visualizing_multivariate_time_series_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/peng_2008_a_method_for_visualizing_multivariate_time_series_data.pdf:application/pdf}
}

@article{dagostino_tutorial_1998,
	title = {Tutorial in biostatistics: propensity score methods for bias reduction in the comparison of a treatment to a non-randomized control group},
	volume = {17},
	url = {http://bacbuc.hd.free.fr/WebDAV/data/DOM/StatMeths/DAgostino-SM1998.pdf},
	shorttitle = {Tutorial in biostatistics},
	pages = {2265--2281},
	number = {19},
	journaltitle = {Stat Med},
	author = {d’Agostino, Ralph B.},
	urldate = {2017-06-27},
	date = {1998},
	file = {d’agostino_1998_tutorial_in_biostatistics.pdf:/home/nathan/Dropbox/njames/zotero_sync/d’agostino_1998_tutorial_in_biostatistics.pdf:application/pdf}
}

@article{cheng_real_2009,
	title = {Real longitudinal data analysis for real people: Building a good enough mixed model},
	issn = {02776715, 10970258},
	url = {http://doi.wiley.com/10.1002/sim.3775},
	doi = {10.1002/sim.3775},
	shorttitle = {Real longitudinal data analysis for real people},
	pages = {n/a--n/a},
	journaltitle = {Statistics in Medicine},
	author = {Cheng, Jing and Edwards, Lloyd J. and Maldonado-Molina, Mildred M. and Komro, Kelli A. and Muller, Keith E.},
	urldate = {2017-06-27},
	date = {2009},
	langid = {english},
	file = {cheng_et_al_2009_real_longitudinal_data_analysis_for_real_people.pdf:/home/nathan/Dropbox/njames/zotero_sync/cheng_et_al_2009_real_longitudinal_data_analysis_for_real_people.pdf:application/pdf}
}

@article{zeileis_escaping_2009,
	title = {Escaping {RGBland}: Selecting colors for statistical graphics},
	volume = {53},
	issn = {01679473},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0167947308005549},
	doi = {10.1016/j.csda.2008.11.033},
	shorttitle = {Escaping {RGBland}},
	pages = {3259--3270},
	number = {9},
	journaltitle = {Computational Statistics \& Data Analysis},
	author = {Zeileis, Achim and Hornik, Kurt and Murrell, Paul},
	urldate = {2017-06-27},
	date = {2009-07},
	langid = {english},
	file = {zeileis_et_al_2009_escaping_rgbland.pdf:/home/nathan/Dropbox/njames/zotero_sync/zeileis_et_al_2009_escaping_rgbland.pdf:application/pdf}
}

@article{barres_how_2013,
	title = {How to Pick a Graduate Advisor},
	volume = {80},
	issn = {08966273},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627313009070},
	doi = {10.1016/j.neuron.2013.10.005},
	pages = {275--279},
	number = {2},
	journaltitle = {Neuron},
	author = {Barres, Ben A.},
	urldate = {2017-06-27},
	date = {2013-10},
	langid = {english},
	file = {barres_2013_how_to_pick_a_graduate_advisor.pdf:/home/nathan/Dropbox/njames/zotero_sync/barres_2013_how_to_pick_a_graduate_advisor.pdf:application/pdf}
}

@article{butz_influence_2010,
	title = {Influence of Caregiver and Provider Communication on Symptom Days and Medication Use for Inner-City Children With Asthma},
	volume = {47},
	issn = {0277-0903, 1532-4303},
	url = {http://www.tandfonline.com/doi/full/10.3109/02770901003692793},
	doi = {10.3109/02770901003692793},
	pages = {478--485},
	number = {4},
	journaltitle = {Journal of Asthma},
	author = {Butz, Arlene and Kub, Joan and Donithan, Michele and James, Nathan T. and Thompson, Richard E. and Bellin, Melissa and Tsoukleris, Mona and Bollinger, Mary Elizabeth},
	urldate = {2017-06-27},
	date = {2010-05},
	langid = {english},
	file = {butz_et_al_2010_influence_of_caregiver_and_provider_communication_on_symptom_days_and.pdf:/home/nathan/Dropbox/njames/zotero_sync/butz_et_al_2010_influence_of_caregiver_and_provider_communication_on_symptom_days_and.pdf:application/pdf}
}

@article{hall_effect_2011,
	title = {Effect of Eliminating Priority Points for {HLA}-B Matching on Racial Disparities in Kidney Transplant Rates},
	volume = {58},
	issn = {02726386},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0272638611010213},
	doi = {10.1053/j.ajkd.2011.05.023},
	pages = {813--816},
	number = {5},
	journaltitle = {American Journal of Kidney Diseases},
	author = {Hall, Erin C. and Massie, Allan B. and James, Nathan T. and Wang, Jacqueline M. Garonzik and Montgomery, Robert A. and Berger, Jonathan C. and Segev, Dorry L.},
	urldate = {2017-06-27},
	date = {2011-11},
	langid = {english},
	file = {hall_et_al_2011_effect_of_eliminating_priority_points_for_hla-b_matching_on_racial_disparities.pdf:/home/nathan/Dropbox/njames/zotero_sync/hall_et_al_2011_effect_of_eliminating_priority_points_for_hla-b_matching_on_racial_disparities.pdf:application/pdf}
}

@article{garonzik-wang_aggressive_2012,
	title = {The Aggressive Phenotype: Center-Level Patterns in the Utilization of Suboptimal Kidneys: The Aggressive Center Phenotype},
	volume = {12},
	issn = {16006135},
	url = {http://doi.wiley.com/10.1111/j.1600-6143.2011.03789.x},
	doi = {10.1111/j.1600-6143.2011.03789.x},
	shorttitle = {The Aggressive Phenotype},
	pages = {400--408},
	number = {2},
	journaltitle = {American Journal of Transplantation},
	author = {Garonzik-Wang, J. M. and James, N. T. and Weatherspoon, K. C. and Deshpande, N. A. and Berger, J. A. and Hall, E. C. and Montgomery, R. A. and Segev, D. L.},
	urldate = {2017-06-27},
	date = {2012-02},
	langid = {english},
	file = {garonzik-wang_et_al_2012_the_aggressive_phenotype.pdf:/home/nathan/Dropbox/njames/zotero_sync/garonzik-wang_et_al_2012_the_aggressive_phenotype.pdf:application/pdf}
}

@article{deshpande_pregnancy_2011,
	title = {Pregnancy Outcomes in Kidney Transplant Recipients: A Systematic Review and Meta-Analysis: Pregnancy Outcomes in Kidney Transplant Recipients},
	volume = {11},
	issn = {16006135},
	url = {http://doi.wiley.com/10.1111/j.1600-6143.2011.03656.x},
	doi = {10.1111/j.1600-6143.2011.03656.x},
	shorttitle = {Pregnancy Outcomes in Kidney Transplant Recipients},
	pages = {2388--2404},
	number = {11},
	journaltitle = {American Journal of Transplantation},
	author = {Deshpande, N. A. and James, N. T. and Kucirka, L. M. and Boyarsky, B. J. and Garonzik-Wang, J. M. and Montgomery, R. A. and Segev, D. L.},
	urldate = {2017-06-27},
	date = {2011-11},
	langid = {english},
	file = {deshpande_et_al_2011_pregnancy_outcomes_in_kidney_transplant_recipients.pdf:/home/nathan/Dropbox/njames/zotero_sync/deshpande_et_al_2011_pregnancy_outcomes_in_kidney_transplant_recipients.pdf:application/pdf}
}

@article{van_arendonk_late_2011,
	title = {Late Graft Loss among Pediatric Recipients of {DCD} Kidneys},
	volume = {6},
	issn = {1555-9041, 1555-905X},
	url = {http://cjasn.asnjournals.org/cgi/doi/10.2215/CJN.03760411},
	doi = {10.2215/CJN.03760411},
	pages = {2705--2711},
	number = {11},
	journaltitle = {Clinical Journal of the American Society of Nephrology},
	author = {Van Arendonk, K. J. and James, N. T. and Locke, J. E. and Montgomery, R. A. and Colombani, P. M. and Segev, D. L.},
	urldate = {2017-06-27},
	date = {2011-11-01},
	langid = {english},
	file = {van_arendonk_et_al_2011_late_graft_loss_among_pediatric_recipients_of_dcd_kidneys.pdf:/home/nathan/Dropbox/njames/zotero_sync/van_arendonk_et_al_2011_late_graft_loss_among_pediatric_recipients_of_dcd_kidneys.pdf:application/pdf}
}

@article{berger_living_2011,
	title = {Living Kidney Donors Ages 70 and Older: Recipient and Donor Outcomes},
	volume = {6},
	issn = {1555-9041, 1555-905X},
	url = {http://cjasn.asnjournals.org/cgi/doi/10.2215/CJN.04160511},
	doi = {10.2215/CJN.04160511},
	shorttitle = {Living Kidney Donors Ages 70 and Older},
	pages = {2887--2893},
	number = {12},
	journaltitle = {Clinical Journal of the American Society of Nephrology},
	author = {Berger, J. C. and Muzaale, A. D. and James, N. and Hoque, M. and Wang, J. M. G. and Montgomery, R. A. and Massie, A. B. and Hall, E. C. and Segev, D. L.},
	urldate = {2017-06-27},
	date = {2011-12-01},
	langid = {english},
	file = {berger_et_al_2011_living_kidney_donors_ages_70_and_older.pdf:/home/nathan/Dropbox/njames/zotero_sync/berger_et_al_2011_living_kidney_donors_ages_70_and_older.pdf:application/pdf}
}

@article{kucirka_association_2011,
	title = {Association of race and age with survival among patients undergoing dialysis},
	volume = {306},
	url = {http://jamanetwork.com/journals/jama/fullarticle/1104204},
	pages = {620--626},
	number = {6},
	journaltitle = {Jama},
	author = {Kucirka, Lauren M. and Grams, Morgan E. and Lessler, Justin and Hall, Erin Carlyle and James, Nathan and Massie, Allan B. and Montgomery, Robert A. and Segev, Dorry L.},
	urldate = {2017-06-27},
	date = {2011},
	file = {kucirka_et_al_2011_association_of_race_and_age_with_survival_among_patients_undergoing_dialysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/kucirka_et_al_2011_association_of_race_and_age_with_survival_among_patients_undergoing_dialysis.pdf:application/pdf}
}

@article{hall_center-level_2012,
	title = {Center-Level Factors and Racial Disparities in Living Donor Kidney Transplantation},
	volume = {59},
	issn = {02726386},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0272638612001084},
	doi = {10.1053/j.ajkd.2011.12.021},
	pages = {849--857},
	number = {6},
	journaltitle = {American Journal of Kidney Diseases},
	author = {Hall, Erin C. and James, Nathan T. and Garonzik Wang, Jacqueline M. and Berger, Jonathan C. and Montgomery, Robert A. and Dagher, Nabil N. and Desai, Niraj M. and Segev, Dorry L.},
	urldate = {2017-06-27},
	date = {2012-06},
	langid = {english},
	file = {hall_et_al_2012_center-level_factors_and_racial_disparities_in_living_donor_kidney.pdf:/home/nathan/Dropbox/njames/zotero_sync/hall_et_al_2012_center-level_factors_and_racial_disparities_in_living_donor_kidney.pdf:application/pdf}
}

@article{deshpande_pregnancy_2012,
	title = {Pregnancy outcomes of liver transplant recipients: A systematic review and meta-analysis},
	volume = {18},
	issn = {15276465},
	url = {http://doi.wiley.com/10.1002/lt.23416},
	doi = {10.1002/lt.23416},
	shorttitle = {Pregnancy outcomes of liver transplant recipients},
	pages = {621--629},
	number = {6},
	journaltitle = {Liver Transplantation},
	author = {Deshpande, Neha A. and James, Nathan T. and Kucirka, Lauren M. and Boyarsky, Brian J. and Garonzik-Wang, Jacqueline M. and Cameron, Andrew M. and Singer, Andrew L. and Dagher, Nabil N. and Segev, Dorry L.},
	urldate = {2017-06-27},
	date = {2012-06},
	langid = {english},
	file = {deshpande_et_al_2012_pregnancy_outcomes_of_liver_transplant_recipients.pdf:/home/nathan/Dropbox/njames/zotero_sync/deshpande_et_al_2012_pregnancy_outcomes_of_liver_transplant_recipients.pdf:application/pdf}
}

@article{montgomery_outcomes_2012,
	title = {Outcomes of {ABO}-Incompatible Kidney Transplantation in the United States:},
	issn = {0041-1337},
	url = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00007890-900000000-99090},
	doi = {10.1097/TP.0b013e318245b2af},
	shorttitle = {Outcomes of {ABO}-Incompatible Kidney Transplantation in the United States},
	pages = {1},
	journaltitle = {Transplantation},
	author = {Montgomery, John R. and Berger, Jonathan C. and Warren, Daniel S. and James, Nathan T. and Montgomery, Robert A. and Segev, Dorry L.},
	urldate = {2017-06-27},
	date = {2012-01},
	langid = {english},
	file = {montgomery_et_al_2012_outcomes_of_abo-incompatible_kidney_transplantation_in_the_united_states.pdf:/home/nathan/Dropbox/njames/zotero_sync/montgomery_et_al_2012_outcomes_of_abo-incompatible_kidney_transplantation_in_the_united_states.pdf:application/pdf}
}

@article{garonzik-wang_live_2012,
	title = {Live Donor Champion: Finding Live Kidney Donors by Separating the Advocate From the Patient},
	volume = {93},
	issn = {0041-1337},
	url = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00007890-201206150-00013},
	doi = {10.1097/TP.0b013e31824e75a5},
	shorttitle = {Live Donor Champion},
	pages = {1147--1150},
	number = {11},
	journaltitle = {Transplantation Journal},
	author = {Garonzik-Wang, Jacqueline M. and Berger, Jonathan C. and Ros, Reside Lorie and Kucirka, Lauren M. and Deshpande, Neha A. and Boyarsky, Brian J. and Montgomery, Robert A. and Hall, Erin C. and James, Nathan T. and Segev, Dorry L.},
	urldate = {2017-06-27},
	date = {2012-06},
	langid = {english},
	file = {garonzik-wang_et_al_2012_live_donor_champion.pdf:/home/nathan/Dropbox/njames/zotero_sync/garonzik-wang_et_al_2012_live_donor_champion.pdf:application/pdf}
}

@article{garonzik-wang_aggressive_2013,
	title = {The Aggressive Phenotype Revisited: Utilization of Higher-Risk Liver Allografts: Liver Aggressive-Center Phenotype},
	volume = {13},
	issn = {16006135},
	url = {http://doi.wiley.com/10.1111/ajt.12151},
	doi = {10.1111/ajt.12151},
	shorttitle = {The Aggressive Phenotype Revisited},
	pages = {936--942},
	number = {4},
	journaltitle = {American Journal of Transplantation},
	author = {Garonzik-Wang, J. M. and James, N. T. and Arendonk, K. J. Van and Gupta, N. and Orandi, B. J. and Hall, E. C. and Massie, A. B. and Montgomery, R. A. and Dagher, N. N. and Singer, A. L. and Cameron, A. M. and Segev, D. L.},
	urldate = {2017-06-27},
	date = {2013-04},
	langid = {english},
	file = {garonzik-wang_et_al_2013_the_aggressive_phenotype_revisited.pdf:/home/nathan/Dropbox/njames/zotero_sync/garonzik-wang_et_al_2013_the_aggressive_phenotype_revisited.pdf:application/pdf}
}

@article{van_arendonk_age_2013,
	title = {Age at Graft Loss after Pediatric Kidney Transplantation: Exploring the High-Risk Age Window},
	volume = {8},
	issn = {1555-9041, 1555-905X},
	url = {http://cjasn.asnjournals.org/cgi/doi/10.2215/CJN.10311012},
	doi = {10.2215/CJN.10311012},
	shorttitle = {Age at Graft Loss after Pediatric Kidney Transplantation},
	pages = {1019--1026},
	number = {6},
	journaltitle = {Clinical Journal of the American Society of Nephrology},
	author = {Van Arendonk, K. J. and James, N. T. and Boyarsky, B. J. and Garonzik-Wang, J. M. and Orandi, B. J. and Magee, J. C. and Smith, J. M. and Colombani, P. M. and Segev, D. L.},
	urldate = {2017-06-27},
	date = {2013-06-07},
	langid = {english},
	file = {van_arendonk_et_al_2013_age_at_graft_loss_after_pediatric_kidney_transplantation.pdf:/home/nathan/Dropbox/njames/zotero_sync/van_arendonk_et_al_2013_age_at_graft_loss_after_pediatric_kidney_transplantation.pdf:application/pdf}
}

@article{curriero_exploring_2013,
	title = {Exploring walking path quality as a factor for urban elementary school children’s active transport to school},
	volume = {10},
	url = {http://journals.humankinetics.com/doi/abs/10.1123/jpah.10.3.323},
	pages = {323--334},
	number = {3},
	journaltitle = {Journal of Physical Activity and Health},
	author = {Curriero, Frank C. and James, Nathan T. and Shields, Timothy M. and Roman, Caterina Gouvis and Furr-Holden, C. Debra M. and Cooley-Strickland, Michele and Pollack, Keshia M.},
	urldate = {2017-06-27},
	date = {2013},
	file = {curriero_et_al_2013_exploring_walking_path_quality_as_a_factor_for_urban_elementary_school.pdf:/home/nathan/Dropbox/njames/zotero_sync/curriero_et_al_2013_exploring_walking_path_quality_as_a_factor_for_urban_elementary_school.pdf:application/pdf}
}

@article{eloyan_analytic_2014,
	title = {Analytic Programming with {fMRI} Data: A Quick-Start Guide for Statisticians Using R},
	volume = {9},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0089470},
	doi = {10.1371/journal.pone.0089470},
	shorttitle = {Analytic Programming with {fMRI} Data},
	pages = {e89470},
	number = {2},
	journaltitle = {{PLoS} {ONE}},
	author = {Eloyan, Ani and Li, Shanshan and Muschelli, John and Pekar, Jim J. and Mostofsky, Stewart H. and Caffo, Brian S.},
	editor = {Yacoub, Essa},
	urldate = {2017-06-28},
	date = {2014-02-28},
	langid = {english},
	file = {eloyan_et_al_2014_analytic_programming_with_fmri_data.PDF:/home/nathan/Dropbox/njames/zotero_sync/eloyan_et_al_2014_analytic_programming_with_fmri_data.PDF:application/pdf}
}

@article{lee_neuroimaging_2005,
	title = {Neuroimaging in traumatic brain imaging},
	volume = {2},
	url = {http://www.sciencedirect.com/science/article/pii/S1545534306700839},
	pages = {372--383},
	number = {2},
	journaltitle = {{NeuroRx}},
	author = {Lee, Bruce and Newberg, Andrew},
	urldate = {2017-06-28},
	date = {2005},
	file = {lee_newberg_2005_neuroimaging_in_traumatic_brain_imaging.pdf:/home/nathan/Dropbox/njames/zotero_sync/lee_newberg_2005_neuroimaging_in_traumatic_brain_imaging.pdf:application/pdf}
}

@article{lee_cuda_2012,
	title = {{CUDA} optimization strategies for compute- and memory-bound neuroimaging algorithms},
	volume = {106},
	issn = {01692607},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0169260710002750},
	doi = {10.1016/j.cmpb.2010.10.013},
	pages = {175--187},
	number = {3},
	journaltitle = {Computer Methods and Programs in Biomedicine},
	author = {Lee, Daren and Dinov, Ivo and Dong, Bin and Gutman, Boris and Yanovsky, Igor and Toga, Arthur W.},
	urldate = {2017-06-28},
	date = {2012-06},
	langid = {english},
	file = {lee_et_al_2012_cuda_optimization_strategies_for_compute-_and_memory-bound_neuroimaging.pdf:/home/nathan/Dropbox/njames/zotero_sync/lee_et_al_2012_cuda_optimization_strategies_for_compute-_and_memory-bound_neuroimaging.pdf:application/pdf}
}

@article{pan_new_2011,
	title = {New and emerging imaging techniques for mapping brain circuitry},
	volume = {67},
	issn = {01650173},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0165017311000178},
	doi = {10.1016/j.brainresrev.2011.02.004},
	pages = {226--251},
	number = {1},
	journaltitle = {Brain Research Reviews},
	author = {Pan, Hong and Epstein, Jane and Silbersweig, David A. and Stern, Emily},
	urldate = {2017-06-28},
	date = {2011-06},
	langid = {english},
	file = {pan_et_al_2011_new_and_emerging_imaging_techniques_for_mapping_brain_circuitry.pdf:/home/nathan/Dropbox/njames/zotero_sync/pan_et_al_2011_new_and_emerging_imaging_techniques_for_mapping_brain_circuitry.pdf:application/pdf}
}

@article{bowman_statistical_2007,
	title = {Statistical Approaches to Functional Neuroimaging Data},
	volume = {17},
	issn = {10525149},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1052514907000913},
	doi = {10.1016/j.nic.2007.09.002},
	pages = {441--458},
	number = {4},
	journaltitle = {Neuroimaging Clinics of North America},
	author = {Bowman, F. {DuBois} and Guo, Ying and Derado, Gordana},
	date = {2007-11},
	langid = {english},
	file = {bowman_et_al_2007_statistical_approaches_to_functional_neuroimaging_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/bowman_et_al_2007_statistical_approaches_to_functional_neuroimaging_data.pdf:application/pdf}
}

@article{webb-vargas_big_2017,
	title = {Big Data and Neuroimaging},
	issn = {1867-1764, 1867-1772},
	url = {http://link.springer.com/10.1007/s12561-017-9195-y},
	doi = {10.1007/s12561-017-9195-y},
	journaltitle = {Statistics in Biosciences},
	author = {Webb-Vargas, Yenny and Chen, Shaojie and Fisher, Aaron and Mejia, Amanda and Xu, Yuting and Crainiceanu, Ciprian and Caffo, Brian and Lindquist, Martin A.},
	urldate = {2017-06-29},
	date = {2017-05-22},
	langid = {english},
	file = {webb-vargas_et_al_2017_big_data_and_neuroimaging.pdf:/home/nathan/Dropbox/njames/zotero_sync/webb-vargas_et_al_2017_big_data_and_neuroimaging.pdf:application/pdf}
}

@article{kang_spatio-spectral_2012,
	title = {Spatio-Spectral Mixed-Effects Model for Functional Magnetic Resonance Imaging Data},
	volume = {107},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2012.664503},
	doi = {10.1080/01621459.2012.664503},
	pages = {568--577},
	number = {498},
	journaltitle = {Journal of the American Statistical Association},
	author = {Kang, Hakmook and Ombao, Hernando and Linkletter, Crystal and Long, Nicole and Badre, David},
	urldate = {2017-06-29},
	date = {2012-06},
	langid = {english},
	file = {kang_et_al_2012_spatio-spectral_mixed-effects_model_for_functional_magnetic_resonance_imaging.pdf:/home/nathan/Dropbox/njames/zotero_sync/kang_et_al_2012_spatio-spectral_mixed-effects_model_for_functional_magnetic_resonance_imaging.pdf:application/pdf}
}

@article{chen_parallel_2017,
	title = {Parallel group independent component analysis for massive {fMRI} data sets},
	volume = {12},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0173496},
	doi = {10.1371/journal.pone.0173496},
	pages = {e0173496},
	number = {3},
	journaltitle = {{PLOS} {ONE}},
	author = {Chen, Shaojie and Huang, Lei and Qiu, Huitong and Nebel, Mary Beth and Mostofsky, Stewart H. and Pekar, James J. and Lindquist, Martin A. and Eloyan, Ani and Caffo, Brian S.},
	editor = {Hayasaka, Satoru},
	urldate = {2017-06-29},
	date = {2017-03-09},
	langid = {english},
	file = {chen_et_al_2017_parallel_group_independent_component_analysis_for_massive_fmri_data_sets.pdf:/home/nathan/Dropbox/njames/zotero_sync/chen_et_al_2017_parallel_group_independent_component_analysis_for_massive_fmri_data_sets.pdf:application/pdf}
}

@article{fisher_fast_2014,
	title = {Fast, Exact Bootstrap Principal Component Analysis for p{\textgreater}1 million},
	url = {http://arxiv.org/abs/1405.0922},
	abstract = {Many have suggested a bootstrap procedure for estimating the sampling variability of principal component analysis ({PCA}) results. However, when the number of measurements per subject (\$p\$) is much larger than the number of subjects (\$n\$), the challenge of calculating and storing the leading principal components from each bootstrap sample can be computationally infeasible. To address this, we outline methods for fast, exact calculation of bootstrap principal components, eigenvalues, and scores. Our methods leverage the fact that all bootstrap samples occupy the same \$n\$-dimensional subspace as the original sample. As a result, all bootstrap principal components are limited to the same \$n\$-dimensional subspace and can be efficiently represented by their low dimensional coordinates in that subspace. Several uncertainty metrics can be computed solely based on the bootstrap distribution of these low dimensional coordinates, without calculating or storing the \$p\$-dimensional bootstrap components. Fast bootstrap {PCA} is applied to a dataset of sleep electroencephalogram ({EEG}) recordings (\$p=900\$, \$n=392\$), and to a dataset of brain magnetic resonance images ({MRIs}) (\$p{\textbackslash}approx\$ 3 million, \$n=352\$). For the brain {MRI} dataset, our method allows for standard errors for the first 3 principal components based on 1000 bootstrap samples to be calculated on a standard laptop in 47 minutes, as opposed to approximately 4 days with standard methods.},
	journaltitle = {{arXiv}:1405.0922 [stat]},
	author = {Fisher, Aaron and Caffo, Brian and Schwartz, Brian and Zipunnikov, Vadim},
	date = {2014-05-05},
	eprinttype = {arxiv},
	eprint = {1405.0922},
	keywords = {Statistics - Methodology, Statistics - Applications, Statistics - Computation},
	file = {arXiv.org Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/WUZQ7HD9/1405.html:text/html;fisher_et_al_2014_fast,_exact_bootstrap_principal_component_analysis_for_p1_million.pdf:/home/nathan/Dropbox/njames/zotero_sync/fisher_et_al_2014_fast,_exact_bootstrap_principal_component_analysis_for_p1_million.pdf:application/pdf}
}

@article{zhu_fusing_2014,
	title = {Fusing {DTI} and {fMRI} data: A survey of methods and applications},
	volume = {102},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811913010070},
	doi = {10.1016/j.neuroimage.2013.09.071},
	shorttitle = {Fusing {DTI} and {fMRI} data},
	pages = {184--191},
	journaltitle = {{NeuroImage}},
	author = {Zhu, Dajiang and Zhang, Tuo and Jiang, Xi and Hu, Xintao and Chen, Hanbo and Yang, Ning and Lv, Jinglei and Han, Junwei and Guo, Lei and Liu, Tianming},
	urldate = {2017-06-29},
	date = {2014-11},
	langid = {english},
	file = {zhu_et_al_2014_fusing_dti_and_fmri_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/zhu_et_al_2014_fusing_dti_and_fmri_data.pdf:application/pdf}
}

@article{uludag_general_2014,
	title = {General overview on the merits of multimodal neuroimaging data fusion},
	volume = {102},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811914003838},
	doi = {10.1016/j.neuroimage.2014.05.018},
	pages = {3--10},
	journaltitle = {{NeuroImage}},
	author = {Uludağ, Kâmil and Roebroeck, Alard},
	urldate = {2017-06-29},
	date = {2014-11},
	langid = {english},
	file = {uludağ_roebroeck_2014_general_overview_on_the_merits_of_multimodal_neuroimaging_data_fusion.pdf:/home/nathan/Dropbox/njames/zotero_sync/uludağ_roebroeck_2014_general_overview_on_the_merits_of_multimodal_neuroimaging_data_fusion.pdf:application/pdf}
}

@article{bowman_spatiotemporal_2007,
	title = {Spatiotemporal Models for Region of Interest Analyses of Functional Neuroimaging Data},
	volume = {102},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1198/016214506000001347},
	doi = {10.1198/016214506000001347},
	pages = {442--453},
	number = {478},
	journaltitle = {Journal of the American Statistical Association},
	author = {Bowman, F. Dubois},
	urldate = {2017-06-29},
	date = {2007-06},
	langid = {english},
	file = {bowman_2007_spatiotemporal_models_for_region_of_interest_analyses_of_functional.pdf:/home/nathan/Dropbox/njames/zotero_sync/bowman_2007_spatiotemporal_models_for_region_of_interest_analyses_of_functional.pdf:application/pdf}
}

@article{bullmore_brain_2011,
	title = {Brain Graphs: Graphical Models of the Human Brain Connectome},
	volume = {7},
	issn = {1548-5943, 1548-5951},
	url = {http://www.annualreviews.org/doi/10.1146/annurev-clinpsy-040510-143934},
	doi = {10.1146/annurev-clinpsy-040510-143934},
	shorttitle = {Brain Graphs},
	pages = {113--140},
	number = {1},
	journaltitle = {Annual Review of Clinical Psychology},
	author = {Bullmore, Edward T. and Bassett, Danielle S.},
	urldate = {2017-06-29},
	date = {2011-04-27},
	langid = {english},
	file = {bullmore_bassett_2011_brain_graphs.pdf:/home/nathan/Dropbox/njames/zotero_sync/bullmore_bassett_2011_brain_graphs.pdf:application/pdf}
}

@article{fitzpatrick_network_2017,
	title = {A network flow approach to visualising the roles of covariates in random forests},
	url = {http://arxiv.org/abs/1706.08702},
	abstract = {We propose novel applications of parallel coordinates plots and Sankey diagrams to represent the hierarchies of interacting covariate effects in random forests. Each visualisation summarises the frequencies of all of the paths through all of the trees in a random forest. Visualisations of the roles of covariates in random forests include: ranked bar or dot charts depicting scalar metrics of the contributions of individual covariates to the predictive accuracy of the random forest; line graphs depicting various summaries of the effect of varying a particular covariate on the predictions from the random forest; heatmaps of metrics of the strengths of interactions between all pairs of covariates; and parallel coordinates plots for each response class depicting the distributions of the values of all covariates among the observations most representative of those predicted to belong that class. Together these visualisations facilitate substantial insights into the roles of covariates in a random forest but do not communicate the frequencies of the hierarchies of covariates effects across the random forest or the orders in which covariates occur in these hierarchies. Our visualisations address these gaps. We demonstrate our visualisations using a random forest fitted to publicly available data and provide a software implementation in the form of an R package.},
	journaltitle = {{arXiv}:1706.08702 [stat]},
	author = {Fitzpatrick, Benjamin R. and Mengersen, Kerrie},
	date = {2017-06-27},
	eprinttype = {arxiv},
	eprint = {1706.08702},
	keywords = {Statistics - Other Statistics},
	file = {arXiv.org Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/R62XWN4W/1706.html:text/html;fitzpatrick_mengersen_2017_a_network_flow_approach_to_visualising_the_roles_of_covariates_in_random_forests.pdf:/home/nathan/Dropbox/njames/zotero_sync/fitzpatrick_mengersen_2017_a_network_flow_approach_to_visualising_the_roles_of_covariates_in_random_forests.pdf:application/pdf}
}

@article{snapinn_remaining_nodate,
	title = {Some remaining challenges regarding multiple endpoints in clinical trials},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/sim.7390/abstract},
	doi = {10.1002/sim.7390},
	abstract = {Despite recent advance in methods for handling multiple endpoints in clinical trials, some challenges remain. This paper discusses some of these challenges, including confusion surrounding the terminology used to describe the multiple endpoints, the justification for simultaneously testing for non-inferiority and superiority in a non-inferiority trial, lack of agreement on the situations under which multiple objectives do or do not lead to the need for a multiplicity correction, and choice of the most appropriate multiple comparisons procedure. In addition, this paper will discuss the position of the recent {FDA} draft guidance, Multiple Endpoints in Clinical Trials, on these issues. Copyright © 2017 John Wiley \& Sons, Ltd.},
	pages = {n/a--n/a},
	journaltitle = {Statist. Med.},
	author = {Snapinn, Steven},
	langid = {english},
	keywords = {adjusted P values, non-inferiority, primary endpoint},
	file = {snapinn_some_remaining_challenges_regarding_multiple_endpoints_in_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/snapinn_some_remaining_challenges_regarding_multiple_endpoints_in_clinical_trials.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/FHSG9WJN/abstract\;jsessionid=9883F00282C66AD0B816DBD4F00E7E04.html:text/html}
}

@article{levin-schwartz_quantifying_2017,
	title = {Quantifying the Interaction and Contribution of Multiple Datasets in Fusion: Application to the Detection of Schizophrenia},
	volume = {36},
	issn = {0278-0062},
	doi = {10.1109/TMI.2017.2678483},
	shorttitle = {Quantifying the Interaction and Contribution of Multiple Datasets in Fusion},
	abstract = {The extraction of information from multiple sets of data is a problem inherent to many disciplines. This is possible by either analyzing the data sets jointly as in data fusion or separately and then combining as in data integration. However, selecting the optimal method to combine and analyze multiset data is an ever-present challenge. The primary reason for this is the difficulty in determining the optimal contribution of each data set to an analysis as well as the amount of potentially exploitable complementary information among data sets. In this paper, we propose a novel classification rate-based technique to unambiguously quantify the contribution of each data set to a fusion result as well as facilitate direct comparisons of fusion methods on real data and apply a new method, independent vector analysis ({IVA}), to multiset fusion. This classification rate-based technique is used on functional magnetic resonance imaging data collected from 121 patients with schizophrenia and 150 healthy controls during the performance of three tasks. Through this application, we find that though optimal performance is achieved by exploiting all tasks, each task does not contribute equally to the result and this framework enables effective quantification of the value added by each task. Our results also demonstrate that data fusion methods are more powerful than data integration methods, with the former achieving a classification rate of 73.5 \% and the latter achieving one of 70.9 \%, a difference which we show is significant when all three tasks are analyzed together. Finally, we show that {IVA}, due to its flexibility, has equivalent or superior performance compared with the popular data fusion method, joint independent component analysis.},
	pages = {1385--1395},
	number = {7},
	journaltitle = {{IEEE} Transactions on Medical Imaging},
	author = {Levin-Schwartz, Y. and Calhoun, V. D. and Adalı, T.},
	date = {2017-07},
	keywords = {Biomedical imaging, Data integration, Image sensors, Independent component analysis, Magnetic resonance imaging, Principal component analysis, Sensor fusion, Functional magnetic resonance imaging ({fMRI}), {ICA}, {IVA}, data fusion, schizophrenia},
	file = {IEEE Xplore Abstract Record:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/8BQKAQSK/7872466.html:text/html;levin-schwartz_et_al_2017_quantifying_the_interaction_and_contribution_of_multiple_datasets_in_fusion.pdf:/home/nathan/Dropbox/njames/zotero_sync/levin-schwartz_et_al_2017_quantifying_the_interaction_and_contribution_of_multiple_datasets_in_fusion.pdf:application/pdf}
}

@article{jordan_introduction_2001,
	title = {An introduction to graphical models},
	url = {http://www.seas.upenn.edu/~mkearns/papers/barbados/jordan-tut.pdf},
	journaltitle = {unpublished book},
	author = {Jordan, Michael I. and Bishop, Chris},
	urldate = {2017-07-03},
	date = {2001},
	file = {jordan_bishop_2001_an_introduction_to_graphical_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/jordan_bishop_2001_an_introduction_to_graphical_models.pdf:application/pdf}
}

@article{bullmore_complex_2009,
	title = {Complex brain networks: graph theoretical analysis of structural and functional systems},
	volume = {10},
	issn = {1471-003X, 1471-0048},
	url = {http://www.nature.com/doifinder/10.1038/nrn2575},
	doi = {10.1038/nrn2575},
	shorttitle = {Complex brain networks},
	pages = {186--198},
	number = {3},
	journaltitle = {Nature Reviews Neuroscience},
	author = {Bullmore, Ed and Sporns, Olaf},
	urldate = {2017-07-03},
	date = {2009-03},
	file = {bullmore_sporns_2009_complex_brain_networks.pdf:/home/nathan/Dropbox/njames/zotero_sync/bullmore_sporns_2009_complex_brain_networks.pdf:application/pdf}
}

@article{yang_general_2014,
	title = {A General Framework for Mixed Graphical Models},
	url = {http://arxiv.org/abs/1411.0288},
	abstract = {"Mixed Data" comprising a large number of heterogeneous variables (e.g. count, binary, continuous, skewed continuous, among other data types) are prevalent in varied areas such as genomics and proteomics, imaging genetics, national security, social networking, and Internet advertising. There have been limited efforts at statistically modeling such mixed data jointly, in part because of the lack of computationally amenable multivariate distributions that can capture direct dependencies between such mixed variables of different types. In this paper, we address this by introducing a novel class of Block Directed Markov Random Fields ({BDMRFs}). Using the basic building block of node-conditional univariate exponential families from Yang et al. (2012), we introduce a class of mixed conditional random field distributions, that are then chained according to a block-directed acyclic graph to form our class of Block Directed Markov Random Fields ({BDMRFs}). The Markov independence graph structure underlying a {BDMRF} thus has both directed and undirected edges. We introduce conditions under which these distributions exist and are normalizable, study several instances of our models, and propose scalable penalized conditional likelihood estimators with statistical guarantees for recovering the underlying network structure. Simulations as well as an application to learning mixed genomic networks from next generation sequencing expression data and mutation data demonstrate the versatility of our methods.},
	journaltitle = {{arXiv}:1411.0288 [math, stat]},
	author = {Yang, Eunho and Ravikumar, Pradeep and Allen, Genevera I. and Baker, Yulia and Wan, Ying-Wooi and Liu, Zhandong},
	date = {2014-11-02},
	eprinttype = {arxiv},
	eprint = {1411.0288},
	keywords = {Mathematics - Statistics Theory, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/KRAVX2J6/1411.html:text/html;yang_et_al_2014_a_general_framework_for_mixed_graphical_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/yang_et_al_2014_a_general_framework_for_mixed_graphical_models.pdf:application/pdf}
}

@article{choe_comparing_nodate,
	title = {Comparing test-retest reliability of dynamic functional connectivity methods},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811917305736},
	doi = {10.1016/j.neuroimage.2017.07.005},
	abstract = {Due to the dynamic, condition-dependent nature of brain activity, interest in estimating rapid functional connectivity ({FC}) changes that occur during resting-state functional magnetic resonance imaging (rs-{fMRI}) has recently soared. However, studying dynamic {FC} is methodologically challenging, due to the low signal-to-noise ratio of the blood oxygen level dependent ({BOLD}) signal in {fMRI} and the massive number of data points generated during the analysis. Thus, it is important to establish methods and summary measures that maximize reliability and the utility of dynamic {FC} to provide insight into brain function. In this study, we investigated the reliability of dynamic {FC} summary measures derived using three commonly used estimation methods - sliding window ({SW}), tapered sliding window ({TSW}), and dynamic conditional correlations ({DCC}) methods. We applied each of these techniques to two publicly available rs-{fMRI} test-retest data sets - the Multi-Modal {MRI} Reproducibility Resource (Kirby Data) and the Human Connectome Project ({HCP} Data). The reliability of two categories of dynamic {FC} summary measures were assessed, specifically basic summary statistics of the dynamic correlations and summary measures derived from recurring whole-brain patterns of {FC} (“brain states”). The results provide evidence that dynamic correlations are reliably detected in both test-retest data sets, and the {DCC} method outperforms {SW} methods in terms of the reliability of summary statistics. However, across all estimation methods, reliability of the brain state-derived measures was low. Notably, the results also show that the {DCC}-derived dynamic correlation variances are significantly more reliable than those derived using the non-parametric estimation methods. This is important, as the fluctuations of dynamic {FC} (i.e., its variance) has a strong potential to provide summary measures that can be used to find meaningful individual differences in dynamic {FC}. We therefore conclude that utilizing the variance of the dynamic connectivity is an important component in any dynamic {FC}-derived summary measure.},
	journaltitle = {{NeuroImage}},
	author = {Choe, Ann S. and Nebel, Mary Beth and Barber, Anita D. and Cohen, Jessica R. and Xu, Yuting and Pekar, James J. and Caffo, Brian and Lindquist, Martin A.},
	file = {choe_et_al_comparing_test-retest_reliability_of_dynamic_functional_connectivity_methods.pdf:/home/nathan/Dropbox/njames/zotero_sync/choe_et_al_comparing_test-retest_reliability_of_dynamic_functional_connectivity_methods.pdf:application/pdf;ScienceDirect Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/V3XAPNRE/S1053811917305736.html:text/html}
}

@online{aickin_invalid_2010,
	title = {Invalid Permutation Tests},
	url = {https://www.hindawi.com/journals/ijmms/2010/769780/},
	abstract = {Permutation tests are often presented in a rather casual manner, in both introductory and advanced statistics textbooks. The appeal of the cleverness of the procedure seems to replace the need for a rigorous argument that it produces valid hypothesis tests. The consequence of this educational failing has been a widespread belief in a “permutation principle”, which is supposed invariably to give tests that are valid by construction, under an absolute minimum of statistical assumptions. Several lines of argument are presented here to show that the permutation principle itself can be invalid, concentrating on the Fisher-Pitman permutation test for two means. A simple counterfactual example illustrates the general problem, and a slightly more elaborate counterfactual argument is used to explain why the main mathematical proof of the validity of permutation tests is mistaken. Two modifications of the permutation test are suggested to be valid in a very modest simulation. In instances where simulation software is readily available, investigating the validity of a specific permutation test can be done easily, requiring only a minimum understanding of statistical technicalities.},
	titleaddon = {International Journal of Mathematics and Mathematical Sciences},
	type = {Research article},
	author = {Aickin, Mikel},
	urldate = {2017-07-07},
	date = {2010},
	langid = {english},
	doi = {10.1155/2010/769780},
	file = {aickin_2010_invalid_permutation_tests.pdf:/home/nathan/Dropbox/njames/zotero_sync/aickin_2010_invalid_permutation_tests.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/HJJJB3CA/769780.html:application/xhtml+xml}
}

@article{wasserstein_asas_2016,
	title = {The {ASA}'s Statement on p-Values: Context, Process, and Purpose},
	volume = {70},
	issn = {0003-1305, 1537-2731},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2016.1154108},
	doi = {10.1080/00031305.2016.1154108},
	shorttitle = {The {ASA}'s Statement on \textit{p} -Values},
	pages = {129--133},
	number = {2},
	journaltitle = {The American Statistician},
	author = {Wasserstein, Ronald L. and Lazar, Nicole A.},
	urldate = {2017-07-09},
	date = {2016-04-02},
	langid = {english},
	file = {wasserstein_lazar_2016_the_asa's_statement_on_p-values.pdf:/home/nathan/Dropbox/njames/zotero_sync/wasserstein_lazar_2016_the_asa's_statement_on_p-values.pdf:application/pdf}
}

@article{fisher_randomized_2014,
	title = {A randomized trial in a massive online open course shows people don’t know what a statistically significant relationship looks like, but they can learn},
	volume = {2},
	issn = {2167-8359},
	url = {https://peerj.com/articles/589},
	doi = {10.7717/peerj.589},
	abstract = {Scatterplots are the most common way for statisticians, scientists, and the public to visually detect relationships between measured variables. At the same time, and despite widely publicized controversy, P-values remain the most commonly used measure to statistically justify relationships identified between variables. Here we measure the ability to detect statistically significant relationships from scatterplots in a randomized trial of 2,039 students in a statistics massive open online course ({MOOC}). Each subject was shown a random set of scatterplots and asked to visually determine if the underlying relationships were statistically significant at the P {\textless} 0.05 level. Subjects correctly classified only 47.4\% (95\% {CI} [45.1\%–49.7\%]) of statistically significant relationships, and 74.6\% (95\% {CI} [72.5\%–76.6\%]) of non-significant relationships. Adding visual aids such as a best fit line or scatterplot smooth increased the probability a relationship was called significant, regardless of whether the relationship was actually significant. Classification of statistically significant relationships improved on repeat attempts of the survey, although classification of non-significant relationships did not. Our results suggest: (1) that evidence-based data analysis can be used to identify weaknesses in theoretical procedures in the hands of average users, (2) data analysts can be trained to improve detection of statistically significant results with practice, but (3) data analysts have incorrect intuition about what statistically significant relationships look like, particularly for small effects. We have built a web tool for people to compare scatterplots with their corresponding p-values which is available here: http://glimmer.rstudio.com/afisher/{EDA}/.},
	pages = {e589},
	journaltitle = {{PeerJ}},
	author = {Fisher, Aaron and Anderson, G. Brooke and Peng, Roger and Leek, Jeff},
	urldate = {2017-08-09},
	date = {2014-10-16},
	langid = {english},
	file = {fisher_et_al_2014_a_randomized_trial_in_a_massive_online_open_course_shows_people_don’t_know_what.pdf:/home/nathan/Dropbox/njames/zotero_sync/fisher_et_al_2014_a_randomized_trial_in_a_massive_online_open_course_shows_people_don’t_know_what.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/A7KRGIR3/589.html:text/html}
}

@article{fudge_fifty_2014,
	title = {Fifty years of J. R. Platt's strong inference},
	volume = {217},
	rights = {© 2014. Published by The Company of Biologists Ltd},
	issn = {0022-0949, 1477-9145},
	url = {http://jeb.biologists.org/content/217/8/1202},
	doi = {10.1242/jeb.104976},
	abstract = {![Figure][1]{\textless}/img{\textgreater}

Douglas Fudge discusses J. R. Platt's classic paper ‘Strong inference: certain systematic methods of scientific thinking may produce much more rapid progress than others’, published in Science in 1964.



In 1964, John R. Platt (1918–1992) published a paper in Science with},
	pages = {1202--1204},
	number = {8},
	journaltitle = {Journal of Experimental Biology},
	author = {Fudge, Douglas S.},
	urldate = {2017-08-09},
	date = {2014-04-15},
	langid = {english},
	pmid = {24744419},
	file = {fudge_2014_fifty_years_of_j.pdf:/home/nathan/Dropbox/njames/zotero_sync/fudge_2014_fifty_years_of_j.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/5EXJG765/1202.html:text/html}
}

@online{noauthor_learning_nodate,
	title = {Learning Sleep Stages from Radio Signals: A Conditional Adversarial Architecture},
	url = {http://sleep.csail.mit.edu/},
	urldate = {2017-08-09}
}

@online{belluz_7_2016,
	title = {The 7 biggest problems facing science, according to 270 scientists},
	url = {https://www.vox.com/2016/7/14/12016710/science-challeges-research-funding-peer-review-process},
	abstract = {These are dark times for science so we asked hundreds of researchers how to fix it.},
	titleaddon = {Vox},
	author = {Belluz, Julia},
	urldate = {2017-08-09},
	date = {2016-07-14},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/DJGS58IA/science-challeges-research-funding-peer-review-process.html:text/html}
}

@article{smith_how_2017,
	title = {How to map the circuits that define us},
	volume = {548},
	url = {http://www.nature.com/news/how-to-map-the-circuits-that-define-us-1.22437},
	doi = {10.1038/548150a},
	abstract = {Neuroscientists want to understand how tangles of neurons produce complex behaviours, but even the simplest networks defy understanding.},
	pages = {150},
	number = {7666},
	journaltitle = {Nature News},
	author = {Smith, Kerri},
	urldate = {2017-08-15},
	date = {2017-08-10},
	file = {smith_2017_how_to_map_the_circuits_that_define_us.pdf:/home/nathan/Dropbox/njames/zotero_sync/smith_2017_how_to_map_the_circuits_that_define_us.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/6TETE23I/how-to-map-the-circuits-that-define-us-1.html:text/html}
}

@article{greenland_statistical_2016,
	title = {Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations},
	volume = {31},
	issn = {0393-2990, 1573-7284},
	url = {http://link.springer.com/10.1007/s10654-016-0149-3},
	doi = {10.1007/s10654-016-0149-3},
	shorttitle = {Statistical tests, P values, confidence intervals, and power},
	pages = {337--350},
	number = {4},
	journaltitle = {European Journal of Epidemiology},
	author = {Greenland, Sander and Senn, Stephen J. and Rothman, Kenneth J. and Carlin, John B. and Poole, Charles and Goodman, Steven N. and Altman, Douglas G.},
	urldate = {2017-08-17},
	date = {2016-04},
	langid = {english},
	file = {greenland_et_al_2016_statistical_tests,_p_values,_confidence_intervals,_and_power.pdf:/home/nathan/Dropbox/njames/zotero_sync/greenland_et_al_2016_statistical_tests,_p_values,_confidence_intervals,_and_power.pdf:application/pdf}
}

@article{senn_bayesian_2003,
	title = {Bayesian, Likelihood, and Frequentist Approaches to Statistics},
	volume = {12},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.708.523&rep=rep1&type=pdf},
	pages = {35--38},
	number = {8},
	journaltitle = {Applied Clinical Trials},
	author = {Senn, Stephen},
	urldate = {2017-08-17},
	date = {2003},
	file = {senn_2003_bayesian,_likelihood,_and_frequentist_approaches_to_statistics.pdf:/home/nathan/Dropbox/njames/zotero_sync/senn_2003_bayesian,_likelihood,_and_frequentist_approaches_to_statistics.pdf:application/pdf}
}

@article{kruschke_bayesian_2017,
	title = {Bayesian data analysis for newcomers},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/10.3758/s13423-017-1272-1},
	doi = {10.3758/s13423-017-1272-1},
	journaltitle = {Psychonomic Bulletin \& Review},
	author = {Kruschke, John K. and Liddell, Torrin M.},
	urldate = {2017-08-24},
	date = {2017-04-12},
	langid = {english},
	file = {kruschke_liddell_2017_bayesian_data_analysis_for_newcomers.pdf:/home/nathan/Dropbox/njames/zotero_sync/kruschke_liddell_2017_bayesian_data_analysis_for_newcomers.pdf:application/pdf}
}

@article{kenett_aspects_2006,
	title = {Aspects of statistical consulting not taught by academia},
	volume = {60},
	issn = {1467-9574},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9574.2006.00327.x/abstract},
	doi = {10.1111/j.1467-9574.2006.00327.x},
	abstract = {Education in statistics is preparing for statistical analysis but not necessarily for statistical consulting. The objective of this paper is to explore the phases that precede and follow statistical analysis. Specifically these include: problem elicitation, data collection and, following statistical data analysis, formulation of findings, and presentation of findings, and recommendations. Some insights derived from a literature review and real-life case studies are provided. Areas for joint research by statisticians and cognitive scientists are outlined.},
	pages = {396--411},
	number = {3},
	journaltitle = {Statistica Neerlandica},
	author = {Kenett, R. and Thyregod, P.},
	date = {2006-08-01},
	langid = {english},
	keywords = {statistical consulting, graphs, problem solving, interpersonal skills},
	file = {kenett_thyregod_2006_aspects_of_statistical_consulting_not_taught_by_academia.pdf:/home/nathan/Dropbox/njames/zotero_sync/kenett_thyregod_2006_aspects_of_statistical_consulting_not_taught_by_academia.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/XV89V5VV/abstract.html:text/html}
}

@article{torkamani_high-definition_2017,
	title = {High-Definition Medicine},
	volume = {170},
	issn = {0092-8674, 1097-4172},
	url = {http://www.cell.com/cell/abstract/S0092-8674(17)30932-7},
	doi = {10.1016/j.cell.2017.08.007},
	pages = {828--843},
	number = {5},
	journaltitle = {Cell},
	author = {Torkamani, Ali and Andersen, Kristian G. and Steinhubl, Steven R. and Topol, Eric J.},
	urldate = {2017-08-26},
	date = {2017-08-24},
	pmid = {28841416},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/HHKE5MPF/S0092-8674(17)30932-7.html:text/html;torkamani_et_al_2017_high-definition_medicine.pdf:/home/nathan/Dropbox/njames/zotero_sync/torkamani_et_al_2017_high-definition_medicine.pdf:application/pdf}
}

@article{shmueli_explain_2010,
	title = {To Explain or to Predict?},
	volume = {25},
	issn = {0883-4237},
	url = {http://projecteuclid.org/euclid.ss/1294167961},
	doi = {10.1214/10-STS330},
	pages = {289--310},
	number = {3},
	journaltitle = {Statistical Science},
	author = {Shmueli, Galit},
	urldate = {2017-08-30},
	date = {2010-08},
	langid = {english},
	file = {shmueli_2010_to_explain_or_to_predict.pdf:/home/nathan/Dropbox/njames/zotero_sync/shmueli_2010_to_explain_or_to_predict.pdf:application/pdf}
}

@article{lin_assessing_1998,
	title = {Assessing the Sensitivity of Regression Results to Unmeasured Confounders in Observational Studies},
	volume = {54},
	url = {http://dlin.web.unc.edu/files/2013/04/LinPsatyKronmal98.pdf},
	pages = {948--963},
	number = {3},
	journaltitle = {Biometrics},
	author = {Lin, D.Y. and Psaty, B.M. and Kronmal, R.A.},
	urldate = {2017-08-30},
	date = {1998-09},
	file = {lin_et_al_1998_assessing_the_sensitivity_of_regression_results_to_unmeasured_confounders_in.pdf:/home/nathan/Dropbox/njames/zotero_sync/lin_et_al_1998_assessing_the_sensitivity_of_regression_results_to_unmeasured_confounders_in.pdf:application/pdf}
}

@article{zhang_sample_2007,
	title = {Sample Mean and Sample Variance: Their Covariance and Their (In)Dependence},
	volume = {61},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1198/000313007X188379},
	doi = {10.1198/000313007X188379},
	shorttitle = {Sample Mean and Sample Variance},
	pages = {159--160},
	number = {2},
	journaltitle = {The American Statistician},
	author = {Zhang, Lingyun},
	urldate = {2017-08-31},
	date = {2007-05},
	langid = {english},
	file = {zhang_2007_sample_mean_and_sample_variance.pdf:/home/nathan/Dropbox/njames/zotero_sync/zhang_2007_sample_mean_and_sample_variance.pdf:application/pdf}
}

@article{bright_cleaning_2017,
	title = {Cleaning up the {fMRI} time series: Mitigating noise with advanced acquisition and correction strategies},
	volume = {154},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811917302793},
	doi = {10.1016/j.neuroimage.2017.03.056},
	series = {Cleaning up the {fMRI} time series: Mitigating noise with advanced acquisition and correction strategies},
	shorttitle = {Cleaning up the {fMRI} time series},
	pages = {1--3},
	journaltitle = {{NeuroImage}},
	author = {Bright, Molly G. and Murphy, Kevin},
	date = {2017-07-01},
	file = {bright_murphy_2017_cleaning_up_the_fmri_time_series.pdf:/home/nathan/Dropbox/njames/zotero_sync/bright_murphy_2017_cleaning_up_the_fmri_time_series.pdf:application/pdf;ScienceDirect Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/WKZRP47A/S1053811917302793.html:text/html}
}

@article{benjamin_redefine_2017,
	title = {Redefine statistical significance},
	url = {https://dukespace.lib.duke.edu/dspace/handle/10161/15438},
	journaltitle = {Nature Human Behaviour},
	author = {Benjamin, Daniel J. and Berger, James O. and Johannesson, Magnus and Nosek, Brian A. and Wagenmakers, Eric-Jan and Berk, Richard and Bollen, Kenneth A. and Brembs, Björn and Brown, Lawrence and Camerer, Colin and {others}},
	urldate = {2017-09-12},
	date = {2017},
	file = {benjamin_et_al_2017_redefine_statistical_significance.pdf:/home/nathan/Dropbox/njames/zotero_sync/benjamin_et_al_2017_redefine_statistical_significance.pdf:application/pdf}
}

@article{poldrack_scanning_2017,
	title = {Scanning the horizon: towards transparent and reproducible neuroimaging research},
	volume = {18},
	issn = {1471-003X, 1471-0048},
	url = {http://www.nature.com/doifinder/10.1038/nrn.2016.167},
	doi = {10.1038/nrn.2016.167},
	shorttitle = {Scanning the horizon},
	pages = {115--126},
	number = {2},
	journaltitle = {Nature Reviews Neuroscience},
	author = {Poldrack, Russell A. and Baker, Chris I. and Durnez, Joke and Gorgolewski, Krzysztof J. and Matthews, Paul M. and Munafò, Marcus R. and Nichols, Thomas E. and Poline, Jean-Baptiste and Vul, Edward and Yarkoni, Tal},
	urldate = {2017-10-18},
	date = {2017-01-05},
	file = {poldrack_et_al_2017_scanning_the_horizon.pdf:/home/nathan/Dropbox/njames/zotero_sync/poldrack_et_al_2017_scanning_the_horizon.pdf:application/pdf}
}

@article{osborne_sample_2004,
	title = {Sample size and subject to item ratio in principal components analysis},
	volume = {9},
	pages = {8},
	number = {11},
	journaltitle = {Practical assessment, research \& evaluation},
	author = {Osborne, Jason W. and Costello, Anna B.},
	date = {2004},
	file = {osborne_costello_2004_sample_size_and_subject_to_item_ratio_in_principal_components_analysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/osborne_costello_2004_sample_size_and_subject_to_item_ratio_in_principal_components_analysis.pdf:application/pdf}
}

@article{mcshane_statistical_2017,
	title = {Statistical Significance and the Dichotomization of Evidence},
	volume = {112},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1289846},
	doi = {10.1080/01621459.2017.1289846},
	pages = {885--895},
	number = {519},
	journaltitle = {Journal of the American Statistical Association},
	author = {{McShane}, Blakeley B. and Gal, David},
	urldate = {2017-11-02},
	date = {2017-07-03},
	langid = {english},
	file = {mcshane_gal_2017_statistical_significance_and_the_dichotomization_of_evidence.pdf:/home/nathan/Dropbox/njames/zotero_sync/mcshane_gal_2017_statistical_significance_and_the_dichotomization_of_evidence.pdf:application/pdf}
}

@article{berry_p-value_2017,
	title = {A p-Value to Die For},
	volume = {112},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1316279},
	doi = {10.1080/01621459.2017.1316279},
	pages = {895--897},
	number = {519},
	journaltitle = {Journal of the American Statistical Association},
	author = {Berry, Donald},
	urldate = {2017-11-02},
	date = {2017-07-03},
	langid = {english},
	file = {berry_2017_a_p-value_to_die_for.pdf:/home/nathan/Dropbox/njames/zotero_sync/berry_2017_a_p-value_to_die_for.pdf:application/pdf}
}

@article{briggs_substitute_2017,
	title = {The Substitute for \textit{p} -Values},
	volume = {112},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1311264},
	doi = {10.1080/01621459.2017.1311264},
	pages = {897--898},
	number = {519},
	journaltitle = {Journal of the American Statistical Association},
	author = {Briggs, William M.},
	urldate = {2017-11-02},
	date = {2017-07-03},
	langid = {english},
	file = {briggs_2017_the_substitute_for_ip-i_-values.pdf:/home/nathan/Dropbox/njames/zotero_sync/briggs_2017_the_substitute_for_ip-i_-values.pdf:application/pdf}
}

@article{gelman_natural_2017,
	title = {Some Natural Solutions to the \textit{p} -Value Communication Problem—and Why They Won’t Work},
	volume = {112},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1311263},
	doi = {10.1080/01621459.2017.1311263},
	pages = {899--901},
	number = {519},
	journaltitle = {Journal of the American Statistical Association},
	author = {Gelman, Andrew and Carlin, John},
	urldate = {2017-11-02},
	date = {2017-07-03},
	langid = {english},
	file = {gelman_carlin_2017_some_natural_solutions_to_the_ip-i_-value_communication_problem—and_why.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_carlin_2017_some_natural_solutions_to_the_ip-i_-value_communication_problem—and_why.pdf:application/pdf}
}

@article{laber_statistical_2017,
	title = {Statistical Significance and the Dichotomization of Evidence: The Relevance of the {ASA} Statement on Statistical Significance and p-Values for Statisticians},
	volume = {112},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1311265},
	doi = {10.1080/01621459.2017.1311265},
	shorttitle = {Statistical Significance and the Dichotomization of Evidence},
	pages = {902--904},
	number = {519},
	journaltitle = {Journal of the American Statistical Association},
	author = {Laber, Eric B. and Shedden, Kerby},
	urldate = {2017-11-02},
	date = {2017-07-03},
	langid = {english},
	file = {laber_shedden_2017_statistical_significance_and_the_dichotomization_of_evidence.pdf:/home/nathan/Dropbox/njames/zotero_sync/laber_shedden_2017_statistical_significance_and_the_dichotomization_of_evidence.pdf:application/pdf}
}

@article{mcshane_rejoinder:_2017,
	title = {Rejoinder: Statistical Significance and the Dichotomization of Evidence},
	volume = {112},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1323642},
	doi = {10.1080/01621459.2017.1323642},
	shorttitle = {Rejoinder},
	pages = {904--908},
	number = {519},
	journaltitle = {Journal of the American Statistical Association},
	author = {{McShane}, Blakeley B. and Gal, David},
	urldate = {2017-11-02},
	date = {2017-07-03},
	langid = {english},
	file = {mcshane_gal_2017_rejoinder.pdf:/home/nathan/Dropbox/njames/zotero_sync/mcshane_gal_2017_rejoinder.pdf:application/pdf}
}

@article{holzhauer_evidence_nodate,
	title = {Evidence synthesis from aggregate recurrent event data for clinical trial design and analysis},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/sim.7549/abstract},
	doi = {10.1002/sim.7549},
	abstract = {Information from historical trials is important for the design, interim monitoring, analysis, and interpretation of clinical trials. Meta-analytic models can be used to synthesize the evidence from historical data, which are often only available in aggregate form. We consider evidence synthesis methods for trials with recurrent event endpoints, which are common in many therapeutic areas. Such endpoints are typically analyzed by negative binomial regression. However, the individual patient data necessary to fit such a model are usually unavailable for historical trials reported in the medical literature. We describe approaches for back-calculating model parameter estimates and their standard errors from available summary statistics with various techniques, including approximate Bayesian computation. We propose to use a quadratic approximation to the log-likelihood for each historical trial based on 2 independent terms for the log mean rate and the log of the dispersion parameter. A Bayesian hierarchical meta-analysis model then provides the posterior predictive distribution for these parameters. Simulations show this approach with back-calculated parameter estimates results in very similar inference as using parameter estimates from individual patient data as an input. We illustrate how to design and analyze a new randomized placebo-controlled exacerbation trial in severe eosinophilic asthma using data from 11 historical trials.},
	pages = {n/a--n/a},
	journaltitle = {Statistics in Medicine},
	author = {Holzhauer, Björn and Wang, Craig and Schmidli, Heinz},
	urldate = {2017-11-20},
	langid = {english},
	keywords = {aggregate data, approximate Bayesian computation, Bayesian hierarchical models, historical data, meta-analysis},
	file = {holzhauer_et_al_evidence_synthesis_from_aggregate_recurrent_event_data_for_clinical_trial.pdf:/home/nathan/Dropbox/njames/zotero_sync/holzhauer_et_al_evidence_synthesis_from_aggregate_recurrent_event_data_for_clinical_trial.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/8VEUARNK/abstract.html:text/html}
}

@article{crane_why_2017,
	title = {Why "Redefining Statistical Significance" Will Not Improve Reproducibility and Could Make the Replication Crisis Worse},
	url = {https://psyarxiv.com/bp2z4/},
	doi = {10.17605/OSF.IO/BP2Z4},
	abstract = {A recent proposal to "redefine statistical significance" (Benjamin, et al. Nature Human Behaviour, 2017) claims that false positive rates "would immediately improve" by factors greater than two and replication rates would double simply by changing the conventional cutoff for 'statistical significance' from P{\textless}0.05 to P{\textless}0.005.  I analyze the veracity of these claims, focusing especially on how Benjamin, et al neglect the effects of P-hacking in assessing the impact of their proposal. My analysis shows that once P-hacking is accounted for the perceived benefits of the lower threshold all but disappear, prompting two main conclusions: (i) The claimed improvements to false positive rate and replication rate in Benjamin, et al (2017) are exaggerated and misleading. (ii) There are plausible scenarios under which the lower cutoff will make the replication crisis worse.},
	journaltitle = {{PsyArXiv}},
	author = {Crane, Harry},
	urldate = {2017-11-20},
	date = {2017-11-19},
	file = {crane_2017_why_redefining_statistical_significance_will_not_improve_reproducibility_and.pdf:/home/nathan/Dropbox/njames/zotero_sync/crane_2017_why_redefining_statistical_significance_will_not_improve_reproducibility_and.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/9QJJ7SF4/bp2z4.html:text/html}
}

@article{albert_teaching_1997,
	title = {Teaching Bayes' Rule: A Data-Oriented Approach},
	volume = {51},
	issn = {00031305},
	url = {http://www.jstor.org/stable/2684896?origin=crossref},
	doi = {10.2307/2684896},
	shorttitle = {Teaching Bayes' Rule},
	pages = {247},
	number = {3},
	journaltitle = {The American Statistician},
	author = {Albert, Jim},
	urldate = {2017-12-30},
	date = {1997-08},
	keywords = {Bayes' Box, Conditional probability, Quantitative literacy, Scatterplot, Simulation, Two-way tables},
	file = {albert_1997_teaching_bayes'_rule.pdf:/home/nathan/Dropbox/njames/zotero_sync/albert_1997_teaching_bayes'_rule.pdf:application/pdf}
}

@article{gelman_philosophy_2013,
	title = {Philosophy and the practice of Bayesian statistics: \textit{Philosophy and the practice of Bayesian statistics}},
	volume = {66},
	issn = {00071102},
	url = {http://doi.wiley.com/10.1111/j.2044-8317.2011.02037.x},
	doi = {10.1111/j.2044-8317.2011.02037.x},
	shorttitle = {Philosophy and the practice of Bayesian statistics},
	pages = {8--38},
	number = {1},
	journaltitle = {British Journal of Mathematical and Statistical Psychology},
	author = {Gelman, Andrew and Shalizi, Cosma Rohilla},
	urldate = {2017-12-30},
	date = {2013-02},
	langid = {english},
	file = {gelman_shalizi_2013_philosophy_and_the_practice_of_bayesian_statistics.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_shalizi_2013_philosophy_and_the_practice_of_bayesian_statistics.pdf:application/pdf}
}

@article{quintana_bayesian_2017,
	title = {Bayesian Analysis: Using Prior Information to Interpret the Results of Clinical Trials},
	volume = {318},
	shorttitle = {Bayesian Analysis},
	pages = {1605--1606},
	number = {16},
	journaltitle = {Jama},
	author = {Quintana, Melanie and Viele, Kert and Lewis, Roger J.},
	date = {2017},
	file = {quintana_et_al_2017_bayesian_analysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/quintana_et_al_2017_bayesian_analysis.pdf:application/pdf}
}

@article{senn_you_2011,
	title = {You may believe you are a Bayesian but you are probably wrong},
	volume = {2},
	number = {42},
	journaltitle = {Rationality, Markets and Morals},
	author = {Senn, Stephen},
	date = {2011},
	file = {senn_2011_you_may_believe_you_are_a_bayesian_but_you_are_probably_wrong.pdf:/home/nathan/Dropbox/njames/zotero_sync/senn_2011_you_may_believe_you_are_a_bayesian_but_you_are_probably_wrong.pdf:application/pdf}
}

@article{berry_teaching_1997,
	title = {Teaching Elementary Bayesian Statistics with Real Applications in Science},
	volume = {51},
	issn = {00031305},
	url = {http://www.jstor.org/stable/2684895?origin=crossref},
	doi = {10.2307/2684895},
	pages = {241},
	number = {3},
	journaltitle = {The American Statistician},
	author = {Berry, Donald A.},
	urldate = {2017-12-30},
	date = {1997-08},
	file = {berry_1997_teaching_elementary_bayesian_statistics_with_real_applications_in_science.pdf:/home/nathan/Dropbox/njames/zotero_sync/berry_1997_teaching_elementary_bayesian_statistics_with_real_applications_in_science.pdf:application/pdf}
}

@article{meredith_bayesian_2017,
	title = {Bayesian Estimation Supersedes the t-Test},
	author = {Meredith, Mike and Kruschke, John},
	date = {2017},
	file = {meredith_kruschke_2017_bayesian_estimation_supersedes_the_t-test.pdf:/home/nathan/Dropbox/njames/zotero_sync/meredith_kruschke_2017_bayesian_estimation_supersedes_the_t-test.pdf:application/pdf}
}

@article{etz_introduction_2017,
	title = {Introduction to Bayesian Inference for Psychology},
	pages = {1--30},
	journaltitle = {Psychonomic Bulletin \& Review},
	author = {Etz, Alexander and Vandekerckhove, Joachim},
	date = {2017},
	file = {etz_vandekerckhove_2017_introduction_to_bayesian_inference_for_psychology.pdf:/home/nathan/Dropbox/njames/zotero_sync/etz_vandekerckhove_2017_introduction_to_bayesian_inference_for_psychology.pdf:application/pdf}
}

@article{lilford_equipoise_1995,
	title = {Equipoise and the ethics of randomization.},
	volume = {88},
	issn = {0141-0768},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1295354/},
	pages = {552--559},
	number = {10},
	journaltitle = {J R Soc Med},
	author = {Lilford, R J and Jackson, J},
	urldate = {2018-01-04},
	date = {1995-10},
	pmid = {8537943},
	pmcid = {PMC1295354},
	file = {lilford_jackson_1995_equipoise_and_the_ethics_of_randomization.pdf:/home/nathan/Dropbox/njames/zotero_sync/lilford_jackson_1995_equipoise_and_the_ethics_of_randomization.pdf:application/pdf}
}

@article{drazen_master_2017,
	title = {Master Protocols to Study Multiple Therapies, Multiple Diseases, or Both},
	volume = {377},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/10.1056/NEJMra1510062},
	doi = {10.1056/NEJMra1510062},
	pages = {62--70},
	number = {1},
	journaltitle = {New England Journal of Medicine},
	author = {Woodcock, Janet and {LaVange}, Lisa M.},
	editor = {Drazen, Jeffrey M. and Harrington, David P. and {McMurray}, John J.V. and Ware, James H. and Woodcock, Janet},
	urldate = {2018-01-04},
	date = {2017-07-06},
	langid = {english},
	file = {woodcock_lavange_2017_master_protocols_to_study_multiple_therapies,_multiple_diseases,_or_both.pdf:/home/nathan/Dropbox/njames/zotero_sync/woodcock_lavange_2017_master_protocols_to_study_multiple_therapies,_multiple_diseases,_or_both.pdf:application/pdf}
}

@article{west_novel_2017,
	title = {Novel Precision Medicine Trial Designs: Umbrellas and Baskets},
	volume = {3},
	issn = {2374-2437},
	url = {http://oncology.jamanetwork.com/article.aspx?doi=10.1001/jamaoncol.2016.5299},
	doi = {10.1001/jamaoncol.2016.5299},
	shorttitle = {Novel Precision Medicine Trial Designs},
	pages = {423},
	number = {3},
	journaltitle = {{JAMA} Oncology},
	author = {West, Howard (Jack)},
	urldate = {2018-01-04},
	date = {2017-03-01},
	langid = {english},
	file = {west_2017_novel_precision_medicine_trial_designs.pdf:/home/nathan/Dropbox/njames/zotero_sync/west_2017_novel_precision_medicine_trial_designs.pdf:application/pdf}
}

@article{rugo_adaptive_2016,
	title = {Adaptive Randomization of Veliparib–Carboplatin Treatment in Breast Cancer},
	volume = {375},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/10.1056/NEJMoa1513749},
	doi = {10.1056/NEJMoa1513749},
	pages = {23--34},
	number = {1},
	journaltitle = {New England Journal of Medicine},
	author = {Rugo, Hope S. and Olopade, Olufunmilayo I. and {DeMichele}, Angela and Yau, Christina and van ’t Veer, Laura J. and Buxton, Meredith B. and Hogarth, Michael and Hylton, Nola M. and Paoloni, Melissa and Perlmutter, Jane and Symmans, W. Fraser and Yee, Douglas and Chien, A. Jo and Wallace, Anne M. and Kaplan, Henry G. and Boughey, Judy C. and Haddad, Tufia C. and Albain, Kathy S. and Liu, Minetta C. and Isaacs, Claudine and Khan, Qamar J. and Lang, Julie E. and Viscusi, Rebecca K. and Pusztai, Lajos and Moulder, Stacy L. and Chui, Stephen Y. and Kemmer, Kathleen A. and Elias, Anthony D. and Edmiston, Kirsten K. and Euhus, David M. and Haley, Barbara B. and Nanda, Rita and Northfelt, Donald W. and Tripathy, Debasish and Wood, William C. and Ewing, Cheryl and Schwab, Richard and Lyandres, Julia and Davis, Sarah E. and Hirst, Gillian L. and Sanil, Ashish and Berry, Donald A. and Esserman, Laura J.},
	urldate = {2018-01-04},
	date = {2016-07-07},
	langid = {english},
	file = {rugo_et_al_2016_adaptive_randomization_of_veliparib–carboplatin_treatment_in_breast_cancer.pdf:/home/nathan/Dropbox/njames/zotero_sync/rugo_et_al_2016_adaptive_randomization_of_veliparib–carboplatin_treatment_in_breast_cancer.pdf:application/pdf}
}

@article{park_adaptive_2016,
	title = {Adaptive Randomization of Neratinib in Early Breast Cancer},
	volume = {375},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/10.1056/NEJMoa1513750},
	doi = {10.1056/NEJMoa1513750},
	pages = {11--22},
	number = {1},
	journaltitle = {New England Journal of Medicine},
	author = {Park, John W. and Liu, Minetta C. and Yee, Douglas and Yau, Christina and van ’t Veer, Laura J. and Symmans, W. Fraser and Paoloni, Melissa and Perlmutter, Jane and Hylton, Nola M. and Hogarth, Michael and {DeMichele}, Angela and Buxton, Meredith B. and Chien, A. Jo and Wallace, Anne M. and Boughey, Judy C. and Haddad, Tufia C. and Chui, Stephen Y. and Kemmer, Kathleen A. and Kaplan, Henry G. and Isaacs, Claudine and Nanda, Rita and Tripathy, Debasish and Albain, Kathy S. and Edmiston, Kirsten K. and Elias, Anthony D. and Northfelt, Donald W. and Pusztai, Lajos and Moulder, Stacy L. and Lang, Julie E. and Viscusi, Rebecca K. and Euhus, David M. and Haley, Barbara B. and Khan, Qamar J. and Wood, William C. and Melisko, Michelle and Schwab, Richard and Helsten, Teresa and Lyandres, Julia and Davis, Sarah E. and Hirst, Gillian L. and Sanil, Ashish and Esserman, Laura J. and Berry, Donald A.},
	urldate = {2018-01-04},
	date = {2016-07-07},
	langid = {english},
	file = {park_et_al_2016_adaptive_randomization_of_neratinib_in_early_breast_cancer.pdf:/home/nathan/Dropbox/njames/zotero_sync/park_et_al_2016_adaptive_randomization_of_neratinib_in_early_breast_cancer.pdf:application/pdf}
}

@article{lewis_platform_2015,
	title = {The Platform Trial An Efficient Strategy for Evaluating Multiple Treatments},
	author = {Lewis, Roger J. and St, W. Carson},
	date = {2015},
	file = {lewis_st_2015_the_platform_trial_an_efficient_strategy_for_evaluating_multiple_treatments.pdf:/home/nathan/Dropbox/njames/zotero_sync/lewis_st_2015_the_platform_trial_an_efficient_strategy_for_evaluating_multiple_treatments.pdf:application/pdf}
}

@article{bhavnani_network_2010,
	title = {Network Analysis of Clinical Trials on Depression: Implications for Comparative Effectiveness Research},
	volume = {2010},
	issn = {1942-597X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041357/},
	shorttitle = {Network Analysis of Clinical Trials on Depression},
	abstract = {A comprehensive understanding of evidence related to treatments for a disease is critical for planning effective clinical care, and for designing future trials. However, it is often difficult to comprehend the available evidence because of the complex combination of interventions across trials, in addition to the limited search and retrieval tools available in databases such as {ClinicalTrials}.gov. Here we demonstrate the use of networks to visualize and quantitatively analyze the co-occurrence of drug interventions across trials on depression in {ClinicalTrials}.gov. The analysis identified general co-occurrence patterns of interventions across all depression trials, and specific co-occurrence patterns related to antidepressants and natural supplements. These results led to insights about the current state of depression trials, and to a graph-theoretic measure to categorize interventions for a disease. We conclude by discussing the opportunities and challenges of generalizing our approach to analyze comparative interventional studies for any disease.},
	pages = {51--55},
	journaltitle = {{AMIA} Annu Symp Proc},
	author = {Bhavnani, Suresh K. and Carini, Simona and Ross, Jessica and Sim, Ida},
	urldate = {2018-01-05},
	date = {2010},
	pmid = {21346939},
	pmcid = {PMC3041357},
	file = {bhavnani_et_al_2010_network_analysis_of_clinical_trials_on_depression.pdf:/home/nathan/Dropbox/njames/zotero_sync/bhavnani_et_al_2010_network_analysis_of_clinical_trials_on_depression.pdf:application/pdf}
}

@article{betancourt_convergence_2017,
	title = {The Convergence of Markov chain Monte Carlo Methods: From the Metropolis method to Hamiltonian Monte Carlo},
	url = {http://arxiv.org/abs/1706.01520},
	shorttitle = {The Convergence of Markov chain Monte Carlo Methods},
	abstract = {From its inception in the 1950s to the modern frontiers of applied statistics, Markov chain Monte Carlo has been one of the most ubiquitous and successful methods in statistical computing. In that time its development has been fueled by increasingly difficult problems and novel techniques from physics. In this article I will review the history of Markov chain Monte Carlo from its inception with the Metropolis method to today's state-of-the-art in Hamiltonian Monte Carlo. Along the way I will focus on the evolving interplay between the statistical and physical perspectives of the method.},
	journaltitle = {{arXiv}:1706.01520 [physics, stat]},
	author = {Betancourt, Michael},
	urldate = {2018-01-06},
	date = {2017-06-05},
	eprinttype = {arxiv},
	eprint = {1706.01520},
	keywords = {Statistics - Methodology, Physics - History and Philosophy of Physics},
	file = {arXiv.org Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/RH4XHRTU/1706.html:text/html;betancourt_2017_the_convergence_of_markov_chain_monte_carlo_methods.pdf:/home/nathan/Dropbox/njames/zotero_sync/betancourt_2017_the_convergence_of_markov_chain_monte_carlo_methods.pdf:application/pdf}
}

@article{altman_what_2000,
	title = {What do we mean by validating a prognostic model?},
	volume = {19},
	issn = {0277-6715, 1097-0258},
	url = {http://doi.wiley.com/10.1002/%28SICI%291097-0258%2820000229%2919%3A4%3C453%3A%3AAID-SIM350%3E3.0.CO%3B2-5},
	doi = {10.1002/(SICI)1097-0258(20000229)19:4<453::AID-SIM350>3.0.CO;2-5},
	pages = {453--473},
	number = {4},
	journaltitle = {Statistics in Medicine},
	author = {Altman, Douglas G. and Royston, Patrick},
	urldate = {2018-01-09},
	date = {2000-02-29},
	langid = {english},
	file = {altman_royston_2000_what_do_we_mean_by_validating_a_prognostic_model.pdf:/home/nathan/Dropbox/njames/zotero_sync/altman_royston_2000_what_do_we_mean_by_validating_a_prognostic_model.pdf:application/pdf}
}

@article{hamada_statistical_2004,
	title = {Statistical Research: Some Advice for Beginners},
	volume = {58},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1198/0003130043295},
	doi = {10.1198/0003130043295},
	shorttitle = {Statistical Research},
	pages = {93--101},
	number = {2},
	journaltitle = {The American Statistician},
	author = {Hamada, Michael and Sitter, Randy},
	urldate = {2018-01-09},
	date = {2004-05},
	langid = {english},
	file = {hamada_sitter_2004_statistical_research.pdf:/home/nathan/Dropbox/njames/zotero_sync/hamada_sitter_2004_statistical_research.pdf:application/pdf}
}

@article{wang_generalized_2017,
	title = {Generalized Scalar-on-Image Regression Models via Total Variation},
	volume = {112},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2016.1194846},
	doi = {10.1080/01621459.2016.1194846},
	pages = {1156--1168},
	number = {519},
	journaltitle = {Journal of the American Statistical Association},
	author = {Wang, Xiao and Zhu, Hongtu and {for the Alzheimer’s Disease Neuroimaging Initiative}},
	urldate = {2018-01-09},
	date = {2017-07-03},
	langid = {english},
	file = {wang_et_al_2017_generalized_scalar-on-image_regression_models_via_total_variation.pdf:/home/nathan/Dropbox/njames/zotero_sync/wang_et_al_2017_generalized_scalar-on-image_regression_models_via_total_variation.pdf:application/pdf}
}

@article{harrington_i-spy_2016,
	title = {I-{SPY} 2 — A Glimpse of the Future of Phase 2 Drug Development?},
	volume = {375},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/10.1056/NEJMp1602256},
	doi = {10.1056/NEJMp1602256},
	pages = {7--9},
	number = {1},
	journaltitle = {New England Journal of Medicine},
	author = {Harrington, David and Parmigiani, Giovanni},
	urldate = {2018-01-09},
	date = {2016-07-07},
	langid = {english},
	file = {harrington_parmigiani_2016_i-spy_2_—_a_glimpse_of_the_future_of_phase_2_drug_development.pdf:/home/nathan/Dropbox/njames/zotero_sync/harrington_parmigiani_2016_i-spy_2_—_a_glimpse_of_the_future_of_phase_2_drug_development.pdf:application/pdf}
}

@incollection{london_clinical_nodate,
	title = {Clinical Equipoise: Foundational Requirement or Fundamental Error?},
	booktitle = {Oxford Handbook of Bioethics},
	author = {London, A J},
	file = {london_clinical_equipoise.pdf:/home/nathan/Dropbox/njames/zotero_sync/london_clinical_equipoise.pdf:application/pdf}
}

@article{freedman_equipoise_1987,
	title = {Equipoise and the Ethics of Clinical Research},
	volume = {317},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/abs/10.1056/NEJM198707163170304},
	doi = {10.1056/NEJM198707163170304},
	pages = {141--145},
	number = {3},
	journaltitle = {New England Journal of Medicine},
	author = {Freedman, Benjamin},
	urldate = {2018-01-09},
	date = {1987-07-16},
	langid = {english},
	file = {freedman_1987_equipoise_and_the_ethics_of_clinical_research.pdf:/home/nathan/Dropbox/njames/zotero_sync/freedman_1987_equipoise_and_the_ethics_of_clinical_research.pdf:application/pdf}
}

@article{grambsch_proportional_1994,
	title = {Proportional hazards tests and diagnostics based on weighted residuals},
	volume = {81},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/81.3.515},
	doi = {10.1093/biomet/81.3.515},
	pages = {515--526},
	number = {3},
	journaltitle = {Biometrika},
	author = {Grambsch, Patricia M. and Therneau, Terry M.},
	urldate = {2018-01-09},
	date = {1994},
	langid = {english},
	file = {grambsch_therneau_1994_proportional_hazards_tests_and_diagnostics_based_on_weighted_residuals.pdf:/home/nathan/Dropbox/njames/zotero_sync/grambsch_therneau_1994_proportional_hazards_tests_and_diagnostics_based_on_weighted_residuals.pdf:application/pdf}
}

@article{efron_statistical_1991,
	title = {Statistical Data Analysis in the Computer Age},
	volume = {253},
	issn = {0036-8075, 1095-9203},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.253.5018.390},
	doi = {10.1126/science.253.5018.390},
	pages = {390--395},
	number = {5018},
	journaltitle = {Science},
	author = {Efron, B. and Tibshirani, R.},
	urldate = {2018-01-09},
	date = {1991-07-12},
	langid = {english},
	file = {efron_tibshirani_1991_statistical_data_analysis_in_the_computer_age.pdf:/home/nathan/Dropbox/njames/zotero_sync/efron_tibshirani_1991_statistical_data_analysis_in_the_computer_age.pdf:application/pdf}
}

@article{mensh_ten_2017,
	title = {Ten simple rules for structuring papers},
	volume = {13},
	pages = {e1005619},
	number = {9},
	journaltitle = {{PLoS} computational biology},
	author = {Mensh, Brett and Kording, Konrad},
	date = {2017},
	file = {mensh_kording_2017_ten_simple_rules_for_structuring_papers.pdf:/home/nathan/Dropbox/njames/zotero_sync/mensh_kording_2017_ten_simple_rules_for_structuring_papers.pdf:application/pdf}
}

@article{wickham_tidy_2014,
	title = {Tidy Data},
	volume = {59},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v59/i10/},
	doi = {10.18637/jss.v059.i10},
	number = {10},
	journaltitle = {Journal of Statistical Software},
	author = {Wickham, Hadley},
	urldate = {2018-01-09},
	date = {2014},
	langid = {english},
	file = {wickham_2014_tidy_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/wickham_2014_tidy_data.pdf:application/pdf}
}

@article{spiegelhalter_probabilistic_1986,
	title = {Probabilistic prediction in patient management and clinical trials},
	volume = {5},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/sim.4780050506/abstract},
	doi = {10.1002/sim.4780050506},
	abstract = {It is argued that the provision of accurate and useful probabilistic assessments of future events should be a fundamental task for biostatisticians collaborating in clinical or experimental medicine, and we explore two aspects of obtaining and evaluating such predictions. When covariate information on patients is available, logistic regression and other multivariate techniques are often used to select prognostic factors and create predictive models. An example shows how the explicit aim of prediction needs to be taken into account in such modelling, and how predictive performance may be assessed by decomposition of a scoring rule. Secondly, results from a program that provides pretrial and interim predictions in clinical trials are displayed, bringing together the use of subjective opinion, Bayesian methodology and techniques for evaluating and criticizing predictions.},
	pages = {421--433},
	number = {5},
	journaltitle = {Statist. Med.},
	author = {Spiegelhalter, D. J.},
	urldate = {2018-01-09},
	date = {1986-09-01},
	langid = {english},
	keywords = {Bayesian inference, Clinical trials, Logistic regression, Prediction, Shrinkage, Subjective probability},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/95WDN7RE/abstract.html:text/html;spiegelhalter_1986_probabilistic_prediction_in_patient_management_and_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/spiegelhalter_1986_probabilistic_prediction_in_patient_management_and_clinical_trials.pdf:application/pdf}
}

@article{mckee_institutionalizing_2015,
	title = {Institutionalizing Bayesianism Within the Organizational Sciences: A Practical Guide Featuring Comments From Eminent Scholars},
	volume = {41},
	issn = {0149-2063, 1557-1211},
	url = {http://journals.sagepub.com/doi/10.1177/0149206314546750},
	doi = {10.1177/0149206314546750},
	shorttitle = {Institutionalizing Bayesianism Within the Organizational Sciences},
	pages = {471--490},
	number = {2},
	journaltitle = {Journal of Management},
	author = {{McKee}, Rob Austin and Miller, C. Chet},
	urldate = {2018-01-11},
	date = {2015-02},
	langid = {english},
	file = {mckee_miller_2015_institutionalizing_bayesianism_within_the_organizational_sciences.pdf:/home/nathan/Dropbox/njames/zotero_sync/mckee_miller_2015_institutionalizing_bayesianism_within_the_organizational_sciences.pdf:application/pdf}
}

@article{kruschke_bayesian_2017-1,
	title = {The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/10.3758/s13423-016-1221-4},
	doi = {10.3758/s13423-016-1221-4},
	shorttitle = {The Bayesian New Statistics},
	journaltitle = {Psychonomic Bulletin \& Review},
	author = {Kruschke, John K. and Liddell, Torrin M.},
	urldate = {2018-01-11},
	date = {2017-02-07},
	langid = {english},
	file = {kruschke_liddell_2017_the_bayesian_new_statistics.pdf:/home/nathan/Dropbox/njames/zotero_sync/kruschke_liddell_2017_the_bayesian_new_statistics.pdf:application/pdf}
}

@article{bennette_against_2012,
	title = {Against quantiles: categorization of continuous variables in epidemiologic research, and its discontents},
	volume = {12},
	shorttitle = {Against quantiles},
	pages = {21},
	number = {1},
	journaltitle = {{BMC} medical research methodology},
	author = {Bennette, Caroline and Vickers, Andrew},
	date = {2012},
	file = {bennette_vickers_2012_against_quantiles.pdf:/home/nathan/Dropbox/njames/zotero_sync/bennette_vickers_2012_against_quantiles.pdf:application/pdf}
}

@article{liu_modeling_2017,
	title = {Modeling continuous response variables using ordinal regression},
	volume = {36},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/sim.7433/abstract},
	doi = {10.1002/sim.7433},
	abstract = {We study the application of a widely used ordinal regression model, the cumulative probability model ({CPM}), for continuous outcomes. Such models are attractive for the analysis of continuous response variables because they are invariant to any monotonic transformation of the outcome and because they directly model the cumulative distribution function from which summaries such as expectations and quantiles can easily be derived. Such models can also readily handle mixed type distributions. We describe the motivation, estimation, inference, model assumptions, and diagnostics. We demonstrate that {CPMs} applied to continuous outcomes are semiparametric transformation models. Extensive simulations are performed to investigate the finite sample performance of these models. We find that properly specified {CPMs} generally have good finite sample performance with moderate sample sizes, but that bias may occur when the sample size is small. Cumulative probability models are fairly robust to minor or moderate link function misspecification in our simulations. For certain purposes, the {CPMs} are more efficient than other models. We illustrate their application, with model diagnostics, in a study of the treatment of {HIV}. {CD}4 cell count and viral load 6 months after the initiation of antiretroviral therapy are modeled using {CPMs}; both variables typically require transformations, and viral load has a large proportion of measurements below a detection limit.},
	pages = {4316--4335},
	number = {27},
	journaltitle = {Statistics in Medicine},
	author = {Liu, Qi and Shepherd, Bryan E. and Li, Chun and Harrell, Frank E.},
	urldate = {2018-01-19},
	date = {2017-11-30},
	langid = {english},
	keywords = {nonparametric maximum likelihood estimation, ordinal regression model, rank-based statistics, semiparametric transformation model},
	file = {liu_et_al_2017_modeling_continuous_response_variables_using_ordinal_regression.pdf:/home/nathan/Dropbox/njames/zotero_sync/liu_et_al_2017_modeling_continuous_response_variables_using_ordinal_regression.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/5RASL62R/abstract.html:text/html}
}

@article{faisal_dynamic_2014,
	title = {Dynamic networks reveal key players in aging},
	volume = {30},
	issn = {1367-4803, 1460-2059},
	url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btu089},
	doi = {10.1093/bioinformatics/btu089},
	pages = {1721--1729},
	number = {12},
	journaltitle = {Bioinformatics},
	author = {Faisal, Fazle E. and Milenković, Tijana},
	urldate = {2018-01-24},
	date = {2014-06-15},
	langid = {english},
	file = {faisal_milenković_2014_dynamic_networks_reveal_key_players_in_aging.pdf:/home/nathan/Dropbox/njames/zotero_sync/faisal_milenković_2014_dynamic_networks_reveal_key_players_in_aging.pdf:application/pdf}
}

@article{hidalgo_dynamic_2009,
	title = {A Dynamic Network Approach for the Study of Human Phenotypes},
	volume = {5},
	issn = {1553-7358},
	url = {http://dx.plos.org/10.1371/journal.pcbi.1000353},
	doi = {10.1371/journal.pcbi.1000353},
	pages = {e1000353},
	number = {4},
	journaltitle = {{PLoS} Computational Biology},
	author = {Hidalgo, César A. and Blumm, Nicholas and Barabási, Albert-László and Christakis, Nicholas A.},
	editor = {Meyers, Lauren Ancel},
	urldate = {2018-01-24},
	date = {2009-04-10},
	langid = {english},
	file = {hidalgo_et_al_2009_a_dynamic_network_approach_for_the_study_of_human_phenotypes.pdf:/home/nathan/Dropbox/njames/zotero_sync/hidalgo_et_al_2009_a_dynamic_network_approach_for_the_study_of_human_phenotypes.pdf:application/pdf}
}

@article{sperling_functional_2010,
	title = {Functional Alterations in Memory Networks in Early Alzheimer’s Disease},
	volume = {12},
	issn = {1535-1084, 1559-1174},
	url = {http://link.springer.com/10.1007/s12017-009-8109-7},
	doi = {10.1007/s12017-009-8109-7},
	pages = {27--43},
	number = {1},
	journaltitle = {{NeuroMolecular} Medicine},
	author = {Sperling, Reisa A. and Dickerson, Bradford C. and Pihlajamaki, Maija and Vannini, Patrizia and {LaViolette}, Peter S. and Vitolo, Ottavio V. and Hedden, Trey and Becker, J. Alex and Rentz, Dorene M. and Selkoe, Dennis J. and Johnson, Keith A.},
	urldate = {2018-01-24},
	date = {2010-03},
	langid = {english},
	file = {sperling_et_al_2010_functional_alterations_in_memory_networks_in_early_alzheimer’s_disease.pdf:/home/nathan/Dropbox/njames/zotero_sync/sperling_et_al_2010_functional_alterations_in_memory_networks_in_early_alzheimer’s_disease.pdf:application/pdf}
}

@article{wu_altered_2011,
	title = {Altered default mode network connectivity in alzheimer's disease—A resting functional {MRI} and bayesian network study},
	volume = {32},
	issn = {1097-0193},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.21153/abstract},
	doi = {10.1002/hbm.21153},
	abstract = {A number of functional magnetic resonance imaging ({fMRI}) studies reported the existence of default mode network ({DMN}) and its disruption due to the presence of a disease such as Alzheimer's disease ({AD}). In this investigation, first, we used the independent component analysis ({ICA}) technique to confirm the {DMN} difference between patients with {AD} and normal control ({NC}) reported in previous studies. Consistent with the previous studies, the decreased resting-state functional connectivity of {DMN} in {AD} was identified in posterior cingulated cortex ({PCC}), medial prefrontal cortex ({MPFC}), inferior parietal cortex ({IPC}), inferior temporal cortex ({ITC}), and hippocampus ({HC}). Moreover, we introduced Bayesian network ({BN}) to study the effective connectivity of {DMN} and the difference between {AD} and {NC}. When compared the {DMN} effective connectivity in {AD} with the one in {NC} using a nonparametric random permutation test, we found that connections from left {HC} to left {IPC}, left {ITC} to right {HC}, right {HC} to left {IPC}, to {MPFC} and to {PCC} were all lost. In addition, in {AD} group, the connection directions between right {HC} and left {HC}, between left {HC} and left {ITC}, and between right {IPC} and right {ITC} were opposite to those in {NC} group. The connections of right {HC} to other regions, except left {HC}, within the {BN} were all statistically in-distinguishable from 0, suggesting an increased right hippocampal pathological and functional burden in {AD}. The altered effective connectivity in patients with {AD} may reveal more characteristics of the disease and may serve as a potential biomarker. Hum Brain Mapp, 2011. © 2011 Wiley-Liss, Inc.},
	pages = {1868--1881},
	number = {11},
	journaltitle = {Hum. Brain Mapp.},
	author = {Wu, Xia and Li, Rui and Fleisher, Adam S. and Reiman, Eric M. and Guan, Xiaoting and Zhang, Yumei and Chen, Kewei and Yao, Li},
	urldate = {2018-01-24},
	date = {2011-11-01},
	langid = {english},
	keywords = {biomarker, effective connectivity, {fMRI}, functional connectivity, resting state},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/SYYM59JU/abstract.html:text/html;wu_et_al_2011_altered_default_mode_network_connectivity_in_alzheimer's_disease—a_resting.pdf:/home/nathan/Dropbox/njames/zotero_sync/wu_et_al_2011_altered_default_mode_network_connectivity_in_alzheimer's_disease—a_resting.pdf:application/pdf}
}

@article{supekar_network_2008,
	title = {Network Analysis of Intrinsic Functional Brain Connectivity in Alzheimer's Disease},
	volume = {4},
	issn = {1553-7358},
	url = {http://dx.plos.org/10.1371/journal.pcbi.1000100},
	doi = {10.1371/journal.pcbi.1000100},
	pages = {e1000100},
	number = {6},
	journaltitle = {{PLoS} Computational Biology},
	author = {Supekar, Kaustubh and Menon, Vinod and Rubin, Daniel and Musen, Mark and Greicius, Michael D.},
	editor = {Sporns, Olaf},
	urldate = {2018-01-24},
	date = {2008-06-27},
	langid = {english},
	file = {supekar_et_al_2008_network_analysis_of_intrinsic_functional_brain_connectivity_in_alzheimer's.pdf:/home/nathan/Dropbox/njames/zotero_sync/supekar_et_al_2008_network_analysis_of_intrinsic_functional_brain_connectivity_in_alzheimer's.pdf:application/pdf}
}

@incollection{braun_human_2001,
	title = {On Human Brain Networks in Health and Disease},
	rights = {Copyright © 2001 John Wiley \& Sons, Ltd. All rights reserved.},
	isbn = {978-0-470-01590-2},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/9780470015902.a0025783/abstract},
	abstract = {The brain is a complex system whose function relies on a diverse set of connections or interactions between brain regions. Using the mathematical framework of complex networks, these interaction patterns can be parsimoniously represented as brain graphs: each brain area is represented as a network node and each connection is represented as a network edge. These methods have been used to demonstrate that human brain networks display properties such as a small-world architecture that may directly facilitate cognitive processes. Moreover, mounting evidence suggests that these properties are altered in disease states, potentially providing important biomarkers for psychiatric and neurological disorders and informing our understanding of the mechanisms of altered cognitive function. Here, the basic concepts in network science are reviewed, and the properties of healthy and diseased brain networks discussed. Relationships between network diagnostics and alterations in behavioural or cognitive variables associated with Alzheimer's disease, schizophrenia and epilepsy are highlighted.

Key Concepts
Key Concepts




* The brain is a complex system that can be represented by a graph.

* In a graph, nodes represent brain regions and edges represent the links or connections between those areas, forming a complex network.

* Brain networks display properties such as a small-world architecture or a hierarchical modular organisation that may directly facilitate cognitive processes.

* These properties are altered in disease states, potentially providing important biomarkers for psychiatric and neurological disorders.},
	booktitle = {{eLS}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Braun, Urs and Muldoon, Sarah F and Bassett, Danielle S},
	urldate = {2018-01-24},
	date = {2001},
	langid = {english},
	doi = {10.1002/9780470015902.a0025783},
	keywords = {schizophrenia, Alzheimer's disease, brain network, epilepsy, graph theory},
	file = {braun_et_al_2001_on_human_brain_networks_in_health_and_disease.pdf:/home/nathan/Dropbox/njames/zotero_sync/braun_et_al_2001_on_human_brain_networks_in_health_and_disease.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/T4UV3K5C/abstract.html:text/html}
}

@article{jack_hypothetical_2010,
	title = {Hypothetical model of dynamic biomarkers of the Alzheimer's pathological cascade},
	volume = {9},
	pages = {119--128},
	number = {1},
	journaltitle = {The Lancet Neurology},
	author = {Jack, Clifford R. and Knopman, David S. and Jagust, William J. and Shaw, Leslie M. and Aisen, Paul S. and Weiner, Michael W. and Petersen, Ronald C. and Trojanowski, John Q.},
	date = {2010},
	file = {jack_et_al_2010_hypothetical_model_of_dynamic_biomarkers_of_the_alzheimer's_pathological_cascade.pdf:/home/nathan/Dropbox/njames/zotero_sync/jack_et_al_2010_hypothetical_model_of_dynamic_biomarkers_of_the_alzheimer's_pathological_cascade.pdf:application/pdf}
}

@article{gomez-ramirez_network-based_2014,
	title = {Network-Based Biomarkers in Alzheimer’s Disease: Review and Future Directions},
	volume = {6},
	issn = {1663-4365},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3912507/},
	doi = {10.3389/fnagi.2014.00012},
	shorttitle = {Network-Based Biomarkers in Alzheimer’s Disease},
	abstract = {By 2050 it is estimated that the number of worldwide Alzheimer’s disease ({AD}) patients will quadruple from the current number of 36 million people. To date, no single test, prior to postmortem examination, can confirm that a person suffers from {AD}. Therefore, there is a strong need for accurate and sensitive tools for the early diagnoses of {AD}. The complex etiology and multiple pathogenesis of {AD} call for a system-level understanding of the currently available biomarkers and the study of new biomarkers via network-based modeling of heterogeneous data types. In this review, we summarize recent research on the study of {AD} as a connectivity syndrome. We argue that a network-based approach in biomarker discovery will provide key insights to fully understand the network degeneration hypothesis (disease starts in specific network areas and progressively spreads to connected areas of the initial loci-networks) with a potential impact for early diagnosis and disease-modifying treatments. We introduce a new framework for the quantitative study of biomarkers that can help shorten the transition between academic research and clinical diagnosis in {AD}.},
	journaltitle = {Front Aging Neurosci},
	author = {Gomez-Ramirez, Jaime and Wu, Jinglong},
	urldate = {2018-01-25},
	date = {2014-02-04},
	pmid = {24550828},
	pmcid = {PMC3912507},
	file = {gomez-ramirez_wu_2014_network-based_biomarkers_in_alzheimer’s_disease.pdf:/home/nathan/Dropbox/njames/zotero_sync/gomez-ramirez_wu_2014_network-based_biomarkers_in_alzheimer’s_disease.pdf:application/pdf}
}

@online{noauthor_network_nodate,
	title = {Network Modeling for Epidemics},
	url = {http://statnet.github.io/nme/index.html},
	urldate = {2018-01-25},
	file = {Network Modeling for Epidemics:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/RMGBFN22/index.html:text/html}
}

@article{wu_network_2014,
	title = {Network biomarkers, interaction networks and dynamical network biomarkers in respiratory diseases},
	volume = {3},
	issn = {2001-1326},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4072888/},
	doi = {10.1186/2001-1326-3-16},
	abstract = {Identification and validation of interaction networks and network biomarkers have become more critical and important in the development of disease-specific biomarkers, which are functionally changed during disease development, progression or treatment. The present review headlined the definition, significance, research and potential application for network biomarkers, interaction networks and dynamical network biomarkers ({DNB}). Disease-specific interaction networks, network biomarkers, or {DNB} have great significance in the understanding of molecular pathogenesis, risk assessment, disease classification and monitoring, or evaluations of therapeutic responses and toxicities. Protein-based {DNB} will provide more information to define the differences between the normal and pre-disease stages, which might point to early diagnosis for patients. Clinical bioinformatics should be a key approach to the identification and validation of disease-specific biomarkers.},
	pages = {16},
	journaltitle = {Clin Transl Med},
	author = {Wu, Xiaodan and Chen, Luonan and Wang, Xiangdong},
	urldate = {2018-01-25},
	date = {2014-06-24},
	pmid = {24995123},
	pmcid = {PMC4072888},
	file = {wu_et_al_2014_network_biomarkers,_interaction_networks_and_dynamical_network_biomarkers_in.pdf:/home/nathan/Dropbox/njames/zotero_sync/wu_et_al_2014_network_biomarkers,_interaction_networks_and_dynamical_network_biomarkers_in.pdf:application/pdf}
}

@article{van_arendonk_choosing_2015,
	title = {Choosing the Order of Deceased Donor and Living Donor Kidney Transplantation in Pediatric Recipients: A Markov Decision Process Model},
	volume = {99},
	issn = {0041-1337},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4320004/},
	doi = {10.1097/TP.0000000000000588},
	shorttitle = {Choosing the Order of Deceased Donor and Living Donor Kidney Transplantation in Pediatric Recipients},
	abstract = {Background
Most pediatric kidney transplant recipients eventually require retransplantation, and the most advantageous timing strategy regarding deceased and living donor transplantation in candidates with only one living donor remains unclear.

Methods
A patient-oriented Markov decision process model was designed to compare, for a given patient with one living donor, living-donor-first followed if necessary by deceased donor retransplantation versus deceased-donor-first followed if necessary by living donor (if still able to donate) or deceased donor (if not) retransplantation. Based on Scientific Registry of Transplant Recipients data, the model was designed to account for waitlist, graft, and patient survival, sensitization, increased risk of graft failure seen during late adolescence, and differential deceased donor waiting times based upon pediatric-priority allocation policies. Based on national cohort data, the model was also designed to account for aging or disease development leading to ineligibility of the living donor over time.

Results
Given a set of candidate and living donor characteristics, the Markov model provides the expected patient survival over a time horizon of 20 years. For the most highly sensitized patients ({PRA}{\textgreater}80\%), a deceased-donor-first strategy was advantageous, but for all other patients ({PRA}{\textless}80\%), a living-donor-first strategy was recommended.

Conclusions
This Markov model illustrates how patients, families, and providers can be provided information and predictions regarding the most advantageous use of deceased donor versus living donor transplantation for pediatric recipients.},
	pages = {360--366},
	number = {2},
	journaltitle = {Transplantation},
	author = {Van Arendonk, Kyle J. and Chow, Eric K.H. and James, Nathan T. and Orandi, Babak J. and Ellison, Trevor A. and Smith, Jodi M. and Colombani, Paul M. and Segev, Dorry L.},
	urldate = {2018-01-26},
	date = {2015-02},
	pmid = {25594552},
	pmcid = {PMC4320004},
	file = {van_arendonk_et_al_2015_choosing_the_order_of_deceased_donor_and_living_donor_kidney_transplantation_in.pdf:/home/nathan/Dropbox/njames/zotero_sync/van_arendonk_et_al_2015_choosing_the_order_of_deceased_donor_and_living_donor_kidney_transplantation_in.pdf:application/pdf}
}

@article{osband_extraction_2016,
	title = {Extraction Time of Kidneys From Deceased Donors and Impact on Outcomes},
	volume = {16},
	issn = {1600-6143},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/ajt.13457/abstract},
	doi = {10.1111/ajt.13457},
	abstract = {Cold ischemia time (from flush to out-of-ice) and warm ischemia time (from out-of-ice to reperfusion) are known to impact delayed graft function ({DGF}) rates and long-term allograft survival following deceased donor kidney transplantation. We propose an additional ischemia time, extraction time, beginning with aortic cross-clamp and perfusion/cooling of the kidneys, and ending with removal of the kidneys and placement on ice on the backtable. During this time the kidneys rewarm, suffering an additional ischemic insult, which may impair transplant function. We measured extraction times of 576 kidneys recovered and transplanted locally between January 2006 and December 2008, then linked to Scientific Registry of Transplant Recipients ({SRTR}) data for outcomes. Extraction time ranged from 14 to 123 min, with a mean of 44.7 min. In {SRTR}-adjusted analyses, longer extraction time and {DGF} were statistically associated (odds ratio [{OR}] = 1.19 per 5 min beyond 60 min, 95\% confidence interval [{CI}] 1.02–1.39, p = 0.03). Up to 60 min of extraction time, {DGF} incidence was 27.8\%; by 120 min it doubled to nearly 60\%. Although not statistically significant ({OR} = 1.19, 95\% {CI} 0.96–1.49, p = 0.11), primary nonfunction rate also rose dramatically to nearly 20\% by 120 min extraction time. Extraction time is a novel and important factor to consider when evaluating a deceased donor kidney offer and when strategizing personnel for kidney recovery.},
	pages = {700--703},
	number = {2},
	journaltitle = {American Journal of Transplantation},
	author = {Osband, A. J. and James, N. T. and Segev, D. L.},
	urldate = {2018-01-26},
	date = {2016-02-01},
	langid = {english},
	file = {osband_et_al_2016_extraction_time_of_kidneys_from_deceased_donors_and_impact_on_outcomes.pdf:/home/nathan/Dropbox/njames/zotero_sync/osband_et_al_2016_extraction_time_of_kidneys_from_deceased_donors_and_impact_on_outcomes.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/W58TA2B4/abstract.html:text/html}
}

@article{gelman_not_2013,
	title = {“Not Only Defended But Also Applied”: The Perceived Absurdity of Bayesian Inference},
	volume = {67},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00031305.2013.760987},
	doi = {10.1080/00031305.2013.760987},
	shorttitle = {“Not Only Defended But Also Applied”},
	pages = {1--5},
	number = {1},
	journaltitle = {The American Statistician},
	author = {Gelman, Andrew and Robert, Christian P.},
	urldate = {2018-02-01},
	date = {2013-02},
	langid = {english},
	file = {gelman_robert_2013_“not_only_defended_but_also_applied”.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_robert_2013_“not_only_defended_but_also_applied”.pdf:application/pdf}
}

@article{efron_missing_1994,
	title = {Missing Data, Imputation, and the Bootstrap},
	volume = {89},
	issn = {01621459},
	url = {http://www.jstor.org/stable/2290846?origin=crossref},
	doi = {10.2307/2290846},
	pages = {463},
	number = {426},
	journaltitle = {Journal of the American Statistical Association},
	author = {Efron, Bradley},
	urldate = {2018-02-03},
	date = {1994-06},
	file = {efron_1994_missing_data,_imputation,_and_the_bootstrap.pdf:/home/nathan/Dropbox/njames/zotero_sync/efron_1994_missing_data,_imputation,_and_the_bootstrap.pdf:application/pdf}
}

@article{van_calster_calibration_2016,
	title = {A calibration hierarchy for risk models was defined: from utopia to empirical data},
	volume = {74},
	issn = {08954356},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0895435615005818},
	doi = {10.1016/j.jclinepi.2015.12.005},
	shorttitle = {A calibration hierarchy for risk models was defined},
	pages = {167--176},
	journaltitle = {Journal of Clinical Epidemiology},
	author = {Van Calster, Ben and Nieboer, Daan and Vergouwe, Yvonne and De Cock, Bavo and Pencina, Michael J. and Steyerberg, Ewout W.},
	urldate = {2018-02-05},
	date = {2016-06},
	langid = {english},
	file = {van_calster_et_al_2016_a_calibration_hierarchy_for_risk_models_was_defined.pdf:/home/nathan/Dropbox/njames/zotero_sync/van_calster_et_al_2016_a_calibration_hierarchy_for_risk_models_was_defined.pdf:application/pdf}
}

@article{van_houwelingen_predictive_1990,
	title = {Predictive value of statistical models},
	volume = {9},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/sim.4780091109/abstract},
	doi = {10.1002/sim.4780091109},
	abstract = {A review is given of different ways of estimating the error rate of a prediction rule based on a statistical model. A distinction is drawn between apparent, optimum and actual error rates. Moreover it is shown how cross-validation can be used to obtain an adjusted predictor with smaller error rate. A detailed discussion is given for ordinary least squares, logistic regression and Cox regression in survival analysis. Finally, the split-sample approach is discussed and demonstrated on two data sets.},
	pages = {1303--1325},
	number = {11},
	journaltitle = {Statist. Med.},
	author = {Van Houwelingen, J. C. and Le Cessie, S.},
	urldate = {2018-02-05},
	date = {1990-11-01},
	langid = {english},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/YKH5TZXC/abstract.html:text/html;van_houwelingen_le_cessie_1990_predictive_value_of_statistical_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/van_houwelingen_le_cessie_1990_predictive_value_of_statistical_models.pdf:application/pdf}
}

@article{costa_case_2017,
	title = {The Case for a Bayesian Approach to Benefit-Risk Assessment:: Overview and Future Directions},
	volume = {51},
	issn = {2168-4790, 2168-4804},
	url = {http://journals.sagepub.com/doi/10.1177/2168479017698190},
	doi = {10.1177/2168479017698190},
	shorttitle = {The Case for a Bayesian Approach to Benefit-Risk Assessment},
	pages = {568--574},
	number = {5},
	journaltitle = {Therapeutic Innovation \& Regulatory Science},
	author = {Costa, Maria J. and He, Weili and Jemiai, Yannis and Zhao, Yueqin and Di Casoli, Carl},
	urldate = {2018-03-15},
	date = {2017-09},
	langid = {english},
	keywords = {Bayesian inference, benefit-risk, decision-making, uncertainty},
	file = {costa_et_al_2017_the_case_for_a_bayesian_approach_to_benefit-risk_assessment.pdf:/home/nathan/Dropbox/njames/zotero_sync/costa_et_al_2017_the_case_for_a_bayesian_approach_to_benefit-risk_assessment.pdf:application/pdf}
}

@article{costa_bayesian_2018,
	title = {Bayesian joint modelling of benefit and risk in drug development},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1852},
	doi = {10.1002/pst.1852},
	journaltitle = {Pharmaceutical Statistics},
	author = {Costa, Maria J. and Drury, Thomas},
	urldate = {2018-03-15},
	date = {2018-02-22},
	langid = {english},
	file = {costa_drury_2018_bayesian_joint_modelling_of_benefit_and_risk_in_drug_development.pdf:/home/nathan/Dropbox/njames/zotero_sync/costa_drury_2018_bayesian_joint_modelling_of_benefit_and_risk_in_drug_development.pdf:application/pdf;costa_drury_2018_bayesian_joint_modelling_of_benefit_and_risk_in_drug_development.pdf:/home/nathan/Dropbox/njames/zotero_sync/costa_drury_2018_bayesian_joint_modelling_of_benefit_and_risk_in_drug_development2.pdf:application/pdf}
}

@article{psioda_bayesian_2018,
	title = {Bayesian clinical trial design using historical data that inform the treatment effect},
	issn = {1465-4644, 1468-4357},
	url = {https://academic.oup.com/biostatistics/advance-article/doi/10.1093/biostatistics/kxy009/4935054},
	doi = {10.1093/biostatistics/kxy009},
	abstract = {We consider the problem of Bayesian sample size determination for a clinical trial in the presence of historical data that inform the treatment effect. Our broadly applicable, simulation-based methodology provides a framework for calibrating the informativeness of a prior while simultaneously identifying the minimum sample size required for a new trial such that the overall design has appropriate power to detect a non-null treatment effect and reasonable type I error control. We develop a comprehensive strategy for eliciting null and alternative sampling prior distributions which are used to deﬁne Bayesian generalizations of the traditional notions of type I error control and power. Bayesian type I error control requires that a weighted-average type I error rate not exceed a prespeciﬁed threshold. We develop a procedure for generating an appropriately sized Bayesian hypothesis test using a simple partial-borrowing power prior which summarizes the fraction of information borrowed from the historical trial. We present results from simulation studies that demonstrate that a hypothesis test procedure based on this simple power prior is as efﬁcient as those based on more complicated meta-analytic priors, such as normalized power priors or robust mixture priors, when all are held to precise type I error control requirements. We demonstrate our methodology using a real data set to design a follow-up clinical trial with time-to-event endpoint for an investigational treatment in high-risk melanoma.},
	journaltitle = {Biostatistics},
	author = {Psioda, Matthew A and Ibrahim, Joseph G},
	urldate = {2018-03-15},
	date = {2018-03-14},
	langid = {english},
	file = {psioda_ibrahim_2018_bayesian_clinical_trial_design_using_historical_data_that_inform_the_treatment.pdf:/home/nathan/Dropbox/njames/zotero_sync/psioda_ibrahim_2018_bayesian_clinical_trial_design_using_historical_data_that_inform_the_treatment.pdf:application/pdf}
}

@article{whitehead_sample_1993,
	title = {Sample size calculations for ordered categorical data},
	volume = {12},
	issn = {02776715, 10970258},
	url = {http://doi.wiley.com/10.1002/sim.4780122404},
	doi = {10.1002/sim.4780122404},
	abstract = {Many clinical trials yield data on an ordered categorical scale such as very good, good, moderate, poor. Under the assumption of proportional odds, such data can be analysed using techniques of logistic regression. In simple comparisons of two treatmentsthis approach becomes equivalent to the Mann-Whitney test. In this paper sample size formulae consistentwith an eventual logistic regressionanalysisare derived.The influence on efficiency of the number and breadth of categories will be examined. Effects of misclassification and of stratification are discussed, and examples of the calculations are given.},
	pages = {2257--2271},
	number = {24},
	journaltitle = {Statistics in Medicine},
	author = {Whitehead, John},
	urldate = {2018-03-21},
	date = {1993-12-30},
	langid = {english},
	file = {whitehead_1993_sample_size_calculations_for_ordered_categorical_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/whitehead_1993_sample_size_calculations_for_ordered_categorical_data.pdf:application/pdf;whitehead_1993_sample_size_calculations_for_ordered_categorical_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/whitehead_1993_sample_size_calculations_for_ordered_categorical_data2.pdf:application/pdf}
}

@article{julious_letter_1996,
	title = {Letter to the Editor: Sample Sizes Calculations for Ordered Categorical Data by J. Whitehead,Statistics in Medicine, 12, 2257-2272 (1993).},
	volume = {15},
	issn = {0277-6715, 1097-0258},
	url = {http://doi.wiley.com/10.1002/%28SICI%291097-0258%2819960530%2915%3A10%3C1065%3A%3AAID-SIM288%3E3.0.CO%3B2-9},
	doi = {10.1002/(SICI)1097-0258(19960530)15:10<1065::AID-SIM288>3.0.CO;2-9},
	shorttitle = {{LETTER} {TO} {THE} {EDITOR}},
	pages = {1065--1066},
	number = {10},
	journaltitle = {Statistics in Medicine},
	author = {Julious, Steven A. and Campbell, Michael J.},
	urldate = {2018-03-21},
	date = {1996-05-30},
	langid = {english},
	file = {julious_campbell_1996_letter_to_the_editor.pdf:/home/nathan/Dropbox/njames/zotero_sync/julious_campbell_1996_letter_to_the_editor.pdf:application/pdf}
}

@article{cook_simultaneous_2015,
	title = {Simultaneous Envelopes for Multivariate Linear Regression},
	volume = {57},
	issn = {0040-1706, 1537-2723},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00401706.2013.872700},
	doi = {10.1080/00401706.2013.872700},
	pages = {11--25},
	number = {1},
	journaltitle = {Technometrics},
	author = {Cook, R. Dennis and Zhang, Xin},
	urldate = {2018-03-21},
	date = {2015-01-02},
	langid = {english},
	file = {cook_zhang_2015_simultaneous_envelopes_for_multivariate_linear_regression.pdf:/home/nathan/Dropbox/njames/zotero_sync/cook_zhang_2015_simultaneous_envelopes_for_multivariate_linear_regression.pdf:application/pdf}
}

@article{crowther_extended_nodate,
	title = {Extended multivariate generalised linear and non-linear mixed eﬀects models},
	abstract = {Multivariate data occurs in a wide range of ﬁelds, with ever more ﬂexible model speciﬁcations being proposed, often within a multivariate generalised linear mixed eﬀects ({MGLME}) framework. In this article, we describe an extended framework, encompassing multiple outcomes of any type, each of which could be repeatedly measured (longitudinal), with any number of levels, and with any number of random eﬀects at each level. Many standard distributions are described, as well as nonstandard user-deﬁned non-linear models. The extension focuses on a complex linear predictor for each outcome model, allowing sharing and linking between outcome models in an extremely ﬂexible way, either by linking random eﬀects directly, or the expected value of one outcome (or function of it) within the linear predictor of another. Non-linear and time-dependent eﬀects are also seamlessly incorporated to the linear predictor through the use of splines or fractional polynomials. We further propose level-speciﬁc random eﬀect distributions and numerical integration techniques to improve usability, relaxing the normally distributed random eﬀects assumption to allow multivariate tdistributed random eﬀects. We consider some special cases of the general framework, describing some new models in the ﬁelds of clustered survival data, joint longitudinal-survival models, and discuss various potential uses of the implementation. User friendly, and easily extendable, software is provided.},
	pages = {21},
	author = {Crowther, Michael J},
	langid = {english},
	file = {crowther_extended_multivariate_generalised_linear_and_non-linear_mixed_eﬀects_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/crowther_extended_multivariate_generalised_linear_and_non-linear_mixed_eﬀects_models.pdf:application/pdf}
}

@article{jones_sequential_1979,
	title = {Sequential Forms of the Log Rank and Modified Wilcoxon Tests for Censored Data},
	volume = {66},
	issn = {00063444},
	url = {http://www.jstor.org/stable/2335249?origin=crossref},
	doi = {10.2307/2335249},
	pages = {105},
	number = {1},
	journaltitle = {Biometrika},
	author = {Jones, David and Whitehead, John},
	urldate = {2018-03-23},
	date = {1979-04},
	langid = {english},
	file = {jones_whitehead_1979_sequential_forms_of_the_log_rank_and_modified_wilcoxon_tests_for_censored_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/jones_whitehead_1979_sequential_forms_of_the_log_rank_and_modified_wilcoxon_tests_for_censored_data.pdf:application/pdf}
}

@article{peter_mccullagh_regression_1980,
	title = {Regression Models for Ordinal Data},
	volume = {42},
	url = {http://www.jstor.org/stable/2984952},
	pages = {109--142},
	number = {2},
	journaltitle = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Peter {McCullagh}},
	date = {1980},
	langid = {english},
	file = {peter_mccullagh_regression_models_for_ordinal_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/peter_mccullagh_regression_models_for_ordinal_data.pdf:application/pdf}
}

@article{berry_bayesian_2006,
	title = {Bayesian clinical trials},
	volume = {5},
	issn = {1474-1776, 1474-1784},
	url = {http://www.nature.com/articles/nrd1927},
	doi = {10.1038/nrd1927},
	abstract = {Bayesian statistical methods are being used increasingly in clinical research because the Bayesian approach is ideally suited to adapting to information that accrues during a trial, potentially allowing for smaller more informative trials and for patients to receive better treatment. Accumulating results can be assessed at any time, including continually, with the possibility of modifying the design of the trial, for example, by slowing (or stopping) or expanding accrual, imbalancing randomization to favour better-performing therapies, dropping or adding treatment arms, and changing the trial population to focus on patient subsets that are responding better to the experimental therapies. Bayesian analyses use available patient-outcome information, including biomarkers that accumulating data indicate might be related to clinical outcome. They also allow for the use of historical information and for synthesizing results of relevant trials. Here, I explain the rationale underlying Bayesian clinical trials, and discuss the potential of such trials to improve the effectiveness of drug development.},
	pages = {27--36},
	number = {1},
	journaltitle = {Nature Reviews Drug Discovery},
	author = {Berry, Donald A.},
	urldate = {2018-03-27},
	date = {2006-01},
	langid = {english},
	file = {berry_2006_bayesian_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/berry_2006_bayesian_clinical_trials.pdf:application/pdf}
}

@article{biswas_bayesian_2009,
	title = {Bayesian clinical trials at the University of Texas M. D. Anderson Cancer Center},
	volume = {6},
	issn = {1740-7745, 1740-7753},
	url = {http://journals.sagepub.com/doi/10.1177/1740774509104992},
	doi = {10.1177/1740774509104992},
	abstract = {Background The Bayesian approach is being used increasingly in medical research. In particular, it has become a standard in designing clinical trials at the University of Texas M. D. Anderson Cancer Center.
Purpose/Methods To address the extent and nature of Bayesian trials conducted at M. D. Anderson, we reviewed the protocols registered in the Protocol Document Online System between 2000 and early 2005. We summarize our findings and give details for three innovative trials that typify those in which a Bayesian approach has played a major role at the center.
Results Of 964 protocols reviewed, 59\% were conducted solely at M. D. Anderson and the rest were multicenter trials. Bayesian designs and analyses were used in about 20\% (195/964) of the protocols that we reviewed. Of the 520 protocols identified as phase I or {II} drug trials, about 34\% were Bayesian. Most of the 195 Bayesian trials were designed by M. D. Anderson statisticians. The Bayesian design features most commonly used were the continuous reassessment method in phase I (toxicity) trials, adaptive randomization in phase {II} trials, and designs to monitor efficacy and toxicity simultaneously. We also provide an insider’s view regarding some practical considerations that have made the design and implementation of so many Bayesian trials possible. Limitations We reviewed only a subset of all M. D. Anderson protocols, but did not exclude any available in electronic form.
Conclusions The large number of Bayesian trials conducted at M. D. Anderson testifies to the receptivity to the Bayesian approach within the center, including principal investigators, regulatory review committees, and patients. Statisticians who take a Bayesian perspective can successfully work to establish a culture of innovation in clinical trial design. Clinical Trials 2009; 6: 205–216. http://ctj.sagepub.com},
	pages = {205--216},
	number = {3},
	journaltitle = {Clinical Trials: Journal of the Society for Clinical Trials},
	author = {Biswas, Swati and Liu, Diane D and Lee, J Jack and Berry, Donald A},
	urldate = {2018-03-27},
	date = {2009-06},
	langid = {english},
	file = {biswas_et_al_2009_bayesian_clinical_trials_at_the_university_of_texas_m.pdf:/home/nathan/Dropbox/njames/zotero_sync/biswas_et_al_2009_bayesian_clinical_trials_at_the_university_of_texas_m.pdf:application/pdf}
}

@article{bishop_bayesian_nodate,
	title = {Bayesian Methods for Neural Networks},
	pages = {18},
	author = {Bishop, Christopher M},
	langid = {english},
	file = {bishop_bayesian_methods_for_neural_networks.pdf:/home/nathan/Dropbox/njames/zotero_sync/bishop_bayesian_methods_for_neural_networks.pdf:application/pdf}
}

@incollection{tejedor_bayesian_2017,
	title = {Bayesian Hypothesis Testing: An Alternative to Null Hypothesis Significance Testing ({NHST}) in Psychology and Social Sciences},
	isbn = {978-953-51-3577-7 978-953-51-3578-4},
	url = {http://www.intechopen.com/books/bayesian-inference/bayesian-hypothesis-testing-an-alternative-to-null-hypothesis-significance-testing-nhst-in-psycholog},
	shorttitle = {Bayesian Hypothesis Testing},
	abstract = {Since the mid-1950s, there has been a clear predominance of the Frequentist approach to hypothesis testing, both in psychology and in social sciences. Despite its popularity in the field of statistics, Bayesian inference is barely known and used in psychology. Frequentist inference, and its null hypothesis significance testing ({NHST}), has been hegemonic through most of the history of scientific psychology. However, the {NHST} has not been exempt of criticisms. Therefore, the aim of this chapter is to introduce a Bayesian approach to hypothesis testing that may represent a useful complement, or even an alternative, to the current {NHST}. The advantages of this Bayesian approach over Frequentist {NHST} will be presented, providing examples that support its use in psychology and social sciences. Conclusions are outlined.},
	booktitle = {Bayesian Inference},
	publisher = {{InTech}},
	author = {Ortega, Alonso and Navarrete, Gorka},
	editor = {Tejedor, Javier Prieto},
	urldate = {2018-04-11},
	date = {2017-11-02},
	langid = {english},
	doi = {10.5772/intechopen.70230},
	file = {ortega_navarrete_2017_bayesian_hypothesis_testing.pdf:/home/nathan/Dropbox/njames/zotero_sync/ortega_navarrete_2017_bayesian_hypothesis_testing.pdf:application/pdf}
}

@article{smania_model-based_2016,
	title = {Model-Based Assessment of Alternative Study Designs in Pediatric Trials. Part {II}: Bayesian Approaches: {CTS} of Bayesian Designs in Pediatrics},
	volume = {5},
	issn = {21638306},
	url = {http://doi.wiley.com/10.1002/psp4.12092},
	doi = {10.1002/psp4.12092},
	shorttitle = {Model-Based Assessment of Alternative Study Designs in Pediatric Trials. Part {II}},
	pages = {402--410},
	number = {8},
	journaltitle = {{CPT}: Pharmacometrics \& Systems Pharmacology},
	author = {Smania, G and Baiardi, P and Ceci, A and Cella, M and Magni, P},
	urldate = {2018-04-11},
	date = {2016-08},
	langid = {english},
	file = {smania_et_al_2016_model-based_assessment_of_alternative_study_designs_in_pediatric_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/smania_et_al_2016_model-based_assessment_of_alternative_study_designs_in_pediatric_trials.pdf:application/pdf}
}

@online{mckenzie_what_nodate,
	title = {What Works for Whom? A Bayesian Approach to Channeling Big Data Streams for Policy Analysis},
	url = {https://aefpweb.org/sites/default/files/webform/41/MoocSimWorkingPaper.pdf},
	author = {{McKenzie}, Mariel},
	urldate = {2018-04-11},
	file = {mckenzie_what_works_for_whom.pdf:/home/nathan/Dropbox/njames/zotero_sync/mckenzie_what_works_for_whom.pdf:application/pdf}
}

@article{ryan_review_2016,
	title = {A Review of Modern Computational Algorithms for Bayesian Optimal Design: A Review of Modern Algorithms for Bayesian Design},
	volume = {84},
	issn = {03067734},
	url = {http://doi.wiley.com/10.1111/insr.12107},
	doi = {10.1111/insr.12107},
	shorttitle = {A Review of Modern Computational Algorithms for Bayesian Optimal Design},
	abstract = {Bayesian experimental design is a fast growing area of research with many real-world applications. As computational power has increased over the years, so has the development of simulation-based design methods, which involve a number of algorithms, such as Markov chain Monte Carlo, sequential Monte Carlo and approximate Bayes methods, facilitating more complex design problems to be solved. The Bayesian framework provides a uniﬁed approach for incorporating prior information and/or uncertainties regarding the statistical model with a utility function which describes the experimental aims. In this paper, we provide a general overview on the concepts involved in Bayesian experimental design, and focus on describing some of the more commonly used Bayesian utility functions and methods for their estimation, as well as a number of algorithms that are used to search over the design space to ﬁnd the Bayesian optimal design. We also discuss other computational strategies for further research in Bayesian optimal design.},
	pages = {128--154},
	number = {1},
	journaltitle = {International Statistical Review},
	author = {Ryan, Elizabeth G. and Drovandi, Christopher C. and {McGree}, James M. and Pettitt, Anthony N.},
	urldate = {2018-04-11},
	date = {2016-04},
	langid = {english},
	file = {ryan_et_al_2016_a_review_of_modern_computational_algorithms_for_bayesian_optimal_design.pdf:/home/nathan/Dropbox/njames/zotero_sync/ryan_et_al_2016_a_review_of_modern_computational_algorithms_for_bayesian_optimal_design.pdf:application/pdf}
}

@article{walley_advantages_2015,
	title = {Advantages of a wholly Bayesian approach to assessing efficacy in early drug development: a case study},
	volume = {14},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1675},
	doi = {10.1002/pst.1675},
	shorttitle = {Advantages of a wholly Bayesian approach to assessing efficacy in early drug development},
	pages = {205--215},
	number = {3},
	journaltitle = {Pharmaceutical Statistics},
	author = {Walley, Rosalind J. and Smith, Claire L. and Gale, Jeremy D. and Woodward, Phil},
	urldate = {2018-04-11},
	date = {2015-05},
	langid = {english},
	file = {walley_et_al_2015_advantages_of_a_wholly_bayesian_approach_to_assessing_efficacy_in_early_drug.pdf:/home/nathan/Dropbox/njames/zotero_sync/walley_et_al_2015_advantages_of_a_wholly_bayesian_approach_to_assessing_efficacy_in_early_drug.pdf:application/pdf}
}

@article{sato_practical_2018,
	title = {Practical characteristics of adaptive design in phase 2 and 3 clinical trials},
	volume = {43},
	issn = {02694727},
	url = {http://doi.wiley.com/10.1111/jcpt.12617},
	doi = {10.1111/jcpt.12617},
	abstract = {What is known and objective: Adaptive design methods are expected to be ethical, reflect real medical practice, increase the likelihood of research and development success and reduce the allocation of patients into ineffective treatment groups by the early termination of clinical trials. However, the comprehensive details regarding which types of clinical trials will include adaptive designs remain unclear. We examined the practical characteristics of adaptive design used in clinical trials.},
	pages = {170--180},
	number = {2},
	journaltitle = {Journal of Clinical Pharmacy and Therapeutics},
	author = {Sato, A. and Shimura, M. and Gosho, M.},
	urldate = {2018-04-11},
	date = {2018-04},
	langid = {english},
	file = {sato_et_al_2018_practical_characteristics_of_adaptive_design_in_phase_2_and_3_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/sato_et_al_2018_practical_characteristics_of_adaptive_design_in_phase_2_and_3_clinical_trials.pdf:application/pdf}
}

@article{berry_emerging_2016,
	title = {Emerging innovations in clinical trial design},
	volume = {99},
	issn = {00099236},
	url = {http://doi.wiley.com/10.1002/cpt.285},
	doi = {10.1002/cpt.285},
	pages = {82--91},
	number = {1},
	journaltitle = {Clinical Pharmacology \& Therapeutics},
	author = {Berry, Da},
	urldate = {2018-04-11},
	date = {2016-01},
	langid = {english},
	file = {berry_2016_emerging_innovations_in_clinical_trial_design.pdf:/home/nathan/Dropbox/njames/zotero_sync/berry_2016_emerging_innovations_in_clinical_trial_design.pdf:application/pdf}
}

@article{montazerhodjat_use_2017,
	title = {Use of Bayesian Decision Analysis to Minimize Harm in Patient-Centered Randomized Clinical Trials in Oncology},
	volume = {3},
	issn = {2374-2437},
	url = {http://oncology.jamanetwork.com/article.aspx?doi=10.1001/jamaoncol.2017.0123},
	doi = {10.1001/jamaoncol.2017.0123},
	abstract = {{OBJECTIVE} To apply Bayesian decision analysis ({BDA}) to cancer therapeutics to choose an alpha and sample size that minimize the potential harm to current and future patients under both null and alternative hypotheses. {DATA} {SOURCES} We used the National Cancer Institute ({NCI}) Surveillance, Epidemiology, and End Results ({SEER}) database and data from the 10 clinical trials of the Alliance for Clinical Trials in Oncology. {STUDY} {SELECTION} The {NCI} {SEER} database was used because it is the most comprehensive cancer database in the United States. The Alliance trial data was used owing to the quality and breadth of data, and because of the expertise in these trials of one of us (D.J.S.). {DATA} {EXTRACTION} {AND} {SYNTHESIS} The {NCI} {SEER} and Alliance data have already been thoroughly vetted. Computations were replicated independently by 2 coauthors and reviewed by all coauthors. {MAIN} {OUTCOMES} {AND} {MEASURES} Our prior hypothesis was that an alpha of 2.5\% would not minimize the overall expected harm to current and future patients for the most deadly cancers, and that a less conservative alpha may be necessary. Our primary study outcomes involve measuring the potential harm to patients under both null and alternative hypotheses using {NCI} and Alliance data, and then computing {BDA}-optimal type 1 error rates and sample sizes for oncology {RCTs}.
{RESULTS} We computed {BDA}-optimal parameters for the 23 most common cancer sites using {NCI} data, and for the 10 Alliance clinical trials. For {RCTs} involving therapies for cancers with short survival times, no existing treatments, and low prevalence, the {BDA}-optimal type 1 error rates were much higher than the traditional 2.5\%. For cancers with longer survival times, existing treatments, and high prevalence, the corresponding {BDA}-optimal error rates were much lower, in some cases even lower than 2.5\%.
{CONCLUSIONS} {AND} {RELEVANCE} Bayesian decision analysis is a systematic, objective, transparent, and repeatable process for deciding the outcomes of {RCTs} that explicitly incorporates burden of disease and patient preferences.},
	pages = {e170123},
	number = {9},
	journaltitle = {{JAMA} Oncology},
	author = {Montazerhodjat, Vahid and Chaudhuri, Shomesh E. and Sargent, Daniel J. and Lo, Andrew W.},
	urldate = {2018-04-11},
	date = {2017-09-14},
	langid = {english},
	file = {montazerhodjat_et_al_2017_use_of_bayesian_decision_analysis_to_minimize_harm_in_patient-centered.pdf:/home/nathan/Dropbox/njames/zotero_sync/montazerhodjat_et_al_2017_use_of_bayesian_decision_analysis_to_minimize_harm_in_patient-centered.pdf:application/pdf}
}

@article{isakov_is_nodate,
	title = {Is the {FDA} Too Conservative or Too Aggressive?: A Bayesian Decision Analysis of Clinical Trial Design∗},
	abstract = {Implicit in the drug-approval process is a host of decisions—target patient population, control group, primary endpoint, sample size, follow-up period, etc.—all of which determine the trade-oﬀ between Type I and Type {II} error. We explore the application of Bayesian decision analysis ({BDA}) to minimize the expected cost of drug approval, where the relative costs of the two types of errors are calibrated using U.S. Burden of Disease Study 2010 data. The results for conventional ﬁxed-sample randomized clinical-trial designs suggest that for terminal illnesses with no existing therapies such as pancreatic cancer, the standard threshold of 2.5\% is substantially more conservative than the {BDA}-optimal threshold of 23.9\% to 27.8\%. For relatively less deadly conditions such as prostate cancer, 2.5\% is more risk-tolerant or aggressive than the {BDA}-optimal threshold of 1.2\% to 1.5\%. We compute {BDA}-optimal sizes for 25 of the most lethal diseases and show how a {BDA}-informed approval process can incorporate all stakeholders’ views in a systematic, transparent, internally consistent, and repeatable manner.},
	pages = {54},
	author = {Isakov, Leah and Lo, Andrew W and Montazerhodjat, Vahid},
	langid = {english},
	file = {isakov_et_al_is_the_fda_too_conservative_or_too_aggressive.pdf:/home/nathan/Dropbox/njames/zotero_sync/isakov_et_al_is_the_fda_too_conservative_or_too_aggressive.pdf:application/pdf}
}

@article{von_hippel_4._2007,
	title = {4. Regression with Missing Ys: An Improved Strategy for Analyzing Multiply Imputed Data},
	volume = {37},
	issn = {0081-1750, 1467-9531},
	url = {http://journals.sagepub.com/doi/10.1111/j.1467-9531.2007.00180.x},
	doi = {10.1111/j.1467-9531.2007.00180.x},
	shorttitle = {4. Regression with Missing Ys},
	pages = {83--117},
	number = {1},
	journaltitle = {Sociological Methodology},
	author = {von Hippel, Paul T.},
	urldate = {2018-04-17},
	date = {2007-08},
	langid = {english},
	file = {von_hippel_2007_4.pdf:/home/nathan/Dropbox/njames/zotero_sync/von_hippel_2007_4.pdf:application/pdf}
}

@article{gelman_r-squared_nodate,
	title = {R-squared for Bayesian regression models∗},
	abstract = {The usual deﬁnition of R2 (variance of the predicted values divided by the variance of the data) has a problem for Bayesian ﬁts, as the numerator can be larger than the denominator. We propose an alternative deﬁnition similar to one that has appeared in the survival analysis literature: the variance of the predicted values divided by the variance of predicted values plus the variance of the errors. This summary is computed automatically for linear and generalized linear regression models ﬁt using rstanarm, our R package for ﬁtting Bayesian applied regression models with Stan.},
	pages = {7},
	author = {Gelman, Andrew and Goodrich, Ben and Gabry, Jonah and Ali, Imad},
	langid = {english},
	file = {gelman_et_al_r-squared_for_bayesian_regression_models∗.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_et_al_r-squared_for_bayesian_regression_models∗.pdf:application/pdf}
}

@article{deyoreo_bayesian_2014,
	title = {Bayesian Nonparametric Modeling for Multivariate Ordinal Regression},
	url = {http://arxiv.org/abs/1408.1027},
	abstract = {Univariate or multivariate ordinal responses are often assumed to arise from a latent continuous parametric distribution, with covariate effects which enter linearly. We introduce a Bayesian nonparametric modeling approach for univariate and multivariate ordinal regression, which is based on mixture modeling for the joint distribution of latent responses and covariates. The modeling framework enables highly flexible inference for ordinal regression relationships, avoiding assumptions of linearity or additivity in the covariate effects. In standard parametric ordinal regression models, computational challenges arise from identifiability constraints and estimation of parameters requiring nonstandard inferential techniques. A key feature of the nonparametric model is that it achieves inferential flexibility, while avoiding these difficulties. In particular, we establish full support of the nonparametric mixture model under fixed cut-off points that relate through discretization the latent continuous responses with the ordinal responses. The practical utility of the modeling approach is illustrated through application to two data sets from econometrics, an example involving regression relationships for ozone concentration, and a multirater agreement problem.},
	journaltitle = {{arXiv}:1408.1027 [stat]},
	author = {{DeYoreo}, Maria and Kottas, Athanasios},
	urldate = {2018-05-09},
	date = {2014-08-05},
	eprinttype = {arxiv},
	eprint = {1408.1027},
	keywords = {Statistics - Methodology},
	file = {arXiv.org Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/DADV5MX3/1408.html:text/html;deyoreo_kottas_2014_bayesian_nonparametric_modeling_for_multivariate_ordinal_regression.pdf:/home/nathan/Dropbox/njames/zotero_sync/deyoreo_kottas_2014_bayesian_nonparametric_modeling_for_multivariate_ordinal_regression.pdf:application/pdf}
}

@article{lawrence_bayesian_2008,
	title = {Bayesian Inference for Multivariate Ordinal Data Using Parameter Expansion},
	volume = {50},
	issn = {0040-1706},
	url = {https://doi.org/10.1198/004017008000000064},
	doi = {10.1198/004017008000000064},
	abstract = {Multivariate ordinal data arise in many applications. This article proposes a new, efficient method for Bayesian inference for multivariate probit models using Markov chain Monte Carlo techniques. The key idea is the novel use of parameter expansion to sample correlation matrices. A nice feature of the approach is that inference is performed using straightforward Gibbs sampling. Bayesian methods for model selection are also discussed. Our approach is motivated by a study of how women make decisions on taking medication to reduce the risk of breast cancer. Furthermore, we compare and contrast the performance of our approach with other methods.},
	pages = {182--191},
	number = {2},
	journaltitle = {Technometrics},
	author = {Lawrence, Earl and Bingham, Derek and Liu, Chuanhai and Nair, Vijayan N.},
	urldate = {2018-05-09},
	date = {2008-05-01},
	keywords = {Gibbs sampling, Multivariate, Ordinal data, Parameter expansion, Probit},
	file = {lawrence_et_al_2008_bayesian_inference_for_multivariate_ordinal_data_using_parameter_expansion.pdf:/home/nathan/Dropbox/njames/zotero_sync/lawrence_et_al_2008_bayesian_inference_for_multivariate_ordinal_data_using_parameter_expansion.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/JKAJQJZ4/004017008000000064.html:text/html}
}

@article{rahman_bayesian_2016,
	title = {Bayesian Quantile Regression for Ordinal Models},
	volume = {11},
	issn = {1936-0975},
	url = {http://projecteuclid.org/euclid.ba/1423083637},
	doi = {10.1214/15-BA939},
	abstract = {The paper introduces a Bayesian estimation method for quantile regression in univariate ordinal models. Two algorithms are presented that utilize the latent variable inferential framework of Albert and Chib (1993) and the normal-exponential mixture representation of the asymmetric Laplace distribution. Estimation utilizes Markov chain Monte Carlo simulation – either Gibbs sampling together with the Metropolis–Hastings algorithm or only Gibbs sampling. The algorithms are employed in two simulation studies and implemented in the analysis of problems in economics (educational attainment) and political economy (public opinion on extending “Bush Tax” cuts). Investigations into model comparison exemplify the practical utility of quantile ordinal models.},
	pages = {1--24},
	number = {1},
	journaltitle = {Bayesian Analysis},
	author = {Rahman, Mohammad Arshad},
	urldate = {2018-05-09},
	date = {2016-03},
	langid = {english},
	file = {rahman_2016_bayesian_quantile_regression_for_ordinal_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/rahman_2016_bayesian_quantile_regression_for_ordinal_models.pdf:application/pdf}
}

@article{albert_bayesian_1993,
	title = {Bayesian Analysis of Binary and Polychotomous Response Data},
	volume = {88},
	issn = {01621459},
	url = {https://www.jstor.org/stable/2290350?origin=crossref},
	doi = {10.2307/2290350},
	pages = {669},
	number = {422},
	journaltitle = {Journal of the American Statistical Association},
	author = {Albert, James H. and Chib, Siddhartha},
	urldate = {2018-05-09},
	date = {1993-06},
	langid = {english},
	keywords = {Gibbs sampling, Binary probit, Data Augmentation, Hierarchical Bayes modeling, Latent data, Logit model, Multinomial probit, Residual Analysis, Student-t link function},
	file = {albert_chib_1993_bayesian_analysis_of_binary_and_polychotomous_response_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/albert_chib_1993_bayesian_analysis_of_binary_and_polychotomous_response_data.pdf:application/pdf}
}

@article{dimitriev_approximate_nodate,
	title = {Approximate Bayesian Binary and Ordinal Regression with Structured Uncertainty in the Inputs},
	abstract = {We propose a novel approach to binary and ordinal prediction with structured uncertainty in the input variables. It is based on efﬁciently approximating the prediction model conditional on the inputs and then marginalizing the conditional model over the input space using Monte Carlo approximation. For efﬁciency, the well-known Laplace approximation is used for the binary case and we derive a similar approximation for the ordinal case. Empirical evaluation on sports data shows that the proposed approach substantially improves forecasting accuracy and highlights the severity of the problem of uncertainty in the input variables in sports.},
	pages = {5},
	author = {Dimitriev, Aleksandar and Štrumbelj, Erik},
	langid = {english},
	file = {dimitriev_štrumbelj_approximate_bayesian_binary_and_ordinal_regression_with_structured_uncertainty.pdf:/home/nathan/Dropbox/njames/zotero_sync/dimitriev_štrumbelj_approximate_bayesian_binary_and_ordinal_regression_with_structured_uncertainty.pdf:application/pdf}
}

@article{sandve_ten_2013,
	title = {Ten Simple Rules for Reproducible Computational Research},
	volume = {9},
	issn = {1553-7358},
	url = {http://dx.plos.org/10.1371/journal.pcbi.1003285},
	doi = {10.1371/journal.pcbi.1003285},
	pages = {e1003285},
	number = {10},
	journaltitle = {{PLoS} Computational Biology},
	author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
	editor = {Bourne, Philip E.},
	urldate = {2018-05-15},
	date = {2013-10-24},
	langid = {english},
	file = {sandve_et_al_2013_ten_simple_rules_for_reproducible_computational_research.pdf:/home/nathan/Dropbox/njames/zotero_sync/sandve_et_al_2013_ten_simple_rules_for_reproducible_computational_research.pdf:application/pdf}
}

@online{leek_five_2017,
	title = {Five ways to fix statistics},
	rights = {2018 Nature},
	url = {http://www.nature.com/articles/d41586-017-07522-z},
	abstract = {As debate rumbles on about how and how much poor statistics is to blame for poor reproducibility, Nature asked influential statisticians to recommend one change to improve science. The common theme? The problem is not our maths, but ourselves.},
	titleaddon = {Nature},
	type = {News},
	author = {Leek, Jeff and {McShane}, Blakeley B. and Gelman, Andrew and Colquhoun, David and Nuijten, Michèle B. and Goodman, Steven N.},
	urldate = {2018-05-18},
	date = {2017-11-28},
	doi = {10.1038/d41586-017-07522-z},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/DLDZ7IPR/d41586-017-07522-z.html:text/html}
}

@article{weiss_bayesian_2018,
	title = {Bayesian methods for analysis of biosimilar phase {III} trials},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.7814},
	doi = {10.1002/sim.7814},
	journaltitle = {Statistics in Medicine},
	author = {Weiss, Robert E. and Xia, Xiaomao and Zhang, Nan and Wang, Hui and Chi, Eric},
	urldate = {2018-05-24},
	date = {2018-05-23},
	langid = {english},
	file = {weiss_et_al_2018_bayesian_methods_for_analysis_of_biosimilar_phase_iii_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/weiss_et_al_2018_bayesian_methods_for_analysis_of_biosimilar_phase_iii_trials.pdf:application/pdf}
}

@online{noauthor_how_nodate,
	title = {How to Do Statistical Research},
	url = {http://stattrak.amstat.org/2013/06/01/how-to-do-statistical-research/},
	urldate = {2018-06-26},
	file = {How to Do Statistical Research:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/Z3ALNX5G/how-to-do-statistical-research.html:text/html}
}

@article{cario_modeling_nodate,
	title = {Modeling and Generating Random Vectors with Arbitrary Marginal Distributions and Correlation Matrix},
	abstract = {We describe a model for representing random vectors whose component random variables have arbitrary marginal distributions and correlation matrix, and describe how to generate data based upon this model for use in a stochastic simulation. The central idea is to transform a multivariate normal random vector into the desired random vector, so we refer to these vectors as having a {NORTA} ({NORmal} To Anything) distribution. {NORTA} vectors are most useful when the marginal distributions of the component random variables are neither identical nor from the same family of distributions, and they are particularly valuable when the dimension of the random vector is greater than two. Several numerical examples are provided.},
	pages = {19},
	author = {Cario, Marne C},
	langid = {english},
	file = {cario_modeling_and_generating_random_vectors_with_arbitrary_marginal_distributions.pdf:/home/nathan/Dropbox/njames/zotero_sync/cario_modeling_and_generating_random_vectors_with_arbitrary_marginal_distributions.pdf:application/pdf}
}

@article{kruschke_bayesian_nodate,
	title = {Bayesian estimation supersedes the t test},
	pages = {33},
	author = {Kruschke, John K},
	langid = {english},
	file = {kruschke_bayesian_estimation_supersedes_the_t_test.pdf:/home/nathan/Dropbox/njames/zotero_sync/kruschke_bayesian_estimation_supersedes_the_t_test.pdf:application/pdf}
}

@article{hobbs_commensurate_2012,
	title = {Commensurate Priors for Incorporating Historical Information in Clinical Trials Using General and Generalized Linear Models},
	volume = {7},
	issn = {1936-0975},
	url = {http://projecteuclid.org/euclid.ba/1346158779},
	doi = {10.1214/12-BA722},
	abstract = {Assessing between-study variability in the context of conventional random-effects meta-analysis is notoriously difficult when incorporating data from only a small number of historical studies. In order to borrow strength, historical and current data are often assumed to be fully homogeneous, but this can have drastic consequences for power and Type I error if the historical information is biased. In this paper, we propose empirical and fully Bayesian modifications of the commensurate prior model (Hobbs et al., 2011) extending Pocock (1976), and evaluate their frequentist and Bayesian properties for incorporating patient-level historical data using general and generalized linear mixed regression models. Our proposed commensurate prior models lead to preposterior admissible estimators that facilitate alternative bias-variance trade-offs than those offered by preexisting methodologies for incorporating historical data from a small number of historical studies. We also provide a sample analysis of a colon cancer trial comparing time-to-disease progression using a Weibull regression model.},
	pages = {639--674},
	number = {3},
	journaltitle = {Bayesian Analysis},
	author = {Hobbs, Brian P. and Sargent, Daniel J. and Carlin, Bradley P.},
	urldate = {2018-06-27},
	date = {2012-09},
	langid = {english},
	file = {hobbs_et_al_2012_commensurate_priors_for_incorporating_historical_information_in_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/hobbs_et_al_2012_commensurate_priors_for_incorporating_historical_information_in_clinical_trials.pdf:application/pdf}
}

@article{hobbs_hierarchical_2011,
	title = {Hierarchical Commensurate and Power Prior Models for Adaptive Incorporation of Historical Information in Clinical Trials},
	volume = {67},
	issn = {0006341X},
	url = {http://doi.wiley.com/10.1111/j.1541-0420.2011.01564.x},
	doi = {10.1111/j.1541-0420.2011.01564.x},
	abstract = {Bayesian clinical trial designs offer the possibility of a substantially reduced sample size, increased statistical power, and reductions in cost and ethical hazard. However when prior and current information conflict, Bayesian methods can lead to higher than expected Type I error, as well as the possibility of a costlier and lengthier trial. This motivates an investigation of the feasibility of hierarchical Bayesian methods for incorporating historical data that are adaptively robust to prior information that reveals itself to be inconsistent with the accumulating experimental data. In this paper, we present several models that allow for the commensurability of the information in the historical and current data to determine how much historical information is used. A primary tool is elaborating the traditional power prior approach based upon a measure of commensurability for Gaussian data. We compare the frequentist performance of several methods using simulations, and close with an example of a colon cancer trial that illustrates a linear models extension of our adaptive borrowing approach. Our proposed methods produce more precise estimates of the model parameters, in particular conferring statistical significance to the observed reduction in tumor size for the experimental regimen as compared to the control regimen.},
	pages = {1047--1056},
	number = {3},
	journaltitle = {Biometrics},
	author = {Hobbs, Brian P. and Carlin, Bradley P. and Mandrekar, Sumithra J. and Sargent, Daniel J.},
	urldate = {2018-06-27},
	date = {2011-09},
	langid = {english},
	file = {hobbs_et_al_2011_hierarchical_commensurate_and_power_prior_models_for_adaptive_incorporation_of.pdf:/home/nathan/Dropbox/njames/zotero_sync/hobbs_et_al_2011_hierarchical_commensurate_and_power_prior_models_for_adaptive_incorporation_of.pdf:application/pdf}
}

@article{viele_use_2014,
	title = {Use of historical control data for assessing treatment effects in clinical trials},
	volume = {13},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1589},
	doi = {10.1002/pst.1589},
	abstract = {Clinical trials rarely, if ever, occur in a vacuum. Generally, large amounts of clinical data are available prior to the start of a study, particularly on the current study’s control arm. There is obvious appeal in using (i.e., ‘borrowing’) this information. With historical data providing information on the control arm, more trial resources can be devoted to the novel treatment while retaining accurate estimates of the current control arm parameters. This can result in more accurate point estimates, increased power, and reduced type I error in clinical trials, provided the historical information is sufficiently similar to the current control data. If this assumption of similarity is not satisfied, however, one can acquire increased mean square error of point estimates due to bias and either reduced power or increased type I error depending on the direction of the bias. In this manuscript, we review several methods for historical borrowing, illustrating how key parameters in each method affect borrowing behavior, and then, we compare these methods on the basis of mean square error, power and type I error. We emphasize two main themes. First, we discuss the idea of ‘dynamic’ (versus ‘static’) borrowing. Second, we emphasize the decision process involved in determining whether or not to include historical borrowing in terms of the perceived likelihood that the current control arm is sufficiently similar to the historical data. Our goal is to provide a clear review of the key issues involved in historical borrowing and provide a comparison of several methods useful for practitioners.},
	pages = {41--54},
	number = {1},
	journaltitle = {Pharmaceutical Statistics},
	author = {Viele, Kert and Berry, Scott and Neuenschwander, Beat and Amzal, Billy and Chen, Fang and Enas, Nathan and Hobbs, Brian and Ibrahim, Joseph G. and Kinnersley, Nelson and Lindborg, Stacy and Micallef, Sandrine and Roychoudhury, Satrajit and Thompson, Laura},
	urldate = {2018-06-27},
	date = {2014-01},
	langid = {english},
	file = {viele_et_al_2014_use_of_historical_control_data_for_assessing_treatment_effects_in_clinical.pdf:/home/nathan/Dropbox/njames/zotero_sync/viele_et_al_2014_use_of_historical_control_data_for_assessing_treatment_effects_in_clinical.pdf:application/pdf}
}

@article{han_covariate-adjusted_2017,
	title = {Covariate-adjusted borrowing of historical control data in randomized clinical trials},
	volume = {16},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1815},
	doi = {10.1002/pst.1815},
	pages = {296--308},
	number = {4},
	journaltitle = {Pharmaceutical Statistics},
	author = {Han, Baoguang and Zhan, Jia and John Zhong, Z. and Liu, Dawei and Lindborg, Stacy},
	urldate = {2018-06-27},
	date = {2017-07},
	langid = {english},
	file = {han_et_al_2017_covariate-adjusted_borrowing_of_historical_control_data_in_randomized_clinical.pdf:/home/nathan/Dropbox/njames/zotero_sync/han_et_al_2017_covariate-adjusted_borrowing_of_historical_control_data_in_randomized_clinical.pdf:application/pdf}
}

@article{galwey_supplementation_2017,
	title = {Supplementation of a clinical trial by historical control data: is the prospect of dynamic borrowing an illusion?: Historical control data: is dynamic borrowing an illusion?},
	volume = {36},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.7180},
	doi = {10.1002/sim.7180},
	shorttitle = {Supplementation of a clinical trial by historical control data},
	pages = {899--916},
	number = {6},
	journaltitle = {Statistics in Medicine},
	author = {Galwey, N. W.},
	urldate = {2018-06-27},
	date = {2017-03-15},
	langid = {english},
	file = {galwey_2017_supplementation_of_a_clinical_trial_by_historical_control_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/galwey_2017_supplementation_of_a_clinical_trial_by_historical_control_data.pdf:application/pdf}
}

@article{yin_bayesian_2017,
	title = {Bayesian randomized clinical trials: From fixed to adaptive design},
	volume = {59},
	issn = {15517144},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1551714416304980},
	doi = {10.1016/j.cct.2017.04.010},
	shorttitle = {Bayesian randomized clinical trials},
	abstract = {Randomized controlled studies are the gold standard for phase {III} clinical trials. Using α-spending functions to control the overall type I error rate, group sequential methods are well established and have been dominating phase {III} studies. Bayesian randomized design, on the other hand, can be viewed as a complement instead of competitive approach to the frequentist methods. For the ﬁxed Bayesian design, the hypothesis testing can be cast in the posterior probability or Bayes factor framework, which has a direct link to the frequentist type I error rate. Bayesian group sequential design relies upon Bayesian decision-theoretic approaches based on backward induction, which is often computationally intensive. Compared with the frequentist approaches, Bayesian methods have several advantages. The posterior predictive probability serves as a useful and convenient tool for trial monitoring, and can be updated at any time as the data accrue during the trial. The Bayesian decisiontheoretic framework possesses a direct link to the decision making in the practical setting, and can be modeled more realistically to reﬂect the actual cost–beneﬁt analysis during the drug development process. Other merits include the possibility of hierarchical modeling and the use of informative priors, which would lead to a more comprehensive utilization of information from both historical and longitudinal data. From ﬁxed to adaptive design, we focus on Bayesian randomized controlled clinical trials and make extensive comparisons with frequentist counterparts through numerical studies.},
	pages = {77--86},
	journaltitle = {Contemporary Clinical Trials},
	author = {Yin, Guosheng and Lam, Chi Kin and Shi, Haolun},
	urldate = {2018-06-27},
	date = {2017-08},
	langid = {english},
	file = {yin_et_al_2017_bayesian_randomized_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/yin_et_al_2017_bayesian_randomized_clinical_trials.pdf:application/pdf}
}

@article{jack_lee_bayesian_2012,
	title = {Bayesian clinical trials in action},
	volume = {31},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.5404},
	doi = {10.1002/sim.5404},
	abstract = {Although the frequentist paradigm has been the predominant approach to clinical trial design since the 1940s, it has several notable limitations. The alternative Bayesian paradigm has been greatly enhanced by advancements in computational algorithms and computer hardware. Compared to its frequentist counterpart, the Bayesian framework has several unique advantages, and its incorporation into clinical trial design is occurring more frequently. Using an extensive literature review to assess how Bayesian methods are used in clinical trials, we find them most commonly used for dose finding, efficacy monitoring, toxicity monitoring, diagnosis/decision making, and for studying pharmacokinetics/pharmacodynamics. The additional infrastructure required for implementing Bayesian methods in clinical trials may include specialized software programs to run the study design, simulation, and analysis, and Web-based applications, which are particularly useful for timely data entry and analysis. Trial success requires not only the development of proper tools but also timely and accurate execution of data entry, quality control, adaptive randomization, and Bayesian computation. The relative merit of the Bayesian and frequentist approaches continues to be the subject of debate in statistics. However, more evidence can be found showing the convergence of the two camps, at least at the practical level. Ultimately, better clinical trial methods lead to more efficient designs, lower sample sizes, more accurate conclusions, and better outcomes for patients enrolled in the trials. Bayesian methods offer attractive alternatives for better trials. More such trials should be designed and conducted to refine the approach and demonstrate its real benefit in action.},
	pages = {2955--2972},
	number = {25},
	journaltitle = {Statistics in Medicine},
	author = {Jack Lee, J. and Chu, Caleb T.},
	urldate = {2018-06-27},
	date = {2012-11-10},
	langid = {english},
	file = {jack_lee_chu_2012_bayesian_clinical_trials_in_action.pdf:/home/nathan/Dropbox/njames/zotero_sync/jack_lee_chu_2012_bayesian_clinical_trials_in_action.pdf:application/pdf}
}

@article{brard_bayesian_2017,
	title = {Bayesian survival analysis in clinical trials: What methods are used in practice?},
	volume = {14},
	issn = {1740-7745, 1740-7753},
	url = {http://journals.sagepub.com/doi/10.1177/1740774516673362},
	doi = {10.1177/1740774516673362},
	shorttitle = {Bayesian survival analysis in clinical trials},
	abstract = {Background: Bayesian statistics are an appealing alternative to the traditional frequentist approach to designing, analysing, and reporting of clinical trials, especially in rare diseases. Time-to-event endpoints are widely used in many medical fields. There are additional complexities to designing Bayesian survival trials which arise from the need to specify a model for the survival distribution. The objective of this article was to critically review the use and reporting of Bayesian methods in survival trials.
Methods: A systematic review of clinical trials using Bayesian survival analyses was performed through {PubMed} and Web of Science databases. This was complemented by a full text search of the online repositories of pre-selected journals. Cost-effectiveness, dose-finding studies, meta-analyses, and methodological papers using clinical trials were excluded.
Results: In total, 28 articles met the inclusion criteria, 25 were original reports of clinical trials and 3 were re-analyses of a clinical trial. Most trials were in oncology (n = 25), were randomised controlled (n = 21) phase {III} trials (n = 13), and half considered a rare disease (n = 13). Bayesian approaches were used for monitoring in 14 trials and for the final analysis only in 14 trials. In the latter case, Bayesian survival analyses were used for the primary analysis in four cases, for the secondary analysis in seven cases, and for the trial re-analysis in three cases. Overall, 12 articles reported fitting Bayesian regression models (semi-parametric, n = 3; parametric, n = 9). Prior distributions were often incompletely reported: 20 articles did not define the prior distribution used for the parameter of interest. Over half of the trials used only non-informative priors for monitoring and the final analysis (n = 12) when it was specified. Indeed, no articles fitting Bayesian regression models placed informative priors on the parameter of interest. The prior for the treatment effect was based on historical data in only four trials. Decision rules were pre-defined in eight cases when trials used Bayesian monitoring, and in only one case when trials adopted a Bayesian approach to the final analysis.
Conclusion: Few trials implemented a Bayesian survival analysis and few incorporated external data into priors. There is scope to improve the quality of reporting of Bayesian methods in survival trials. Extension of the Consolidated Standards of Reporting Trials statement for reporting Bayesian clinical trials is recommended.},
	pages = {78--87},
	number = {1},
	journaltitle = {Clinical Trials: Journal of the Society for Clinical Trials},
	author = {Brard, Caroline and Le Teuff, Gwénaël and Le Deley, Marie-Cécile and Hampson, Lisa V},
	urldate = {2018-06-27},
	date = {2017-02},
	langid = {english},
	file = {brard_et_al_2017_bayesian_survival_analysis_in_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/brard_et_al_2017_bayesian_survival_analysis_in_clinical_trials.pdf:application/pdf}
}

@article{durante_bayesian_2018,
	title = {Bayesian Inference and Testing of Group Differences in Brain Networks},
	volume = {13},
	issn = {1936-0975},
	url = {https://projecteuclid.org/euclid.ba/1479179031},
	doi = {10.1214/16-BA1030},
	abstract = {Network data are increasingly collected along with other variables of interest. Our motivation is drawn from neurophysiology studies measuring brain connectivity networks for a sample of individuals along with their membership to a low or high creative reasoning group. It is of paramount importance to develop statistical methods for testing of global and local changes in the structural interconnections among brain regions across groups. We develop a general Bayesian procedure for inference and testing of group diﬀerences in the network structure, which relies on a nonparametric representation for the conditional probability mass function associated with a network-valued random variable. By leveraging a mixture of low-rank factorizations, we allow simple global and local hypothesis testing adjusting for multiplicity. An eﬃcient Gibbs sampler is deﬁned for posterior computation. We provide theoretical results on the ﬂexibility of the model and assess testing performance in simulations. The approach is applied to provide novel insights on the relationships between human brain networks and creativity.},
	pages = {29--58},
	number = {1},
	journaltitle = {Bayesian Analysis},
	author = {Durante, Daniele and Dunson, David B.},
	urldate = {2018-06-27},
	date = {2018-03},
	langid = {english},
	file = {durante_dunson_2018_bayesian_inference_and_testing_of_group_differences_in_brain_networks.pdf:/home/nathan/Dropbox/njames/zotero_sync/durante_dunson_2018_bayesian_inference_and_testing_of_group_differences_in_brain_networks.pdf:application/pdf}
}

@article{paulon_joint_2018,
	title = {Joint modeling of recurrent events and survival: a Bayesian non-parametric approach},
	issn = {1465-4644, 1468-4357},
	url = {https://academic.oup.com/biostatistics/advance-article/doi/10.1093/biostatistics/kxy026/5050476},
	doi = {10.1093/biostatistics/kxy026},
	shorttitle = {Joint modeling of recurrent events and survival},
	abstract = {Heart failure ({HF}) is one of the main causes of morbidity, hospitalization, and death in the western world, and the economic burden associated with {HF} management is relevant and expected to increase in the future. We consider hospitalization data for {HF} in the most populated Italian Region, Lombardia. Data were extracted from the administrative data warehouse of the regional healthcare system. The main clinical outcome of interest is time to death and research focus is on investigating how recurrent hospitalizations affect the time to event. The main contribution of the article is to develop a joint model for gap times between consecutive rehospitalizations and survival time. The probability models for the gap times and for the survival outcome share a common patient speciﬁc frailty term. Using a ﬂexible Dirichlet process model for the random-effects distribution accounts for patient heterogeneity in recurrent event trajectories. Moreover, the joint model allows for dependent censoring of gap times by death or administrative reasons and for the correlations between different gap times for the same individual. It is straightforward to include covariates in the survival and/or recurrence process through the speciﬁcation of appropriate regression terms. The main advantages of the proposed methodology are wide applicability, ease of interpretation, and efﬁcient computations. Posterior inference is implemented through Markov chain Monte Carlo methods.},
	journaltitle = {Biostatistics},
	author = {Paulon, Giorgio and De Iorio, Maria and Guglielmi, Alessandra and Ieva, Francesca},
	urldate = {2018-07-09},
	date = {2018-07-06},
	langid = {english},
	file = {paulon_et_al_2018_joint_modeling_of_recurrent_events_and_survival.pdf:/home/nathan/Dropbox/njames/zotero_sync/paulon_et_al_2018_joint_modeling_of_recurrent_events_and_survival.pdf:application/pdf}
}

@article{kurum_copula_2018,
	title = {A copula model for joint modeling of longitudinal and time-invariant mixed outcomes: Joint modeling of longitudinal and time-invariant mixed outcomes},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.7855},
	doi = {10.1002/sim.7855},
	shorttitle = {A copula model for joint modeling of longitudinal and time-invariant mixed outcomes},
	pages = {1--13},
	journaltitle = {Statistics in Medicine},
	author = {Kürüm, Esra and Jeske, Daniel R. and Behrendt, Carolyn E. and Lee, Peter},
	urldate = {2018-07-09},
	date = {2018-07-02},
	langid = {english},
	file = {kürüm_et_al_2018_a_copula_model_for_joint_modeling_of_longitudinal_and_time-invariant_mixed.pdf:/home/nathan/Dropbox/njames/zotero_sync/kürüm_et_al_2018_a_copula_model_for_joint_modeling_of_longitudinal_and_time-invariant_mixed.pdf:application/pdf}
}

@article{alhamzawi_bayesian_2016,
	title = {Bayesian Quantile Regression for Ordinal Longitudinal Data},
	url = {http://arxiv.org/abs/1603.00297},
	abstract = {Since the pioneering work by Koenker and Bassett (1978), quantile regression models and its applications have become increasingly popular and important for research in many areas. In this paper, a random eﬀects ordinal quantile regression model is proposed for analysis of longitudinal data with ordinal outcome of interest. An eﬃcient Gibbs sampling algorithm was derived for ﬁtting the model to the data based on a location-scale mixture representation of the skewed double exponential distribution. The proposed approach is illustrated using simulated data and a real data example. This is the ﬁrst work to discuss quantile regression for analysis of longitudinal data with ordinal outcome.},
	journaltitle = {{arXiv}:1603.00297 [stat]},
	author = {Alhamzawi, Rahim},
	urldate = {2018-07-17},
	date = {2016-02-27},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1603.00297},
	keywords = {Statistics - Computation, Bayesian inference, ordinal regression model, Cut-points, Longitudinal data, Quantile regression},
	file = {alhamzawi_2016_bayesian_quantile_regression_for_ordinal_longitudinal_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/alhamzawi_2016_bayesian_quantile_regression_for_ordinal_longitudinal_data.pdf:application/pdf}
}

@article{schoenfeld_bayesian_2009,
	title = {Bayesian design using adult data to augment pediatric trials},
	volume = {6},
	issn = {1740-7745, 1740-7753},
	url = {http://journals.sagepub.com/doi/10.1177/1740774509339238},
	doi = {10.1177/1740774509339238},
	abstract = {Background—It can be difficult to conduct pediatric clinical trials because there is often a low incidence of the disease in children, making accrual slow or infeasible. In addition, low mortality and morbidity in this population make it impractical to achieve adequate power. In this case, the only evidence for treatment efficacy comes from adult trials. Since pediatric care providers are accustomed to relying on evidence from adult studies, it is natural to consider borrowing information from adult trials.
Purpose—The goal of this article is to propose a Bayesian approach to the design and analysis of pediatric trials to allow borrowing strength from previous or simultaneous adult trials.
Methods—We apply a hierarchical model for which the efficacy parameter from the adult trial and that of the pediatric trail are considered to be draws from a normal distribution. The choice of (the variance of) this distribution is guided by discussion with medical experts. We show that with this information, one can calculate the sample size required for the pediatric trial. We discuss how inference of these studies in pediatric populations depends on the parameter that captures the similarity of the treatment efficacy in adults compared to children.
Results—The Bayesian approach can substantially increase the power of a pediatric clinical trial (or equivalently decrease the number of subjects required) by formally leveraging the data from the adult trial. Limitations—Our method relies on obtaining a value for the inter-study variability,, which may be difficult to describe to a clinical investigator.
Conclusions—The Bayesian approach has the potential of making pediatric clinical trials feasible because it has the effect of borrowing strength from adult trials, thus requiring a smaller pediatric trial to show efficacy of a drug in children.},
	pages = {297--304},
	number = {4},
	journaltitle = {Clinical Trials: Journal of the Society for Clinical Trials},
	author = {Schoenfeld, David A and {Hui Zheng} and Finkelstein, Dianne M},
	urldate = {2018-07-17},
	date = {2009-08},
	langid = {english},
	file = {schoenfeld_et_al_2009_bayesian_design_using_adult_data_to_augment_pediatric_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/schoenfeld_et_al_2009_bayesian_design_using_adult_data_to_augment_pediatric_trials.pdf:application/pdf}
}

@article{rijmen_bayesian_2008,
	title = {Bayesian networks with a logistic regression model for the conditional probabilities},
	volume = {48},
	issn = {0888613X},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0888613X08000121},
	doi = {10.1016/j.ijar.2008.01.001},
	abstract = {Logistic regression techniques can be used to restrict the conditional probabilities of a Bayesian network for discrete variables. More speciﬁcally, each variable of the network can be modeled through a logistic regression model, in which the parents of the variable deﬁne the covariates. When all main eﬀects and interactions between the parent variables are incorporated as covariates, the conditional probabilities are estimated without restrictions, as in a traditional Bayesian network. By incorporating interaction terms up to a speciﬁc order only, the number of parameters can be drastically reduced. Furthermore, ordered logistic regression can be used when the categories of a variable are ordered, resulting in even more parsimonious models. Parameters are estimated by a modiﬁed junction tree algorithm. The approach is illustrated with the Alarm network.},
	pages = {659--666},
	number = {2},
	journaltitle = {International Journal of Approximate Reasoning},
	author = {Rijmen, Frank},
	urldate = {2018-07-17},
	date = {2008-06},
	langid = {english},
	file = {rijmen_2008_bayesian_networks_with_a_logistic_regression_model_for_the_conditional.pdf:/home/nathan/Dropbox/njames/zotero_sync/rijmen_2008_bayesian_networks_with_a_logistic_regression_model_for_the_conditional.pdf:application/pdf}
}

@article{ishwaran_univariate_2000,
	title = {Univariate and multirater ordinal cumulative link regression with covariate specific cutpoints},
	volume = {28},
	issn = {03195724, 1708945X},
	url = {http://doi.wiley.com/10.2307/3315912},
	doi = {10.2307/3315912},
	abstract = {The author considers a reparameterized version of the Bayesian ordinal cumulative link regression model as a tool for exploring relationships between covariates and “cutpoint” parameters. The use of this parameterization allows to ﬁt models using the leapfrog hybrid Monte Carlo method, and to bypass latent variable data augmentation and the slow convergence of the cutpoints which it usually entails. The proposed Gibbs sampler is not model speciﬁc and can be easily modiﬁed to handle diﬀerent link functions. The approach is illustrated by considering data from a pediatric radiology study.},
	pages = {715--730},
	number = {4},
	journaltitle = {Canadian Journal of Statistics},
	author = {Ishwaran, Hemant},
	urldate = {2018-07-17},
	date = {2000-12},
	langid = {english},
	file = {ishwaran_2000_univariate_and_multirater_ordinal_cumulative_link_regression_with_covariate.pdf:/home/nathan/Dropbox/njames/zotero_sync/ishwaran_2000_univariate_and_multirater_ordinal_cumulative_link_regression_with_covariate.pdf:application/pdf;ishwaran_2000_univariate_and_multirater_ordinal_cumulative_link_regression_with_covariate.pdf:/home/nathan/Dropbox/njames/zotero_sync/ishwaran_2000_univariate_and_multirater_ordinal_cumulative_link_regression_with_covariate2.pdf:application/pdf}
}

@article{ntzoufras_bayesian_2003,
	title = {Bayesian variable and link determination for generalised linear models},
	volume = {111},
	issn = {03783758},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0378375802002987},
	doi = {10.1016/S0378-3758(02)00298-7},
	abstract = {In this paper, we describe full Bayesian inference for generalised linear models where uncertainty exists about the structure of the linear predictor, the linear parameters and the link function. Choice of suitable prior distributions is discussed in detail and we propose an e cient reversible jump Markov chain Monte-Carlo algorithm for calculating posterior summaries. We illustrate our method with two data examples.},
	pages = {165--180},
	number = {1},
	journaltitle = {Journal of Statistical Planning and Inference},
	author = {Ntzoufras, Ioannis and Dellaportas, Petros and Forster, Jonathan J},
	urldate = {2018-07-17},
	date = {2003-02},
	langid = {english},
	file = {ntzoufras_et_al_2003_bayesian_variable_and_link_determination_for_generalised_linear_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/ntzoufras_et_al_2003_bayesian_variable_and_link_determination_for_generalised_linear_models.pdf:application/pdf}
}

@article{lang_bayesian_1999,
	title = {Bayesian ordinal and binary regression models with a parametric family of mixture links},
	volume = {31},
	issn = {01679473},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0167947399000079},
	doi = {10.1016/S0167-9473(99)00007-9},
	abstract = {An ordinal and binary regression model with parametric link is introduced. The link is a member of a one-parameter family of “mixture links”, a family that comprises smooth mixtures of the extreme minimum-value, extreme maximum-value, and logistic distributions. A Bayesian version of this exible model serves as a vehicle for introducing a priori information regarding the choice of link. Owing to non-conjugacy, posterior and predictive distributions are approximated using Markov chain Monte Carlo simulation methods. Link-independent, Bayesian interpretations of covariate e ects are described. The method is illustrated through the analyses of several data sets. c 1999 Elsevier Science B.V. All rights reserved.},
	pages = {59--87},
	number = {1},
	journaltitle = {Computational Statistics \& Data Analysis},
	author = {Lang, Joseph B.},
	urldate = {2018-07-17},
	date = {1999-07},
	langid = {english},
	file = {lang_1999_bayesian_ordinal_and_binary_regression_models_with_a_parametric_family_of.pdf:/home/nathan/Dropbox/njames/zotero_sync/lang_1999_bayesian_ordinal_and_binary_regression_models_with_a_parametric_family_of.pdf:application/pdf}
}

@article{mallick_generalized_1994,
	title = {Generalized Linear Models with Unknown Link Functions},
	volume = {81},
	issn = {00063444},
	url = {https://www.jstor.org/stable/2336954?origin=crossref},
	doi = {10.2307/2336954},
	abstract = {Generalized linear models are widely used by data analysts. However, the choice of the link function is often made arbitrarily. Here we permit the data to estimate the link function by incorporating it as an unknown in the model. Since the link function is usually taken to be strictly increasing, by a strictly increasing transformation of its range to the unit interval we can model it as a strictly increasing cumulative distribution function. The transformation results in a domain which is [0, 1]. We model the cumulative distribution function as a mixture of Beta cumulative distribution functions, noting that the latter family is dense within the collection of all continuous densities on [0, 1]. For the fitting of the model we take a Bayesian approach, encouraging vague priors, to focus upon the likelihood. We discuss choices of such priors as well as the integrability of the resultant posteriors. Implementation of the Bayesian approach is carried out using sampling based methods, in particular, a tailored Metropolis-within-Gibbs algorithm. An illustrative example utilising data involving wave damage to cargo ships is provided.},
	pages = {237},
	number = {2},
	journaltitle = {Biometrika},
	author = {Mallick, Bani K. and Gelfand, Alan E.},
	urldate = {2018-07-17},
	date = {1994-06},
	langid = {english},
	file = {mallick_gelfand_1994_generalized_linear_models_with_unknown_link_functions.pdf:/home/nathan/Dropbox/njames/zotero_sync/mallick_gelfand_1994_generalized_linear_models_with_unknown_link_functions.pdf:application/pdf}
}

@article{albert_bayesian_1997,
	title = {Bayesian Methods for Cumulative, Sequential and Two-step Ordinal Data Regression Models},
	abstract = {This paper considers the fitting, criticism and comparison of three ordinal regression models \{ the cumulative, sequential and two-step models. E cient algorithms based on Markov chain Monte Carlo methods are developed for each model. In the case of the cumulative model, a new Metropolis-Hastings procedure to sample the cut points is proposed. This procedure relies on a simple transformation of the cut-points that leaves the transformed cut-points unordered. For comparing these models, we develop a coherent approach based on marginal likelihoods and Bayes factors. To help in the assignment of prior distributions to regression parameters and the cut-points, di erent methods for forming and representing prior beliefs are provided. One set of methods is based on the idea of a training sample and a prior imaginary sample. Another method is based on the direct assessment of distributions on the multinomial response, followed by change of variable to a distribution on the parameters of the model. All of the ideas are illustrated in two data sets, one from the National Longitudinal Survey of Youth in the {US} and the other from the General Social Survey in Canada.},
	pages = {33},
	author = {Albert, Jim and Chib, Siddhartha},
	date = {1997-07-19},
	langid = {english},
	file = {albert_chib_bayesian_methods_for_cumulative,_sequential_and_two-step_ordinal_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/albert_chib_bayesian_methods_for_cumulative,_sequential_and_two-step_ordinal_data.pdf:application/pdf}
}

@article{spiegelhalter_bayesian_2002,
	title = {Bayesian measures of model complexity and fit},
	volume = {64},
	issn = {1369-7412, 1467-9868},
	url = {http://doi.wiley.com/10.1111/1467-9868.00353},
	doi = {10.1111/1467-9868.00353},
	abstract = {We consider the problem of comparing complex hierarchical models in which the number of parameters is not clearly deﬁned. Using an information theoretic argument we derive a measure {pD} for the effective number of parameters in a model as the difference between the posterior mean of the deviance and the deviance at the posterior means of the parameters of interest. In general {pD} approximately corresponds to the trace of the product of Fisher’s information and the posterior covariance, which in normal models is the trace of the ‘hat’ matrix projecting observations onto ﬁtted values. Its properties in exponential families are explored. The posterior mean deviance is suggested as a Bayesian measure of ﬁt or adequacy, and the contributions of individual observations to the ﬁt and complexity can give rise to a diagnostic plot of deviance residuals against leverages. Adding {pD} to the posterior mean deviance gives a deviance information criterion for comparing models, which is related to other information criteria and has an approximate decision theoretic justiﬁcation. The procedure is illustrated in some examples, and comparisons are drawn with alternative Bayesian and classical proposals. Throughout it is emphasized that the quantities required are trivial to compute in a Markov chain Monte Carlo analysis.},
	pages = {583--639},
	number = {4},
	journaltitle = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Spiegelhalter, David J. and Best, Nicola G. and Carlin, Bradley P. and van der Linde, Angelika},
	urldate = {2018-07-17},
	date = {2002-10},
	langid = {english},
	file = {spiegelhalter_et_al_2002_bayesian_measures_of_model_complexity_and_fit.pdf:/home/nathan/Dropbox/njames/zotero_sync/spiegelhalter_et_al_2002_bayesian_measures_of_model_complexity_and_fit.pdf:application/pdf}
}

@article{li_bayesian_nodate,
	title = {Bayesian inference for joint modelling of longitudinally continuous, binary and ordinal events},
	pages = {4},
	author = {Li, Qiuju and Pan, Jianxin and Belcher, John},
	langid = {english},
	file = {li_et_al_bayesian_inference_for_joint_modelling_of_longitudinally_continuous,_binary_and.pdf:/home/nathan/Dropbox/njames/zotero_sync/li_et_al_bayesian_inference_for_joint_modelling_of_longitudinally_continuous,_binary_and.pdf:application/pdf}
}

@article{gelman_stan:_2015,
	title = {Stan: A Probabilistic Programming Language for Bayesian Inference and Optimization},
	volume = {40},
	issn = {1076-9986, 1935-1054},
	url = {http://journals.sagepub.com/doi/10.3102/1076998615606113},
	doi = {10.3102/1076998615606113},
	shorttitle = {Stan},
	abstract = {Stan is a free and open-source C++ program that performs Bayesian inference or optimization for arbitrary user-speciﬁed models and can be called from the command line, R, Python, Matlab, or Julia, and has great promise for ﬁtting large and complex statistical models in many areas of application. We discuss Stan from users’ and developers’ perspectives and illustrate with a simple but nontrivial nonlinear regression example.},
	pages = {530--543},
	number = {5},
	journaltitle = {Journal of Educational and Behavioral Statistics},
	author = {Gelman, Andrew and Lee, Daniel and Guo, Jiqiang},
	urldate = {2018-07-17},
	date = {2015-10},
	langid = {english},
	file = {gelman_et_al_2015_stan.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_et_al_2015_stan.pdf:application/pdf}
}

@article{jordan_what_2011,
	title = {What are the open problems in Bayesian Statistics?},
	pages = {4},
	author = {Jordan, Michael I},
	date = {2011},
	langid = {english},
	file = {jordan_2011_what_are_the_open_problems_in_bayesian_statistics.pdf:/home/nathan/Dropbox/njames/zotero_sync/jordan_2011_what_are_the_open_problems_in_bayesian_statistics.pdf:application/pdf}
}

@article{genest_everything_2007,
	title = {Everything You Always Wanted to Know about Copula Modeling but Were Afraid to Ask},
	volume = {12},
	issn = {1084-0699, 1943-5584},
	url = {http://ascelibrary.org/doi/10.1061/%28ASCE%291084-0699%282007%2912%3A4%28347%29},
	doi = {10.1061/(ASCE)1084-0699(2007)12:4(347)},
	abstract = {This paper presents an introduction to inference for copula models, based on rank methods. By working out in detail a small, ﬁctitious numerical example, the writers exhibit the various steps involved in investigating the dependence between two random variables and in modeling it using copulas. Simple graphical tools and numerical techniques are presented for selecting an appropriate model, estimating its parameters, and checking its goodness-of-ﬁt. A larger, realistic application of the methodology to hydrological data is then presented.},
	pages = {347--368},
	number = {4},
	journaltitle = {Journal of Hydrologic Engineering},
	author = {Genest, Christian and Favre, Anne-Catherine},
	urldate = {2018-07-17},
	date = {2007-07},
	langid = {english},
	file = {genest_favre_2007_everything_you_always_wanted_to_know_about_copula_modeling_but_were_afraid_to.pdf:/home/nathan/Dropbox/njames/zotero_sync/genest_favre_2007_everything_you_always_wanted_to_know_about_copula_modeling_but_were_afraid_to.pdf:application/pdf}
}

@article{li_extending_2015,
	title = {Extending approximate Bayesian computation methods to high dimensions via a Gaussian copula model},
	url = {http://arxiv.org/abs/1504.04093},
	abstract = {Approximate Bayesian computation ({ABC}) refers to a family of inference methods used in the Bayesian analysis of complex models where evaluation of the likelihood is difﬁcult. Conventional {ABC} methods often suﬀer from the curse of dimensionality, and a marginal adjustment strategy was recently introduced in the literature to improve the performance of {ABC} algorithms in high-dimensional problems. The marginal adjustment approach is extended using a Gaussian copula approximation. The method ﬁrst estimates the bivariate posterior for each pair of parameters separately using a 2-dimensional Gaussian copula, and then combines these estimates together to estimate the joint posterior. The approximation works well in large sample settings when the posterior is approximately normal, but also works well in many cases which are far from that situation due to the nonparametric estimation of the marginal posterior distributions. If each bivariate posterior distribution can be well estimated with a lowdimensional {ABC} analysis then this Gaussian copula method can extend {ABC} methods to problems of high dimension. The method also results in an analytic expression for the approximate posterior which is useful for many purposes such as approximation of the likelihood itself. This method is illustrated with several examples.},
	journaltitle = {{arXiv}:1504.04093 [stat]},
	author = {Li, Jingjing and Nott, David J. and Fan, Yanan and Sisson, Scott A.},
	urldate = {2018-07-17},
	date = {2015-04-15},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1504.04093},
	keywords = {Statistics - Computation},
	file = {li_et_al_2015_extending_approximate_bayesian_computation_methods_to_high_dimensions_via_a.pdf:/home/nathan/Dropbox/njames/zotero_sync/li_et_al_2015_extending_approximate_bayesian_computation_methods_to_high_dimensions_via_a2.pdf:application/pdf}
}

@article{park_simple_1996,
	title = {A Simple Method for Generating Correlated Binary Variates},
	volume = {50},
	issn = {00031305},
	url = {https://www.jstor.org/stable/2684925?origin=crossref},
	doi = {10.2307/2684925},
	pages = {306},
	number = {4},
	journaltitle = {The American Statistician},
	author = {Park, Chul Gyu and Park, Taesung and Shin, Dong Wan},
	urldate = {2018-07-17},
	date = {1996-11},
	langid = {english},
	file = {park_et_al_1996_a_simple_method_for_generating_correlated_binary_variates.pdf:/home/nathan/Dropbox/njames/zotero_sync/park_et_al_1996_a_simple_method_for_generating_correlated_binary_variates.pdf:application/pdf}
}

@article{riviere_competing_2015,
	title = {Competing designs for drug combination in phase I dose-finding clinical trials},
	volume = {34},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.6094},
	doi = {10.1002/sim.6094},
	pages = {1--12},
	number = {1},
	journaltitle = {Statistics in Medicine},
	author = {Riviere, M.-K. and Dubois, F. and Zohar, S.},
	urldate = {2018-07-17},
	date = {2015-01-15},
	langid = {english},
	file = {riviere_et_al_2015_competing_designs_for_drug_combination_in_phase_i_dose-finding_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/riviere_et_al_2015_competing_designs_for_drug_combination_in_phase_i_dose-finding_clinical_trials.pdf:application/pdf}
}

@article{riviere_bayesian_2014,
	title = {A Bayesian dose-finding design for drug combination clinical trials based on the logistic model},
	volume = {13},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1621},
	doi = {10.1002/pst.1621},
	abstract = {In early phase dose-ﬁnding cancer studies, the objective is to determine the maximum tolerated dose, deﬁned as the highest dose with an acceptable dose-limiting toxicity rate. Finding this dose for drug-combination trials is complicated due to drug-drug interactions, and many trial designs have been proposed to address this issue. These designs rely on complicated statistical models that typically are not familiar to clinicians, and are rarely used in practice. The aim of this paper is to propose a Bayesian dose-ﬁnding design for drug combination trials based on standard logistic regression. Under the proposed design, we continuously update the posterior estimates of the model parameters to make the decisions of dose assignment and early stopping. Simulation studies show that the proposed design is competitive and outperforms some existing designs. We also extend our design to handle delayed toxicities.},
	pages = {247--257},
	number = {4},
	journaltitle = {Pharmaceutical Statistics},
	author = {Riviere, Marie-Karelle and Yuan, Ying and Dubois, Frédéric and Zohar, Sarah},
	urldate = {2018-07-17},
	date = {2014-07},
	langid = {english},
	file = {riviere_et_al_2014_a_bayesian_dose-finding_design_for_drug_combination_clinical_trials_based_on.pdf:/home/nathan/Dropbox/njames/zotero_sync/riviere_et_al_2014_a_bayesian_dose-finding_design_for_drug_combination_clinical_trials_based_on.pdf:application/pdf}
}

@article{zhong_trivariate_2012,
	title = {A trivariate continual reassessment method for phase I/{II} trials of toxicity, efficacy, and surrogate efficacy},
	volume = {31},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.5477},
	doi = {10.1002/sim.5477},
	pages = {3885--3895},
	number = {29},
	journaltitle = {Statistics in Medicine},
	author = {Zhong, Wei and Koopmeiners, Joseph S. and Carlin, Bradley P.},
	urldate = {2018-07-17},
	date = {2012-12-20},
	langid = {english},
	file = {zhong_et_al_2012_a_trivariate_continual_reassessment_method_for_phase_i-ii_trials_of_toxicity,.pdf:/home/nathan/Dropbox/njames/zotero_sync/zhong_et_al_2012_a_trivariate_continual_reassessment_method_for_phase_i-ii_trials_of_toxicity,.pdf:application/pdf}
}

@article{yin_bayesian_2009,
	title = {Bayesian dose finding in oncology for drug combinations by copula regression},
	volume = {58},
	issn = {00359254, 14679876},
	url = {http://doi.wiley.com/10.1111/j.1467-9876.2009.00649.x},
	doi = {10.1111/j.1467-9876.2009.00649.x},
	abstract = {Treating patients with a combination of agents is becoming commonplace in cancer clinical trials, with biochemical synergism often the primary focus. In a typical drug combination trial, the toxicity proﬁle of each individual drug has already been thoroughly studied in singleagent trials, which naturally offers rich prior information.We propose a Bayesian adaptive design for dose ﬁnding that is based on a copula-type model to account for the synergistic effect of two or more drugs in combination. To search for the maximum tolerated dose combination, we continuously update the posterior estimates for the toxicity probabilities of the combined doses. By reordering the dose toxicities in the two-dimensional probability space, we adaptively assign each new cohort of patients to the most appropriate dose. Dose escalation, de-escalation or staying at the same doses is determined by comparing the posterior estimates of the probabilities of toxicity of combined doses and the prespeciﬁed toxicity target. We conduct extensive simulation studies to examine the operating characteristics of the design and illustrate the proposed method under various practical scenarios.},
	pages = {211--224},
	number = {2},
	journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	author = {Yin, Guosheng and Yuan, Ying},
	urldate = {2018-07-17},
	date = {2009-05},
	langid = {english},
	file = {yin_yuan_2009_bayesian_dose_finding_in_oncology_for_drug_combinations_by_copula_regression.pdf:/home/nathan/Dropbox/njames/zotero_sync/yin_yuan_2009_bayesian_dose_finding_in_oncology_for_drug_combinations_by_copula_regression.pdf:application/pdf}
}

@article{demarta_t_2007,
	title = {The t Copula and Related Copulas},
	volume = {73},
	issn = {03067734},
	url = {http://doi.wiley.com/10.1111/j.1751-5823.2005.tb00254.x},
	doi = {10.1111/j.1751-5823.2005.tb00254.x},
	abstract = {The t copula and its properties are described with a focus on issues related to the dependence of extreme values. The Gaussian mixture representation of a multivariate t distribution is used as a starting point to construct two new copulas, the skewed t copula and the grouped t copula, which allow more heterogeneity in the modelling of dependent observations. Extreme value considerations are used to derive two further new copulas: the t extreme value copula is the limiting copula of componentwise maxima of t distributed random vectors; the t lower tail copula is the limiting copula of bivariate observations from a t distribution that are conditioned to lie below some joint threshold that is progressively lowered. Both these copulas may be approximated for practical purposes by simpler, better-known copulas, these being the Gumbel and Clayton copulas respectively.},
	pages = {111--129},
	number = {1},
	journaltitle = {International Statistical Review},
	author = {Demarta, Stefano and {McNeil}, Alexander J.},
	urldate = {2018-07-17},
	date = {2007-01-15},
	langid = {english},
	file = {demarta_mcneil_2007_the_t_copula_and_related_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/demarta_mcneil_2007_the_t_copula_and_related_copulas.pdf:application/pdf}
}

@online{schmidt_coping_nodate,
	title = {Coping with Copulas},
	url = {http://www.archiv.stochastik.uni-freiburg.de/homepages/schmidt/publications/TSchmidt_Copulas.pdf},
	author = {Schmidt, Thorsten},
	urldate = {2018-07-17},
	file = {schmidt_coping_with_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/schmidt_coping_with_copulas.pdf:application/pdf}
}

@article{yan_enjoy_2007,
	title = {Enjoy the Joy of Copulas: With a Package Copula},
	volume = {21},
	abstract = {Copulas have become a popular tool in multivariate modeling successfully applied in many ﬁelds. A good open-source implementation of copulas is much needed for more practitioners to enjoy the joy of copulas. This article presents the design, features, and some implementation details of the R package copula. The package provides a carefully designed and easily extensible platform for multivariate modeling with copulas in R. S4 classes for most frequently used elliptical copulas and Archimedean copulas are implemented, with methods for density/distribution evaluation, random number generation, and graphical display. Fitting copula-based models with maximum likelihood method is provided as template examples. With the classes and methods in the package, the package can be easily extended by user-deﬁned copulas and margins to solve problems.},
	pages = {21},
	number = {4},
	journaltitle = {Journal of Statistical Software},
	author = {Yan, Jun},
	date = {2007-10},
	langid = {english},
	file = {yan_enjoy_the_joy_of_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/yan_enjoy_the_joy_of_copulas.pdf:application/pdf}
}

@online{genest_joy_nodate,
	title = {The Joy of Copulas: Bivariate distributions with Uniform Marginals},
	url = {http://www.ressources-actuarielles.net/EXT/ISFA/1226.nsf/9c8e3fd4d8874d60c1257052003eced6/14af2550e3b03d6fc1256f5400590a69/$FILE/AmerStatist-1986.pdf},
	author = {Genest, Christian and {MacKay}, Jock},
	urldate = {2018-07-17},
	file = {genest_mackay_the_joy_of_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/genest_mackay_the_joy_of_copulas.pdf:application/pdf}
}

@online{genest_statistical_nodate,
	title = {Statistical Inference Procedures for Bivariate Archimedean Copulas},
	url = {https://www.mat.ulaval.ca/fileadmin/mat/documents/lrivest/Publications/30-GenestRivest1993.pdf},
	author = {Genest, Christian and Rivest, Louis-Paul},
	urldate = {2018-07-17},
	file = {genest_rivest_statistical_inference_procedures_for_bivariate_archimedean_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/genest_rivest_statistical_inference_procedures_for_bivariate_archimedean_copulas.pdf:application/pdf}
}

@article{bebu_properties_2018,
	title = {Properties of composite time to first event versus joint marginal analyses of multiple outcomes: Properties of composite time to first event versus joint marginal analyses of multiple outcomes},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.7849},
	doi = {10.1002/sim.7849},
	shorttitle = {Properties of composite time to first event versus joint marginal analyses of multiple outcomes},
	journaltitle = {Statistics in Medicine},
	author = {Bebu, Ionut and Lachin, John M.},
	urldate = {2018-07-17},
	date = {2018-06-28},
	langid = {english},
	file = {bebu_lachin_2018_properties_of_composite_time_to_first_event_versus_joint_marginal_analyses_of.pdf:/home/nathan/Dropbox/njames/zotero_sync/bebu_lachin_2018_properties_of_composite_time_to_first_event_versus_joint_marginal_analyses_of.pdf:application/pdf}
}

@article{liu_assessment_2018,
	title = {Assessment of Bayesian expected power via Bayesian bootstrap: Expected Power via Bayesian Bootstrap},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.7826},
	doi = {10.1002/sim.7826},
	shorttitle = {Assessment of Bayesian expected power via Bayesian bootstrap},
	journaltitle = {Statistics in Medicine},
	author = {Liu, Fang},
	urldate = {2018-07-17},
	date = {2018-06-25},
	langid = {english},
	file = {liu_2018_assessment_of_bayesian_expected_power_via_bayesian_bootstrap.pdf:/home/nathan/Dropbox/njames/zotero_sync/liu_2018_assessment_of_bayesian_expected_power_via_bayesian_bootstrap.pdf:application/pdf}
}

@article{morgan_bayesian_2018,
	title = {Bayesian applications in pharmaceutical statistics},
	volume = {17},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1876},
	doi = {10.1002/pst.1876},
	pages = {298--300},
	number = {4},
	journaltitle = {Pharmaceutical Statistics},
	author = {Morgan, David},
	urldate = {2018-07-17},
	date = {2018-07},
	langid = {english},
	file = {morgan_2018_bayesian_applications_in_pharmaceutical_statistics.pdf:/home/nathan/Dropbox/njames/zotero_sync/morgan_2018_bayesian_applications_in_pharmaceutical_statistics.pdf:application/pdf}
}

@article{dallow_better_2018,
	title = {Better decision making in drug development through adoption of formal prior elicitation},
	volume = {17},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1854},
	doi = {10.1002/pst.1854},
	pages = {301--316},
	number = {4},
	journaltitle = {Pharmaceutical Statistics},
	author = {Dallow, Nigel and Best, Nicky and Montague, Timothy H},
	urldate = {2018-07-17},
	date = {2018-07},
	langid = {english},
	file = {dallow_et_al_2018_better_decision_making_in_drug_development_through_adoption_of_formal_prior.pdf:/home/nathan/Dropbox/njames/zotero_sync/dallow_et_al_2018_better_decision_making_in_drug_development_through_adoption_of_formal_prior.pdf:application/pdf}
}

@article{ghosh_bayesian_2018,
	title = {Bayesian approach for assessing noninferiority in a three-arm trial with binary endpoint: Bayesian approach for assessing noninferiority in a three-arm trial with binary endpoint},
	volume = {17},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1851},
	doi = {10.1002/pst.1851},
	shorttitle = {Bayesian approach for assessing noninferiority in a three-arm trial with binary endpoint},
	pages = {342--357},
	number = {4},
	journaltitle = {Pharmaceutical Statistics},
	author = {Ghosh, Santu and Tiwari, Ram C. and Ghosh, Samiran},
	urldate = {2018-07-17},
	date = {2018-07},
	langid = {english},
	file = {ghosh_et_al_2018_bayesian_approach_for_assessing_noninferiority_in_a_three-arm_trial_with_binary.pdf:/home/nathan/Dropbox/njames/zotero_sync/ghosh_et_al_2018_bayesian_approach_for_assessing_noninferiority_in_a_three-arm_trial_with_binary.pdf:application/pdf}
}

@article{cunanan_evaluating_2014,
	title = {Evaluating the performance of copula models in phase I-{II} clinical trials under model misspecification},
	volume = {14},
	issn = {1471-2288},
	url = {http://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-14-51},
	doi = {10.1186/1471-2288-14-51},
	abstract = {Background: Traditionally, phase I oncology trials are designed to determine the maximum tolerated dose ({MTD}), defined as the highest dose with an acceptable probability of dose limiting toxicities({DLT}), of a new treatment via a dose escalation study. An alternate approach is to jointly model toxicity and efficacy and allow dose escalation to depend on a pre-specified efficacy/toxicity tradeoff in a phase I-{II} design. Several phase I-{II} trial designs have been discussed in the literature; while these model-based designs are attractive in their performance, they are potentially vulnerable to model misspecification.
Methods: Phase I-{II} designs often rely on copula models to specify the joint distribution of toxicity and efficacy, which include an additional correlation parameter that can be difficult to estimate. We compare and contrast three models for the joint probability of toxicity and efficacy, including two copula models that have been proposed for use in phase I-{II} clinical trials and a simple model that assumes the two outcomes are independent. We evaluate the performance of the various models through simulation both when the models are correct and under model misspecification.
Results: Both models exhibited similar performance, as measured by the probability of correctly identifying the optimal dose and the number of subjects treated at the optimal dose, regardless of whether the data were generated from the correct or incorrect copula, even when there is substantial correlation between the two outcomes. Similar results were observed for a simple model that assumes independence, even in the presence of strong correlation. Further simulation results indicate that estimating the correlation parameter in copula models is difficult with the sample sizes used in Phase I-{II} clinical trials.
Conclusions: Our simulation results indicate that the operating characteristics of phase I-{II} clinical trials are robust to misspecification of the copula model but that a simple model that assumes independence performs just as well due to difficulty in estimating the copula model correlation parameters from binary data.},
	number = {1},
	journaltitle = {{BMC} Medical Research Methodology},
	author = {Cunanan, Kristen and Koopmeiners, Joseph S},
	urldate = {2018-07-26},
	date = {2014-12},
	langid = {english},
	file = {cunanan_koopmeiners_2014_evaluating_the_performance_of_copula_models_in_phase_i-ii_clinical_trials_under.pdf:/home/nathan/Dropbox/njames/zotero_sync/cunanan_koopmeiners_2014_evaluating_the_performance_of_copula_models_in_phase_i-ii_clinical_trials_under.pdf:application/pdf}
}

@article{tao_dose-finding_2013,
	title = {Dose-Finding Based on Bivariate Efficacy-Toxicity Outcome Using Archimedean Copula},
	volume = {8},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0078805},
	doi = {10.1371/journal.pone.0078805},
	abstract = {In dose-finding clinical study, it is common that multiple endpoints are of interest. For instance, efficacy and toxicity endpoints are both primary in clinical trials. In this article, we propose a joint model for correlated efficacy-toxicity outcome constructed with Archimedean Copula, and extend the continual reassessment method ({CRM}) to a bivariate trial design in which the optimal dose for phase {III} is based on both efficacy and toxicity. Specially, considering numerous cases that continuous and discrete outcomes are observed in drug study, we will extend our joint model to mixed correlated outcomes. We demonstrate through simulations that our algorithm based on Archimedean Copula model has excellent operating characteristics.},
	pages = {e78805},
	number = {11},
	journaltitle = {{PLoS} {ONE}},
	author = {Tao, Yuxi and Liu, Junlin and Li, Zhihui and Lin, Jinguan and Lu, Tao and Yan, Fangrong},
	editor = {Emmert-Streib, Frank},
	urldate = {2018-07-26},
	date = {2013-11-12},
	langid = {english},
	file = {tao_et_al_2013_dose-finding_based_on_bivariate_efficacy-toxicity_outcome_using_archimedean.pdf:/home/nathan/Dropbox/njames/zotero_sync/tao_et_al_2013_dose-finding_based_on_bivariate_efficacy-toxicity_outcome_using_archimedean.pdf:application/pdf}
}

@article{yuan_bayesian_2011,
	title = {Bayesian phase I/{II} adaptively randomized oncology trials with combined drugs},
	volume = {5},
	issn = {1932-6157},
	url = {http://arxiv.org/abs/1108.1614},
	doi = {10.1214/10-AOAS433},
	abstract = {We propose a new integrated phase I/{II} trial design to identify the most efficacious dose combination that also satisfies certain safety requirements for drug-combination trials. We first take a Bayesian copula-type model for dose finding in phase I. After identifying a set of admissible doses, we immediately move the entire set forward to phase {II}. We propose a novel adaptive randomization scheme to favor assigning patients to more efficacious dose-combination arms. Our adaptive randomization scheme takes into account both the point estimate and variability of efficacy. By using a moving reference to compare the relative efficacy among treatment arms, our method achieves a high resolution to distinguish different arms. We also consider groupwise adaptive randomization when efficacy is late-onset. We conduct extensive simulation studies to examine the operating characteristics of the proposed design, and illustrate our method using a phase I/{II} melanoma clinical trial.},
	pages = {924--942},
	number = {2},
	journaltitle = {The Annals of Applied Statistics},
	author = {Yuan, Ying and Yin, Guosheng},
	urldate = {2018-07-26},
	date = {2011-06},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1108.1614},
	keywords = {Statistics - Applications},
	file = {yuan_yin_2011_bayesian_phase_i-ii_adaptively_randomized_oncology_trials_with_combined_drugs.pdf:/home/nathan/Dropbox/njames/zotero_sync/yuan_yin_2011_bayesian_phase_i-ii_adaptively_randomized_oncology_trials_with_combined_drugs.pdf:application/pdf}
}

@article{owzar_copulas:_2003,
	title = {Copulas: concepts and novel applications},
	volume = {61},
	abstract = {A bivariate copula can be statistically interpreted as a bivariate distribution function with uniform marginals. Sklar (1959) argues that for any bivariate distribution function, say H with marginals F and G, there exists a copula functional, say C, such that H[x, y] = C[F[x], G[y]] , for (x, y)T in the support of H. What is to presented is a self-contained review, mainly from a statistical point of view, of the concept of copulas vis-a-vis multivariate distributions and dependence and to motivate their utility via a number of applications to the design of clinical trials, microarray studies with survival endpoints and the analysis of dependent Receiver Operator Curves ({ROC}).},
	pages = {323--353},
	number = {3},
	journaltitle = {International Journal of Statistics},
	author = {Owzar, Kouros and Sen, Pranab Kumar},
	date = {2003},
	langid = {english},
	file = {owzar_sen_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/owzar_sen_copulas.pdf:application/pdf}
}

@online{noauthor_society_nodate,
	title = {Society for Clinical Trials ({SCT})},
	url = {http://www.sctweb.org/public/search/detail.cfm?ID=A7C6951B-EAD9-AA85-9BD63CC8386DE3E1},
	urldate = {2018-07-26},
	file = {Society for Clinical Trials (SCT):/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/WPADVTBP/detail.html:text/html}
}

@article{carey_problems_2016,
	title = {Some Problems with Randomized Controlled Trials and Some Viable Alternatives: Randomized Controlled Trials Problems and Some Alternatives},
	volume = {23},
	issn = {10633995},
	url = {http://doi.wiley.com/10.1002/cpp.1942},
	doi = {10.1002/cpp.1942},
	shorttitle = {Some Problems with Randomized Controlled Trials and Some Viable Alternatives},
	pages = {87--95},
	number = {1},
	journaltitle = {Clinical Psychology \& Psychotherapy},
	author = {Carey, Timothy A. and Stiles, William B.},
	urldate = {2018-08-06},
	date = {2016-01},
	langid = {english},
	file = {carey_stiles_2016_some_problems_with_randomized_controlled_trials_and_some_viable_alternatives.pdf:/home/nathan/Dropbox/njames/zotero_sync/carey_stiles_2016_some_problems_with_randomized_controlled_trials_and_some_viable_alternatives.pdf:application/pdf}
}

@article{ford_pragmatic_2016,
	title = {Pragmatic Trials},
	volume = {374},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/10.1056/NEJMe1601510},
	doi = {10.1056/NEJMe1601510},
	pages = {2167--2167},
	number = {22},
	journaltitle = {New England Journal of Medicine},
	author = {Ford, Ian and Norrie, John},
	urldate = {2018-08-06},
	date = {2016-06-02},
	langid = {english},
	file = {ford_norrie_2016_pragmatic_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/ford_norrie_2016_pragmatic_trials.pdf:application/pdf}
}

@article{loudon_precis-2_2015,
	title = {The {PRECIS}-2 tool: designing trials that are fit for purpose},
	volume = {350},
	issn = {1756-1833},
	url = {http://www.bmj.com/cgi/doi/10.1136/bmj.h2147},
	doi = {10.1136/bmj.h2147},
	shorttitle = {The {PRECIS}-2 tool},
	pages = {h2147--h2147},
	issue = {may08 1},
	journaltitle = {{BMJ}},
	author = {Loudon, K. and Treweek, S. and Sullivan, F. and Donnan, P. and Thorpe, K. E. and Zwarenstein, M.},
	urldate = {2018-08-06},
	date = {2015-05-08},
	langid = {english},
	file = {loudon_et_al_2015_the_precis-2_tool.pdf:/home/nathan/Dropbox/njames/zotero_sync/loudon_et_al_2015_the_precis-2_tool.pdf:application/pdf}
}

@article{deaton_understanding_2018,
	title = {Understanding and misunderstanding randomized controlled trials},
	volume = {210},
	issn = {02779536},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0277953617307359},
	doi = {10.1016/j.socscimed.2017.12.005},
	abstract = {Randomized Controlled Trials ({RCTs}) are increasingly popular in the social sciences, not only in medicine. We argue that the lay public, and sometimes researchers, put too much trust in {RCTs} over other methods of investigation. Contrary to frequent claims in the applied literature, randomization does not equalize everything other than the treatment in the treatment and control groups, it does not automatically deliver a precise estimate of the average treatment eﬀect ({ATE}), and it does not relieve us of the need to think about (observed or unobserved) covariates. Finding out whether an estimate was generated by chance is more diﬃcult than commonly believed. At best, an {RCT} yields an unbiased estimate, but this property is of limited practical value. Even then, estimates apply only to the sample selected for the trial, often no more than a convenience sample, and justiﬁcation is required to extend the results to other groups, including any population to which the trial sample belongs, or to any individual, including an individual in the trial. Demanding ‘external validity’ is unhelpful because it expects too much of an {RCT} while undervaluing its potential contribution. {RCTs} do indeed require minimal assumptions and can operate with little prior knowledge. This is an advantage when persuading distrustful audiences, but it is a disadvantage for cumulative scientiﬁc progress, where prior knowledge should be built upon, not discarded. {RCTs} can play a role in building scientiﬁc knowledge and useful predictions but they can only do so as part of a cumulative program, combining with other methods, including conceptual and theoretical development, to discover not ‘what works’, but ‘why things work’.},
	pages = {2--21},
	journaltitle = {Social Science \& Medicine},
	author = {Deaton, Angus and Cartwright, Nancy},
	urldate = {2018-08-06},
	date = {2018-08},
	langid = {english},
	file = {deaton_cartwright_2018_understanding_and_misunderstanding_randomized_controlled_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/deaton_cartwright_2018_understanding_and_misunderstanding_randomized_controlled_trials.pdf:application/pdf}
}

@article{psioda_practical_2018,
	title = {A practical Bayesian adaptive design incorporating data from historical controls: A practical Bayesian adaptive design incorporating data from historical controls},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.7897},
	doi = {10.1002/sim.7897},
	shorttitle = {A practical Bayesian adaptive design incorporating data from historical controls},
	journaltitle = {Statistics in Medicine},
	author = {Psioda, Matthew A. and Soukup, Mat and Ibrahim, Joseph G.},
	urldate = {2018-08-06},
	date = {2018-07-22},
	langid = {english},
	file = {psioda_et_al_2018_a_practical_bayesian_adaptive_design_incorporating_data_from_historical_controls.pdf:/home/nathan/Dropbox/njames/zotero_sync/psioda_et_al_2018_a_practical_bayesian_adaptive_design_incorporating_data_from_historical_controls.pdf:application/pdf}
}

@article{lin_uniformly_2018,
	title = {Uniformly most powerful Bayesian interval design for phase I dose-finding trials: Uniformly most powerful Bayesian interval design for phase I dose-finding trials},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1889},
	doi = {10.1002/pst.1889},
	shorttitle = {Uniformly most powerful Bayesian interval design for phase I dose-finding trials},
	journaltitle = {Pharmaceutical Statistics},
	author = {Lin, Ruitao and Yin, Guosheng},
	urldate = {2018-08-06},
	date = {2018-07-31},
	langid = {english},
	file = {lin_yin_2018_uniformly_most_powerful_bayesian_interval_design_for_phase_i_dose-finding_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/lin_yin_2018_uniformly_most_powerful_bayesian_interval_design_for_phase_i_dose-finding_trials.pdf:application/pdf}
}

@article{lin_propensity_2018,
	title = {Propensity score matched augmented controls in randomized clinical trials: A case study: Clinical Trial Data Augmentation through Propensity Scores},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1879},
	doi = {10.1002/pst.1879},
	shorttitle = {Propensity score matched augmented controls in randomized clinical trials},
	journaltitle = {Pharmaceutical Statistics},
	author = {Lin, Junjing and Gamalo-Siebers, Margaret and Tiwari, Ram},
	urldate = {2018-08-06},
	date = {2018-07-31},
	langid = {english},
	file = {lin_et_al_2018_propensity_score_matched_augmented_controls_in_randomized_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/lin_et_al_2018_propensity_score_matched_augmented_controls_in_randomized_clinical_trials.pdf:application/pdf}
}

@article{takeda_bayesian_2018,
	title = {Bayesian dose-finding phase I trial design incorporating pharmacokinetic assessment in the field of oncology},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1890},
	doi = {10.1002/pst.1890},
	journaltitle = {Pharmaceutical Statistics},
	author = {Takeda, Kentaro and Komatsu, Kanji and Morita, Satoshi},
	urldate = {2018-08-06},
	date = {2018-07-31},
	langid = {english},
	file = {takeda_et_al_2018_bayesian_dose-finding_phase_i_trial_design_incorporating_pharmacokinetic.pdf:/home/nathan/Dropbox/njames/zotero_sync/takeda_et_al_2018_bayesian_dose-finding_phase_i_trial_design_incorporating_pharmacokinetic.pdf:application/pdf}
}

@article{perrone_optimal_2016,
	title = {Optimal designs for copula models},
	volume = {50},
	issn = {0233-1888, 1029-4910},
	url = {http://www.tandfonline.com/doi/full/10.1080/02331888.2015.1111892},
	doi = {10.1080/02331888.2015.1111892},
	abstract = {Copula modelling has in the past decade become a standard tool in many areas of applied statistics. However, a largely neglected aspect concerns the design of related experiments. Particularly the issue of whether the estimation of copula parameters can be enhanced by optimizing experimental conditions and how robust all the parameter estimates for the model are with respect to the type of copula employed. In this paper an equivalence theorem for (bivariate) copula models is provided that allows formulation of eﬃcient design algorithms and quick checks of whether designs are optimal or at least eﬃcient. Some examples illustrate that in practical situations considerable gains in design eﬃciency can be achieved. A natural comparison between diﬀerent copula models with respect to design eﬃciency is provided as well.},
	pages = {917--929},
	number = {4},
	journaltitle = {Statistics},
	author = {Perrone, E. and Müller, W.G.},
	urldate = {2018-08-09},
	date = {2016-07-03},
	langid = {english},
	file = {perrone_müller_2016_optimal_designs_for_copula_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/perrone_müller_2016_optimal_designs_for_copula_models.pdf:application/pdf}
}

@article{deldossi_optimal_2018,
	title = {Optimal design to discriminate between rival copula models for a bivariate binary response},
	issn = {1133-0686, 1863-8260},
	url = {http://link.springer.com/10.1007/s11749-018-0595-1},
	doi = {10.1007/s11749-018-0595-1},
	abstract = {We consider a bivariate logistic model for a binary response, and we assume that two rival dependence structures are possible. Copula functions are very useful tools to model different kinds of dependence with arbitrary marginal distributions. We consider Clayton and Gumbel copulae as competing association models. The focus is on applications in testing a new drug looking at both efﬁcacy and toxicity outcomes. In this context, one of the main goals is to ﬁnd the dose which maximizes the probability of efﬁcacy without toxicity, herein called P-optimal dose. If the P-optimal dose changes under the two rival copulae, then it is relevant to identify the proper association model. To this aim, we propose a criterion (called {PKL}) which enables us to ﬁnd the optimal doses to discriminate between the rival copulae, subject to a constraint that protects patients against dangerous doses. Furthermore, by applying the likelihood ratio test for non-nested models, via a simulation study we conﬁrm that the {PKL}-optimal design is really able to discriminate between the rival copulae.},
	journaltitle = {{TEST}},
	author = {Deldossi, Laura and Osmetti, Silvia Angela and Tommasi, Chiara},
	urldate = {2018-08-09},
	date = {2018-07-20},
	langid = {english},
	file = {deldossi_et_al_2018_optimal_design_to_discriminate_between_rival_copula_models_for_a_bivariate.pdf:/home/nathan/Dropbox/njames/zotero_sync/deldossi_et_al_2018_optimal_design_to_discriminate_between_rival_copula_models_for_a_bivariate.pdf:application/pdf}
}

@online{noauthor_significance_nodate,
	title = {Significance magazine - Cargo-cult statistics and scientific crisis {\textbar} Significance magazine},
	url = {https://www.significancemagazine.com/593},
	urldate = {2018-08-10},
	file = {Significance magazine - Cargo-cult statistics and scientific crisis | Significance magazine:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/WR5QYFDS/593.html:text/html}
}

@article{genest_primer_2007,
	title = {A Primer on Copulas for Count Data},
	volume = {37},
	issn = {0515-0361, 1783-1350},
	url = {https://www.cambridge.org/core/product/identifier/S0515036100014963/type/journal_article},
	doi = {10.2143/AST.37.2.2024077},
	abstract = {The authors review various facts about copulas linking discrete distributions. They show how the possibility of ties that results from atoms in the probability distribution invalidates various familiar relations that lie at the root of copula theory in the continuous case. They highlight some of the dangers and limitations of an undiscriminating transposition of modeling and inference practices from the continuous setting into the discrete one.},
	pages = {475--515},
	number = {2},
	journaltitle = {{ASTIN} Bulletin},
	author = {Genest, Christian and Nešlehová, Johanna},
	urldate = {2018-08-13},
	date = {2007-11},
	langid = {english},
	file = {genest_nešlehová_2007_a_primer_on_copulas_for_count_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/genest_nešlehová_2007_a_primer_on_copulas_for_count_data.pdf:application/pdf}
}

@article{genest_goodness--fit_2009,
	title = {Goodness-of-fit tests for copulas: A review and a power study},
	volume = {44},
	issn = {01676687},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0167668707001205},
	doi = {10.1016/j.insmatheco.2007.10.005},
	shorttitle = {Goodness-of-fit tests for copulas},
	abstract = {Many proposals have been made recently for goodness-of-ﬁt testing of copula models. After reviewing them brieﬂy, the authors concentrate on “blanket tests”, i.e., those whose implementation requires neither an arbitrary categorization of the data nor any strategic choice of smoothing parameter, weight function, kernel, window, etc. The authors present a critical review of these procedures and suggest new ones. They describe and interpret the results of a large Monte Carlo experiment designed to assess the effect of the sample size and the strength of dependence on the level and power of the blanket tests for various combinations of copula models under the null hypothesis and the alternative. To circumvent problems in the determination of the limiting distribution of the test statistics under composite null hypotheses, they recommend the use of a double parametric bootstrap procedure, whose implementation is detailed. They conclude with a number of practical recommendations.},
	pages = {199--213},
	number = {2},
	journaltitle = {Insurance: Mathematics and Economics},
	author = {Genest, Christian and Rémillard, Bruno and Beaudoin, David},
	urldate = {2018-08-13},
	date = {2009-04},
	langid = {english},
	file = {genest_et_al_2009_goodness-of-fit_tests_for_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/genest_et_al_2009_goodness-of-fit_tests_for_copulas.pdf:application/pdf;genest_et_al_2009_goodness-of-fit_tests_for_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/genest_et_al_2009_goodness-of-fit_tests_for_copulas2.pdf:application/pdf}
}

@article{mikosch_copulas:_2006,
	title = {Copulas: Tales and facts},
	volume = {9},
	issn = {1386-1999, 1572-915X},
	url = {http://link.springer.com/10.1007/s10687-006-0015-x},
	doi = {10.1007/s10687-006-0015-x},
	shorttitle = {Copulas},
	pages = {3--20},
	number = {1},
	journaltitle = {Extremes},
	author = {Mikosch, Thomas},
	urldate = {2018-08-13},
	date = {2006-11-27},
	langid = {english},
	file = {mikosch_2006_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/mikosch_2006_copulas.pdf:application/pdf}
}

@article{embrechts_discussion_2006,
	title = {Discussion of “Copulas: Tales and facts”, by Thomas Mikosch},
	volume = {9},
	issn = {1386-1999, 1572-915X},
	url = {http://link.springer.com/10.1007/s10687-006-0021-z},
	doi = {10.1007/s10687-006-0021-z},
	shorttitle = {Discussion of “Copulas},
	pages = {45--47},
	number = {1},
	journaltitle = {Extremes},
	author = {Embrechts, Paul},
	urldate = {2018-08-13},
	date = {2006-11-27},
	langid = {english},
	file = {embrechts_2006_discussion_of_“copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/embrechts_2006_discussion_of_“copulas.pdf:application/pdf}
}

@article{de_vries_discussion_2006,
	title = {Discussion of “Copulas: Tales and facts”, by Thomas Mikosch},
	volume = {9},
	issn = {1386-1999, 1572-915X},
	url = {http://link.springer.com/10.1007/s10687-006-0017-8},
	doi = {10.1007/s10687-006-0017-8},
	shorttitle = {Discussion of “Copulas},
	pages = {23--25},
	number = {1},
	journaltitle = {Extremes},
	author = {de Vries, Casper G. and Zhou, Chen},
	urldate = {2018-08-13},
	date = {2006-11-27},
	langid = {english},
	file = {de_vries_zhou_2006_discussion_of_“copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/de_vries_zhou_2006_discussion_of_“copulas.pdf:application/pdf}
}

@article{joe_discussion_2006,
	title = {Discussion of “Copulas: Tales and facts”, by Thomas Mikosch},
	volume = {9},
	issn = {1386-1999, 1572-915X},
	url = {http://link.springer.com/10.1007/s10687-006-0019-6},
	doi = {10.1007/s10687-006-0019-6},
	shorttitle = {Discussion of “Copulas},
	pages = {37--41},
	number = {1},
	journaltitle = {Extremes},
	author = {Joe, Harry},
	urldate = {2018-08-13},
	date = {2006-11-27},
	langid = {english},
	file = {joe_2006_discussion_of_“copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/joe_2006_discussion_of_“copulas.pdf:application/pdf}
}

@article{genest_discussion_2006,
	title = {Discussion of “Copulas: Tales and facts”, by Thomas Mikosch},
	volume = {9},
	issn = {1386-1999, 1572-915X},
	url = {http://link.springer.com/10.1007/s10687-006-0018-7},
	doi = {10.1007/s10687-006-0018-7},
	shorttitle = {Discussion of “Copulas},
	pages = {27--36},
	number = {1},
	journaltitle = {Extremes},
	author = {Genest, Christian and Rémillard, Bruno},
	urldate = {2018-08-13},
	date = {2006-11-27},
	langid = {english},
	file = {genest_rémillard_2006_discussion_of_“copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/genest_rémillard_2006_discussion_of_“copulas.pdf:application/pdf}
}

@article{durante_stat_2016,
	title = {Stat Trek. An interview with Christian Genest},
	volume = {4},
	issn = {2300-2298},
	url = {https://www.degruyter.com/view/j/demo.2016.4.issue-1/demo-2016-0005/demo-2016-0005.xml},
	doi = {10.1515/demo-2016-0005},
	number = {1},
	journaltitle = {Dependence Modeling},
	author = {Durante, Fabrizio and Puccetti, Giovanni and Scherer, Matthias and Vanduffel, Steven},
	urldate = {2018-08-13},
	date = {2016-01-12},
	langid = {english},
	file = {durante_et_al_2016_stat_trek.pdf:/home/nathan/Dropbox/njames/zotero_sync/durante_et_al_2016_stat_trek.pdf:application/pdf}
}

@article{wetzel_eye_2018,
	title = {Eye Tracking Results in Postconcussive Syndrome Versus Normative Participants},
	volume = {59},
	issn = {1552-5783},
	url = {http://iovs.arvojournals.org/article.aspx?doi=10.1167/iovs.18-23815},
	doi = {10.1167/iovs.18-23815},
	abstract = {{PURPOSE}. Standard physical, neurologic, and neuropsychologic examinations may not detect abnormalities after mild traumatic brain injury ({mTBI}). An analysis of eye movements may be more sensitive to neurologic dysfunction.
{METHODS}. We performed eye tracking assessments in 71 active duty and veteran military personnel with persistent postconcussive symptoms (3 months to 5 years after {mTBI}) and 75 volunteers with no history of brain injury. Both eyes were sampled at 500 Hz and analyzed for various eye measurement parameters during visual tasks involving the saccadic and smooth systems.
{RESULTS}. No difference between {mTBI} and normal participants in main sequence proﬁles was observed. On the circular task, intersaccadic interval duration was shorter in {mTBI} compared with normal subjects (horizontal: Cohen’s D ¼ À0.65; vertical: Cohen’s D ¼ À0.75). For reading, absolute saccadic amplitudes (Cohen’s D ¼ À0.76) and average forward saccadic amplitudes were lower (Cohen’s D ¼ À0.61). Absolute ﬁxation velocity was higher (Cohen’s D ¼ 1.02), and overall ﬁxation durations (Cohen’s D ¼ 0.58), regression durations (Cohen’s D ¼ 0.49), and forward saccadic durations (Cohen’s D¼0.54) were longer. {mTBI} participants had more ﬁxations (Cohen’s D ¼ 0.54) and regressions per line (Cohen’s D ¼ 0.70) and read fewer lines (Cohen’s D ¼ À0.38) than normal subjects. On the horizontal ramp task, {mTBI} participants had lower weighted smooth pursuit gains (Cohen’s D ¼ À0.55). On the horizontal step task, {mTBI} participants had shorter mean ﬁxation times (Cohen’s D ¼ À0.55).
{CONCLUSIONS}. These results suggest vulnerability of the smooth pursuit and saccadic systems in {mTBI}. Eye tracking shows promise as an objective, sensitive assessment of damage after {mTBI}. ({ClinicalTrials}.gov number, {NCT}01611194, {NCT}01925963.)},
	pages = {4011},
	number = {10},
	journaltitle = {Investigative Opthalmology \& Visual Science},
	author = {Wetzel, Paul A. and Lindblad, Anne S. and Raizada, Hardik and James, Nathan and Mulatya, Caroline and Kannan, Mary A. and Villamar, Zoe and Gitchel, George T. and Weaver, Lindell K.},
	urldate = {2018-08-15},
	date = {2018-08-07},
	langid = {english},
	file = {wetzel_et_al_2018_eye_tracking_results_in_postconcussive_syndrome_versus_normative_participants.pdf:/home/nathan/Dropbox/njames/zotero_sync/wetzel_et_al_2018_eye_tracking_results_in_postconcussive_syndrome_versus_normative_participants.pdf:application/pdf}
}

@article{mt-isa_balancing_2014,
	title = {Balancing benefit and risk of medicines: a systematic review and classification of available methodologies: {TAXONOMY} {OF} {BENEFIT}-{RISK} {ASSESSMENT} {METHODOLOGIES}},
	volume = {23},
	issn = {10538569},
	url = {http://doi.wiley.com/10.1002/pds.3636},
	doi = {10.1002/pds.3636},
	shorttitle = {Balancing benefit and risk of medicines},
	abstract = {Background The need for formal and structured approaches for beneﬁt–risk assessment of medicines is increasing, as is the complexity of the scientiﬁc questions addressed before making decisions on the beneﬁt–risk balance of medicines. We systematically collected, appraised and classiﬁed available beneﬁt–risk methodologies to facilitate and inform their future use.
Methods A systematic review of publications identiﬁed beneﬁt–risk assessment methodologies. Methodologies were appraised on their fundamental principles, features, graphical representations, assessability and accessibility. We created a taxonomy of methodologies to facilitate understanding and choice.
Results We identiﬁed 49 methodologies, critically appraised and classiﬁed them into four categories: frameworks, metrics, estimation techniques and utility survey techniques. Eight frameworks describe qualitative steps in beneﬁt–risk assessment and eight quantify beneﬁt–risk balance. Nine metric indices include threshold indices to measure either beneﬁt or risk; health indices measure quality-of-life over time; and trade-off indices integrate beneﬁts and risks. Six estimation techniques support beneﬁt–risk modelling and evidence synthesis. Four utility survey techniques elicit robust value preferences from relevant stakeholders to the beneﬁt–risk decisions.
Conclusions Methodologies to help beneﬁt–risk assessments of medicines are diverse and each is associated with different limitations and strengths. There is not a ‘one-size-ﬁts-all’ method, and a combination of methods may be needed for each beneﬁt–risk assessment. The taxonomy introduced herein may guide choice of adequate methodologies. Finally, we recommend 13 of 49 methodologies for further appraisal for use in the real-life beneﬁt–risk assessment of medicines. Copyright © 2014 John Wiley \& Sons, Ltd.},
	pages = {667--678},
	number = {7},
	journaltitle = {Pharmacoepidemiology and Drug Safety},
	author = {Mt-Isa, Shahrul and Hallgreen, Christine E. and Wang, Nan and Callréus, Torbjörn and Genov, Georgy and Hirsch, Ian and Hobbiger, Stephen F. and Hockley, Kimberley S. and Luciani, Davide and Phillips, Lawrence D. and Quartey, George and Sarac, Sinan B. and Stoeckert, Isabelle and Tzoulaki, Ioanna and Micaleff, Alain and Ashby, Deborah and {On behalf of the IMI-PROTECT benefit-risk participants}},
	urldate = {2018-08-16},
	date = {2014-07},
	langid = {english},
	file = {mt-isa_et_al_2014_balancing_benefit_and_risk_of_medicines.pdf:/home/nathan/Dropbox/njames/zotero_sync/mt-isa_et_al_2014_balancing_benefit_and_risk_of_medicines.pdf:application/pdf}
}

@article{embrechts_copulas:_2009,
	title = {Copulas: A Personal View},
	volume = {76},
	issn = {00224367, 15396975},
	url = {http://doi.wiley.com/10.1111/j.1539-6975.2009.01310.x},
	doi = {10.1111/j.1539-6975.2009.01310.x},
	shorttitle = {Copulas},
	abstract = {Copula modeling has taken the world of ﬁnance and insurance, and well beyond, by storm. Why is this? In this article, I review the early start of this development, discuss some important current research, mainly from an applications point of view, and comment on potential future developments. An alternative title of the article would be “Demystifying the copula craze.” The article also contains what I would like to call the copula must-reads.},
	pages = {639--650},
	number = {3},
	journaltitle = {Journal of Risk and Insurance},
	author = {Embrechts, Paul},
	urldate = {2018-08-16},
	date = {2009-09},
	langid = {english},
	file = {embrechts_2009_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/embrechts_2009_copulas.pdf:application/pdf}
}

@incollection{sklar_random_1996,
	location = {Hayward, {CA}},
	title = {Random variables, distribution functions, and copulas---a personal look backward and forward},
	isbn = {978-0-940600-40-9},
	url = {http://projecteuclid.org/euclid.lnms/1215452606},
	pages = {1--14},
	booktitle = {Institute of Mathematical Statistics Lecture Notes - Monograph Series},
	publisher = {Institute of Mathematical Statistics},
	author = {Sklar, A.},
	urldate = {2018-08-24},
	date = {1996},
	langid = {english},
	doi = {10.1214/lnms/1215452606},
	file = {sklar_1996_random_variables,_distribution_functions,_and_copulas---a_personal_look.pdf:/home/nathan/Dropbox/njames/zotero_sync/sklar_1996_random_variables,_distribution_functions,_and_copulas---a_personal_look.pdf:application/pdf}
}

@article{huard_bayesian_2006,
	title = {Bayesian copula selection},
	volume = {51},
	issn = {01679473},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0167947305002094},
	doi = {10.1016/j.csda.2005.08.010},
	abstract = {In recent years, the use of copulas has grown extremely fast and with it, the need for a simple and reliable method to choose the right copula family. Existing methods pose numerous difﬁculties and none is entirely satisfactory. We propose a Bayesian method to select the most probable copula family among a given set. The copula parameters are treated as nuisance variables, and hence do not have to be estimated. Furthermore, by a parameterization of the copula density in terms of Kendall’s , the prior on the parameter is replaced by a prior on , conceptually more meaningful. The prior on , common to all families in the set of tested copulas, serves as a basis for their comparison. Using simulated data sets, we study the reliability of the method and observe the following: (1) the frequency of successful identiﬁcation approaches 100\% as the sample size increases, (2) for weakly correlated variables, larger samples are necessary for reliable identiﬁcation.},
	pages = {809--822},
	number = {2},
	journaltitle = {Computational Statistics \& Data Analysis},
	author = {Huard, David and Évin, Guillaume and Favre, Anne-Catherine},
	urldate = {2018-08-24},
	date = {2006-11},
	langid = {english},
	file = {huard_et_al_2006_bayesian_copula_selection.pdf:/home/nathan/Dropbox/njames/zotero_sync/huard_et_al_2006_bayesian_copula_selection.pdf:application/pdf}
}

@article{gruber_bayesian_2017,
	title = {Bayesian Model Selection of Regular Vine Copulas},
	issn = {1936-0975},
	url = {https://projecteuclid.org/euclid.ba/1514516431},
	doi = {10.1214/17-BA1089},
	abstract = {Regular vine copulas are a ﬂexible class of dependence models, but Bayesian methodology for model selection and inference is not yet fully developed. We propose sparsity-inducing but otherwise non-informative priors, and present novel proposals to enable reversible jump Markov chain Monte Carlo posterior simulation for Bayesian model selection and inference. Our method is the ﬁrst to jointly estimate the posterior distribution of all trees of a regular vine copula. This represents a substantial improvement over existing frequentist and Bayesian strategies, which can only select one tree at a time and are known to induce bias. A simulation study demonstrates the feasibility of our strategy and shows that it combines superior selection and reduced computation time compared to Bayesian tree-by-tree selection. In a real data example, we forecast the daily expected tail loss of a portfolio of nine exchange-traded funds using a fully Bayesian multivariate dynamic model built around Bayesian regular vine copulas to illustrate our model’s viability for ﬁnancial analysis and risk estimation.},
	journaltitle = {Bayesian Analysis},
	author = {Gruber, Lutz F. and Czado, Claudia},
	urldate = {2018-08-24},
	date = {2017-12},
	langid = {english},
	file = {gruber_czado_2017_bayesian_model_selection_of_regular_vine_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/gruber_czado_2017_bayesian_model_selection_of_regular_vine_copulas.pdf:application/pdf}
}

@article{silva_copula_2008,
	title = {Copula, marginal distributions and model selection: a Bayesian note},
	volume = {18},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-008-9058-y},
	doi = {10.1007/s11222-008-9058-y},
	shorttitle = {Copula, marginal distributions and model selection},
	abstract = {Copula functions and marginal distributions are combined to produce multivariate distributions. We show advantages of estimating all parameters of these models using the Bayesian approach, which can be done with standard Markov chain Monte Carlo algorithms. Deviance-based model selection criteria are also discussed when applied to copula models since they are invariant under monotone increasing transformations of the marginals. We focus on the deviance information criterion. The joint estimation takes into account all dependence structure of the parameters’ posterior distributions in our chosen model selection criteria. Two Monte Carlo studies are conducted to show that model identiﬁcation improves when the model parameters are jointly estimated. We study the Bayesian estimation of all unknown quantities at once considering bivariate copula functions and three known marginal distributions.},
	pages = {313--320},
	number = {3},
	journaltitle = {Statistics and Computing},
	author = {Silva, Ralph dos Santos and Lopes, Hedibert Freitas},
	urldate = {2018-08-24},
	date = {2008-09},
	langid = {english},
	file = {silva_lopes_2008_copula,_marginal_distributions_and_model_selection.pdf:/home/nathan/Dropbox/njames/zotero_sync/silva_lopes_2008_copula,_marginal_distributions_and_model_selection.pdf:application/pdf}
}

@article{inoue_relationship_2005,
	title = {Relationship Between Bayesian and Frequentist Sample Size Determination},
	volume = {59},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1198/000313005X21069},
	doi = {10.1198/000313005X21069},
	pages = {79--87},
	number = {1},
	journaltitle = {The American Statistician},
	author = {Inoue, Lurdes Y.T and Berry, Donald A and Parmigiani, Giovanni},
	urldate = {2018-08-24},
	date = {2005-02},
	langid = {english},
	file = {inoue_et_al_2005_relationship_between_bayesian_and_frequentist_sample_size_determination.pdf:/home/nathan/Dropbox/njames/zotero_sync/inoue_et_al_2005_relationship_between_bayesian_and_frequentist_sample_size_determination.pdf:application/pdf}
}

@article{adcock_sample_1997,
	title = {Sample size determination: a review},
	volume = {46},
	issn = {0039-0526, 1467-9884},
	url = {http://doi.wiley.com/10.1111/1467-9884.00082},
	doi = {10.1111/1467-9884.00082},
	shorttitle = {Sample size determination},
	abstract = {This paper is concerned with methods of sample size determination. The approach is to cover a small number of simple problems, such as estimating the mean of a normal distribution or the slope in a regression equation, and to present some key techniques. The methods covered are in two groups: frequentist and Bayesian. Frequentist methods specify a null and alternative hypothesis for the parameter of interest and then find the sample size by controlling both size and power. These methods often need to use prior information but cannot allow for the uncertainty that is associated with it. By contrast, the Bayesian approach offers a wide variety of techniques, all of which offer the ability to deal with uncertainty associated with prior information.},
	pages = {261--283},
	number = {2},
	journaltitle = {Journal of the Royal Statistical Society: Series D (The Statistician)},
	author = {Adcock, C. J.},
	urldate = {2018-08-24},
	date = {1997-07},
	langid = {english},
	file = {adcock_1997_sample_size_determination.pdf:/home/nathan/Dropbox/njames/zotero_sync/adcock_1997_sample_size_determination.pdf:application/pdf}
}

@article{tansuchat_copulas_2018,
	title = {Copulas based seemingly unrelated quantile regression},
	volume = {1053},
	issn = {1742-6588, 1742-6596},
	url = {http://stacks.iop.org/1742-6596/1053/i=1/a=012102?key=crossref.0f1525e5548c6a061823afe3ade52965},
	doi = {10.1088/1742-6596/1053/1/012102},
	abstract = {We propose a multivariate copulas based seemingly unrelated quantile regression. We add the multivariate copula density function into the likelihood to relax the strong assumption of multivariate normal distribution of the conventional model. The simulation study is conducted to evaluate the performance of our proposed model. Moreover, we apply our proposed model to the Fama-French equation in order to investigate the systematic risk in the three major stocks in {NASDAQ} market. The results of this study suggest that our proposed model provides a particularly good description of these stock prices at every quantile level.},
	pages = {012102},
	journaltitle = {Journal of Physics: Conference Series},
	author = {Tansuchat, Roengchai and Maneejuk, Paravee and Yamaka, Woraphon and Sriboonchitta, Songsak},
	urldate = {2018-09-06},
	date = {2018-07},
	langid = {english},
	file = {tansuchat_et_al_2018_copulas_based_seemingly_unrelated_quantile_regression.pdf:/home/nathan/Dropbox/njames/zotero_sync/tansuchat_et_al_2018_copulas_based_seemingly_unrelated_quantile_regression.pdf:application/pdf}
}

@article{han_bayesian_2016,
	title = {Bayesian Learning with Dependency Structures via Latent Factors, Mixtures, and Copulas},
	pages = {144},
	author = {Han, Shaobo},
	date = {2016},
	langid = {english},
	file = {han_2016_bayesian_learning_with_dependency_structures_via_latent_factors,_mixtures,_and.pdf:/home/nathan/Dropbox/njames/zotero_sync/han_2016_bayesian_learning_with_dependency_structures_via_latent_factors,_mixtures,_and.pdf:application/pdf}
}

@inproceedings{han_variational_2016,
	location = {Cadiz, Spain},
	title = {Variational Gaussian Copula Inference},
	volume = {51},
	abstract = {We utilize copulas to constitute a uniﬁed framework for constructing and optimizing variational proposals in hierarchical Bayesian models. For models with continuous and non-Gaussian hidden variables, we propose a semiparametric and automated variational Gaussian copula approach, in which the parametric Gaussian copula family is able to preserve multivariate posterior dependence, and the nonparametric transformations based on Bernstein polynomials provide ample ﬂexibility in characterizing the univariate marginal posteriors.},
	pages = {829--838},
	booktitle = {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics ({AISTATS})},
	author = {Han, Shaobo and Liao, Xuejun and Dunson, David B and Carin, Lawrence},
	date = {2016},
	langid = {english},
	file = {han_et_al_variational_gaussian_copula_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/han_et_al_variational_gaussian_copula_inference.pdf:application/pdf}
}

@article{grazian_approximate_2017,
	title = {Approximate Bayesian Inference in Semiparametric Copula Models},
	volume = {12},
	issn = {1936-0975},
	url = {https://projecteuclid.org/euclid.ba/1510110045},
	doi = {10.1214/17-BA1080},
	abstract = {We describe a simple method for making inference on a functional of a multivariate distribution, based on its copula representation. We make use of an approximate Bayesian Monte Carlo algorithm, where the proposed values of the functional of interest are weighted in terms of their Bayesian exponentially tilted empirical likelihood. This method is particularly useful when the “true” likelihood function associated with the working model is too costly to evaluate or when the working model is only partially speciﬁed.},
	pages = {991--1016},
	number = {4},
	journaltitle = {Bayesian Analysis},
	author = {Grazian, Clara and Liseo, Brunero},
	urldate = {2018-09-06},
	date = {2017-12},
	langid = {english},
	file = {grazian_liseo_2017_approximate_bayesian_inference_in_semiparametric_copula_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/grazian_liseo_2017_approximate_bayesian_inference_in_semiparametric_copula_models.pdf:application/pdf}
}

@article{ning_nonparametric_2017,
	title = {A Nonparametric Bayesian Approach to Copula Estimation},
	url = {http://arxiv.org/abs/1702.07089},
	abstract = {We propose a novel Dirichlet-based P´olya tree (D-P tree) prior on the copula and based on the D-P tree prior, a nonparametric Bayesian inference procedure. Through theoretical analysis and simulations, we are able to show that the ﬂexibility of the D-P tree prior ensures its consistency in copula estimation, thus able to detect more subtle and complex copula structures than earlier nonparametric Bayesian models, such as a Gaussian copula mixture. Further, the continuity of the imposed D-P tree prior leads to a more favorable smoothing eﬀect in copula estimation over classic frequentist methods, especially with small sets of observations. We also apply our method to the copula prediction between the S\&P 500 index and the {IBM} stock prices during the 2007-08 ﬁnancial crisis, ﬁnding that D-P tree-based methods enjoy strong robustness and ﬂexibility over classic methods under such irregular market behaviors.},
	journaltitle = {{arXiv}:1702.07089 [stat]},
	author = {Ning, Shaoyang and Shephard, Neil},
	urldate = {2018-09-06},
	date = {2017-02-22},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1702.07089},
	keywords = {Statistics - Methodology},
	file = {ning_shephard_2017_a_nonparametric_bayesian_approach_to_copula_estimation.pdf:/home/nathan/Dropbox/njames/zotero_sync/ning_shephard_2017_a_nonparametric_bayesian_approach_to_copula_estimation.pdf:application/pdf}
}

@article{romeo_bayesian_2018,
	title = {Bayesian bivariate survival analysis using the power variance function copula},
	volume = {24},
	issn = {1380-7870, 1572-9249},
	url = {http://link.springer.com/10.1007/s10985-017-9396-1},
	doi = {10.1007/s10985-017-9396-1},
	pages = {355--383},
	number = {2},
	journaltitle = {Lifetime Data Analysis},
	author = {Romeo, Jose S. and Meyer, Renate and Gallardo, Diego I.},
	urldate = {2018-09-06},
	date = {2018-04},
	langid = {english},
	file = {romeo_et_al_2018_bayesian_bivariate_survival_analysis_using_the_power_variance_function_copula.pdf:/home/nathan/Dropbox/njames/zotero_sync/romeo_et_al_2018_bayesian_bivariate_survival_analysis_using_the_power_variance_function_copula.pdf:application/pdf}
}

@article{golchi_sequential_nodate,
	title = {Sequential Monte Carlo for response adaptive randomized trials},
	abstract = {Response adaptive randomized clinical trials have gained popularity due to their ﬂexibility for adjusting design components, including arm allocation probabilities, at any point in the trial according to the intermediate results. In the Bayesian framework, allocation probabilities to different treatment arms are commonly deﬁned as functionals of the posterior distributions of parameters of the outcome distribution for each treatment. In a non-conjugate model, however, repeated updates of the posterior distribution can be computationally intensive. In this article, we propose an adaptation of sequential Monte Carlo for efﬁciently updating the posterior distribution of parameters as new outcomes are observed in a general adaptive trial design. An efﬁcient computational tool facilitates implementation of more ﬂexible designs with more frequent interim looks that can in turn reduce the required sample size and expected number of failures in clinical trials. Moreover, more complex statistical models that reﬂect realistic modeling assumptions can be used for analysis of trial results.},
	pages = {15},
	author = {Golchi, Shirin},
	langid = {english},
	file = {golchi_sequential_monte_carlo_for_response_adaptive_randomized_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/golchi_sequential_monte_carlo_for_response_adaptive_randomized_trials.pdf:application/pdf}
}

@unpublished{nelsen_properties_2002,
	title = {Properties and applications of copulas: A brief survey},
	author = {Nelsen, Roger B},
	date = {2002},
	langid = {english},
	file = {nelsen_properties_and_applications_of_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/nelsen_properties_and_applications_of_copulas.pdf:application/pdf}
}

@article{murray_utility-based_2018,
	title = {A utility-based design for randomized comparative trials with ordinal outcomes and prognostic subgroups: {OrdBUB} Design with Subgroups},
	issn = {0006341X},
	url = {http://doi.wiley.com/10.1111/biom.12842},
	doi = {10.1111/biom.12842},
	shorttitle = {A utility-based design for randomized comparative trials with ordinal outcomes and prognostic subgroups},
	abstract = {A design is proposed for randomized comparative trials with ordinal outcomes and prognostic subgroups. The design accounts for patient heterogeneity by allowing possibly diﬀerent comparative conclusions within subgroups. The comparative testing criterion is based on utilities for the levels of the ordinal outcome and a Bayesian probability model. Designs based on two alternative models that include treatment-subgroup interactions are considered, the proportional odds model and a non-proportional odds model with a hierarchical prior that shrinks toward the proportional odds model. A third design that assumes homogeneity and ignores possible treatment-subgroup interactions also is considered. The three approaches are applied to construct group sequential designs for a trial of nutritional prehabilitation versus standard of care for esophageal cancer patients undergoing chemoradiation and surgery, including both untreated patients and salvage patients whose disease has recurred following previous therapy. A simulation study is presented that compares the three designs, including evaluation of within-subgroup type I and {II} error probabilities under a variety of scenarios including diﬀerent combinations of treatment-subgroup interactions.},
	journaltitle = {Biometrics},
	author = {Murray, Thomas A. and Yuan, Ying and Thall, Peter F. and Elizondo, Joan H. and Hofstetter, Wayne L.},
	urldate = {2018-09-18},
	date = {2018-01-22},
	langid = {english},
	file = {murray_et_al_2018_a_utility-based_design_for_randomized_comparative_trials_with_ordinal_outcomes.pdf:/home/nathan/Dropbox/njames/zotero_sync/murray_et_al_2018_a_utility-based_design_for_randomized_comparative_trials_with_ordinal_outcomes.pdf:application/pdf}
}

@article{tan_bayesian_2018,
	title = {Bayesian Inference for the One-Factor Copula Model},
	issn = {1061-8600, 1537-2715},
	url = {https://www.tandfonline.com/doi/full/10.1080/10618600.2018.1482765},
	doi = {10.1080/10618600.2018.1482765},
	abstract = {We develop efficient Bayesian inference for the one-factor copula model with two significant contributions over existing methodologies. First, our approach leads to straightforward inference on dependence parameters and the latent factor; only inference on the former is available under frequentist alternatives. Second, we develop a reversible jump Markov chain Monte Carlo algorithm that averages over models constructed from different bivariate copula building blocks. Our approach accommodates any combination of discrete and continuous margins. Through extensive simulations, we compare the computational and Monte Carlo efficiency of alternative proposed sampling schemes. The preferred algorithm provides reliable inference on parameters, the latent factor, and model space. The potential of the methodology is highlighted in an empirical study of 10 binary measures of socio-economic deprivation collected for 11,463 East Timorese households. The importance of conducting inference on the latent factor is motivated by constructing a poverty index using estimates of the factor. Compared to a linear Gaussian factor model, our model average improves out-of-sample fit. The relationships between the poverty index and observed variables uncovered by our approach are diverse and allow for a richer and more precise understanding of the dependence between overall deprivation and individual measures of well-being.},
	pages = {1--19},
	journaltitle = {Journal of Computational and Graphical Statistics},
	author = {Tan, Ban Kheng and Panagiotelis, Anastasios and Athanasopoulos, George},
	urldate = {2018-09-18},
	date = {2018-06-11},
	langid = {english},
	file = {tan_et_al_2018_bayesian_inference_for_the_one-factor_copula_model.pdf:/home/nathan/Dropbox/njames/zotero_sync/tan_et_al_2018_bayesian_inference_for_the_one-factor_copula_model.pdf:application/pdf}
}

@article{quan_case_2018,
	title = {A case study of an adaptive design for a clinical trial with 2 doses and 2 endpoints in a rare disease area},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1902},
	doi = {10.1002/pst.1902},
	journaltitle = {Pharmaceutical Statistics},
	author = {Quan, Hui and Xu, Yi and Chen, Yixin and Gao, Lei and Chen, Xun},
	urldate = {2018-09-18},
	date = {2018-09-16},
	langid = {english},
	file = {quan_et_al_2018_a_case_study_of_an_adaptive_design_for_a_clinical_trial_with_2_doses_and_2.pdf:/home/nathan/Dropbox/njames/zotero_sync/quan_et_al_2018_a_case_study_of_an_adaptive_design_for_a_clinical_trial_with_2_doses_and_2.pdf:application/pdf}
}

@article{shepherd_accounting_2011,
	title = {Accounting for Data Errors Discovered from an Audit in Multiple Linear Regression},
	volume = {67},
	issn = {0006341X},
	url = {http://doi.wiley.com/10.1111/j.1541-0420.2010.01543.x},
	doi = {10.1111/j.1541-0420.2010.01543.x},
	abstract = {A data coordinating team performed onsite audits and discovered discrepancies between the data sent to the coordinating center and that recorded at sites. We present statistical methods for incorporating audit results into analyses. This can be thought of as a measurement error problem, where the distribution of errors is a mixture with a point mass at 0. If the error rate is nonzero, then even if the mean of the discrepancy between the reported and correct values of a predictor is 0, naive estimates of the association between two continuous variables will be biased. We consider scenarios where there are (1) errors in the predictor, (2) errors in the outcome, and (3) possibly correlated errors in the predictor and outcome. We show how to incorporate the error rate and magnitude, estimated from a random subset (the audited records), to compute unbiased estimates of association and proper conﬁdence intervals. We then extend these results to multiple linear regression where multiple covariates may be incorrect in the database and the rate and magnitude of the errors may depend on study site. We study the ﬁnite sample properties of our estimators using simulations, discuss some practical considerations, and illustrate our methods with data from 2815 {HIV}-infected patients in Latin America, of whom 234 had their data audited using a sequential auditing plan.},
	pages = {1083--1091},
	number = {3},
	journaltitle = {Biometrics},
	author = {Shepherd, Bryan E. and Yu, Chang},
	urldate = {2018-09-26},
	date = {2011-09},
	langid = {english},
	file = {shepherd_yu_2011_accounting_for_data_errors_discovered_from_an_audit_in_multiple_linear.pdf:/home/nathan/Dropbox/njames/zotero_sync/shepherd_yu_2011_accounting_for_data_errors_discovered_from_an_audit_in_multiple_linear.pdf:application/pdf}
}

@article{kojadinovic_modeling_2010,
	title = {Modeling Multivariate Distributions with Continuous Margins Using the \textbf{copula} \textit{R} Package},
	volume = {34},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v34/i09/},
	doi = {10.18637/jss.v034.i09},
	abstract = {The copula-based modeling of multivariate distributions with continuous margins is presented as a succession of rank-based tests: a multivariate test of randomness followed by a test of mutual independence and a series of goodness-of-ﬁt tests. All the tests under consideration are based on the empirical copula, which is a nonparametric rank-based estimator of the true unknown copula. The principles of the tests are recalled and their implementation in the copula R package is brieﬂy described. Their use in the construction of a copula model from data is thoroughly illustrated on real insurance and ﬁnancial data.},
	number = {9},
	journaltitle = {Journal of Statistical Software},
	author = {Kojadinovic, Ivan and Yan, Jun},
	urldate = {2018-09-27},
	date = {2010},
	langid = {english},
	file = {kojadinovic_yan_2010_modeling_multivariate_distributions_with_continuous_margins_using_the.pdf:/home/nathan/Dropbox/njames/zotero_sync/kojadinovic_yan_2010_modeling_multivariate_distributions_with_continuous_margins_using_the.pdf:application/pdf}
}

@article{valle_bayesian_2018,
	title = {Bayesian non-parametric conditional copula estimation of twin data},
	volume = {67},
	issn = {00359254},
	url = {http://doi.wiley.com/10.1111/rssc.12237},
	doi = {10.1111/rssc.12237},
	abstract = {Several studies on heritability in twins aim at understanding the different contribution of environmental and genetic factors to speciﬁc traits. Considering the national merit twin study, our purpose is to analyse correctly the inﬂuence of socio-economic status on the relationship between twins’ cognitive abilities. Our methodology is based on conditional copulas, which enable us to model the effect of a covariate driving the strength of dependence between the main variables. We propose a ﬂexible Bayesian non-parametric approach for the estimation of conditional copulas, which can model any conditional copula density. Our methodology extends the work of Wu, Wang and Walker in 2015 by introducing dependence from a covariate in an inﬁnite mixture model. Our results suggest that environmental factors are more inﬂuential in families with lower socio-economic position.},
	pages = {523--548},
	number = {3},
	journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	author = {Valle, Luciana Dalla and Leisen, Fabrizio and Rossini, Luca},
	urldate = {2018-09-27},
	date = {2018-04},
	langid = {english},
	file = {valle_et_al_2018_bayesian_non-parametric_conditional_copula_estimation_of_twin_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/valle_et_al_2018_bayesian_non-parametric_conditional_copula_estimation_of_twin_data.pdf:application/pdf}
}

@article{moller_multivariate_2013,
	title = {Multivariate probabilistic forecasting using ensemble Bayesian model averaging and copulas},
	volume = {139},
	issn = {00359009},
	url = {http://doi.wiley.com/10.1002/qj.2009},
	doi = {10.1002/qj.2009},
	pages = {982--991},
	number = {673},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	author = {Möller, Annette and Lenkoski, Alex and Thorarinsdottir, Thordis L.},
	urldate = {2018-09-27},
	date = {2013-04},
	langid = {english},
	file = {möller_et_al_2013_multivariate_probabilistic_forecasting_using_ensemble_bayesian_model_averaging.pdf:/home/nathan/Dropbox/njames/zotero_sync/möller_et_al_2013_multivariate_probabilistic_forecasting_using_ensemble_bayesian_model_averaging.pdf:application/pdf}
}

@article{craiu_mixed_2012,
	title = {In mixed company: Bayesian inference for bivariate conditional copula models with discrete and continuous outcomes},
	volume = {110},
	issn = {0047259X},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0047259X12000796},
	doi = {10.1016/j.jmva.2012.03.010},
	shorttitle = {In mixed company},
	abstract = {Conditional copula models are flexible tools for modelling complex dependence structures in regression settings. We construct Bayesian inference for the conditional copula model adapted to regression settings in which the bivariate outcome is continuous or mixed. The dependence between the copula parameter and the covariate is modelled using cubic splines. The proposed joint Bayesian inference is carried out using adaptive Markov chain Monte Carlo sampling. The deviance information criterion ({DIC}) is used for selecting the copula family that best approximates the data and for choosing the calibration function. The performances of the estimation and model selection methods are investigated using simulations.},
	pages = {106--120},
	journaltitle = {Journal of Multivariate Analysis},
	author = {Craiu, V. Radu and Sabeti, Avideh},
	urldate = {2018-09-27},
	date = {2012-09},
	langid = {english},
	file = {craiu_sabeti_2012_in_mixed_company.pdf:/home/nathan/Dropbox/njames/zotero_sync/craiu_sabeti_2012_in_mixed_company.pdf:application/pdf}
}

@thesis{sabeti_bayesian_2013,
	title = {Bayesian Inference for Bivariate Conditional Copula Models with Continuous or Mixed Outcomes},
	abstract = {The main goal of this thesis is to develop Bayesian model for studying the inﬂuence of covariate on dependence between random variables. Conditional copula models are ﬂexible tools for modelling complex dependence structures. We construct Bayesian inference for the conditional copula model adapted to regression settings in which the bivariate outcome is continuous or mixed (binary and continuous) and the copula parameter varies with covariate values. The functional relationship between the copula parameter and the covariate is modelled using cubic splines. We also extend our work to additive models which would allow us to handle more than one covariate while keeping the computational burden within reasonable limits. We perform the proposed joint Bayesian inference via adaptive Markov chain Monte Carlo sampling. The deviance information criterion and cross-validated marginal log-likelihood criterion are employed for three model selection problems: 1) choosing the copula family that best ﬁts the data, 2) selecting the calibration function, i.e., checking if parametric form for copula parameter is suitable and 3) determining the number of independent variables in the additive model. The performance of the estimation and model selection techniques are investigated via simulations and demonstrated on two data sets: 1) Matched Multiple Birth and 2) Burn Injury. In which of interest is the inﬂuence of gestational age and maternal age on twin birth weights in the former data, whereas in the later data we are interested in investigating how patient’s age aﬀects the severity of burn injury and the probability of death.},
	pagetotal = {111},
	institution = {University of Toronto},
	type = {phdthesis},
	author = {Sabeti, Avideh},
	date = {2013},
	langid = {english},
	file = {sabeti_bayesian_inference_for_bivariate_conditional_copula_models_with_continuous_or.pdf:/home/nathan/Dropbox/njames/zotero_sync/sabeti_bayesian_inference_for_bivariate_conditional_copula_models_with_continuous_or.pdf:application/pdf}
}

@article{acar_statistical_2013,
	title = {Statistical testing of covariate effects in conditional copula models},
	volume = {7},
	issn = {1935-7524},
	url = {http://projecteuclid.org/euclid.ejs/1385995292},
	doi = {10.1214/13-EJS866},
	abstract = {In conditional copula models, the copula parameter is deterministically linked to a covariate via the calibration function. The latter is of central interest for inference and is usually estimated nonparametrically. However, in many applications it is scientiﬁcally important to test whether the calibration function is constant or not. Moreover, a correct model of a constant relationship results in signiﬁcant gains of statistical eﬃciency. We develop methodology for testing a parametric formulation of the calibration function against a general alternative and propose a generalized likelihood ratio-type test that enables conditional copula model diagnostics. We derive the asymptotic null distribution of the proposed test and study its ﬁnite sample performance using simulations. The method is applied to two data examples.},
	pages = {2822--2850},
	number = {0},
	journaltitle = {Electronic Journal of Statistics},
	author = {Acar, Elif F. and Craiu, Radu V. and Yao, Fang},
	urldate = {2018-09-27},
	date = {2013},
	langid = {english},
	file = {acar_et_al_2013_statistical_testing_of_covariate_effects_in_conditional_copula_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/acar_et_al_2013_statistical_testing_of_covariate_effects_in_conditional_copula_models.pdf:application/pdf}
}

@article{klein_simultaneous_2016,
	title = {Simultaneous inference in structured additive conditional copula regression models: a unifying Bayesian approach},
	volume = {26},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-015-9573-6},
	doi = {10.1007/s11222-015-9573-6},
	shorttitle = {Simultaneous inference in structured additive conditional copula regression models},
	pages = {841--860},
	number = {4},
	journaltitle = {Statistics and Computing},
	author = {Klein, Nadja and Kneib, Thomas},
	urldate = {2018-09-27},
	date = {2016-07},
	langid = {english},
	file = {klein_kneib_2016_simultaneous_inference_in_structured_additive_conditional_copula_regression.pdf:/home/nathan/Dropbox/njames/zotero_sync/klein_kneib_2016_simultaneous_inference_in_structured_additive_conditional_copula_regression.pdf:application/pdf}
}

@article{levi_gaussian_2016,
	title = {Gaussian Process Single Index Models for Conditional Copulas},
	url = {http://arxiv.org/abs/1603.03028},
	abstract = {Parametric conditional copula models allow the copula parameters to vary with a set of covariates according to an unknown calibration function. Flexible Bayesian inference for the calibration function of a bivariate conditional copula is proposed via a sparse Gaussian process ({GP}) prior distribution over the set of smooth calibration functions for the single index model ({SIM}). The estimation of parameters from the marginal distributions and the calibration function is done jointly via Markov Chain Monte Carlo sampling from the full posterior distribution. A new Conditional Cross Validated Pseudo-Marginal ({CCVML}) criterion is introduced in order to perform copula selection and is modiﬁed using a permutation-based procedure to assess data support for the simplifying assumption. The performance of the estimation method and model selection criteria is studied via a series of simulations using correct and misspeciﬁed models with Clayton, Frank and Gaussian copulas and a numerical application involving red wine features.},
	journaltitle = {{arXiv}:1603.03028 [stat]},
	author = {Levi, Evgeny and Craiu, Radu V.},
	urldate = {2018-09-27},
	date = {2016-03-09},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1603.03028},
	keywords = {Statistics - Methodology},
	file = {levi_craiu_2016_gaussian_process_single_index_models_for_conditional_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/levi_craiu_2016_gaussian_process_single_index_models_for_conditional_copulas.pdf:application/pdf}
}

@article{levi_bayesian_2018,
	title = {Bayesian inference for conditional copulas using Gaussian Process single index models},
	volume = {122},
	issn = {01679473},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167947318300148},
	doi = {10.1016/j.csda.2018.01.013},
	abstract = {Parametric conditional copula models allow the copula parameters to vary with a set of covariates according to an unknown calibration function. Flexible Bayesian inference for the calibration function of a bivariate conditional copula is introduced. The prior distribution over the set of smooth calibration functions is built using a sparse Gaussian process ({GP}) prior for the single index model ({SIM}). The estimation of parameters from the marginal distributions and the calibration function is done jointly via Markov Chain Monte Carlo sampling from the full posterior distribution. A new Conditional Cross Validated {PseudoMarginal} ({CCVML}) criterion is used to perform copula selection and is modified using a permutation-based procedure to assess data support for the simplifying assumption. The performance of the estimation method and model selection criteria is studied via a series of simulations using correct and misspecified models with Clayton, Frank and Gaussian copulas and a numerical application involving red wine features.},
	pages = {115--134},
	journaltitle = {Computational Statistics \& Data Analysis},
	author = {Levi, Evgeny and Craiu, Radu V.},
	urldate = {2018-09-27},
	date = {2018-06},
	langid = {english},
	file = {levi_craiu_2018_bayesian_inference_for_conditional_copulas_using_gaussian_process_single_index.pdf:/home/nathan/Dropbox/njames/zotero_sync/levi_craiu_2018_bayesian_inference_for_conditional_copulas_using_gaussian_process_single_index.pdf:application/pdf}
}

@article{fermanian_single-index_2018,
	title = {Single-index copulas},
	volume = {165},
	issn = {0047259X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0047259X17303032},
	doi = {10.1016/j.jmva.2017.11.004},
	abstract = {We introduce so-called single-index copulas. They are semi-parametric conditional copulas whose parameter is an unknown link function of a univariate index only. We propose estimates of this link function and of the finite-dimensional unknown parameter. The asymptotic properties of the latter estimates are stated. Thanks to some properties of conditional Kendall’s tau, we illustrate our technical conditions with several usual copula families.},
	pages = {27--55},
	journaltitle = {Journal of Multivariate Analysis},
	author = {Fermanian, Jean-David and Lopez, Olivier},
	urldate = {2018-09-27},
	date = {2018-05},
	langid = {english},
	file = {fermanian_lopez_2018_single-index_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/fermanian_lopez_2018_single-index_copulas.pdf:application/pdf}
}

@book{nelsen_introduction_2006,
	location = {New York},
	edition = {2nd ed},
	title = {An introduction to copulas},
	isbn = {978-0-387-28659-4},
	series = {Springer series in statistics},
	pagetotal = {269},
	publisher = {Springer},
	author = {Nelsen, Roger B.},
	date = {2006},
	keywords = {Copulas (Mathematical statistics)}
}

@book{joe_dependence_2015,
	location = {Boca Raton},
	title = {Dependence modeling with copulas},
	isbn = {978-1-4665-8322-1},
	series = {Monographs on statistics and applied probability},
	pagetotal = {462},
	number = {134},
	publisher = {{CRC} Press, Taylor \& Francis Group},
	author = {Joe, Harry},
	date = {2015},
	keywords = {Copulas (Mathematical statistics), Dependence (Statistics), Probabilities}
}

@software{hofert_copula:_2016,
	title = {copula: Multivariate Dependence with Copulas},
	url = {http://cran.r-project.org/package=copula},
	version = {0.999-15},
	author = {Hofert, Marius and Kojadinovic, Ivan and Maechler, Martin and Yan, Jun},
	date = {2016}
}

@book{yuan_bayesian_2016,
	location = {Boca Raton},
	title = {Bayesian designs for phase I-{II} clinical trials},
	isbn = {978-1-4987-0955-2},
	series = {Chapman \& Hall/{CRC} Biostatistics series},
	pagetotal = {310},
	publisher = {{CRC} Press,Taylor \& Francis Group},
	author = {Yuan, Ying and Nguyen, Hoang Q. and Thall, Peter F.},
	date = {2016},
	note = {{OCLC}: ocn936350306},
	keywords = {Clinical trials, Bayes Theorem, Bayesian statistical decision theory, Clinical Trials, Phase I as Topic, Clinical Trials, Phase {II} as Topic, Dose-Response Relationship, Drug, Drugs, Statistical methods, Statistics as Topic, Testing Statistical methods}
}

@article{schepsmeier_derivatives_2014,
	title = {Derivatives and Fisher information of bivariate copulas},
	volume = {55},
	issn = {0932-5026, 1613-9798},
	url = {http://link.springer.com/10.1007/s00362-013-0498-x},
	doi = {10.1007/s00362-013-0498-x},
	abstract = {Data sets with complex relationships between random variables are increasingly studied in statistical applications. A popular approach to model their dependence is the use of copula functions. Our contribution is to derive expressions for the observed and expected information for several bivariate copula families, in particular for the Student’s t-copula. Further likelihood derivatives which are required for numerical implementations are computed and a numerically stable implementation is provided in the R-package {VineCopula}. Using a real world data set of stock returns, we demonstrate the applicability of our approach for the routinely calculation of standard errors. In particular, we illustrate how this prevents overestimating the time-variation of dependence parameters in a rolling window analysis.},
	pages = {525--542},
	number = {2},
	journaltitle = {Statistical Papers},
	author = {Schepsmeier, Ulf and Stöber, Jakob},
	urldate = {2018-10-05},
	date = {2014-05},
	langid = {english},
	file = {schepsmeier_stöber_2014_derivatives_and_fisher_information_of_bivariate_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/schepsmeier_stöber_2014_derivatives_and_fisher_information_of_bivariate_copulas.pdf:application/pdf}
}

@article{meyer_bivariate_2013,
	title = {The Bivariate Normal Copula},
	volume = {42},
	issn = {0361-0926, 1532-415X},
	url = {http://arxiv.org/abs/0912.2816},
	doi = {10.1080/03610926.2011.611316},
	abstract = {We collect well known and less known facts about the bivariate normal distribution and translate them into copula language. In addition, we prove a very general formula for the bivariate normal copula, we compute Gini’s gamma, and we provide improved bounds and approximations on the diagonal.},
	pages = {2402--2422},
	number = {13},
	journaltitle = {Communications in Statistics - Theory and Methods},
	author = {Meyer, Christian},
	urldate = {2018-10-05},
	date = {2013-07-03},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {0912.2816},
	keywords = {60E15, 62H20, 62E99, Mathematics - Probability, Quantitative Finance - Computational Finance},
	file = {meyer_2013_the_bivariate_normal_copula.pdf:/home/nathan/Dropbox/njames/zotero_sync/meyer_2013_the_bivariate_normal_copula.pdf:application/pdf}
}

@article{dragalin_adaptive_2006,
	title = {Adaptive designs for dose-finding based on efficacy–toxicity response},
	volume = {136},
	issn = {03783758},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0378375805001862},
	doi = {10.1016/j.jspi.2005.08.005},
	abstract = {We propose a new adaptive procedure for dose-ﬁnding in clinical trials when both efﬁcacy and toxicity responses are available. We model the distribution of this bivariate binary endpoint using either Gumbel bivariate logistic regression or Cox bivariate binary model. In both cases, the analytic formulae for the Fisher information matrix are obtained, that form the basis for derivation of the locally optimal and adaptive designs.},
	pages = {1800--1823},
	number = {6},
	journaltitle = {Journal of Statistical Planning and Inference},
	author = {Dragalin, Vladimir and Fedorov, Valerii},
	urldate = {2018-10-05},
	date = {2006-06},
	langid = {english},
	file = {dragalin_fedorov_2006_adaptive_designs_for_dose-finding_based_on_efficacy–toxicity_response.pdf:/home/nathan/Dropbox/njames/zotero_sync/dragalin_fedorov_2006_adaptive_designs_for_dose-finding_based_on_efficacy–toxicity_response.pdf:application/pdf}
}

@article{denman_design_2011,
	title = {Design of experiments for bivariate binary responses modelled by Copula functions},
	volume = {55},
	issn = {01679473},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0167947310003129},
	doi = {10.1016/j.csda.2010.07.025},
	abstract = {Optimal design for generalized linear models has primarily focused on univariate data. Often experiments are performed that have multiple dependent responses described by regression type models, and it is of interest and of value to design the experiment for all these responses. This requires a multivariate distribution underlying a pre-chosen model for the data. Here, we consider the design of experiments for bivariate binary data which are dependent. We explore Copula functions which provide a rich and flexible class of structures to derive joint distributions for bivariate binary data. We present methods for deriving optimal experimental designs for dependent bivariate binary data using Copulas, and demonstrate that, by including the dependence between responses in the design process, more efficient parameter estimates are obtained than by the usual practice of simply designing for a single variable only. Further, we investigate the robustness of designs with respect to initial parameter estimates and Copula function, and also show the performance of compound criteria within this bivariate binary setting.},
	pages = {1509--1520},
	number = {4},
	journaltitle = {Computational Statistics \& Data Analysis},
	author = {Denman, N.G. and {McGree}, J.M. and Eccleston, J.A. and Duffull, S.B.},
	urldate = {2018-10-05},
	date = {2011-04},
	langid = {english},
	file = {denman_et_al_2011_design_of_experiments_for_bivariate_binary_responses_modelled_by_copula.pdf:/home/nathan/Dropbox/njames/zotero_sync/denman_et_al_2011_design_of_experiments_for_bivariate_binary_responses_modelled_by_copula.pdf:application/pdf}
}

@article{de_leon_copula-based_2011,
	title = {Copula-based regression models for a bivariate mixed discrete and continuous outcome},
	volume = {30},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.4087},
	doi = {10.1002/sim.4087},
	pages = {175--185},
	number = {2},
	journaltitle = {Statistics in Medicine},
	author = {de Leon, A. R. and Wu, B.},
	urldate = {2018-10-05},
	date = {2011-01-30},
	langid = {english},
	file = {de_leon_wu_2011_copula-based_regression_models_for_a_bivariate_mixed_discrete_and_continuous.pdf:/home/nathan/Dropbox/njames/zotero_sync/de_leon_wu_2011_copula-based_regression_models_for_a_bivariate_mixed_discrete_and_continuous.pdf:application/pdf}
}

@article{dette_comments_2014,
	title = {Some Comments on Copula-Based Regression},
	volume = {109},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2014.916577},
	doi = {10.1080/01621459.2014.916577},
	pages = {1319--1324},
	number = {507},
	journaltitle = {Journal of the American Statistical Association},
	author = {Dette, Holger and Van Hecke, Ria and Volgushev, Stanislav},
	urldate = {2018-10-05},
	date = {2014-07-03},
	langid = {english},
	file = {dette_et_al_2014_some_comments_on_copula-based_regression.pdf:/home/nathan/Dropbox/njames/zotero_sync/dette_et_al_2014_some_comments_on_copula-based_regression.pdf:application/pdf}
}

@article{oakes_regression_2000,
	title = {Regression in a bivariate copula model},
	volume = {87},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/87.2.345},
	doi = {10.1093/biomet/87.2.345},
	pages = {345--352},
	number = {2},
	journaltitle = {Biometrika},
	author = {Oakes, D},
	urldate = {2018-10-05},
	date = {2000-06-01},
	langid = {english},
	file = {oakes_2000_regression_in_a_bivariate_copula_model.pdf:/home/nathan/Dropbox/njames/zotero_sync/oakes_2000_regression_in_a_bivariate_copula_model.pdf:application/pdf}
}

@article{zapf_what_2018,
	title = {What makes a biostatistician?},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.7998},
	doi = {10.1002/sim.7998},
	journaltitle = {Statistics in Medicine},
	author = {Zapf, Antonia and Huebner, Marianne and Rauch, Geraldine and Kieser, Meinhard},
	urldate = {2018-10-08},
	date = {2018-10-07},
	langid = {english},
	file = {zapf_et_al_2018_what_makes_a_biostatistician.pdf:/home/nathan/Dropbox/njames/zotero_sync/zapf_et_al_2018_what_makes_a_biostatistician.pdf:application/pdf}
}

@article{park_bayesian_2018,
	title = {Bayesian Inference in the Presence of Intractable Normalizing Functions},
	volume = {113},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2018.1448824},
	doi = {10.1080/01621459.2018.1448824},
	abstract = {Models with intractable normalizing functions arise frequently in statistics. Common examples of such models include exponential random graph models for social networks and Markov point processes for ecology and disease modeling. Inference for these models is complicated because the normalizing functions of their probability distributions include the parameters of interest. In Bayesian analysis, they result in so-called doubly intractable posterior distributions which pose significant computational challenges. Several Monte Carlo methods have emerged in recent years to address Bayesian inference for such models. We provide a framework for understanding the algorithms, and elucidate connections among them. Through multiple simulated and real data examples, we compare and contrast the computational and statistical efficiency of these algorithms and discuss their theoretical bases. Our study provides practical recommendations for practitioners along with directions for future research for Markov chain Monte Carlo ({MCMC}) methodologists. Supplementary materials for this article are available online.},
	pages = {1372--1390},
	number = {523},
	journaltitle = {Journal of the American Statistical Association},
	author = {Park, Jaewoo and Haran, Murali},
	urldate = {2018-10-11},
	date = {2018-07-03},
	langid = {english},
	file = {park_haran_2018_bayesian_inference_in_the_presence_of_intractable_normalizing_functions.pdf:/home/nathan/Dropbox/njames/zotero_sync/park_haran_2018_bayesian_inference_in_the_presence_of_intractable_normalizing_functions.pdf:application/pdf}
}

@article{rover_model_2018,
	title = {Model averaging for robust extrapolation in evidence synthesis: Model averaging for robust extrapolation in evidence synthesis},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.7991},
	doi = {10.1002/sim.7991},
	shorttitle = {Model averaging for robust extrapolation in evidence synthesis},
	journaltitle = {Statistics in Medicine},
	author = {Röver, Christian and Wandel, Simon and Friede, Tim},
	urldate = {2018-10-11},
	date = {2018-10-10},
	langid = {english},
	file = {röver_et_al_2018_model_averaging_for_robust_extrapolation_in_evidence_synthesis.pdf:/home/nathan/Dropbox/njames/zotero_sync/röver_et_al_2018_model_averaging_for_robust_extrapolation_in_evidence_synthesis.pdf:application/pdf}
}

@article{masarotto_gaussian_2017,
	title = {Gaussian Copula Regression in R},
	volume = {77},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v77/i08/},
	doi = {10.18637/jss.v077.i08},
	abstract = {This article describes the R package gcmr for ﬁtting Gaussian copula marginal regression models. The Gaussian copula provides a mathematically convenient framework to handle various forms of dependence in regression models arising, for example, in time series, longitudinal studies or spatial data. The package gcmr implements maximum likelihood inference for Gaussian copula marginal regression. The likelihood function is approximated with a sequential importance sampling algorithm in the discrete case. The package is designed to allow a ﬂexible speciﬁcation of the regression model and the dependence structure. Illustrations include negative binomial modeling of longitudinal count data, beta regression for time series of rates and logistic regression for spatially correlated binomial data.},
	number = {8},
	journaltitle = {Journal of Statistical Software},
	author = {Masarotto, Guido and Varin, Cristiano},
	urldate = {2018-10-12},
	date = {2017},
	langid = {english},
	file = {masarotto_varin_2017_gaussian_copula_regression_in_r.pdf:/home/nathan/Dropbox/njames/zotero_sync/masarotto_varin_2017_gaussian_copula_regression_in_r.pdf:application/pdf}
}

@article{masarotto_gaussian_2012,
	title = {Gaussian copula marginal regression},
	volume = {6},
	issn = {1935-7524},
	url = {http://projecteuclid.org/euclid.ejs/1346421603},
	doi = {10.1214/12-EJS721},
	abstract = {This paper identiﬁes and develops the class of Gaussian copula models for marginal regression analysis of non-normal dependent observations. The class provides a natural extension of traditional linear regression models with normal correlated errors. Any kind of continuous, discrete and categorical responses is allowed. Dependence is conveniently modelled in terms of multivariate normal errors. Inference is performed through a likelihood approach. While the likelihood function is available in closed-form for continuous responses, in the non-continuous setting numerical approximations are used. Residual analysis and a speciﬁcation test are suggested for validating the adequacy of the assumed multivariate model. Methodology is implemented in a R package called gcmr. Illustrations include simulations and real data applications regarding time series, cross-design data, longitudinal studies, survival analysis and spatial regression.},
	pages = {1517--1549},
	number = {0},
	journaltitle = {Electronic Journal of Statistics},
	author = {Masarotto, Guido and Varin, Cristiano},
	urldate = {2018-10-12},
	date = {2012},
	langid = {english},
	file = {masarotto_varin_2012_gaussian_copula_marginal_regression.pdf:/home/nathan/Dropbox/njames/zotero_sync/masarotto_varin_2012_gaussian_copula_marginal_regression.pdf:application/pdf}
}

@article{pitt_efficient_2006,
	title = {Efficient Bayesian inference for Gaussian copula regression models},
	volume = {93},
	issn = {1464-3510, 0006-3444},
	url = {http://academic.oup.com/biomet/article/93/3/537/380692/Efficient-Bayesian-inference-for-Gaussian-copula},
	doi = {10.1093/biomet/93.3.537},
	abstract = {A Gaussian copula regression model gives a tractable way of handling a multivariate regression when some of the marginal distributions are non-Gaussian. Our paper presents a general Bayesian approach for estimating a Gaussian copula model that can handle any combination of discrete and continuous marginals, and generalises Gaussian graphical models to the Gaussian copula framework. Posterior inference is carried out using a novel and efficient simulation method. The methods in the paper are applied to simulated and real data.},
	pages = {537--554},
	number = {3},
	journaltitle = {Biometrika},
	author = {Pitt, Michael and Chan, David and Kohn, Robert},
	urldate = {2018-10-12},
	date = {2006-09-01},
	langid = {english},
	file = {pitt_et_al_2006_efficient_bayesian_inference_for_gaussian_copula_regression_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/pitt_et_al_2006_efficient_bayesian_inference_for_gaussian_copula_regression_models.pdf:application/pdf}
}

@article{song_joint_2009,
	title = {Joint Regression Analysis of Correlated Data Using Gaussian Copulas},
	volume = {65},
	issn = {0006341X},
	url = {http://doi.wiley.com/10.1111/j.1541-0420.2008.01058.x},
	doi = {10.1111/j.1541-0420.2008.01058.x},
	abstract = {This article concerns a new joint modeling approach for correlated data analysis. Utilizing Gaussian copulas, we present a uniﬁed and ﬂexible machinery to integrate separate one-dimensional generalized linear models ({GLMs}) into a joint regression analysis of continuous, discrete, and mixed correlated outcomes. This essentially leads to a multivariate analogue of the univariate {GLM} theory and hence an eﬃciency gain in the estimation of regression coeﬃcients. The availability of joint probability models enables us to develop a full maximum likelihood inference. Numerical illustrations are focused on regression models for discrete correlated data, including multidimensional logistic regression models and a joint model for mixed normal and binary outcomes. In the simulation studies, the proposed copula-based joint model is compared to the popular generalized estimating equations, which is a moment-based estimating equation method to join univariate {GLMs}. Two real-world data examples are used in the illustration.},
	pages = {60--68},
	number = {1},
	journaltitle = {Biometrics},
	author = {Song, Peter X.-K. and Li, Mingyao and Yuan, Ying},
	urldate = {2018-10-12},
	date = {2009-03},
	langid = {english},
	file = {song_et_al_2009_joint_regression_analysis_of_correlated_data_using_gaussian_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/song_et_al_2009_joint_regression_analysis_of_correlated_data_using_gaussian_copulas.pdf:application/pdf}
}

@thesis{roy_conditional_2015,
	title = {Conditional Dependence in Joint Modelling of Longitudinal Non-Gaussian Outcomes},
	pagetotal = {71},
	institution = {University of Calgary},
	type = {{MS}},
	author = {Roy, Mili},
	date = {2015},
	langid = {english},
	file = {roy_conditional_dependence_in_joint_modelling_of_longitudinal_non-gaussian_outcomes.pdf:/home/nathan/Dropbox/njames/zotero_sync/roy_conditional_dependence_in_joint_modelling_of_longitudinal_non-gaussian_outcomes.pdf:application/pdf}
}

@article{smith_estimation_2012,
	title = {Estimation of Copula Models With Discrete Margins via Bayesian Data Augmentation},
	volume = {107},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2011.644501},
	doi = {10.1080/01621459.2011.644501},
	pages = {290--303},
	number = {497},
	journaltitle = {Journal of the American Statistical Association},
	author = {Smith, Michael S. and Khaled, Mohamad A.},
	urldate = {2018-10-12},
	date = {2012-03},
	langid = {english},
	file = {smith_khaled_2012_estimation_of_copula_models_with_discrete_margins_via_bayesian_data_augmentation.pdf:/home/nathan/Dropbox/njames/zotero_sync/smith_khaled_2012_estimation_of_copula_models_with_discrete_margins_via_bayesian_data_augmentation.pdf:application/pdf}
}

@article{kauermann_flexible_2013,
	title = {Flexible Copula Density Estimation with Penalized Hierarchical B-splines: Flexible copula density estimation},
	volume = {40},
	issn = {03036898},
	url = {http://doi.wiley.com/10.1111/sjos.12018},
	doi = {10.1111/sjos.12018},
	shorttitle = {Flexible Copula Density Estimation with Penalized Hierarchical B-splines},
	abstract = {The paper introduces a new method for ﬂexible spline ﬁtting for copula density estimation. Spline coeﬃcients are penalized to achieve a smooth ﬁt. To weaken the curse of dimensionality, instead of a full tensor spline basis, a reduced tensor product based on sparse grids Zenger (1991) is used. To achieve uniform margins of the copula density, linear constraints are placed on the spline coeﬃcients and quadratic programming is used to ﬁt the model. Simulations and practical examples accompany the presentation.},
	pages = {685--705},
	number = {4},
	journaltitle = {Scandinavian Journal of Statistics},
	author = {Kauermann, Göran and Schellhase, Christian and Ruppert, David},
	urldate = {2018-10-12},
	date = {2013-12},
	langid = {english},
	file = {kauermann_et_al_2013_flexible_copula_density_estimation_with_penalized_hierarchical_b-splines.pdf:/home/nathan/Dropbox/njames/zotero_sync/kauermann_et_al_2013_flexible_copula_density_estimation_with_penalized_hierarchical_b-splines.pdf:application/pdf}
}

@article{wichitaksorn_efficient_2012,
	title = {Efficient Estimation of Some Elliptical Copula Regression Models through Scale Mixtures of Normal},
	issn = {1556-5068},
	url = {http://www.ssrn.com/abstract=2125587},
	doi = {10.2139/ssrn.2125587},
	abstract = {We simplify the implementation of some elliptical copula regression models through the normal representation. Both copula and marginal probability density functions are expressed as the scale mixtures of normals to facilitate the estimation procedure. With the fact that all elliptical distributions have the same correlation structure and some of them can be expressed as a scale mixture of multivariate normal, we can then estimate their correlation matrix with ease. Two simulation studies are illustrated to assess the performance of our proposed models and methods. We also conduct two empirical studies on U.S. excess return and Thai wage earnings to show the applicability to the multivariate Capital Asset Pricing Model and the bivariate seemingly unrelated Tobit model, respectively.},
	journaltitle = {{SSRN} Electronic Journal},
	author = {Wichitaksorn, Nuttanan and Gerlach, Richard H. and Choy, Boris},
	urldate = {2018-10-12},
	date = {2012},
	langid = {english},
	file = {wichitaksorn_et_al_2012_efficient_estimation_of_some_elliptical_copula_regression_models_through_scale.pdf:/home/nathan/Dropbox/njames/zotero_sync/wichitaksorn_et_al_2012_efficient_estimation_of_some_elliptical_copula_regression_models_through_scale.pdf:application/pdf}
}

@thesis{baek_copula-based_2010,
	title = {A Copula-Based Method for Analyzing Bivariate Binary Longitudinal Data},
	abstract = {The work presented as part of this dissertation is primarily motivated by a randomized trial for {HIV} serodiscordant couples. Specifically, the Multisite {HIV}/{STD} Prevention Trial for African American Couples is a behavioral modification trial for African American, heterosexual, {HIV} discordant couples. In this trial, investigators developed and evaluated a couple-based behavioral intervention for reducing risky shared sexual behaviors and collected retrospective outcomes from both partners at baseline and at 3 follow-ups to evaluate the intervention efficacy. As the outcomes refer to the couples' shared sexual behavior, couples' responses are expected to be correlated, and modeling approaches should account for multiple sources of correlation: within-individual over time as well as within-couple both at the same measurement time and at different times. This dissertation details the novel application copulas to modeling dyadic, longitudinal binary data to estimate reliability and efficacy. Copulas have long been analytic tools for modeling multivariate outcomes in other settings. Particularly, we selected a mixture of max-infinitely divisible (max-id) copula because it has a number of attractive analytic features.},
	pagetotal = {95},
	institution = {University of Pennsylvania},
	type = {phdthesis},
	author = {Baek, Seunghee},
	date = {2010},
	langid = {english},
	file = {baek_a_copula-based_method_for_analyzing_bivariate_binary_longitudinal_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/baek_a_copula-based_method_for_analyzing_bivariate_binary_longitudinal_data.pdf:application/pdf}
}

@thesis{ding_copula_2015,
	title = {Copula Regression Models for the Analysis of Correlated Data with Missing Values},
	pagetotal = {127},
	institution = {University of Michigan},
	type = {phdthesis},
	author = {Ding, Wei},
	date = {2015},
	langid = {english},
	file = {ding_copula_regression_models_for_the_analysis_of_correlated_data_with_missing_values.pdf:/home/nathan/Dropbox/njames/zotero_sync/ding_copula_regression_models_for_the_analysis_of_correlated_data_with_missing_values.pdf:application/pdf}
}

@article{chiu_using_2012,
	title = {Using Copulas to Introduce Dependence in Dose-Response Modeling of Multiple Binary Endpoints},
	volume = {17},
	issn = {1085-7117, 1537-2693},
	url = {http://link.springer.com/10.1007/s13253-011-0078-2},
	doi = {10.1007/s13253-011-0078-2},
	pages = {107--127},
	number = {1},
	journaltitle = {Journal of Agricultural, Biological, and Environmental Statistics},
	author = {Chiu, Weihsueh A. and Crump, Kenny S.},
	urldate = {2018-10-12},
	date = {2012-04},
	langid = {english},
	file = {chiu_crump_2012_using_copulas_to_introduce_dependence_in_dose-response_modeling_of_multiple.pdf:/home/nathan/Dropbox/njames/zotero_sync/chiu_crump_2012_using_copulas_to_introduce_dependence_in_dose-response_modeling_of_multiple.pdf:application/pdf}
}

@article{gunawan_mixed_2018,
	title = {Mixed Marginal Copula Modeling},
	issn = {0735-0015, 1537-2707},
	url = {https://www.tandfonline.com/doi/full/10.1080/07350015.2018.1469998},
	doi = {10.1080/07350015.2018.1469998},
	pages = {1--11},
	journaltitle = {Journal of Business \& Economic Statistics},
	author = {Gunawan, David and Khaled, Mohamad A. and Kohn, Robert},
	urldate = {2018-10-12},
	date = {2018-05-09},
	langid = {english},
	file = {gunawan_et_al_2018_mixed_marginal_copula_modeling.pdf:/home/nathan/Dropbox/njames/zotero_sync/gunawan_et_al_2018_mixed_marginal_copula_modeling.pdf:application/pdf}
}

@article{wichitaksorn_modeling_2011,
	title = {Modeling Dependence of Seemingly Unrelated Tobit Model through Copula: A Bayesian Analysis},
	volume = {3},
	abstract = {We extend the Bayesian analysis of Seemingly Unrelated Tobit models by modeling dependence through a bivariate Gaussian copula. Having employed the copula approach, we avail ourselves of more flexibility in coupling together various distributions for marginal errors of the model. Bayesian Markov Chain Monte Carlo methods through {MetropolisHastings} coincident with data augmentation are performed to obtain the parameter estimates through a simulation study. We also apply our model and methods to Thai wage earnings data in 2002, which yield satisfactory results.},
	pages = {6--19},
	number = {3},
	journaltitle = {Thailand Econometrics Society},
	author = {Wichitaksorn, Nuttanan and Choy, S T Boris},
	date = {2011-01},
	langid = {english},
	file = {wichitaksorn_choy_modeling_dependence_of_seemingly_unrelated_tobit_model_through_copula.pdf:/home/nathan/Dropbox/njames/zotero_sync/wichitaksorn_choy_modeling_dependence_of_seemingly_unrelated_tobit_model_through_copula.pdf:application/pdf}
}

@thesis{wu_contributions_2013,
	title = {Contributions to Copula Modeling of Mixed Discrete-Continuous Outcomes},
	pagetotal = {126},
	institution = {University of Calgary},
	type = {phdthesis},
	author = {Wu, Beilei},
	date = {2013-07},
	langid = {english},
	file = {wu_contributions_to_copula_modeling_of_mixed_discrete-continuous_outcomes.pdf:/home/nathan/Dropbox/njames/zotero_sync/wu_contributions_to_copula_modeling_of_mixed_discrete-continuous_outcomes.pdf:application/pdf}
}

@article{kauermann_penalized_2014,
	title = {Penalized marginal likelihood estimation of finite mixtures of Archimedean copulas},
	volume = {29},
	issn = {0943-4062, 1613-9658},
	url = {http://link.springer.com/10.1007/s00180-013-0454-1},
	doi = {10.1007/s00180-013-0454-1},
	abstract = {This paper proposes ﬁnite mixtures of different Archimedean copula families as a ﬂexible tool for modelling the dependence structure in multivariate data. A novel approach to estimating the parameters in this mixture model is presented by maximizing the penalized marginal likelihood via iterative quadratic programming. The motivation for the penalized marginal likelihood stems from an underlying Bayesian model that imposes a prior distribution on the parameter of each Archimedean copula family. An approximative marginal likelihood is obtained by a classical quadrature discretization of the integral w.r.t. each family-speciﬁc prior distribution, thus yielding a ﬁnite mixture model. Family-speciﬁc smoothness penalties are added and the penalized marginal likelihood is maximized using an iterative quadratic programming routine. For comparison purposes, we also present a fully Bayesian approach via simulation-based posterior computation. The performance of the novel estimation approach is evaluated by simulations and two examples involving the modelling of the interdependence of exchange rates and of wind speed measurements, respectively. For these examples, penalized marginal likelihood estimates are compared to the corresponding Bayesian estimates.},
	pages = {283--306},
	number = {1},
	journaltitle = {Computational Statistics},
	author = {Kauermann, Göran and Meyer, Renate},
	urldate = {2018-10-12},
	date = {2014-02},
	langid = {english},
	file = {kauermann_meyer_2014_penalized_marginal_likelihood_estimation_of_finite_mixtures_of_archimedean.pdf:/home/nathan/Dropbox/njames/zotero_sync/kauermann_meyer_2014_penalized_marginal_likelihood_estimation_of_finite_mixtures_of_archimedean.pdf:application/pdf}
}

@article{madsen_joint_2011,
	title = {Joint Regression Analysis for Discrete Longitudinal Data},
	volume = {67},
	issn = {0006341X},
	url = {http://doi.wiley.com/10.1111/j.1541-0420.2010.01494.x},
	doi = {10.1111/j.1541-0420.2010.01494.x},
	abstract = {We introduce an approximation to the Gaussian copula likelihood of Song, Li, and Yuan (2009, Biometrics 65, 60–68) used to estimate regression parameters from correlated discrete or mixed bivariate or trivariate outcomes. Our approximation allows estimation of parameters from response vectors of length much larger than three, and is asymptotically equivalent to the Gaussian copula likelihood. We estimate regression parameters from the toenail infection data of De Backer et al. (1996, British Journal of Dermatology 134, 16–17), which consist of binary response vectors of length seven or less from 294 subjects. Although maximizing the Gaussian copula likelihood yields estimators that are asymptotically more eﬃcient than generalized estimating equation ({GEE}) estimators, our simulation study illustrates that for ﬁnite samples, {GEE} estimators can actually be as much as 20\% more eﬃcient.},
	pages = {1171--1175},
	number = {3},
	journaltitle = {Biometrics},
	author = {Madsen, L. and Fang, Y.},
	urldate = {2018-10-12},
	date = {2011-09},
	langid = {english},
	file = {madsen_fang_2011_joint_regression_analysis_for_discrete_longitudinal_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/madsen_fang_2011_joint_regression_analysis_for_discrete_longitudinal_data.pdf:application/pdf}
}

@article{madsen_authors_2011,
	title = {The authors replied as follows:},
	volume = {67},
	issn = {0006341X},
	url = {http://doi.wiley.com/10.1111/j.1541-0420.2011.01698.x},
	doi = {10.1111/j.1541-0420.2011.01698.x},
	shorttitle = {The authors replied as follows},
	pages = {1670--1671},
	number = {4},
	journaltitle = {Biometrics},
	author = {Madsen, L. and Fang, Y.},
	urldate = {2018-10-12},
	date = {2011-12},
	langid = {english},
	file = {madsen_fang_2011_the_authors_replied_as_follows.pdf:/home/nathan/Dropbox/njames/zotero_sync/madsen_fang_2011_the_authors_replied_as_follows.pdf:application/pdf}
}

@article{wichitaksorn_efficient_2018,
	title = {Efficient {MCMC} estimation of some elliptical copula regression models through scale mixtures of normals: Elliptical copula regression models through scale mixtures of normals},
	issn = {15241904},
	url = {http://doi.wiley.com/10.1002/asmb.2410},
	doi = {10.1002/asmb.2410},
	shorttitle = {Efficient {MCMC} estimation of some elliptical copula regression models through scale mixtures of normals},
	abstract = {This paper proposes an efficient estimation method for some elliptical copula regression models by expressing both copula density and marginal density functions as scale mixtures of normals ({SMN}). Implementing these models using the {SMN} is novel and allows efficient estimation via Bayesian methods. An innovative algorithm for the case of complex semicontinuous margins is also presented. We utilize the facts that copulas are invariant to the location and scale of the margins; all elliptical distributions have the same correlation structure; and some densities can be represented by the {SMN}. Two simulation studies, one on continuous margins and the other on semicontinuous margins, highlight the favorable performance of the proposed methods. Two empirical studies, one on the {US} excess returns and one on the Thai wage earnings, further illustrate the applicability of the proposals.},
	journaltitle = {Applied Stochastic Models in Business and Industry},
	author = {Wichitaksorn, Nuttanan and Gerlach, Richard and Choy, S.T. Boris},
	urldate = {2018-10-12},
	date = {2018-09-24},
	langid = {english},
	file = {wichitaksorn_et_al_2018_efficient_mcmc_estimation_of_some_elliptical_copula_regression_models_through.pdf:/home/nathan/Dropbox/njames/zotero_sync/wichitaksorn_et_al_2018_efficient_mcmc_estimation_of_some_elliptical_copula_regression_models_through.pdf:application/pdf}
}

@article{senarathne_bayesian_2017,
	title = {Bayesian sequential design for Copula models: a comparison of designs selected under diﬀerent Copula models},
	abstract = {Copula models provide ﬂexible structures to derive the joint distribution of multivariate responses. However, they are rarely considered in the experimental design context, particularly in a Bayesian framework where model and parameter uncertainty are considered. In this work, a variety of such models are explored, which explain dependence structures in experiments where bivariate discrete and mixed responses are observed. A sequential Monte Carlo algorithm is adopted to reduce the computational eﬀort required in deriving sequential designs. Further, the performance of the total entropy utility function is evaluated under diﬀerent Copula models, which allows us to derive designs for the dual objectives of parameter estimation and model discrimination for Copula models. The results show that the total entropy utility function appears to estimate parameters equally well for all Copula models considered, and it is possible to discriminate between all Copula models considered despite having similar tail dependence. However, for experiments which yield binary and continuous data, it may require observing a large number of data points (around 1000) to discriminate between some Copula models, and this may not be possible in practice.},
	pages = {37},
	author = {Senarathne, {SGJ} and Drovandi, {CC} and {McGree}, {JM}},
	date = {2017},
	langid = {english},
	file = {senarathne_et_al_2017_bayesian_sequential_design_for_copula_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/senarathne_et_al_2017_bayesian_sequential_design_for_copula_models.pdf:application/pdf}
}

@article{fang_bayesian_2014,
	title = {A Bayesian Approach to Inference and Prediction for Spatially Correlated Count Data Based on Gaussian Copula Model},
	abstract = {Gaussian Copula has been successfully applied in spatially correlated count data due to its ability to completely model the high-dimensional dependence. In this article, we develop a Bayesian method to fulﬁll both parameter estimation and spatial prediction for spatially correlated count data set. A {MCMC} scheme ({MetropolisCHastings} Algorithm plus rejection sampling) is adopted to iteratively update parameter estimates; upon convergence the parameters are then used for spatial (missing count data) prediction. In terms of parameter estimation, we show that our approach yields better and more consistent results than the existing method and that our approach can signiﬁcantly decrease computational burden, in the same real-life data set. Moreover, we compare the spatial prediction performance to the common Generalized Additive Models ({GAM}). The results in the real-life dataset as well as a well-designed simulated data set both demonstrate that our approach outperforms {GAMs}, especially when the missing data is small.},
	pages = {8},
	author = {Fang, Yan},
	date = {2014},
	langid = {english},
	file = {fang_2014_a_bayesian_approach_to_inference_and_prediction_for_spatially_correlated_count.pdf:/home/nathan/Dropbox/njames/zotero_sync/fang_2014_a_bayesian_approach_to_inference_and_prediction_for_spatially_correlated_count.pdf:application/pdf}
}

@article{ganjali_copula_2015,
	title = {A Copula Approach to Joint Modeling of Longitudinal Measurements and Survival Times Using Monte Carlo Expectation-Maximization with Application to {AIDS} Studies},
	volume = {25},
	issn = {1054-3406, 1520-5711},
	url = {http://www.tandfonline.com/doi/full/10.1080/10543406.2014.971584},
	doi = {10.1080/10543406.2014.971584},
	pages = {1077--1099},
	number = {5},
	journaltitle = {Journal of Biopharmaceutical Statistics},
	author = {Ganjali, M. and Baghfalaki, T.},
	urldate = {2018-10-12},
	date = {2015-09-03},
	langid = {english},
	file = {ganjali_baghfalaki_2015_a_copula_approach_to_joint_modeling_of_longitudinal_measurements_and_survival.pdf:/home/nathan/Dropbox/njames/zotero_sync/ganjali_baghfalaki_2015_a_copula_approach_to_joint_modeling_of_longitudinal_measurements_and_survival.pdf:application/pdf}
}

@article{jiryaie_gaussian_2016,
	title = {Gaussian copula distributions for mixed data, with application in discrimination},
	volume = {86},
	issn = {0094-9655, 1563-5163},
	url = {http://www.tandfonline.com/doi/full/10.1080/00949655.2015.1077386},
	doi = {10.1080/00949655.2015.1077386},
	pages = {1643--1659},
	number = {9},
	journaltitle = {Journal of Statistical Computation and Simulation},
	author = {Jiryaie, F. and Withanage, N. and Wu, B. and de Leon, A.R.},
	urldate = {2018-10-12},
	date = {2016-06-12},
	langid = {english},
	file = {jiryaie_et_al_2016_gaussian_copula_distributions_for_mixed_data,_with_application_in_discrimination.pdf:/home/nathan/Dropbox/njames/zotero_sync/jiryaie_et_al_2016_gaussian_copula_distributions_for_mixed_data,_with_application_in_discrimination.pdf:application/pdf}
}

@article{kolev_copula-based_2009,
	title = {Copula-based regression models: A survey},
	volume = {139},
	issn = {03783758},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0378375809001517},
	doi = {10.1016/j.jspi.2009.05.023},
	shorttitle = {Copula-based regression models},
	abstract = {In this review paper we collect several results about copula-based models, especially concerning regression models, by focusing on some insurance applications. © 2009 Elsevier B.V. All rights reserved.},
	pages = {3847--3856},
	number = {11},
	journaltitle = {Journal of Statistical Planning and Inference},
	author = {Kolev, Nikolai and Paiva, Delhi},
	urldate = {2018-10-12},
	date = {2009-11},
	langid = {english},
	file = {kolev_paiva_2009_copula-based_regression_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/kolev_paiva_2009_copula-based_regression_models.pdf:application/pdf}
}

@article{wu_bayesian_2014,
	title = {Bayesian Nonparametric Inference for a Multivariate Copula Function},
	volume = {16},
	issn = {1387-5841, 1573-7713},
	url = {http://link.springer.com/10.1007/s11009-013-9348-5},
	doi = {10.1007/s11009-013-9348-5},
	abstract = {The paper presents a general Bayesian nonparametric approach for estimating a high dimensional copula. We first introduce the skew–normal copula, which we then extend to an infinite mixture model. The skew–normal copula fixes some limitations in the Gaussian copula. An {MCMC} algorithm is developed to draw samples from the correct posterior distribution and the model is investigated using both simulated and real applications.},
	pages = {747--763},
	number = {3},
	journaltitle = {Methodology and Computing in Applied Probability},
	author = {Wu, Juan and Wang, Xue and Walker, Stephen G.},
	urldate = {2018-10-12},
	date = {2014-09},
	langid = {english},
	file = {wu_et_al_2014_bayesian_nonparametric_inference_for_a_multivariate_copula_function.pdf:/home/nathan/Dropbox/njames/zotero_sync/wu_et_al_2014_bayesian_nonparametric_inference_for_a_multivariate_copula_function.pdf:application/pdf}
}

@article{burda_copula_2014,
	title = {Copula based factorization in Bayesian multivariate infinite mixture models},
	volume = {127},
	issn = {0047259X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0047259X14000347},
	doi = {10.1016/j.jmva.2014.02.011},
	abstract = {Bayesian nonparametric models based on infinite mixtures of density kernels have been recently gaining in popularity due to their flexibility and feasibility of implementation even in complicated modeling scenarios. However, these models have been rarely applied in more than one dimension. Indeed, implementation in the multivariate case is inherently difficult due to the rapidly increasing number of parameters needed to characterize the joint dependence structure accurately. In this paper, we propose a factorization scheme of multivariate dependence structures based on the copula modeling framework, whereby each marginal dimension in the mixing parameter space is modeled separately and the marginals are then linked by a nonparametric random copula function. Specifically, we consider nonparametric univariate Gaussian mixtures for the marginals and a multivariate random Bernstein polynomial copula for the link function, under the Dirichlet process prior. We show that in a multivariate setting this scheme leads to an improvement in the precision of a density estimate relative to the commonly used multivariate Gaussian mixture. We derive weak posterior consistency of the copula-based mixing scheme for general kernel types under high-level conditions, and strong posterior consistency for the specific Bernstein–Gaussian mixture model.},
	pages = {200--213},
	journaltitle = {Journal of Multivariate Analysis},
	author = {Burda, Martin and Prokhorov, Artem},
	urldate = {2018-10-12},
	date = {2014-05},
	langid = {english},
	file = {burda_prokhorov_2014_copula_based_factorization_in_bayesian_multivariate_infinite_mixture_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/burda_prokhorov_2014_copula_based_factorization_in_bayesian_multivariate_infinite_mixture_models.pdf:application/pdf}
}

@article{stober_comorbidity_2015,
	title = {Comorbidity of chronic diseases in the elderly: Patterns identified by a copula design for mixed responses},
	volume = {88},
	issn = {01679473},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167947315000304},
	doi = {10.1016/j.csda.2015.02.001},
	shorttitle = {Comorbidity of chronic diseases in the elderly},
	abstract = {Joint modeling of multiple health related random variables is essential to develop an understanding for the public health consequences of an aging population. This is particularly true for patients suffering from multiple chronic diseases. The contribution is to introduce a novel model for multivariate data where some response variables are discrete and some are continuous. It is based on pair copula constructions ({PCCs}) and has two major advantages over existing methodology. First, expressing the joint dependence structure in terms of bivariate copulas leads to a computationally advantageous expression for the likelihood function. This makes maximum likelihood estimation feasible for large multidimensional data sets. Second, different and possibly asymmetric bivariate (conditional) marginal distributions are allowed which is necessary to accurately describe the limiting behavior of conditional distributions for mixed discrete and continuous responses. The advantages and the favorable predictive performance of the model are demonstrated using data from the Second Longitudinal Study of Aging ({LSOA} {II}).},
	pages = {28--39},
	journaltitle = {Computational Statistics \& Data Analysis},
	author = {Stöber, Jakob and Hong, Hyokyoung Grace and Czado, Claudia and Ghosh, Pulak},
	urldate = {2018-10-12},
	date = {2015-08},
	langid = {english},
	file = {stöber_et_al_2015_comorbidity_of_chronic_diseases_in_the_elderly.pdf:/home/nathan/Dropbox/njames/zotero_sync/stöber_et_al_2015_comorbidity_of_chronic_diseases_in_the_elderly.pdf:application/pdf}
}

@incollection{jeliazkov_copula_2014,
	title = {Copula Analysis of Correlated Counts},
	volume = {34},
	isbn = {978-1-78441-185-5 978-1-78441-184-8},
	url = {http://www.emeraldinsight.com/doi/10.1108/S0731-905320140000034021},
	abstract = {Copula modeling enables the analysis of multivariate count data that has previously required imposition of potentially undesirable correlation restrictions or has limited attention to models with only a few outcomes. This article presents a method for analyzing correlated counts that is appealing because it retains well-known marginal distributions for each response while simultaneously allowing for ﬂexible correlations among the outcomes. The proposed framework extends the applicability of the method to settings with high-dimensional outcomes and provides an eﬃcient simulation method to generate the correlation matrix in a single step. Another open problem that is tackled is that of model comparison. In particular, the article presents techniques for estimating marginal likelihoods and Bayes factors in copula models. The methodology is implemented in a study of the joint behavior of four categories of U.S. technology patents. The results reveal that patent counts exhibit high levels of correlation among categories and that joint modeling is crucial for eliciting the interactions among these variables.},
	pages = {325--348},
	booktitle = {Advances in Econometrics},
	publisher = {Emerald Group Publishing Limited},
	author = {Hee Lee, Esther},
	editor = {Jeliazkov, Ivan and Poirier, Dale J.},
	urldate = {2018-10-12},
	date = {2014-11-19},
	langid = {english},
	doi = {10.1108/S0731-905320140000034021},
	file = {hee_lee_2014_copula_analysis_of_correlated_counts.pdf:/home/nathan/Dropbox/njames/zotero_sync/hee_lee_2014_copula_analysis_of_correlated_counts.pdf:application/pdf}
}

@article{min_bayesian_2010,
	title = {Bayesian inference for multivariate copulas using pair-copula constructions},
	volume = {8},
	abstract = {We provide a Bayesian analysis of pair-copula constructions ({PCCs}) (Aas et al., 2009), which outperform many other multivariate copula constructions in modeling dependencies in financial data. We use bivariate t-copulas as building blocks in a {PCC} to allow extreme events in bivariate margins individually. While parameters may be estimated by maximum likelihood, confidence intervals are difficult to obtain. Consequently, we develop a Markov chain Monte Carlo ({MCMC}) algorithm and compute credible intervals. Standard errors obtained from {MCMC} output are compared to those obtained from a numerical Hessian matrix and bootstrapping. As applications, we consider Norwegian financial returns and Euro swap rates. Finally, we apply the Bayesian model selection approach of Congdon (2006) to identify conditional independence, thus constructing more parsimonious {PCCs}.},
	pages = {511--546},
	number = {4},
	journaltitle = {Journal of Financial Econometrics},
	author = {Min, Aleksey and Czado, Claudia},
	date = {2010},
	langid = {english},
	file = {min_czado_2010_bayesian_inference_for_multivariate_copulas_using_pair-copula_constructions.pdf:/home/nathan/Dropbox/njames/zotero_sync/min_czado_2010_bayesian_inference_for_multivariate_copulas_using_pair-copula_constructions.pdf:application/pdf}
}

@article{smith_modeling_2010,
	title = {Modeling Longitudinal Data Using a Pair-Copula Decomposition of Serial Dependence},
	volume = {105},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1198/jasa.2010.tm09572},
	doi = {10.1198/jasa.2010.tm09572},
	pages = {1467--1479},
	number = {492},
	journaltitle = {Journal of the American Statistical Association},
	author = {Smith, Michael and Min, Aleksey and Almeida, Carlos and Czado, Claudia},
	urldate = {2018-10-12},
	date = {2010-12},
	langid = {english},
	file = {smith_et_al_2010_modeling_longitudinal_data_using_a_pair-copula_decomposition_of_serial.pdf:/home/nathan/Dropbox/njames/zotero_sync/smith_et_al_2010_modeling_longitudinal_data_using_a_pair-copula_decomposition_of_serial.pdf:application/pdf}
}

@article{azam_mixed_2015,
	title = {Mixed Density Based Copula Likelihood},
	issn = {1556-5068},
	url = {http://www.ssrn.com/abstract=2546690},
	doi = {10.2139/ssrn.2546690},
	abstract = {We consider a new copula method for mixed marginals of discrete and continuous random variables. Unlike the Bayesian methods in the literature , we use maximum likelihood estimation based on closed-form copula functions. We show with a simulation that our methodology performs similar to the method of Hoﬀ (2007) for mixed data, but is considerably simpler to estimate. We extend to a time series setting, where the parameters are allowed to vary over time. In an empirical application using data from the 2013 Household Finance Survey, we show how the copula dependence between income (continuous) and discrete household characteristics varies across groups who were aﬀected diﬀerently by the recent economic crisis.},
	journaltitle = {{SSRN} Electronic Journal},
	author = {Azam, Kazim and Lucas, Andre},
	urldate = {2018-10-12},
	date = {2015},
	langid = {english},
	file = {azam_lucas_2015_mixed_density_based_copula_likelihood.pdf:/home/nathan/Dropbox/njames/zotero_sync/azam_lucas_2015_mixed_density_based_copula_likelihood.pdf:application/pdf}
}

@article{hoff_extending_2007,
	title = {Extending the rank likelihood for semiparametric copula estimation},
	volume = {1},
	issn = {1932-6157},
	url = {http://projecteuclid.org/euclid.aoas/1183143739},
	doi = {10.1214/07-AOAS107},
	pages = {265--283},
	number = {1},
	journaltitle = {The Annals of Applied Statistics},
	author = {Hoff, Peter},
	urldate = {2018-10-12},
	date = {2007-06},
	langid = {english},
	file = {hoff_2007_extending_the_rank_likelihood_for_semiparametric_copula_estimation.pdf:/home/nathan/Dropbox/njames/zotero_sync/hoff_2007_extending_the_rank_likelihood_for_semiparametric_copula_estimation.pdf:application/pdf}
}

@article{wei_parallel_2016,
	title = {Parallel Computing for Copula Parameter Estimation with Big Data: A Simulation Study},
	pages = {26},
	author = {Wei, Zheng and Kim, Daeyoung and Conlon, Erin M},
	date = {2016-09},
	langid = {english},
	file = {wei_et_al_parallel_computing_for_copula_parameter_estimation_with_big_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/wei_et_al_parallel_computing_for_copula_parameter_estimation_with_big_data.pdf:application/pdf}
}

@thesis{diaz-martinez_use_2017,
	title = {The Use of Copulas in Cost-Effectiveness Analysis},
	abstract = {Background: Copula methods have been proposed as a way of modeling dependence between random variables because it lies in the flexibility of the assumption on marginals. As previous authors stated, "A copula is a function which joins or “couples” a multivariate distribution function to its one-dimensional marginal distribution functions. Given that cost and effectiveness are often related to each other and therefore they show statistical dependence, the use of copulas to handle uncertainty caused by sampling variation could be potentially useful when costeffectiveness analyses ({CEA}) are performed using patient-level data. The objective of this study was to empirically compare various copula distributions with two traditional methods, namely, the bootstrapping approach and the Bayesian approach assuming that incremental cost and {LYs} gained are bivariate normally distributed.
Methods: The patient-level data from a previously published observational study were analyzed using four copula distributions: independent, Farlie-Gumbel-Morgenstern ({FGM}), Frank and Clayton copulas. Using the results from the traditional methods previously published, models were compared in terms of incremental cost, incremental life years ({LYs}) gained and the costeffectiveness acceptability curves ({CEACs}) based on the net monetary benefit ({NMB}).
Results: Using the traditional methods provided similar results. The most pronounced impact was the improvement in precision given that the confidence intervals were so much narrower for the copulas methods in comparison to the traditional methods. Consequently, the probability of being optimal derived from the Frank and Clayton copulas were close to 1.0 at a willingness to pay (������) of {CA}\$20,000. By contrast, the traditional methods were optimal for a ������ of \$100,000 {CAD}.
Conclusions: The results of this study demonstreate the potential impact and importance of copulas in patient-level cost-effectiveness analysis. This approach could be particularly important in those situations where the data suggests some kind of dependence and some restrictions on the marginals, as observed in our case study.},
	pagetotal = {51},
	institution = {{McMaster} University},
	type = {{MS}},
	author = {Díaz-Martínez, Juan Pablo},
	date = {2017-08},
	langid = {english},
	file = {díaz-martínez_the_use_of_copulas_in_cost-effectiveness_analysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/díaz-martínez_the_use_of_copulas_in_cost-effectiveness_analysis.pdf:application/pdf}
}

@unpublished{azam_marginal_2012,
	title = {Marginal Speciﬁcations and a Gaussian Copula Estimation},
	abstract = {Multivariate analysis involving random variables of diﬀerent type like count, continuous or mixture of both is frequently required in economics. A Copula based methodology can be adopted for such data, where the association among the random variables is independent to their speciﬁc marginal distributions. Depending upon the chosen marginal speciﬁcations, copula estimation proceeds. A semi-parametric copula estimation, where the marginals are speciﬁed empirically performs very well, but for discrete data it’s appropriateness is questioned (see Genest et al. (1995)). Hoﬀ (2007) proposes a methodology where the marginal distributions are left completely unspeciﬁed and the copula parameters are estimated based on the order statistics of the observed data. We conduct an analysis to determine the eﬀect on the estimates of a gaussian copula due to various marginal speciﬁcations. Employing a bayesian framework, we ﬁnd that treating marginal distribution as unknown outperforms empirically distributed margins and misspeciﬁed margins in terms of biasedness and mean square error in small samples.},
	author = {Azam, Kazim},
	date = {2012},
	langid = {english},
	file = {azam_marginal_speciﬁcations_and_a_gaussian_copula_estimation.pdf:/home/nathan/Dropbox/njames/zotero_sync/azam_marginal_speciﬁcations_and_a_gaussian_copula_estimation.pdf:application/pdf}
}

@thesis{ghosh_copula_2009,
	title = {Copula Based Hierarchical Bayesian Models},
	pagetotal = {141},
	institution = {Texas A\&M University},
	type = {phdthesis},
	author = {Ghosh, Souparno},
	date = {2009-08},
	langid = {english},
	file = {ghosh_copula_based_hierarchical_bayesian_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/ghosh_copula_based_hierarchical_bayesian_models.pdf:application/pdf}
}

@article{zilko_copula_2016,
	title = {Copula in a multivariate mixed discrete–continuous model},
	volume = {103},
	issn = {01679473},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167947316300895},
	doi = {10.1016/j.csda.2016.02.017},
	abstract = {The use of different copula-based models to represent the joint distribution of an eightdimensional mixed discrete and continuous problem consisting of five discrete and three continuous variables is investigated. The discussion starts with the theoretical properties of the copula-based models. Four different models are constructed for the data collected for the purpose of predicting the length of disruption caused by problems with the train detection system in the Dutch railway network and their performance is tested. The more complex models turn out to represent the data better. Nevertheless, it is shown that the simpler eight dimensional Normal copula still constitutes a statistically sound model for the data.},
	pages = {28--55},
	journaltitle = {Computational Statistics \& Data Analysis},
	author = {Zilko, Aurelius A. and Kurowicka, Dorota},
	urldate = {2018-10-12},
	date = {2016-11},
	langid = {english},
	file = {zilko_kurowicka_2016_copula_in_a_multivariate_mixed_discrete–continuous_model.pdf:/home/nathan/Dropbox/njames/zotero_sync/zilko_kurowicka_2016_copula_in_a_multivariate_mixed_discrete–continuous_model.pdf:application/pdf}
}

@article{hamasaki_sample_2013,
	title = {Sample size determination for clinical trials with co-primary outcomes: exponential event times},
	volume = {12},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1545},
	doi = {10.1002/pst.1545},
	shorttitle = {Sample size determination for clinical trials with co-primary outcomes},
	pages = {28--34},
	number = {1},
	journaltitle = {Pharmaceutical Statistics},
	author = {Hamasaki, Toshimitsu and Sugimoto, Tomoyuki and Evans, Scott and Sozu, Takashi},
	urldate = {2018-10-12},
	date = {2013-01},
	langid = {english},
	file = {hamasaki_et_al_2013_sample_size_determination_for_clinical_trials_with_co-primary_outcomes.pdf:/home/nathan/Dropbox/njames/zotero_sync/hamasaki_et_al_2013_sample_size_determination_for_clinical_trials_with_co-primary_outcomes.pdf:application/pdf}
}

@article{sharples_role_2018,
	title = {The role of statistics in the era of big data: Electronic health records for healthcare research},
	volume = {136},
	issn = {01677152},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167715218300890},
	doi = {10.1016/j.spl.2018.02.044},
	shorttitle = {The role of statistics in the era of big data},
	abstract = {The transferring of medical records into huge electronic databases has opened up opportunities for research but requires attention to data quality, study design and issues of bias and confounding.},
	pages = {105--110},
	journaltitle = {Statistics \& Probability Letters},
	author = {Sharples, Linda D.},
	urldate = {2018-10-16},
	date = {2018-05},
	langid = {english},
	file = {sharples_2018_the_role_of_statistics_in_the_era_of_big_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/sharples_2018_the_role_of_statistics_in_the_era_of_big_data.pdf:application/pdf}
}

@article{weber_quantifying_2018,
	title = {Quantifying the association between progression-free survival and overall survival in oncology trials using Kendall's tau: Correlation between progression-free survival and overall survival},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.8001},
	doi = {10.1002/sim.8001},
	shorttitle = {Quantifying the association between progression-free survival and overall survival in oncology trials using Kendall's tau},
	journaltitle = {Statistics in Medicine},
	author = {Weber, Enya M. and Titman, Andrew C.},
	urldate = {2018-10-17},
	date = {2018-10-12},
	langid = {english},
	file = {weber_titman_2018_quantifying_the_association_between_progression-free_survival_and_overall.pdf:/home/nathan/Dropbox/njames/zotero_sync/weber_titman_2018_quantifying_the_association_between_progression-free_survival_and_overall.pdf:application/pdf}
}

@article{smith_applications_2018,
	title = {Applications of Bayesian statistical methodology to clinical trial design: A case study of a phase 2 trial with an interim futility assessment in patients with knee osteoarthritis},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1906},
	doi = {10.1002/pst.1906},
	shorttitle = {Applications of Bayesian statistical methodology to clinical trial design},
	journaltitle = {Pharmaceutical Statistics},
	author = {Smith, Claire L. and Jin, Yan and Raddad, Eyas and {McNearney}, Terry A. and Ni, Xiao and Monteith, David and Brown, Roger and Deeg, Mark A. and Schnitzer, Thomas},
	urldate = {2018-10-17},
	date = {2018-10-15},
	langid = {english},
	file = {smith_et_al_2018_applications_of_bayesian_statistical_methodology_to_clinical_trial_design.pdf:/home/nathan/Dropbox/njames/zotero_sync/smith_et_al_2018_applications_of_bayesian_statistical_methodology_to_clinical_trial_design.pdf:application/pdf}
}

@article{kucukelbir_automatic_2016,
	title = {Automatic Differentiation Variational Inference},
	url = {http://arxiv.org/abs/1603.00788},
	abstract = {Probabilistic modeling is iterative. A scientist posits a simple model, ﬁts it to her data, reﬁnes it according to her analysis, and repeats. However, ﬁtting complex models to large data is a bottleneck in this process. Deriving algorithms for new models can be both mathematically and computationally challenging, which makes it difﬁcult to efﬁciently cycle through the steps. To this end, we develop automatic differentiation variational inference ({ADVI}). Using our method, the scientist only provides a probabilistic model and a dataset, nothing else. {ADVI} automatically derives an efﬁcient variational inference algorithm, freeing the scientist to reﬁne and explore many models. {ADVI} supports a broad class of models—no conjugacy assumptions are required. We study {ADVI} across ten different models and apply it to a dataset with millions of observations. {ADVI} is integrated into Stan, a probabilistic programming system; it is available for immediate use.},
	journaltitle = {{arXiv}:1603.00788 [cs, stat]},
	author = {Kucukelbir, Alp and Tran, Dustin and Ranganath, Rajesh and Gelman, Andrew and Blei, David M.},
	urldate = {2018-10-23},
	date = {2016-03-02},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1603.00788},
	keywords = {Statistics - Computation, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {kucukelbir_et_al_2016_automatic_differentiation_variational_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/kucukelbir_et_al_2016_automatic_differentiation_variational_inference.pdf:application/pdf}
}

@article{neiswanger_asymptotically_2013,
	title = {Asymptotically Exact, Embarrassingly Parallel {MCMC}},
	url = {http://arxiv.org/abs/1311.4780},
	abstract = {Communication costs, resulting from synchronization requirements during learning, can greatly slow down many parallel machine learning algorithms. In this paper, we present a parallel Markov chain Monte Carlo ({MCMC}) algorithm in which subsets of data are processed independently, with very little communication. First, we arbitrarily partition data onto multiple machines. Then, on each machine, any classical {MCMC} method (e.g., Gibbs sampling) may be used to draw samples from a posterior distribution given the data subset. Finally, the samples from each machine are combined to form samples from the full posterior. This embarrassingly parallel algorithm allows each machine to act independently on a subset of the data (without communication) until the ﬁnal combination stage. We prove that our algorithm generates asymptotically exact samples and empirically demonstrate its ability to parallelize burn-in and sampling in several models.},
	journaltitle = {{arXiv}:1311.4780 [cs, stat]},
	author = {Neiswanger, Willie and Wang, Chong and Xing, Eric},
	urldate = {2018-10-23},
	date = {2013-11-19},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1311.4780},
	keywords = {Statistics - Computation, Statistics - Machine Learning, Computer Science - Machine Learning, Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {neiswanger_et_al_2013_asymptotically_exact,_embarrassingly_parallel_mcmc.pdf:/home/nathan/Dropbox/njames/zotero_sync/neiswanger_et_al_2013_asymptotically_exact,_embarrassingly_parallel_mcmc.pdf:application/pdf}
}

@article{blei_variational_2017,
	title = {Variational Inference: A Review for Statisticians},
	volume = {112},
	issn = {0162-1459, 1537-274X},
	url = {http://arxiv.org/abs/1601.00670},
	doi = {10.1080/01621459.2017.1285773},
	shorttitle = {Variational Inference},
	abstract = {One of the core problems of modern statistics is to approximate difﬁcult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference ({VI}), a method from machine learning that approximates probability densities through optimization. {VI} has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind {VI} is to ﬁrst posit a family of densities and then to ﬁnd the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-ﬁeld variational inference, discuss the special case of {VI} applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in {VI} and highlight important open problems. {VI} is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.},
	pages = {859--877},
	number = {518},
	journaltitle = {Journal of the American Statistical Association},
	author = {Blei, David M. and Kucukelbir, Alp and {McAuliffe}, Jon D.},
	urldate = {2018-10-23},
	date = {2017-04-03},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1601.00670},
	keywords = {Statistics - Computation, Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {blei_et_al_2017_variational_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/blei_et_al_2017_variational_inference.pdf:application/pdf}
}

@article{gelman_prior_2017,
	title = {The prior can generally only be understood in the context of the likelihood},
	volume = {19},
	issn = {1099-4300},
	url = {http://arxiv.org/abs/1708.07487},
	doi = {10.3390/e19100555},
	abstract = {A key sticking point of Bayesian analysis is the choice of prior distribution, and there is a vast literature on potential defaults including uniform priors, Jeﬀreys’ priors, reference priors, maximum entropy priors, and weakly informative priors. These methods, however, often manifest a key conceptual tension in prior modeling: a model encoding true prior information should be chosen without reference to the model of the measurement process, but almost all common prior modeling techniques are implicitly motivated by a reference likelihood. In this paper we resolve this apparent paradox by placing the choice of prior into the context of the entire Bayesian analysis, from inference to prediction to model evaluation.},
	pages = {555},
	number = {10},
	journaltitle = {Entropy},
	author = {Gelman, Andrew and Simpson, Daniel and Betancourt, Michael},
	urldate = {2018-10-23},
	date = {2017-10-19},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1708.07487},
	keywords = {Statistics - Methodology},
	file = {gelman_et_al_2017_the_prior_can_generally_only_be_understood_in_the_context_of_the_likelihood.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_et_al_2017_the_prior_can_generally_only_be_understood_in_the_context_of_the_likelihood.pdf:application/pdf}
}

@article{riley_minimum_2018,
	title = {Minimum sample size for developing a multivariable prediction model: Part I - Continuous outcomes},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.7993},
	doi = {10.1002/sim.7993},
	shorttitle = {Minimum sample size for developing a multivariable prediction model},
	journaltitle = {Statistics in Medicine},
	author = {Riley, Richard D. and Snell, Kym I.E. and Ensor, Joie and Burke, Danielle L. and Harrell, Frank E. and Moons, Karel G.M. and Collins, Gary S.},
	urldate = {2018-10-23},
	date = {2018-10-22},
	langid = {english},
	file = {riley_et_al_2018_minimum_sample_size_for_developing_a_multivariable_prediction_model.pdf:/home/nathan/Dropbox/njames/zotero_sync/riley_et_al_2018_minimum_sample_size_for_developing_a_multivariable_prediction_model.pdf:application/pdf}
}

@article{smaldino_natural_2016,
	title = {The natural selection of bad science},
	volume = {3},
	issn = {2054-5703},
	url = {http://rsos.royalsocietypublishing.org/lookup/doi/10.1098/rsos.160384},
	doi = {10.1098/rsos.160384},
	pages = {160384},
	number = {9},
	journaltitle = {Royal Society Open Science},
	author = {Smaldino, Paul E. and {McElreath}, Richard},
	urldate = {2018-10-23},
	date = {2016-09},
	langid = {english},
	file = {smaldino_mcelreath_2016_the_natural_selection_of_bad_science.pdf:/home/nathan/Dropbox/njames/zotero_sync/smaldino_mcelreath_2016_the_natural_selection_of_bad_science.pdf:application/pdf}
}

@article{he_framework_2012,
	title = {A framework for joint modeling and joint assessment of efficacy and safety endpoints for probability of success evaluation and optimal dose selection},
	volume = {31},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.4446},
	doi = {10.1002/sim.4446},
	pages = {401--419},
	number = {5},
	journaltitle = {Statistics in Medicine},
	author = {He, Weili and Cao, Xiting and Xu, Lu},
	urldate = {2018-10-23},
	date = {2012-02-28},
	langid = {english},
	file = {he_et_al_2012_a_framework_for_joint_modeling_and_joint_assessment_of_efficacy_and_safety.pdf:/home/nathan/Dropbox/njames/zotero_sync/he_et_al_2012_a_framework_for_joint_modeling_and_joint_assessment_of_efficacy_and_safety.pdf:application/pdf}
}

@article{waddingham_bayesian_2016,
	title = {A Bayesian approach to probabilistic sensitivity analysis in structured benefit-risk assessment: A Bayesian approach to probabilistic sensitivity analysis},
	volume = {58},
	issn = {03233847},
	url = {http://doi.wiley.com/10.1002/bimj.201300254},
	doi = {10.1002/bimj.201300254},
	shorttitle = {A Bayesian approach to probabilistic sensitivity analysis in structured benefit-risk assessment},
	pages = {28--42},
	number = {1},
	journaltitle = {Biometrical Journal},
	author = {Waddingham, Ed and Mt-Isa, Shahrul and Nixon, Richard and Ashby, Deborah},
	urldate = {2018-10-23},
	date = {2016-01},
	langid = {english},
	file = {waddingham_et_al_2016_a_bayesian_approach_to_probabilistic_sensitivity_analysis_in_structured.pdf:/home/nathan/Dropbox/njames/zotero_sync/waddingham_et_al_2016_a_bayesian_approach_to_probabilistic_sensitivity_analysis_in_structured.pdf:application/pdf}
}

@article{thall_dose-finding_2004,
	title = {Dose-Finding Based on Efficacy-Toxicity Trade-Offs},
	volume = {60},
	issn = {0006341X},
	url = {http://doi.wiley.com/10.1111/j.0006-341X.2004.00218.x},
	doi = {10.1111/j.0006-341X.2004.00218.x},
	abstract = {We present an adaptive Bayesian method for dose-ﬁnding in phase I/{II} clinical trials based on trade-oﬀs between the probabilities of treatment eﬃcacy and toxicity. The method accommodates either trinary or bivariate binary outcomes, as well as eﬃcacy probabilities that possibly are nonmonotone in dose. Doses are selected for successive patient cohorts based on a set of eﬃcacy–toxicity trade-oﬀ contours that partition the two-dimensional outcome probability domain. Priors are established by solving for hyperparameters that optimize the ﬁt of the model to elicited mean outcome probabilities. For trinary outcomes, the new algorithm is compared to the method of Thall and Russell (1998, Biometrics 54, 251–264) by application to a trial of rapid treatment for ischemic stroke. The bivariate binary outcome case is illustrated by a trial of graft-versus-host disease treatment in allogeneic bone marrow transplantation. Computer simulations show that, under a wide rage of dose-outcome scenarios, the new method has high probabilities of making correct decisions and treats most patients at doses with desirable eﬃcacy–toxicity trade-oﬀs.},
	pages = {684--693},
	number = {3},
	journaltitle = {Biometrics},
	author = {Thall, Peter F. and Cook, John D.},
	urldate = {2018-10-23},
	date = {2004-09},
	langid = {english},
	file = {thall_cook_2004_dose-finding_based_on_efficacy-toxicity_trade-offs.pdf:/home/nathan/Dropbox/njames/zotero_sync/thall_cook_2004_dose-finding_based_on_efficacy-toxicity_trade-offs.pdf:application/pdf}
}

@article{shih_inferences_1995,
	title = {Inferences on the Association Parameter in Copula Models for Bivariate Survival Data},
	volume = {51},
	issn = {0006341X},
	url = {https://www.jstor.org/stable/2533269?origin=crossref},
	doi = {10.2307/2533269},
	abstract = {We investigate two-stage parametric and two-stage semi-parametric estimation procedures for the association parameter in copula models for bivariate survival data where censoring in either or both components is allowed. We derive asymptotic properties of the estimators and compare their performance by simulations. Both parametric and semi-parametric estimators of the association parameter are efficient at independence, and the parameter estimates in the margins have high efficiency and are robust to misspecification of dependency structures. In addition, we propose a consistent variance estimator for the semi-parametric estimator of the association parameter. We apply the proposed methods to an {AIDS} data set for illustration.},
	pages = {1384--1399},
	number = {4},
	journaltitle = {Biometrics},
	author = {Shih, Joanna H. and Louis, Thomas A.},
	urldate = {2018-10-23},
	date = {1995-12},
	langid = {english},
	file = {shih_louis_1995_inferences_on_the_association_parameter_in_copula_models_for_bivariate_survival.pdf:/home/nathan/Dropbox/njames/zotero_sync/shih_louis_1995_inferences_on_the_association_parameter_in_copula_models_for_bivariate_survival.pdf:application/pdf}
}

@article{fu_joint_2013,
	title = {Joint modeling of progression-free survival and overall survival by a Bayesian normal induced copula estimation model},
	volume = {32},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.5487},
	doi = {10.1002/sim.5487},
	pages = {240--254},
	number = {2},
	journaltitle = {Statistics in Medicine},
	author = {Fu, Haoda and Wang, Yanping and Liu, Jingyi and Kulkarni, Pandurang M. and Melemed, Allen S.},
	urldate = {2018-10-23},
	date = {2013-01-30},
	langid = {english},
	file = {fu_et_al_2013_joint_modeling_of_progression-free_survival_and_overall_survival_by_a_bayesian.pdf:/home/nathan/Dropbox/njames/zotero_sync/fu_et_al_2013_joint_modeling_of_progression-free_survival_and_overall_survival_by_a_bayesian.pdf:application/pdf}
}

@article{renfro_bayesian_2012,
	title = {Bayesian adjusted R2 for the meta-analytic evaluation of surrogate time-to-event endpoints in clinical trials},
	volume = {31},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.4416},
	doi = {10.1002/sim.4416},
	pages = {743--761},
	number = {8},
	journaltitle = {Statistics in Medicine},
	author = {Renfro, Lindsay A. and Shi, Qian and Sargent, Daniel J. and Carlin, Bradley P.},
	urldate = {2018-10-23},
	date = {2012-04-13},
	langid = {english},
	file = {renfro_et_al_2012_bayesian_adjusted_r2_for_the_meta-analytic_evaluation_of_surrogate.pdf:/home/nathan/Dropbox/njames/zotero_sync/renfro_et_al_2012_bayesian_adjusted_r2_for_the_meta-analytic_evaluation_of_surrogate.pdf:application/pdf}
}

@article{wang_estimating_2003,
	title = {Estimating the association parameter for copula models under dependent censoring},
	volume = {65},
	issn = {1369-7412, 1467-9868},
	url = {http://doi.wiley.com/10.1111/1467-9868.00385},
	doi = {10.1111/1467-9868.00385},
	abstract = {Many biomedical studies involve the analysis of multiple events. The dependence between the times to these end points is often of scientific interest. We investigate a situation when one end point is subject to censoring by the other. The model assumptions of Day and co-workers and Fine and co-workers are extended to more general structures where the level of association may vary with time. Two types of estimating function are proposed. Asymptotic properties of the proposed estimators are derived. Their ﬁnite sample performance is studied via simulations. The inference procedures are applied to two real data sets for illustration.},
	pages = {257--273},
	number = {1},
	journaltitle = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Wang, Weijing},
	urldate = {2018-10-23},
	date = {2003-02},
	langid = {english},
	file = {wang_2003_estimating_the_association_parameter_for_copula_models_under_dependent_censoring.pdf:/home/nathan/Dropbox/njames/zotero_sync/wang_2003_estimating_the_association_parameter_for_copula_models_under_dependent_censoring.pdf:application/pdf}
}

@article{shemyakin_copula_2006,
	title = {Copula models of joint last survivor analysis},
	volume = {22},
	issn = {1524-1904, 1526-4025},
	url = {http://doi.wiley.com/10.1002/asmb.629},
	doi = {10.1002/asmb.629},
	abstract = {Copula models are becoming increasingly popular for modelling dependencies between random variables. The range of their recent applications includes such ﬁelds as analysis of extremes in ﬁnancial assets and returns; failure of paired organs in health science; reliability studies; and human mortality in insurance.},
	pages = {211--224},
	number = {2},
	journaltitle = {Applied Stochastic Models in Business and Industry},
	author = {Shemyakin, Arkady and Youn, Heekyung},
	urldate = {2018-10-23},
	date = {2006-03},
	langid = {english},
	file = {shemyakin_youn_2006_copula_models_of_joint_last_survivor_analysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/shemyakin_youn_2006_copula_models_of_joint_last_survivor_analysis.pdf:application/pdf}
}

@article{chaloner_graphical_1993,
	title = {Graphical Elicitation of a Prior Distribution for a Clinical Trial},
	volume = {42},
	issn = {00390526},
	url = {https://www.jstor.org/stable/10.2307/2348469?origin=crossref},
	doi = {10.2307/2348469},
	abstract = {Bayesian methods are potentially useful for the design, monitoring and analysis of clinical trials. These methods, however, require that prior information be quantified and that the methods be robust. This paper describes a method to help quantify beliefs in the form of a prior distribution about regression coefficients in a proportional hazards regression model. The method uses dynamic graphical displays of probability distributions that can be freehand adjusted. The method was developed for, and is applied to, a randomized trial comparing prophylaxes for toxoplasmosis in a population of {HIV}-positive individuals. Prior distributions from five {AIDS} experts are elicited. The experts represent a community of consumers of the results of the trial and these prior distributions can be used to try to make the monitoring and analysis of the trial robust.},
	pages = {341},
	number = {4},
	journaltitle = {The Statistician},
	author = {Chaloner, Kathryn and Church, Timothy and Louis, Thomas A. and Matts, John P.},
	urldate = {2018-10-23},
	date = {1993},
	langid = {english},
	file = {chaloner_et_al_1993_graphical_elicitation_of_a_prior_distribution_for_a_clinical_trial.pdf:/home/nathan/Dropbox/njames/zotero_sync/chaloner_et_al_1993_graphical_elicitation_of_a_prior_distribution_for_a_clinical_trial.pdf:application/pdf}
}

@article{hougaard_frailty_1995,
	title = {Frailty models for survival data},
	volume = {1},
	issn = {1380-7870, 1572-9249},
	url = {http://link.springer.com/10.1007/BF00985760},
	doi = {10.1007/BF00985760},
	abstract = {A frailty model is a random effects model for time variables, where the random effect (the frailty) has a multiplicative effect on the hazard. It can be used for univariate (independent) failure times, i.e. to describe the influence of unobserved covariates in a {proportiOnal} hazards model. More interesting, however, is to consider multivariate (dependent) failure times generated as conditionally independent times given the frailty. This approach can be used both for survival times for individuals, like twins or family members, and for repeated events for the same individual. The standard assumption is to use a gamma distribution for the frailty, but this is a restriction that implies that the dependence is most important for late events. More generally, the distribution can be stable, inverse Gaussian, or follow a power variance function exponential family. Theoretically, large differences are seen between the choices. In practice, using the largest model makes it possible to allow for more general de{\textasciitilde}ndence structures, without making the formulas too complicated.},
	pages = {255--273},
	number = {3},
	journaltitle = {Lifetime Data Analysis},
	author = {Hougaard, Philip},
	urldate = {2018-10-23},
	date = {1995},
	langid = {english},
	file = {hougaard_1995_frailty_models_for_survival_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/hougaard_1995_frailty_models_for_survival_data.pdf:application/pdf}
}

@article{gao_avoiding_2009,
	title = {Avoiding the high Bonferroni penalty in genome-wide association studies},
	issn = {07410395, 10982272},
	url = {http://doi.wiley.com/10.1002/gepi.20430},
	doi = {10.1002/gepi.20430},
	abstract = {A major challenge in genome-wide association studies ({GWASs}) is to derive the multiple testing threshold when hypothesis tests are conducted using a large number of single nucleotide polymorphisms. Permutation tests are considered the gold standard in multiple testing adjustment in genetic association studies. However, it is computationally intensive, especially for {GWASs}, and can be impractical if a large number of random shuffles are used to ensure accuracy. Many researchers have developed approximation algorithms to relieve the computing burden imposed by permutation. One particularly attractive alternative to permutation is to calculate the effective number of independent tests, Meff, which has been shown to be promising in genetic association studies. In this study, we compare recently developed Meff methods and validate them by the permutation test with 10,000 random shuffles using two real {GWAS} data sets: an Illumina 1M {BeadChip} and an Affymetrix {GeneChip}® Human Mapping 500K Array Set. Our results show that the {simpleM} method produces the best approximation of the permutation threshold, and it does so in the shortest amount of time. We also show that Meff is indeed valid on a genome-wide scale in these data sets based on statistical theory and significance tests. The significance thresholds derived can provide practical guidelines for other studies using similar population samples and genotyping platforms.},
	pages = {n/a--n/a},
	journaltitle = {Genetic Epidemiology},
	author = {Gao, Xiaoyi and Becker, Lewis C. and Becker, Diane M. and Starmer, Joshua D. and Province, Michael A.},
	urldate = {2018-10-30},
	date = {2009},
	langid = {english},
	file = {gao_et_al_2009_avoiding_the_high_bonferroni_penalty_in_genome-wide_association_studies.pdf:/home/nathan/Dropbox/njames/zotero_sync/gao_et_al_2009_avoiding_the_high_bonferroni_penalty_in_genome-wide_association_studies.pdf:application/pdf}
}

@article{pocock_win_2012,
	title = {The win ratio: a new approach to the analysis of composite endpoints in clinical trials based on clinical priorities},
	volume = {33},
	issn = {0195-668X, 1522-9645},
	url = {https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehr352},
	doi = {10.1093/eurheartj/ehr352},
	shorttitle = {The win ratio},
	pages = {176--182},
	number = {2},
	journaltitle = {European Heart Journal},
	author = {Pocock, S. J. and Ariti, C. A. and Collier, T. J. and Wang, D.},
	urldate = {2018-10-30},
	date = {2012-01-02},
	langid = {english},
	file = {pocock_et_al_2012_the_win_ratio.pdf:/home/nathan/Dropbox/njames/zotero_sync/pocock_et_al_2012_the_win_ratio.pdf:application/pdf}
}

@article{oakes_win-ratio_2016,
	title = {On the win-ratio statistic in clinical trials with multiple types of event},
	volume = {103},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/asw026},
	doi = {10.1093/biomet/asw026},
	abstract = {Pocock et al. (2012), following Finkelstein \& Schoenfeld (1999), has popularized the win ratio for analysis of controlled clinical trials with multiple types of outcome event. The approach uses pairwise comparisons between patients in the treatment and control groups using a primary 10 outcome, say the time to death, with ties broken using a secondary outcome, say the time to hospitalization. In general the observed pairwise preferences and the weight they attach to the component rankings will depend on the distribution of potential follow-up time. We present expressions for the win and loss probabilities for general bivariate survival models when followup of all patients is limited to a speciﬁed time horizon. In the special case of a bivariate Lehmann 15 model we show that the win ratio does not depend on this horizon. We show how the win ratio may be estimated non-parametrically or from a parametric model. Extensions to events of three or more types are described. Application of the method of marginal estimation due to Wei et al. (1989) to this problem is described.},
	pages = {742--745},
	number = {3},
	journaltitle = {Biometrika},
	author = {Oakes, D.},
	urldate = {2018-10-30},
	date = {2016-09},
	langid = {english},
	file = {oakes_2016_on_the_win-ratio_statistic_in_clinical_trials_with_multiple_types_of_event.pdf:/home/nathan/Dropbox/njames/zotero_sync/oakes_2016_on_the_win-ratio_statistic_in_clinical_trials_with_multiple_types_of_event.pdf:application/pdf}
}

@article{rogers_analysing_2014,
	title = {Analysing recurrent hospitalizations in heart failure: a review of statistical methodology, with application to {CHARM}-Preserved: Analysing recurrent hospitalizations},
	volume = {16},
	issn = {13889842},
	url = {http://doi.wiley.com/10.1002/ejhf.29},
	doi = {10.1002/ejhf.29},
	shorttitle = {Analysing recurrent hospitalizations in heart failure},
	pages = {33--40},
	number = {1},
	journaltitle = {European Journal of Heart Failure},
	author = {Rogers, Jennifer K. and Pocock, Stuart J. and {McMurray}, John J.V. and Granger, Christopher B. and Michelson, Eric L. and Östergren, Jan and Pfeffer, Marc A. and Solomon, Scott D. and Swedberg, Karl and Yusuf, Salim},
	urldate = {2018-10-30},
	date = {2014-01},
	langid = {english},
	file = {rogers_et_al_2014_analysing_recurrent_hospitalizations_in_heart_failure.pdf:/home/nathan/Dropbox/njames/zotero_sync/rogers_et_al_2014_analysing_recurrent_hospitalizations_in_heart_failure.pdf:application/pdf}
}

@article{sankoh_use_2014,
	title = {Use of composite endpoints in clinical trials},
	volume = {33},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.6205},
	doi = {10.1002/sim.6205},
	pages = {4709--4714},
	number = {27},
	journaltitle = {Statistics in Medicine},
	author = {Sankoh, Abdul J. and Li, Haihong and D'Agostino, Ralph B.},
	urldate = {2018-10-30},
	date = {2014-11-30},
	langid = {english},
	file = {sankoh_et_al_2014_use_of_composite_endpoints_in_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/sankoh_et_al_2014_use_of_composite_endpoints_in_clinical_trials.pdf:application/pdf}
}

@article{sankoh_composite_2017,
	title = {Composite and multicomponent end points in clinical trials},
	volume = {36},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.7386},
	doi = {10.1002/sim.7386},
	pages = {4437--4440},
	number = {28},
	journaltitle = {Statistics in Medicine},
	author = {Sankoh, Abdul J. and Li, Haihong and D'Agostino, Ralph B.},
	urldate = {2018-10-30},
	date = {2017-12-10},
	langid = {english},
	file = {sankoh_et_al_2017_composite_and_multicomponent_end_points_in_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/sankoh_et_al_2017_composite_and_multicomponent_end_points_in_clinical_trials.pdf:application/pdf}
}

@article{sun_evaluating_nodate,
	title = {Evaluating Treatment Efficacy by Multiple End Points in Phase {II} Acute Heart Failure Clinical Trials},
	abstract = {Background—To assess concomitant simultaneous effects on multiple end points using global statistical methods in phase {II} acute heart failure studies.
Methods and Results—Using simulations we have assessed different statistical methods to evaluate concomitant effects of a new intervention on dyspnea relief (using 2 measures), length of hospital stay, worsening heart failure to 5 days, mortality, and heart failure readmission to 30 days. Treatment effect scenarios included large (20\% to 28\% relative improvements) and very large (30\% to 43\% relative improvements) effects among others. Placebo responses and correlations among end points typical in recent acute heart failure clinical trials were used. Powers for the average Z score exceeded 70\% with ≥75 patients per group for 35\% relative improvement across all 6 end points. Assessing dyspnea alone generally provides lower power than the average Z score approach, with power deducted ≈50\% under most of scenarios. Other approaches generally provide lower power than the average Z score method.
Conclusions—Assessing the effects of new therapies on multiple clinical end points using the average Z score enables detection of therapeutic efficacy using sample sizes of 100 to 150 patients per group, approximately double the power achievable assessing the effects on dyspnea alone.  (Circ Heart Fail. 2012;5:742–749.)},
	pages = {8},
	author = {Sun, Hengrui and Davison, Beth A and Cotter, Gad and Pencina, Michael J and Koch, Gary G},
	langid = {english},
	file = {sun_et_al_evaluating_treatment_efficacy_by_multiple_end_points_in_phase_ii_acute_heart.pdf:/home/nathan/Dropbox/njames/zotero_sync/sun_et_al_evaluating_treatment_efficacy_by_multiple_end_points_in_phase_ii_acute_heart.pdf:application/pdf}
}

@article{sun_analyzing_2017,
	title = {Analyzing multiple endpoints in a confirmatory randomized clinical trial-an approach that addresses stratification, missing values, baseline imbalance and multiplicity for strictly ordinal outcomes: Analyzing multiple endpoints using closed testing procedure},
	volume = {16},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1799},
	doi = {10.1002/pst.1799},
	shorttitle = {Analyzing multiple endpoints in a confirmatory randomized clinical trial-an approach that addresses stratification, missing values, baseline imbalance and multiplicity for strictly ordinal outcomes},
	pages = {157--166},
	number = {2},
	journaltitle = {Pharmaceutical Statistics},
	author = {Sun, Hengrui and Kawaguchi, Atsushi and Koch, Gary},
	urldate = {2018-10-30},
	date = {2017-03},
	langid = {english},
	file = {sun_et_al_2017_analyzing_multiple_endpoints_in_a_confirmatory_randomized_clinical_trial-an.pdf:/home/nathan/Dropbox/njames/zotero_sync/sun_et_al_2017_analyzing_multiple_endpoints_in_a_confirmatory_randomized_clinical_trial-an.pdf:application/pdf}
}

@article{wang_inference_2017,
	title = {Inference in randomized trials with death and missingness: Inference in Randomized Trials with Death and Missingness},
	volume = {73},
	issn = {0006341X},
	url = {http://doi.wiley.com/10.1111/biom.12594},
	doi = {10.1111/biom.12594},
	shorttitle = {Inference in randomized trials with death and missingness},
	abstract = {In randomized studies involving severely ill patients, functional outcomes are often unobserved due to missed clinic visits, premature withdrawal, or death. It is well known that if these unobserved functional outcomes are not handled properly, biased treatment comparisons can be produced. In this article, we propose a procedure for comparing treatments that is based on a composite endpoint that combines information on both the functional outcome and survival. We further propose a missing data imputation scheme and sensitivity analysis strategy to handle the unobserved functional outcomes not due to death. Illustrations of the proposed method are given by analyzing data from a recent non-small cell lung cancer clinical trial and a recent trial of sedation interruption among mechanically ventilated patients.},
	pages = {431--440},
	number = {2},
	journaltitle = {Biometrics},
	author = {Wang, Chenguang and Scharfstein, Daniel O. and Colantuoni, Elizabeth and Girard, Timothy D. and Yan, Ying},
	urldate = {2018-10-30},
	date = {2017-06},
	langid = {english},
	file = {wang_et_al_2017_inference_in_randomized_trials_with_death_and_missingness.pdf:/home/nathan/Dropbox/njames/zotero_sync/wang_et_al_2017_inference_in_randomized_trials_with_death_and_missingness.pdf:application/pdf}
}

@article{wittes_changing_2002,
	title = {On changing a long-term clinical trial midstream},
	volume = {21},
	issn = {0277-6715, 1097-0258},
	url = {http://doi.wiley.com/10.1002/sim.1282},
	doi = {10.1002/sim.1282},
	abstract = {Clinical triallists are often reluctant to alter the protocol or the design of an ongoing study in part because of concern that changes may a ect the integrity of the study. This paper encourages considering changes in long-term clinical trials when the medical environment changes or when the accruing data from the trial lead to questioning the assumptions underlying the original design. One must make such changes in a way that will not cast doubt on the integrity of the trial. An important aspect of the design is choice of sample size. Methodology for sample size recalculation has matured over the decade. Several techniques are now available for the usual types of endpoints – continuous, discrete and time-to-failure – as well as for longitudinal analysis. Published papers describe the choices of variance at the time of recalculation, approaches to estimation and testing at the end of the study, and the time of recalculation. In a study with a sponsor, a Data Safety Monitoring Board ({DSMB}) and an Executive Committee, one or more of these three groups is responsible for recommending increases in sample size when the accruing data indicate that the assumed variance underestimated the true variance. Sometimes a statistician independent of all three bodies performs the relevant calculations and sends the recommendation to the sponsor. This paper argues that the {DSMB} should not generally be the responsible body because knowledge of treatment e ect can place it in an uncomfortable position. Copyright ? 2002 John Wiley \& Sons, Ltd.},
	pages = {2789--2795},
	number = {19},
	journaltitle = {Statistics in Medicine},
	author = {Wittes, Janet},
	urldate = {2018-10-30},
	date = {2002-10-15},
	langid = {english},
	file = {wittes_2002_on_changing_a_long-term_clinical_trial_midstream.pdf:/home/nathan/Dropbox/njames/zotero_sync/wittes_2002_on_changing_a_long-term_clinical_trial_midstream.pdf:application/pdf}
}

@article{evans_when_2007,
	title = {When and How Can Endpoints Be Changed after Initiation of a Randomized Clinical Trial},
	volume = {2},
	issn = {1555-5887},
	url = {http://dx.plos.org/10.1371/journal.pctr.0020018},
	doi = {10.1371/journal.pctr.0020018},
	pages = {e18},
	number = {4},
	journaltitle = {{PLoS} Clinical Trials},
	author = {Evans, Scott},
	urldate = {2018-10-30},
	date = {2007-04-13},
	langid = {english},
	file = {evans_2007_when_and_how_can_endpoints_be_changed_after_initiation_of_a_randomized_clinical.pdf:/home/nathan/Dropbox/njames/zotero_sync/evans_2007_when_and_how_can_endpoints_be_changed_after_initiation_of_a_randomized_clinical.pdf:application/pdf}
}

@article{felker_global_2010,
	title = {A Global Rank End Point for Clinical Trials in Acute Heart Failure},
	volume = {3},
	issn = {1941-3289, 1941-3297},
	url = {https://www.ahajournals.org/doi/10.1161/CIRCHEARTFAILURE.109.926030},
	doi = {10.1161/CIRCHEARTFAILURE.109.926030},
	pages = {643--646},
	number = {5},
	journaltitle = {Circulation: Heart Failure},
	author = {Felker, G. Michael and Maisel, Alan S.},
	urldate = {2018-10-30},
	date = {2010-09},
	langid = {english},
	file = {felker_maisel_2010_a_global_rank_end_point_for_clinical_trials_in_acute_heart_failure.pdf:/home/nathan/Dropbox/njames/zotero_sync/felker_maisel_2010_a_global_rank_end_point_for_clinical_trials_in_acute_heart_failure.pdf:application/pdf}
}

@article{finkelstein_combining_1999,
	title = {Combining mortality and longitudinal measures in clinical trials},
	volume = {18},
	issn = {0277-6715, 1097-0258},
	url = {http://doi.wiley.com/10.1002/%28SICI%291097-0258%2819990615%2918%3A11%3C1341%3A%3AAID-SIM129%3E3.0.CO%3B2-7},
	doi = {10.1002/(SICI)1097-0258(19990615)18:11<1341::AID-SIM129>3.0.CO;2-7},
	abstract = {Clinical trials often assess therapeutic beneÿt on the basis of an event such as death or the diagnosis of disease. Usually, there are several additional longitudinal measures of clinical status which are collected to be used in the treatment comparison. This paper proposes a simple non-parametric test which combines a time to event measure and a longitudinal measure so that a substantial treatment di erence on either of the measures will reject the null hypothesis. The test is applied on {AIDS} prophylaxis and paediatric trials. Copyright ? 1999 John Wiley \& Sons, Ltd.},
	pages = {1341--1354},
	number = {11},
	journaltitle = {Statistics in Medicine},
	author = {Finkelstein, Dianne M. and Schoenfeld, David A.},
	urldate = {2018-10-30},
	date = {1999-06-15},
	langid = {english},
	file = {finkelstein_schoenfeld_1999_combining_mortality_and_longitudinal_measures_in_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/finkelstein_schoenfeld_1999_combining_mortality_and_longitudinal_measures_in_clinical_trials.pdf:application/pdf}
}

@article{irony_utility_2017,
	title = {The “Utility” in Composite Outcome Measures: Measuring What Is Important to Patients},
	volume = {318},
	issn = {0098-7484},
	url = {http://jama.jamanetwork.com/article.aspx?doi=10.1001/jama.2017.14001},
	doi = {10.1001/jama.2017.14001},
	shorttitle = {The “Utility” in Composite Outcome Measures},
	pages = {1820},
	number = {18},
	journaltitle = {{JAMA}},
	author = {Irony, Telba Z.},
	urldate = {2018-10-30},
	date = {2017-11-14},
	langid = {english},
	file = {irony_2017_the_“utility”_in_composite_outcome_measures.pdf:/home/nathan/Dropbox/njames/zotero_sync/irony_2017_the_“utility”_in_composite_outcome_measures.pdf:application/pdf}
}

@article{chi_effect_2017,
	title = {Effect of extended-duration thromboprophylaxis on venous thromboembolism and major bleeding among acutely ill hospitalized medical patients: a bivariate analysis},
	volume = {15},
	issn = {15387933},
	url = {http://doi.wiley.com/10.1111/jth.13783},
	doi = {10.1111/jth.13783},
	shorttitle = {Effect of extended-duration thromboprophylaxis on venous thromboembolism and major bleeding among acutely ill hospitalized medical patients},
	pages = {1913--1922},
	number = {10},
	journaltitle = {Journal of Thrombosis and Haemostasis},
	author = {Chi, G. and Goldhaber, S. Z. and Kittelson, J. M. and Turpie, A. G. G. and Hernandez, A. F. and Hull, R. D. and Gold, A. and Curnutte, J. T. and Cohen, A. T. and Harrington, R. A. and Gibson, C. M.},
	urldate = {2018-10-30},
	date = {2017-10},
	langid = {english},
	file = {chi_et_al_2017_effect_of_extended-duration_thromboprophylaxis_on_venous_thromboembolism_and.pdf:/home/nathan/Dropbox/njames/zotero_sync/chi_et_al_2017_effect_of_extended-duration_thromboprophylaxis_on_venous_thromboembolism_and.pdf:application/pdf}
}

@article{cook_multiplicity_1996,
	title = {Multiplicity Considerations in the Design and Analysis of Clinical Trials},
	volume = {159},
	issn = {09641998},
	url = {https://www.jstor.org/stable/10.2307/2983471?origin=crossref},
	doi = {10.2307/2983471},
	abstract = {The needforefficienutse ofavailableresourcesinmedicalresearchhas led to theincreased appeal of clinicaltrialdesignsbased on multipleresponses,multipletreatmenatrmsand repeatedtestsof {significanceI}.n recentyearstherehas been considerablemethodological workpertainingto thesetypesofmultiplecomparison,withthecommonobjectivetypically {beingthecontroloftheexperimentatlypeI} errorrate.Herewe reconsidertheappropriateness of theseobjectivesin a varietyof contextsand suggestthat multiple-comparison {proceduresarefrequentlaydoptedunnecessarilyIn}. particularwe arguethat,providedthat a selectnumberof importantwell-definedclinicalquestionsare specifiedat the design, thereare situationsinwhichmultipletestsofsignificanccean be performewd ithoutcontrol of {theexperimentatlypeI} errorrate.The primaryrestrictionforthisto be reasonableis thattestresultsare interpretemd arginally.},
	pages = {93},
	number = {1},
	journaltitle = {Journal of the Royal Statistical Society. Series A (Statistics in Society)},
	author = {Cook, Richard J. and Farewell, Vern T.},
	urldate = {2018-10-30},
	date = {1996},
	langid = {english},
	file = {cook_farewell_1996_multiplicity_considerations_in_the_design_and_analysis_of_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/cook_farewell_1996_multiplicity_considerations_in_the_design_and_analysis_of_clinical_trials.pdf:application/pdf}
}

@article{dong_generalized_2016,
	title = {A generalized analytic solution to the win ratio to analyze a composite endpoint considering the clinical importance order among components: A generalized analytic solution to the win ratio},
	volume = {15},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1763},
	doi = {10.1002/pst.1763},
	shorttitle = {A generalized analytic solution to the win ratio to analyze a composite endpoint considering the clinical importance order among components},
	pages = {430--437},
	number = {5},
	journaltitle = {Pharmaceutical Statistics},
	author = {Dong, Gaohong and Li, Di and Ballerstedt, Steffen and Vandemeulebroecke, Marc},
	urldate = {2018-10-30},
	date = {2016-09},
	langid = {english},
	file = {dong_et_al_2016_a_generalized_analytic_solution_to_the_win_ratio_to_analyze_a_composite.pdf:/home/nathan/Dropbox/njames/zotero_sync/dong_et_al_2016_a_generalized_analytic_solution_to_the_win_ratio_to_analyze_a_composite.pdf:application/pdf}
}

@article{bakal_impact_2015,
	title = {Impact of weighted composite compared to traditional composite endpoints for the design of randomized controlled trials},
	volume = {24},
	issn = {0962-2802, 1477-0334},
	url = {http://journals.sagepub.com/doi/10.1177/0962280211436004},
	doi = {10.1177/0962280211436004},
	abstract = {Composite endpoints are commonly used in cardiovascular clinical trials. When using a composite endpoint a subject is considered to have an event when the first component endpoint has occurred. The use of composite endpoints offers the ability to incorporate several clinically important endpoint events thereby augmenting the event rate and increasing statistical power for a given sample size. One assumption of the composite is that all component events are of equal clinical importance. This assumption is rarely achieved given the diversity of component endpoints included. One means of adjusting for this diversity is to adjust the outcomes using severity weights determined a priori. The use of a weighted endpoint also allows for the incorporation of multiple endpoints per patient. Although weighting the outcomes lowers the effective number of events, it offers additional information that reduces the variance of the estimate. We created a series of simulation studies to examine the effect on power as the individual components of a typical composite were changed. In one study, we noted that the weighted composite was able to offer discriminative power when the component outcomes were altered, while the traditional method was not. In the other study, we noted that the weighted composite offered a similar level of power to the traditional composite when the change was driven by the more severe endpoints.},
	pages = {980--988},
	number = {6},
	journaltitle = {Statistical Methods in Medical Research},
	author = {Bakal, Jeffrey A and Westerhout, Cynthia M and Armstrong, Paul W},
	urldate = {2018-10-30},
	date = {2015-12},
	langid = {english},
	file = {bakal_et_al_2015_impact_of_weighted_composite_compared_to_traditional_composite_endpoints_for.pdf:/home/nathan/Dropbox/njames/zotero_sync/bakal_et_al_2015_impact_of_weighted_composite_compared_to_traditional_composite_endpoints_for.pdf:application/pdf}
}

@article{bakal_evaluation_2013,
	title = {Evaluation of early percutaneous coronary intervention vs. standard therapy after fibrinolysis for {ST}-segment elevation myocardial infarction: contribution of weighting the composite endpoint},
	volume = {34},
	issn = {0195-668X, 1522-9645},
	url = {https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehs438},
	doi = {10.1093/eurheartj/ehs438},
	shorttitle = {Evaluation of early percutaneous coronary intervention vs. standard therapy after fibrinolysis for {ST}-segment elevation myocardial infarction},
	pages = {903--908},
	number = {12},
	journaltitle = {European Heart Journal},
	author = {Bakal, J. A. and Westerhout, C. M. and Cantor, W. J. and Fernandez-Aviles, F. and Welsh, R. C. and Fitchett, D. and Goodman, S. G. and Armstrong, P. W.},
	urldate = {2018-10-30},
	date = {2013-03-02},
	langid = {english},
	file = {bakal_et_al_2013_evaluation_of_early_percutaneous_coronary_intervention_vs.pdf:/home/nathan/Dropbox/njames/zotero_sync/bakal_et_al_2013_evaluation_of_early_percutaneous_coronary_intervention_vs.pdf:application/pdf}
}

@article{bakal_applying_2015,
	title = {Applying novel methods to assess clinical outcomes: insights from the {TRILOGY} {ACS} trial},
	volume = {36},
	issn = {0195-668X, 1522-9645},
	url = {https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehu262},
	doi = {10.1093/eurheartj/ehu262},
	shorttitle = {Applying novel methods to assess clinical outcomes},
	pages = {385--392},
	number = {6},
	journaltitle = {European Heart Journal},
	author = {Bakal, J. A. and Roe, M. T. and Ohman, E. M. and Goodman, S. G. and Fox, K. A. A. and Zheng, Y. and Westerhout, C. M. and Hochman, J. S. and Lokhnygina, Y. and Brown, E. B. and Armstrong, P. W.},
	urldate = {2018-10-30},
	date = {2015-02-02},
	langid = {english},
	file = {bakal_et_al_2015_applying_novel_methods_to_assess_clinical_outcomes.pdf:/home/nathan/Dropbox/njames/zotero_sync/bakal_et_al_2015_applying_novel_methods_to_assess_clinical_outcomes.pdf:application/pdf}
}

@article{brown_multitype_2017,
	title = {Multitype Events and the Analysis of Heart Failure Readmissions: Illustration of a New Modeling Approach and Comparison With Familiar Composite End Points},
	volume = {10},
	issn = {1941-7713, 1941-7705},
	url = {https://www.ahajournals.org/doi/10.1161/CIRCOUTCOMES.116.003382},
	doi = {10.1161/CIRCOUTCOMES.116.003382},
	shorttitle = {Multitype Events and the Analysis of Heart Failure Readmissions},
	abstract = {Background—Heart failure–related hospital readmissions and mortality are often outcomes in clinical trials. Patients may experience multiple hospital readmissions over time with mortality acting as a dependent terminal event. Univariate composite end points are used for the analysis of readmissions. We may amend these approaches to include emergency department visits as a further outcome. An alternative multivariate modeling approach that categorizes hospital readmissions and emergency department visits as separate event types is proposed.
Methods and Results—We seek to compare the modeling approach which handles event types as separate, correlated end points against composites that amalgamate them to create a unified end point. Using a heart failure data set for illustration, a model with random effects for event types is estimated. The time-to-first event, unmatched win-ratio, and days-aliveand-out-of-hospital composites are derived for comparison. The model provides supplementary statistics such as the correlation among event types and yields considerably more power than the competing composite end points.
Conclusions—The effect on individual outcomes is lost when they are intermingled to form a univariate composite. Simultaneously modeling different outcomes provides an alternative or supplementary analysis that may yield greater statistical power and additional insights. Improvements in software have made the multitype events model easier to implement and thus a useful, more efficient option when analyzing heart failure hospital readmissions and emergency department visits.  (Circ Cardiovasc Qual Outcomes. 2017;10:e003382. {DOI}: 10.1161/{CIRCOUTCOMES}.116.003382.)},
	number = {6},
	journaltitle = {Circulation: Cardiovascular Quality and Outcomes},
	author = {Brown, Paul M. and Ezekowitz, Justin A.},
	urldate = {2018-10-30},
	date = {2017-06},
	langid = {english},
	file = {brown_ezekowitz_2017_multitype_events_and_the_analysis_of_heart_failure_readmissions.pdf:/home/nathan/Dropbox/njames/zotero_sync/brown_ezekowitz_2017_multitype_events_and_the_analysis_of_heart_failure_readmissions.pdf:application/pdf}
}

@article{berridge_analysis_1991,
	title = {Analysis of failure time data with ordinal categories of response},
	volume = {10},
	issn = {02776715, 10970258},
	url = {http://doi.wiley.com/10.1002/sim.4780101108},
	doi = {10.1002/sim.4780101108},
	abstract = {When failure times are observed, additional information concerning the type of failure is often recorded. A method which simultaneously models the failure times and additional information in the form of ordinal categories is discussed. An application to clinical trial data, in which the failure times are times of onset of headache, and the headaches are classified into the ordinal categories mild, moderate and severe, illustrates how this method may be used and how the final model can be interpreted. The continuation ratio model, which is used in this method, is described in detail.},
	pages = {1703--1710},
	number = {11},
	journaltitle = {Statistics in Medicine},
	author = {Berridge, Damon M. and Whitehead, John},
	urldate = {2018-10-30},
	date = {1991-11},
	langid = {english},
	file = {berridge_whitehead_1991_analysis_of_failure_time_data_with_ordinal_categories_of_response.pdf:/home/nathan/Dropbox/njames/zotero_sync/berridge_whitehead_1991_analysis_of_failure_time_data_with_ordinal_categories_of_response.pdf:application/pdf}
}

@article{durante_singular_2015,
	title = {On the Singular Components of a Copula},
	volume = {52},
	abstract = {We analyze copulas with a nontrivial singular component by using their Markov kernel representation. In particular, we provide existence results for copulas with a prescribed singular component. The constructions not only help to deal with problems related to multivariate stochastic systems of lifetimes when joint defaults can occur with a nonzero probability, but even provide a copula maximizing the probability of joint default.},
	pages = {1175--1182},
	journaltitle = {Journal of Applied Probability},
	author = {Durante, Fabrizio and Fernández-Sánchez, Juan and Trutschnig, Wolfgang},
	date = {2015},
	langid = {english},
	file = {durante_et_al_on_the_singular_components_of_a_copula.pdf:/home/nathan/Dropbox/njames/zotero_sync/durante_et_al_on_the_singular_components_of_a_copula.pdf:application/pdf}
}

@article{arakelian_clustering_2014,
	title = {Clustering Dependencies Via Mixtures of Copulas},
	volume = {43},
	issn = {0361-0918, 1532-4141},
	url = {http://www.tandfonline.com/doi/abs/10.1080/03610918.2012.752832},
	doi = {10.1080/03610918.2012.752832},
	pages = {1644--1661},
	number = {7},
	journaltitle = {Communications in Statistics - Simulation and Computation},
	author = {Arakelian, Veni and Karlis, Dimitris},
	urldate = {2018-11-13},
	date = {2014-01},
	langid = {english},
	file = {arakelian_karlis_2014_clustering_dependencies_via_mixtures_of_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/arakelian_karlis_2014_clustering_dependencies_via_mixtures_of_copulas.pdf:application/pdf}
}

@article{gelman_why_2012,
	title = {Why We (Usually) Don't Have to Worry About Multiple Comparisons},
	volume = {5},
	issn = {1934-5747, 1934-5739},
	url = {http://www.tandfonline.com/doi/abs/10.1080/19345747.2011.618213},
	doi = {10.1080/19345747.2011.618213},
	abstract = {Applied researchers often ﬁnd themselves making statistical inferences in settings that would seem to require multiple comparisons adjustments. We challenge the Type I error paradigm that underlies these corrections. Moreover we posit that the problem of multiple comparisons can disappear entirely when viewed from a hierarchical Bayesian perspective. We propose building multilevel models in the settings where multiple comparisons arise. Multilevel models perform partial pooling (shifting estimates toward each other), whereas classical procedures typically keep the centers of intervals stationary, adjusting for multiple comparisons by making the intervals wider (or, equivalently, adjusting the p values corresponding to intervals of ﬁxed width). Thus, multilevel models address the multiple comparisons problem and also yield more efﬁcient estimates, especially in settings with low group-level variation, which is where multiple comparisons are a particular concern.},
	pages = {189--211},
	number = {2},
	journaltitle = {Journal of Research on Educational Effectiveness},
	author = {Gelman, Andrew and Hill, Jennifer and Yajima, Masanao},
	urldate = {2018-11-14},
	date = {2012-04},
	langid = {english},
	file = {gelman_et_al_2012_why_we_(usually)_don't_have_to_worry_about_multiple_comparisons.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_et_al_2012_why_we_(usually)_don't_have_to_worry_about_multiple_comparisons.pdf:application/pdf}
}

@article{annis_bayesian_2017,
	title = {Bayesian inference with Stan: A tutorial on adding custom distributions},
	volume = {49},
	issn = {1554-3528},
	url = {http://link.springer.com/10.3758/s13428-016-0746-9},
	doi = {10.3758/s13428-016-0746-9},
	shorttitle = {Bayesian inference with Stan},
	abstract = {When evaluating cognitive models based on fits to observed data (or, really, any model that has free parameters), parameter estimation is critically important. Traditional techniques like hill climbing by minimizing or maximizing a fit statistic often result in point estimates. Bayesian approaches instead estimate parameters as posterior probability distributions, and thus naturally account for the uncertainty associated with parameter estimation; Bayesian approaches also offer powerful and principled methods for model comparison. Although software applications such as {WinBUGS} (Lunn, Thomas, Best, \& Spiegelhalter, Statistics and Computing, 10, 325–337, 2000) and {JAGS} (Plummer, 2003) provide Bturnkey{\textasciicircum}-style packages for Bayesian inference, they can be inefficient when dealing with models whose parameters are correlated, which is often the case for cognitive models, and they can impose significant technical barriers to adding custom distributions, which is often necessary when implementing cognitive models within a Bayesian framework. A recently developed software package called Stan (Stan Development Team, 2015) can solve both problems, as well as provide a turnkey solution to Bayesian inference. We present a tutorial on how to use Stan and how to add custom distributions to it, with an example using the linear ballistic accumulator model (Brown \& Heathcote, Cognitive Psychology, 57, 153–178. doi:10.1016/j.cogpsych.2007.12.002, 2008).},
	pages = {863--886},
	number = {3},
	journaltitle = {Behavior Research Methods},
	author = {Annis, Jeffrey and Miller, Brent J. and Palmeri, Thomas J.},
	urldate = {2018-12-14},
	date = {2017-06},
	langid = {english},
	keywords = {Bayesian inference, Linear ballistic accumulator, Probabilistic programming, Stan},
	file = {annis_et_al_2017_bayesian_inference_with_stan.pdf:/home/nathan/Dropbox/njames/zotero_sync/annis_et_al_2017_bayesian_inference_with_stan.pdf:application/pdf}
}

@article{liddell_analyzing_2018,
	title = {Analyzing ordinal data with metric models: What could possibly go wrong?},
	volume = {79},
	issn = {00221031},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022103117307746},
	doi = {10.1016/j.jesp.2018.08.009},
	shorttitle = {Analyzing ordinal data with metric models},
	abstract = {We surveyed all articles in the Journal of Personality and Social Psychology ({JPSP}), Psychological Science ({PS}), and the Journal of Experimental Psychology: General ({JEP}:G) that mentioned the term “Likert,” and found that 100\% of the articles that analyzed ordinal data did so using a metric model. We present novel evidence that analyzing ordinal data as if they were metric can systematically lead to errors. We demonstrate false alarms (i.e., detecting an eﬀect where none exists, Type I errors) and failures to detect eﬀects (i.e., loss of power, Type {II} errors). We demonstrate systematic inversions of eﬀects, for which treating ordinal data as metric indicates the opposite ordering of means than the true ordering of means. We show the same problems — false alarms, misses, and inversions — for interactions in factorial designs and for trend analyses in regression. We demonstrate that averaging across multiple ordinal measurements does not solve or even ameliorate these problems. A central contribution is a graphical explanation of how and when the misrepresentations occur. Moreover, we point out that there is no sure-ﬁre way to detect these problems by treating the ordinal values as metric, and instead we advocate use of ordered-probit models (or similar) because they will better describe the data. Finally, although frequentist approaches to some ordered-probit models are available, we use Bayesian methods because of their ﬂexibility in specifying models and their richness and accuracy in providing parameter estimates. An R script is provided for running an analysis that compares ordered-probit and metric models.},
	pages = {328--348},
	journaltitle = {Journal of Experimental Social Psychology},
	author = {Liddell, Torrin M. and Kruschke, John K.},
	urldate = {2019-01-09},
	date = {2018-11},
	langid = {english},
	file = {liddell_kruschke_2018_analyzing_ordinal_data_with_metric_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/liddell_kruschke_2018_analyzing_ordinal_data_with_metric_models.pdf:application/pdf}
}

@article{burkner_ordinal_nodate,
	title = {Ordinal Regression Models in Psychology: A Tutorial},
	url = {https://osf.io/x8swp},
	doi = {10.31234/osf.io/x8swp},
	shorttitle = {Ordinal Regression Models in Psychology},
	abstract = {Ordinal variables, while extremely common in Psychology, are almost exclusively analysed with statistical models that falsely assume them to be metric. This practice can lead to distorted effect size estimates, inflated error rates, and other problems. We argue for the application of ordinal models that make appropriate assumptions about the variables under study. In this tutorial article, we first explain the three major ordinal model classes; the cumulative, sequential and adjacent category models. We then show how to fit ordinal models in a fully Bayesian framework with the R package brms, using data sets on stem cell opinions and marriage time courses. Appendices provide detailed mathematical derivations of the models and a discussion of censored ordinal models. Ordinal models provide better theoretical interpretation and numerical inference from ordinal data, and we recommend their widespread adoption in Psychology.},
	author = {Bürkner, Paul - Christian and Vuorre, Matti},
	urldate = {2019-01-09},
	langid = {english},
	file = {bürkner_vuorre_ordinal_regression_models_in_psychology.pdf:/home/nathan/Dropbox/njames/zotero_sync/bürkner_vuorre_ordinal_regression_models_in_psychology.pdf:application/pdf}
}

@article{de_neve_semiparametric_2019,
	title = {Semiparametric linear transformation models: Effect measures, estimators, and applications: Semiparametric linear transformation models},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.8078},
	doi = {10.1002/sim.8078},
	shorttitle = {Semiparametric linear transformation models},
	journaltitle = {Statistics in Medicine},
	author = {De Neve, Jan and Thas, Olivier and Gerds, Thomas A.},
	urldate = {2019-01-06},
	date = {2019-01-04},
	langid = {english},
	file = {de_neve_et_al_2019_semiparametric_linear_transformation_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/de_neve_et_al_2019_semiparametric_linear_transformation_models.pdf:application/pdf}
}

@article{gomes_copula_2019,
	title = {Copula selection models for non-Gaussian outcomes that are missing not at random: Copula selection models for non-Normal data},
	volume = {38},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.7988},
	doi = {10.1002/sim.7988},
	shorttitle = {Copula selection models for non-Gaussian outcomes that are missing not at random},
	pages = {480--496},
	number = {3},
	journaltitle = {Statistics in Medicine},
	author = {Gomes, Manuel and Radice, Rosalba and Camarena Brenes, Jose and Marra, Giampiero},
	urldate = {2019-01-06},
	date = {2019-02-10},
	langid = {english},
	file = {gomes_et_al_2019_copula_selection_models_for_non-gaussian_outcomes_that_are_missing_not_at_random.pdf:/home/nathan/Dropbox/njames/zotero_sync/gomes_et_al_2019_copula_selection_models_for_non-gaussian_outcomes_that_are_missing_not_at_random.pdf:application/pdf}
}

@article{klein_mixed_2019,
	title = {Mixed binary-continuous copula regression models with application to adverse birth outcomes: Mixed Binary-Continuous Copula Regression Models},
	volume = {38},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.7985},
	doi = {10.1002/sim.7985},
	shorttitle = {Mixed binary-continuous copula regression models with application to adverse birth outcomes},
	pages = {413--436},
	number = {3},
	journaltitle = {Statistics in Medicine},
	author = {Klein, Nadja and Kneib, Thomas and Marra, Giampiero and Radice, Rosalba and Rokicki, Slawa and {McGovern}, Mark E.},
	urldate = {2019-01-06},
	date = {2019-02-10},
	langid = {english},
	file = {klein_et_al_2019_mixed_binary-continuous_copula_regression_models_with_application_to_adverse.pdf:/home/nathan/Dropbox/njames/zotero_sync/klein_et_al_2019_mixed_binary-continuous_copula_regression_models_with_application_to_adverse.pdf:application/pdf}
}

@article{chen_copula_2017,
	title = {Copula regression models for discrete and mixed bivariate responses},
	volume = {11},
	issn = {1559-8608, 1559-8616},
	url = {https://www.tandfonline.com/doi/full/10.1080/15598608.2016.1278059},
	doi = {10.1080/15598608.2016.1278059},
	abstract = {Estimation of the dependencies between bivariate discrete or mixed responses can be diﬃcult. In this article, we propose a copula-based model with latent variables associated with discrete margins to account for correlations between bivariate discrete responses. Furthermore, we generalize this strategy for jointly modeling the dependencies between mixed responses in regression mixed models. The proposed method allows the adoption of ﬂexible discrete margins and copula functions for various types of data. Maximum likelihood is used for model estimation; particularly, the estimation for bivariate responses in copula-based regression mixed models can be implemented using the {SAS} {PROC} {NLMIXED} procedure via adaptive Gaussian quadrature. In addition, a mixed model with non-Gaussian random eﬀects can also be easily ﬁtted using the same {SAS} procedure after reformulating the likelihood function by multiplying and dividing by a Gaussian density. Simulation results show good performance for bivariate discrete or mixed outcomes ranging from noncorrelated to highly correlated responses. An analysis of student performance in California schools shows a drastic improvement in estimation precision from the joint model versus two independent ﬁts.},
	pages = {515--530},
	number = {4},
	journaltitle = {Journal of Statistical Theory and Practice},
	author = {Chen, Yuhui and Hanson, Timothy},
	urldate = {2019-01-04},
	date = {2017-10-02},
	langid = {english},
	file = {chen_hanson_2017_copula_regression_models_for_discrete_and_mixed_bivariate_responses.pdf:/home/nathan/Dropbox/njames/zotero_sync/chen_hanson_2017_copula_regression_models_for_discrete_and_mixed_bivariate_responses.pdf:application/pdf}
}

@article{kwak_estimation_2017,
	title = {Estimation and inference of the joint conditional distribution for multivariate longitudinal data using nonparametric copulas},
	volume = {29},
	issn = {1048-5252, 1029-0311},
	url = {https://www.tandfonline.com/doi/full/10.1080/10485252.2017.1324966},
	doi = {10.1080/10485252.2017.1324966},
	abstract = {In this paper we study estimating the joint conditional distributions of multivariate longitudinal outcomes using regression models and copulas. For the estimation of marginal models, we consider a class of time-varying transformation models and combine the two marginal models using nonparametric empirical copulas. Our models and estimation method can be applied in many situations where the conditional mean-based models are not good enough. Empirical copulas combined with time-varying transformation models may allow quite flexible modelling for the joint conditional distributions for multivariate longitudinal data. We derive the asymptotic properties for the copula-based estimators of the joint conditional distribution functions. For illustration we apply our estimation method to an epidemiological study of childhood growth and blood pressure.},
	pages = {491--514},
	number = {3},
	journaltitle = {Journal of Nonparametric Statistics},
	author = {Kwak, Minjung},
	urldate = {2019-01-04},
	date = {2017-07-03},
	langid = {english},
	file = {kwak_2017_estimation_and_inference_of_the_joint_conditional_distribution_for_multivariate.pdf:/home/nathan/Dropbox/njames/zotero_sync/kwak_2017_estimation_and_inference_of_the_joint_conditional_distribution_for_multivariate.pdf:application/pdf}
}

@article{lai_mixed_2015,
	title = {Mixed response and time-to-event endpoints for multistage single-arm phase {II} design},
	volume = {16},
	issn = {1745-6215},
	url = {http://trialsjournal.biomedcentral.com/articles/10.1186/s13063-015-0743-9},
	doi = {10.1186/s13063-015-0743-9},
	abstract = {Background: The objective of phase {II} cancer clinical trials is to determine if a treatment has sufficient activity to warrant further study. The efficiency of a conventional phase {II} trial design has been the object of considerable debate, particularly when the study regimen is characteristically cytostatic. At the time of development of a phase {II} cancer trial, we accumulated clinical experience regarding the time to progression ({TTP}) for similar classes of drugs and for standard therapy. By considering the time to event ({TTE}) in addition to the tumor response endpoint, a mixed-endpoint phase {II} design may increase the efficiency and ability of selecting promising cytotoxic and cytostatic agents for further development.
Methods: We proposed a single-arm phase {II} trial design by extending the Zee multinomial method to fully use mixed endpoints with tumor response and the {TTE}. In this design, the dependence between the probability of response and the {TTE} outcome is modeled through a Gaussian copula.
Results: Given the type I and type {II} errors and the hypothesis as defined by the response rate ({RR}) and median {TTE}, such as median {TTP}, the decision rules for a two-stage phase {II} trial design can be generated. We demonstrated through simulation that the proposed design has a smaller expected sample size and higher early stopping probability under the null hypothesis than designs based on a single-response endpoint or a single {TTE} endpoint.
Conclusions: The proposed design is more efficient for screening new cytotoxic or cytostatic agents and less likely to miss an effective agent than the alternative single-arm design.},
	number = {1},
	journaltitle = {Trials},
	author = {Lai, Xin and Zee, Benny Chung-Ying},
	urldate = {2019-01-04},
	date = {2015-12},
	langid = {english},
	file = {lai_zee_2015_mixed_response_and_time-to-event_endpoints_for_multistage_single-arm_phase_ii.pdf:/home/nathan/Dropbox/njames/zotero_sync/lai_zee_2015_mixed_response_and_time-to-event_endpoints_for_multistage_single-arm_phase_ii.pdf:application/pdf}
}

@article{zhang_bayesian_2015,
	title = {A Bayesian method for analyzing combinations of continuous, ordinal, and nominal categorical data with missing values},
	volume = {135},
	issn = {0047259X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0047259X14002620},
	doi = {10.1016/j.jmva.2014.11.007},
	abstract = {From a Bayesian perspective, we propose a general method for analyzing a combination of continuous, ordinal (including binary), and categorical/nominal multivariate measures with missing values. We assume multivariate normal linear regression models for multivariate continuous measures, multivariate probit models for correlated ordinal measures, and multivariate multinomial probit models for multivariate categorical/nominal measures. Then we assume a multivariate normal linear model on the continuous vector comprised of continuous variables and those underlying normal variables for ordinal variables from multivariate probit models and for categorical variables from multinomial probit models. We develop a Markov chain Monte Carlo ({MCMC}) algorithm to estimate unknown parameters including regression parameters, cut-points for ordinal data from the multivariate probit models, and the covariance matrix encompassing both continuous variables and the underlying normal latent variables. Combining the continuous variables and the normal latent variables allows us to model combinations of continuous, ordinal, and categorical multivariate data simultaneously. The framework incorporates flexible priors for the covariance matrix, provides a foundation for inference about the underlying covariance structure, and imputes missing data where needed. The method is illustrated through simulated examples and two real data applications.},
	pages = {43--58},
	journaltitle = {Journal of Multivariate Analysis},
	author = {Zhang, Xiao and Boscardin, W. John and Belin, Thomas R. and Wan, Xiaohai and He, Yulei and Zhang, Kui},
	urldate = {2019-01-04},
	date = {2015-03},
	langid = {english},
	file = {zhang_et_al_2015_a_bayesian_method_for_analyzing_combinations_of_continuous,_ordinal,_and.pdf:/home/nathan/Dropbox/njames/zotero_sync/zhang_et_al_2015_a_bayesian_method_for_analyzing_combinations_of_continuous,_ordinal,_and.pdf:application/pdf}
}

@article{faugeras_quantile-copula_2009,
	title = {A quantile-copula approach to conditional density estimation},
	volume = {100},
	issn = {0047259X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0047259X09000621},
	doi = {10.1016/j.jmva.2009.03.006},
	abstract = {A new kernel-type estimator of the conditional density is proposed. It is based on an efficient quantile transformation of the data. The proposed estimator, which is based on the copula representation, turns out to have a remarkable product form. Its large-sample properties are considered and comparisons in terms of bias and variance are made with competitors based on nonparametric regression. A comparative simulation study is also provided.},
	pages = {2083--2099},
	number = {9},
	journaltitle = {Journal of Multivariate Analysis},
	author = {Faugeras, Olivier P.},
	urldate = {2019-01-04},
	date = {2009-10},
	langid = {english},
	file = {faugeras_2009_a_quantile-copula_approach_to_conditional_density_estimation.pdf:/home/nathan/Dropbox/njames/zotero_sync/faugeras_2009_a_quantile-copula_approach_to_conditional_density_estimation.pdf:application/pdf}
}

@article{conlon_surrogacy_2017,
	title = {Surrogacy assessment using principal stratification and a Gaussian copula model},
	volume = {26},
	issn = {0962-2802, 1477-0334},
	url = {http://journals.sagepub.com/doi/10.1177/0962280214539655},
	doi = {10.1177/0962280214539655},
	abstract = {In clinical trials, a surrogate outcome (S) can be measured before the outcome of interest (T) and may provide early information regarding the treatment (Z) effect on T. Many methods of surrogacy validation rely on models for the conditional distribution of T given Z and S. However, S is a post-randomization variable, and unobserved, simultaneous predictors of S and T may exist, resulting in a non-causal interpretation. Frangakis and Rubin developed the concept of principal surrogacy, stratifying on the joint distribution of the surrogate marker under treatment and control to assess the association between the causal effects of treatment on the marker and the causal effects of treatment on the clinical outcome. Working within the principal surrogacy framework, we address the scenario of an ordinal categorical variable as a surrogate for a censored failure time true endpoint. A Gaussian copula model is used to model the joint distribution of the potential outcomes of T, given the potential outcomes of S. Because the proposed model cannot be fully identified from the data, we use a Bayesian estimation approach with prior distributions consistent with reasonable assumptions in the surrogacy assessment setting. The method is applied to data from a colorectal cancer clinical trial, previously analyzed by Burzykowski et al.},
	pages = {88--107},
	number = {1},
	journaltitle = {Statistical Methods in Medical Research},
	author = {Conlon, Asc and Taylor, Jmg and Elliott, Mr},
	urldate = {2019-01-04},
	date = {2017-02},
	langid = {english},
	file = {conlon_et_al_2017_surrogacy_assessment_using_principal_stratification_and_a_gaussian_copula_model.pdf:/home/nathan/Dropbox/njames/zotero_sync/conlon_et_al_2017_surrogacy_assessment_using_principal_stratification_and_a_gaussian_copula_model.pdf:application/pdf}
}

@article{kwak_estimation_2017-1,
	title = {Estimation and inference on the joint conditional distribution for bivariate longitudinal data using Gaussian copula},
	volume = {46},
	issn = {12263192},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1226319216300606},
	doi = {10.1016/j.jkss.2016.11.005},
	abstract = {In this paper we study estimating the joint conditional distributions of bivariate longitudinal outcomes using regression models and copulas. For the estimation of marginal models we consider a class of time-varying transformation models and combine the two marginal models using Gaussian copulas. Our models and estimation method can be applied in many situations where the conditional mean-based models are not good enough. Gaussian copulas combined with time-varying transformation models may allow convenient and easy-to-interpret modeling for the joint conditional distributions for bivariate longitudinal data. We derive the asymptotic properties for the copula based estimators of the joint conditional distribution functions. For illustration we apply our estimation method to an epidemiological study of childhood growth and blood pressure and also investigate finite sample properties of our procedures through a simulation study.},
	pages = {349--364},
	number = {3},
	journaltitle = {Journal of the Korean Statistical Society},
	author = {Kwak, Minjung},
	urldate = {2019-01-04},
	date = {2017-09},
	langid = {english},
	file = {kwak_2017_estimation_and_inference_on_the_joint_conditional_distribution_for_bivariate.pdf:/home/nathan/Dropbox/njames/zotero_sync/kwak_2017_estimation_and_inference_on_the_joint_conditional_distribution_for_bivariate.pdf:application/pdf}
}

@incollection{gelman_robit_2005,
	location = {Chichester, {UK}},
	title = {Robit Regression: A Simple Robust Alternative to Logistic and Probit Regression},
	isbn = {978-0-470-09045-9 978-0-470-09043-5},
	url = {http://doi.wiley.com/10.1002/0470090456.ch21},
	shorttitle = {Robit Regression},
	pages = {227--238},
	booktitle = {Wiley Series in Probability and Statistics},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Liu, Chuanhai},
	editor = {Gelman, Andrew and Meng, Xiao-Li},
	urldate = {2019-01-04},
	date = {2005-07-14},
	doi = {10.1002/0470090456.ch21},
	file = {liu_2005_robit_regression.pdf:/home/nathan/Dropbox/njames/zotero_sync/liu_2005_robit_regression.pdf:application/pdf}
}

@article{lau_cumulative_1992,
	title = {Cumulative Meta-Analysis of Therapeutic Trials for Myocardial Infarction},
	volume = {327},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/abs/10.1056/NEJM199207233270406},
	doi = {10.1056/NEJM199207233270406},
	pages = {248--254},
	number = {4},
	journaltitle = {New England Journal of Medicine},
	author = {Lau, Joseph and Antman, Elliott M. and Jimenez-Silva, Jeanette and Kupelnick, Bruce and Mosteller, Frederick and Chalmers, Thomas C.},
	urldate = {2018-12-27},
	date = {1992-07-23},
	langid = {english},
	file = {lau_et_al_1992_cumulative_meta-analysis_of_therapeutic_trials_for_myocardial_infarction.pdf:/home/nathan/Dropbox/njames/zotero_sync/lau_et_al_1992_cumulative_meta-analysis_of_therapeutic_trials_for_myocardial_infarction.pdf:application/pdf}
}

@incollection{john_kontoghiorghes_parallel_2005,
	title = {Parallel Bayesian Computation},
	volume = {20052841},
	isbn = {978-0-8247-4067-2 978-1-4200-2868-3},
	url = {http://www.crcnetbase.com/doi/abs/10.1201/9781420028683.ch16},
	pages = {477--508},
	booktitle = {Handbook of Parallel Computing and Statistics},
	publisher = {Chapman and Hall/{CRC}},
	author = {Wilkinson, Darren},
	editor = {John Kontoghiorghes, Erricos},
	urldate = {2018-12-19},
	date = {2005-12-21},
	langid = {english},
	doi = {10.1201/9781420028683.ch16},
	file = {wilkinson_2005_parallel_bayesian_computation.pdf:/home/nathan/Dropbox/njames/zotero_sync/wilkinson_2005_parallel_bayesian_computation.pdf:application/pdf}
}

@article{terenin_gpu-accelerated_2018,
	title = {{GPU}-accelerated Gibbs sampling: a case study of the Horseshoe Probit model},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-018-9809-3},
	doi = {10.1007/s11222-018-9809-3},
	shorttitle = {{GPU}-accelerated Gibbs sampling},
	abstract = {Gibbs sampling is a widely used Markov chain Monte Carlo ({MCMC}) method for numerically approximating integrals of interest in Bayesian statistics and other mathematical sciences. Many implementations of {MCMC} methods do not extend easily to parallel computing environments, as their inherently sequential nature incurs a large synchronization cost. In the case study illustrated by this paper, we show how to do Gibbs sampling in a fully data-parallel manner on a graphics processing unit, for a large class of exchangeable models that admit latent variable representations. Our approach takes a systems perspective, with emphasis placed on efﬁcient use of compute hardware. We demonstrate our method on a Horseshoe Probit regression model and ﬁnd that our implementation scales effectively to thousands of predictors and millions of data points simultaneously.},
	journaltitle = {Statistics and Computing},
	author = {Terenin, Alexander and Dong, Shawfeng and Draper, David},
	urldate = {2018-12-19},
	date = {2018-03-19},
	langid = {english},
	file = {terenin_et_al_2018_gpu-accelerated_gibbs_sampling.pdf:/home/nathan/Dropbox/njames/zotero_sync/terenin_et_al_2018_gpu-accelerated_gibbs_sampling.pdf:application/pdf}
}

@article{green_bayesian_2015,
	title = {Bayesian computation: a summary of the current state, and samples backwards and forwards},
	volume = {25},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-015-9574-5},
	doi = {10.1007/s11222-015-9574-5},
	shorttitle = {Bayesian computation},
	abstract = {Recent decades have seen enormous improvements in computational inference for statistical models; there have been competitive continual enhancements in a wide range of computational tools. In Bayesian inference, ﬁrst and foremost, {MCMC} techniques have continued to evolve, moving from random walk proposals to Langevin drift, to Hamiltonian Monte Carlo, and so on, with both theoretical and algorithmic innovations opening new opportunities to practitioners. However, this impressive evolution in capacity is confronted by an even steeper increase in the complexity of the datasets to be addressed. The difﬁculties of modelling and then handling ever more complex datasets most likely call for a new type of tool for computational inference that dramatically reduces the dimension and size of the raw data while capturing its essential aspects. Approximate models and algorithms may thus be at the core of the next computational revolution.},
	pages = {835--862},
	number = {4},
	journaltitle = {Statistics and Computing},
	author = {Green, Peter J. and Łatuszyński, Krzysztof and Pereyra, Marcelo and Robert, Christian P.},
	urldate = {2018-12-19},
	date = {2015-07},
	langid = {english},
	file = {green_et_al_2015_bayesian_computation.pdf:/home/nathan/Dropbox/njames/zotero_sync/green_et_al_2015_bayesian_computation.pdf:application/pdf}
}

@article{barthel_dependence_2018,
	title = {Dependence modeling for recurrent event times subject to right‐censoring with D‐vine copulas},
	issn = {1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13014},
	doi = {10.1111/biom.13014},
	journaltitle = {Biometrics},
	author = {Barthel, Nicole and Geerdens, Candida and Czado, Claudia and Janssen, Paul},
	urldate = {2018-12-17},
	date = {2018-12-14},
	langid = {english},
	file = {barthel_et_al_2018_dependence_modeling_for_recurrent_event_times_subject_to_right‐censoring_with.pdf:/home/nathan/Dropbox/njames/zotero_sync/barthel_et_al_2018_dependence_modeling_for_recurrent_event_times_subject_to_right‐censoring_with.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/MZUA4SZ4/biom.html:text/html}
}

@incollection{lin_bivariate_2016,
	location = {Cham},
	title = {A Bivariate Random-Effects Copula Model for Length of Stay and Cost},
	isbn = {978-3-319-42567-2 978-3-319-42568-9},
	url = {http://link.springer.com/10.1007/978-3-319-42568-9_25},
	pages = {339--352},
	booktitle = {Statistical Applications from Clinical Trials and Personalized Medicine to Finance and Business Analytics},
	publisher = {Springer International Publishing},
	author = {Tang, Xiaoqin and Luo, Zhehui and Gardiner, Joseph C.},
	editor = {Lin, Jianchang and Wang, Bushi and Hu, Xiaowen and Chen, Kun and Liu, Ray},
	urldate = {2019-01-09},
	date = {2016},
	doi = {10.1007/978-3-319-42568-9_25},
	file = {tang_et_al_2016_a_bivariate_random-effects_copula_model_for_length_of_stay_and_cost.pdf:/home/nathan/Dropbox/njames/zotero_sync/tang_et_al_2016_a_bivariate_random-effects_copula_model_for_length_of_stay_and_cost.pdf:application/pdf}
}

@article{noh_copula-based_2013,
	title = {Copula-Based Regression Estimation and Inference},
	volume = {108},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2013.783842},
	doi = {10.1080/01621459.2013.783842},
	pages = {676--688},
	number = {502},
	journaltitle = {Journal of the American Statistical Association},
	author = {Noh, Hohsuk and Ghouch, Anouar El and Bouezmarni, Taoufik},
	urldate = {2019-01-10},
	date = {2013-06},
	langid = {english},
	file = {noh_et_al_2013_copula-based_regression_estimation_and_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/noh_et_al_2013_copula-based_regression_estimation_and_inference.pdf:application/pdf}
}

@article{garonzik-wang_frailty_2012,
	title = {Frailty and Delayed Graft Function in Kidney Transplant Recipients},
	volume = {147},
	issn = {0004-0010},
	url = {http://archsurg.jamanetwork.com/article.aspx?doi=10.1001/archsurg.2011.1229},
	doi = {10.1001/archsurg.2011.1229},
	pages = {190},
	number = {2},
	journaltitle = {Archives of Surgery},
	author = {Garonzik-Wang, Jacqueline M.},
	urldate = {2019-01-10},
	date = {2012-02-01},
	langid = {english},
	file = {garonzik-wang_2012_frailty_and_delayed_graft_function_in_kidney_transplant_recipients.pdf:/home/nathan/Dropbox/njames/zotero_sync/garonzik-wang_2012_frailty_and_delayed_graft_function_in_kidney_transplant_recipients.pdf:application/pdf}
}

@article{efron_why_1986,
	title = {Why Isn't Everyone a Bayesian?},
	volume = {40},
	issn = {00031305},
	url = {https://www.jstor.org/stable/2683105?origin=crossref},
	doi = {10.2307/2683105},
	pages = {1},
	number = {1},
	journaltitle = {The American Statistician},
	author = {Efron, B.},
	urldate = {2019-01-10},
	date = {1986-02},
	file = {efron_1986_why_isn't_everyone_a_bayesian.pdf:/home/nathan/Dropbox/njames/zotero_sync/efron_1986_why_isn't_everyone_a_bayesian.pdf:application/pdf}
}

@misc{green_reversible_2009,
	title = {Reversible jump {MCMC}},
	author = {Green, Peter J. and Hastie, David I.},
	date = {2009-06-13},
	file = {green_hastie_2009_reversible_jump_mcmc.pdf:/home/nathan/Dropbox/njames/zotero_sync/green_hastie_2009_reversible_jump_mcmc.pdf:application/pdf}
}

@article{writing_group_for_the_womens_health_initiative_investigators_risks_2002,
	title = {Risks and Benefits of Estrogen Plus Progestin in Healthy Postmenopausal Women: Principal Results From the Women's Health Initiative Randomized Controlled Trial},
	volume = {288},
	issn = {00987484, 15383598},
	url = {http://jama.ama-assn.org/cgi/doi/10.1001/jama.288.3.321},
	doi = {10.1001/jama.288.3.321},
	shorttitle = {Risks and Benefits of Estrogen Plus Progestin in Healthy Postmenopausal Women},
	pages = {321--333},
	number = {3},
	journaltitle = {{JAMA}: The Journal of the American Medical Association},
	author = {{Writing Group for the Women's Health Initiative Investigators}},
	urldate = {2019-01-10},
	date = {2002-07-17},
	file = {writing_group_for_the_women's_health_initiative_investigators_2002_risks_and_benefits_of_estrogen_plus_progestin_in_healthy_postmenopausal_women.pdf:/home/nathan/Dropbox/njames/zotero_sync/writing_group_for_the_women's_health_initiative_investigators_2002_risks_and_benefits_of_estrogen_plus_progestin_in_healthy_postmenopausal_women2.pdf:application/pdf}
}

@article{efron_controversies_1978,
	title = {Controversies in the Foundations of Statistics},
	volume = {85},
	issn = {0002-9890, 1930-0972},
	url = {https://www.tandfonline.com/doi/full/10.1080/00029890.1978.11994566},
	doi = {10.1080/00029890.1978.11994566},
	pages = {231--246},
	number = {4},
	journaltitle = {The American Mathematical Monthly},
	author = {Efron, Bradley},
	urldate = {2019-01-10},
	date = {1978-04},
	langid = {english},
	file = {efron_1978_controversies_in_the_foundations_of_statistics.pdf:/home/nathan/Dropbox/njames/zotero_sync/efron_1978_controversies_in_the_foundations_of_statistics.pdf:application/pdf}
}

@article{stampfer_postmenopausal_1991,
	title = {Postmenopausal Estrogen Therapy and Cardiovascular Disease: Ten-Year Follow-up from the Nurses' Health Study},
	volume = {325},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/abs/10.1056/NEJM199109123251102},
	doi = {10.1056/NEJM199109123251102},
	shorttitle = {Postmenopausal Estrogen Therapy and Cardiovascular Disease},
	pages = {756--762},
	number = {11},
	journaltitle = {New England Journal of Medicine},
	author = {Stampfer, Meir J. and Colditz, Graham A. and Willett, Walter C. and Manson, {JoAnn} E. and Rosner, Bernard and Speizer, Frank E. and Hennekens, Charles H.},
	urldate = {2019-01-10},
	date = {1991-09-12},
	langid = {english},
	file = {stampfer_et_al_1991_postmenopausal_estrogen_therapy_and_cardiovascular_disease.pdf:/home/nathan/Dropbox/njames/zotero_sync/stampfer_et_al_1991_postmenopausal_estrogen_therapy_and_cardiovascular_disease.pdf:application/pdf}
}

@article{gesmann_using_nodate,
	title = {Using the Google Visualisation {API} with R},
	abstract = {The {googleVis} package provides an interface between R and the Google Visualisation {API}. The Google Visualisation {API} offers interactive charts which can be embedded into web pages. The most well known of those charts is probably the Motion Chart, popularised by Hans Rosling in his {TED} talks. With the {googleVis} package users can create easily web pages with interactive charts based on R data frames and display them either via the R.rsp package or within their own sites. The current version (0.2.2) of the package provides interfaces to Motion Charts, Annotated Time Lines, Maps, Geo Maps, Tables and Tree Maps.},
	pages = {4},
	author = {Gesmann, Markus},
	langid = {english},
	file = {gesmann_using_the_google_visualisation_api_with_r.pdf:/home/nathan/Dropbox/njames/zotero_sync/gesmann_using_the_google_visualisation_api_with_r.pdf:application/pdf}
}

@article{billard_role_1998,
	title = {The Role of Statistics and the Statistician},
	volume = {52},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1998.10480589},
	doi = {10.1080/00031305.1998.10480589},
	pages = {319--324},
	number = {4},
	journaltitle = {The American Statistician},
	author = {Billard, Lynne},
	urldate = {2019-01-10},
	date = {1998-11},
	langid = {english},
	file = {billard_1998_the_role_of_statistics_and_the_statistician.pdf:/home/nathan/Dropbox/njames/zotero_sync/billard_1998_the_role_of_statistics_and_the_statistician.pdf:application/pdf}
}

@article{park_bayesian_2004,
	title = {Bayesian Multilevel Estimation with Poststratification: State-Level Estimates from National Polls},
	volume = {12},
	url = {http://www.jstor.org/stable/25791784},
	pages = {375--385},
	number = {4},
	journaltitle = {Political Analysis},
	author = {Park, David K. and Gelman, Andrew and work(s):, Joseph Bafumi Reviewed},
	date = {2004},
	langid = {english},
	file = {park_et_al_2004_bayesian_multilevel_estimation_with_poststratification.pdf:/home/nathan/Dropbox/njames/zotero_sync/park_et_al_2004_bayesian_multilevel_estimation_with_poststratification.pdf:application/pdf}
}

@misc{z-q_bayesian_nodate,
	title = {Bayesian Methods on Statisical Methods on the Common Mean},
	author = {Z-Q, John Lu and Guthrie, Will},
	file = {z-q_guthrie_bayesian_methods_on_statisical_methods_on_the_common_mean.PDF:/home/nathan/Dropbox/njames/zotero_sync/z-q_guthrie_bayesian_methods_on_statisical_methods_on_the_common_mean.PDF:application/pdf}
}

@article{zou_modified_2004,
	title = {A Modified Poisson Regression Approach to Prospective Studies with Binary Data},
	volume = {159},
	issn = {0002-9262},
	url = {https://academic.oup.com/aje/article-lookup/doi/10.1093/aje/kwh090},
	doi = {10.1093/aje/kwh090},
	pages = {702--706},
	number = {7},
	journaltitle = {American Journal of Epidemiology},
	author = {Zou, G.},
	urldate = {2019-01-10},
	date = {2004-04-01},
	langid = {english},
	file = {zou_2004_a_modified_poisson_regression_approach_to_prospective_studies_with_binary_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/zou_2004_a_modified_poisson_regression_approach_to_prospective_studies_with_binary_data.pdf:application/pdf}
}

@article{mensh_ten_nodate,
	title = {Ten simple rules for structuring papers},
	abstract = {The title not only transmits the paper’s central contribution but can also serve as a constant reminder (to you) to focus the text on transmitting that idea. Science is, after all, the abstraction of simple principles from complex data. The title is the ultimate refinement of the paper’s contribution. Thinking about the title early—and regularly returning to hone it—can help not only the writing of the paper but also the process of designing experiments or developing theories. This Rule of One is the most difficult rule to optimally implement because it comes face-toface with the key challenge of science, which is to make the claim and/or model as simple as the data and logic can support but no simpler. In the end, your struggle to find this balance may appropriately result in “one contribution” that is multifaceted. For example, a technology paper may describe both its new technology and a biological result using it; the bridge that unifies these two facets is a clear description of how the new technology can be used to do new biology.},
	pages = {9},
	author = {Mensh, Brett and Kording, Konrad},
	langid = {english},
	file = {mensh_kording_ten_simple_rules_for_structuring_papers.pdf:/home/nathan/Dropbox/njames/zotero_sync/mensh_kording_ten_simple_rules_for_structuring_papers.pdf:application/pdf}
}

@article{nikoloulopoulos_multivariate_2008,
	title = {Multivariate logit copula model with an application to dental data},
	volume = {27},
	issn = {02776715, 10970258},
	url = {http://doi.wiley.com/10.1002/sim.3449},
	doi = {10.1002/sim.3449},
	abstract = {Applications of copulas for multivariate continuous data abound but there are only a few that treat multivariate binary data. In the present paper, we model multivariate binary data based on copulas using mixtures of max-inﬁnitely divisible copulas, introduced by Joe and Hu (J. Multivar. Anal. 1996; 57(2): 240–265). When applying copulas to binary data the marginal distributions also contribute to the dependence measures. We propose the use of covariate information in the copula parameters to obtain a direct effect of a covariate on dependence. To deal with model uncertainty due to selecting among several candidate models, we use a model averaging technique. We apply the model to data from the {SignalTandmobiel} c dental study and, in particular, to four binary responses that refer to caries experience in the mandibular and maxillary left and right molars. We aim to model Kendall’s tau associations between them, and examine how covariate information affects these associations. We found that there are systematically larger associations between the two mandibular and the two maxillary molars. Using covariates to model these associations more closely, we found that the systematic ﬂuoride and age of the children affect the associations. Note that such relationships could not have been revealed by methods that focus on the marginal models. Copyright q 2008 John Wiley \& Sons, Ltd.},
	pages = {6393--6406},
	number = {30},
	journaltitle = {Statistics in Medicine},
	author = {Nikoloulopoulos, Aristidis K. and Karlis, Dimitris},
	urldate = {2019-01-11},
	date = {2008-12-30},
	langid = {english},
	file = {nikoloulopoulos_karlis_2008_multivariate_logit_copula_model_with_an_application_to_dental_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/nikoloulopoulos_karlis_2008_multivariate_logit_copula_model_with_an_application_to_dental_data.pdf:application/pdf}
}

@article{nikoloulopoulos_finite_2009,
	title = {Finite normal mixture copulas for multivariate discrete data modeling},
	volume = {139},
	issn = {03783758},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378375809001542},
	doi = {10.1016/j.jspi.2009.05.034},
	abstract = {A new family of copulas is introduced that provides flexible dependence structure while being tractable and simple to use for multivariate discrete data modeling. The construction exploits finite mixtures of uncorrelated normal distributions. Accordingly, the cumulative distribution function is simply the product of univariate normal distributions. At the same time, however, the mixing operation introduces association. The properties of the new family of copulas are examined and a concrete application is used to show its applicability.},
	pages = {3878--3890},
	number = {11},
	journaltitle = {Journal of Statistical Planning and Inference},
	author = {Nikoloulopoulos, Aristidis K. and Karlis, Dimitris},
	urldate = {2019-01-11},
	date = {2009-11},
	langid = {english},
	file = {nikoloulopoulos_karlis_2009_finite_normal_mixture_copulas_for_multivariate_discrete_data_modeling.pdf:/home/nathan/Dropbox/njames/zotero_sync/nikoloulopoulos_karlis_2009_finite_normal_mixture_copulas_for_multivariate_discrete_data_modeling.pdf:application/pdf}
}

@article{joe_multivariate_1996,
	title = {Multivariate Distributions from Mixtures of Max-Infinitely Divisible Distributions},
	volume = {57},
	issn = {0047259X},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0047259X96900329},
	doi = {10.1006/jmva.1996.0032},
	pages = {240--265},
	number = {2},
	journaltitle = {Journal of Multivariate Analysis},
	author = {Joe, Harry and Hu, Taizhong},
	urldate = {2019-01-11},
	date = {1996-05},
	langid = {english},
	file = {joe_hu_1996_multivariate_distributions_from_mixtures_of_max-infinitely_divisible.pdf:/home/nathan/Dropbox/njames/zotero_sync/joe_hu_1996_multivariate_distributions_from_mixtures_of_max-infinitely_divisible.pdf:application/pdf}
}

@article{wu_gaussian_2014,
	title = {Gaussian Copula Mixed Models for Clustered Mixed Outcomes, With Application in Developmental Toxicology},
	volume = {19},
	issn = {1085-7117, 1537-2693},
	url = {http://link.springer.com/10.1007/s13253-013-0155-9},
	doi = {10.1007/s13253-013-0155-9},
	pages = {39--56},
	number = {1},
	journaltitle = {Journal of Agricultural, Biological, and Environmental Statistics},
	author = {Wu, Beilei and de Leon, Alexander R.},
	urldate = {2019-01-11},
	date = {2014-03},
	langid = {english},
	file = {wu_de_leon_2014_gaussian_copula_mixed_models_for_clustered_mixed_outcomes,_with_application_in.pdf:/home/nathan/Dropbox/njames/zotero_sync/wu_de_leon_2014_gaussian_copula_mixed_models_for_clustered_mixed_outcomes,_with_application_in.pdf:application/pdf}
}

@article{li_varying-association_2018,
	title = {Varying-association copula models for multivariate survival data: {VARYING}-{ASSOCIATION} {COPULA}},
	volume = {46},
	issn = {03195724},
	url = {http://doi.wiley.com/10.1002/cjs.11474},
	doi = {10.1002/cjs.11474},
	shorttitle = {Varying-association copula models for multivariate survival data},
	pages = {556--576},
	number = {4},
	journaltitle = {Canadian Journal of Statistics},
	author = {Li, Hui and Cao, Zhiqiang and Yin, Guosheng},
	urldate = {2019-01-11},
	date = {2018-12},
	langid = {english},
	file = {li_et_al_2018_varying-association_copula_models_for_multivariate_survival_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/li_et_al_2018_varying-association_copula_models_for_multivariate_survival_data.pdf:application/pdf}
}

@article{hua_tail_2011,
	title = {Tail order and intermediate tail dependence of multivariate copulas},
	volume = {102},
	issn = {0047259X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0047259X11000911},
	doi = {10.1016/j.jmva.2011.05.011},
	abstract = {In order to study copula families that have tail patterns and tail asymmetry different from multivariate Gaussian and t copulas, we introduce the concepts of tail order and tail order functions. These provide an integrated way to study both tail dependence and intermediate tail dependence. Some fundamental properties of tail order and tail order functions are obtained. For the multivariate Archimedean copula, we relate the tail heaviness of a positive random variable to the tail behavior of the Archimedean copula constructed from the Laplace transform of the random variable, and extend the results of Charpentier and Segers [7] [A. Charpentier, J. Segers, Tails of multivariate Archimedean copulas, Journal of Multivariate Analysis 100 (7) (2009) 1521–1537] for upper tails of Archimedean copulas. In addition, a new one-parameter Archimedean copula family based on the Laplace transform of the inverse Gamma distribution is proposed; it possesses patterns of upper and lower tails not seen in commonly used copula families. Finally, tail orders are studied for copulas constructed from mixtures of max-infinitely divisible copulas.},
	pages = {1454--1471},
	number = {10},
	journaltitle = {Journal of Multivariate Analysis},
	author = {Hua, Lei and Joe, Harry},
	urldate = {2019-01-13},
	date = {2011-11},
	langid = {english},
	file = {hua_joe_2011_tail_order_and_intermediate_tail_dependence_of_multivariate_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/hua_joe_2011_tail_order_and_intermediate_tail_dependence_of_multivariate_copulas.pdf:application/pdf}
}

@book{evans_fundamental_2016,
	location = {Boca Raton},
	title = {Fundamental Concepts for New Clinical Trialists},
	isbn = {978-1-4200-9087-1},
	series = {Chapman \& Hall/{CRC} biostatistics series},
	pagetotal = {348},
	publisher = {{CRC} Press, Taylor \& Francis Group},
	author = {Evans, Scott R. and Ting, Naitee},
	date = {2016},
	note = {{OCLC}: ocn928721458},
	keywords = {Clinical trials, Statistical methods, Clinical Trials as Topic, Methodology, Research Design}
}

@book{friedman_fundamentals_2015,
	location = {New York, {NY}},
	edition = {5th ed.},
	title = {Fundamentals of Clinical Trials},
	isbn = {978-3-319-18538-5},
	abstract = {Literaturangaben},
	pagetotal = {551},
	publisher = {Springer New York},
	author = {Friedman, Lawrence M. and Furberg, Curt D. and {DeMets}, David L. and Reboussin, David M. and Granger, Christopher B.},
	date = {2015},
	note = {{OCLC}: 935903160}
}

@article{teixeira-pinto_correlated_2009,
	title = {Correlated bivariate continuous and binary outcomes: Issues and applications},
	volume = {28},
	issn = {02776715, 10970258},
	url = {http://doi.wiley.com/10.1002/sim.3588},
	doi = {10.1002/sim.3588},
	shorttitle = {Correlated bivariate continuous and binary outcomes},
	abstract = {Increasingly multiple outcomes are collected in order to characterize treatment effectiveness or to evaluate the impact of large policy initiatives. Often the multiple outcomes are non-commensurate, e.g. measured on different scales. The common approach to inference is to model each outcome separately ignoring the potential correlation among the responses. We describe and contrast several full likelihood and quasilikelihood multivariate methods for non-commensurate outcomes. We present a new multivariate model to analyze binary and continuous correlated outcomes using a latent variable. We study the efﬁciency gains of the multivariate methods relative to the univariate approach. For complete data, all approaches yield consistent parameter estimates. When the mean structure of all outcomes depends on the same set of covariates, efﬁciency gains by adopting a multivariate approach are negligible. In contrast, when the mean outcomes depend on different covariate sets, large efﬁciency gains are realized. Three real examples illustrate the different approaches. Copyright q 2009 John Wiley \& Sons, Ltd.},
	pages = {1753--1773},
	number = {13},
	journaltitle = {Statistics in Medicine},
	author = {Teixeira-Pinto, Armando and Normand, Sharon-Lise T.},
	urldate = {2019-01-14},
	date = {2009-06-15},
	langid = {english},
	file = {teixeira-pinto_normand_2009_correlated_bivariate_continuous_and_binary_outcomes.pdf:/home/nathan/Dropbox/njames/zotero_sync/teixeira-pinto_normand_2009_correlated_bivariate_continuous_and_binary_outcomes.pdf:application/pdf}
}

@article{tyler_use_2011,
	title = {The use and abuse of multiple outcomes in randomized controlled depression trials},
	volume = {32},
	issn = {15517144},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1551714410002430},
	doi = {10.1016/j.cct.2010.12.007},
	abstract = {Objective: Multiple outcomes are commonly analyzed in randomized trials. Interpretation of the results of trials with many outcomes is not always straightforward. We characterize the prevalence and factors associated with multiple outcomes in reports of clinical trials of depression, methods used to account for these outcomes, and concordance between published analyses and original protocol specifications.
Methods: A {PubMed} search for randomized controlled depression trials that included multiple outcomes published between January 2007 and October 2008 in 6 medical journals. Original study protocols were reviewed where available. Parallel data collection by 2 abstractors was used to determine trial registration information, the number of outcomes, and analytical method.
Results: Of the 55 included trials, nearly half of the papers reported more than 1 primary outcome, while almost all (90.9\%, n = 50) reported more than 2 combined primary or secondary outcomes. Relatively few of the studies (5.8\%, n = 3) adjusted for multiple outcomes. While most studies had published protocols in clinical trial registries (76.4\%, n = 42), many did not specify outcomes in the protocol (n = 11) and a number had discrepancies with the published report.
Conclusions: Multiple outcomes are prevalent in randomized controlled depression trials and appropriate statistical analyses to account for these methods are rarely used. Not all studies filed protocols, and there were discrepancies between these protocols and published reports. These issues complicate interpretability of trial results, and in some cases may lead to spurious conclusions. Promulgation of guidelines to improve analysis and reporting of multiple outcomes is warranted.},
	pages = {299--304},
	number = {2},
	journaltitle = {Contemporary Clinical Trials},
	author = {Tyler, Kristin M. and Normand, Sharon-Lise T. and Horton, Nicholas J.},
	urldate = {2019-01-14},
	date = {2011-03},
	langid = {english},
	file = {tyler_et_al_2011_the_use_and_abuse_of_multiple_outcomes_in_randomized_controlled_depression.pdf:/home/nathan/Dropbox/njames/zotero_sync/tyler_et_al_2011_the_use_and_abuse_of_multiple_outcomes_in_randomized_controlled_depression.pdf:application/pdf}
}

@article{stone_additive_nodate,
	title = {Additive Splines in Statistics},
	abstract = {Additive models for regression functions and logistic regression functions are considered in which the component functions are ﬁtted by cubic splines constrained to be linear in the tails. Rules and strategies for knot placement are discussed, and two illustrative applications of the resulting methodology are presented. Key words: Regression; Logistic regression; Additivity; Spline.},
	pages = {5},
	author = {Stone, Charles J and Koo, Cha-Yong},
	langid = {english},
	file = {stone_koo_additive_splines_in_statistics.pdf:/home/nathan/Dropbox/njames/zotero_sync/stone_koo_additive_splines_in_statistics.pdf:application/pdf}
}

@article{krupskii_factor_2013,
	title = {Factor copula models for multivariate data},
	volume = {120},
	issn = {0047259X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0047259X13000870},
	doi = {10.1016/j.jmva.2013.05.001},
	abstract = {General conditional independence models for d observed variables, in terms of p latent variables, are presented in terms of bivariate copulas that link observed data to latent variables. The representation is called a factor copula model and the classical multivariate normal model with a correlation matrix having a factor structure is a special case. Dependence and tail properties of the model are obtained. The factor copula model can handle multivariate data with tail dependence and tail asymmetry, properties that the multivariate normal copula does not possess. It is a good choice for modeling high-dimensional data as a parametric form can be specified to have O(d) dependence parameters instead of O(d2) parameters. Data examples show that, based on the Akaike information criterion, the factor copula model provides a good fit to financial return data, in comparison with related truncated vine copula models.},
	pages = {85--101},
	journaltitle = {Journal of Multivariate Analysis},
	author = {Krupskii, Pavel and Joe, Harry},
	urldate = {2019-01-15},
	date = {2013-09},
	langid = {english},
	file = {krupskii_joe_2013_factor_copula_models_for_multivariate_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/krupskii_joe_2013_factor_copula_models_for_multivariate_data.pdf:application/pdf}
}

@article{drazen_large_2017,
	title = {The Large Pharmaceutical Company Perspective},
	volume = {376},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/10.1056/NEJMra1510069},
	doi = {10.1056/NEJMra1510069},
	pages = {52--60},
	number = {1},
	journaltitle = {New England Journal of Medicine},
	author = {Rosenblatt, Michael},
	editor = {Drazen, Jeffrey M. and Harrington, David P. and {McMurray}, John J.V. and Ware, James H. and Woodcock, Janet},
	urldate = {2019-01-15},
	date = {2017-01-05},
	langid = {english},
	file = {rosenblatt_2017_the_large_pharmaceutical_company_perspective.pdf:/home/nathan/Dropbox/njames/zotero_sync/rosenblatt_2017_the_large_pharmaceutical_company_perspective.pdf:application/pdf}
}

@article{fermanian_statistical_2004,
	title = {Some Statistical Pitfalls in Copula Modeling for Financial Applications},
	issn = {1556-5068},
	url = {http://www.ssrn.com/abstract=558981},
	doi = {10.2139/ssrn.558981},
	abstract = {In this paper we discuss some statistical pitfalls that may occur in modeling cross-dependences with copulas in financial applications. In particular we focus on issues arising in the estimation and the empirical choice of copulas as well as in the design of time-dependent copulas.},
	journaltitle = {{SSRN} Electronic Journal},
	author = {Fermanian, Jean-David and Scaillet, O.},
	urldate = {2019-01-16},
	date = {2004},
	langid = {english},
	file = {fermanian_scaillet_2004_some_statistical_pitfalls_in_copula_modeling_for_financial_applications.pdf:/home/nathan/Dropbox/njames/zotero_sync/fermanian_scaillet_2004_some_statistical_pitfalls_in_copula_modeling_for_financial_applications.pdf:application/pdf}
}

@article{zimmer_using_2006,
	title = {Using Trivariate Copulas to Model Sample Selection and Treatment Effects: Application to Family Health Care Demand},
	volume = {24},
	issn = {0735-0015, 1537-2707},
	url = {http://www.tandfonline.com/doi/abs/10.1198/073500105000000153},
	doi = {10.1198/073500105000000153},
	shorttitle = {Using Trivariate Copulas to Model Sample Selection and Treatment Effects},
	pages = {63--76},
	number = {1},
	journaltitle = {Journal of Business \& Economic Statistics},
	author = {Zimmer, David M and Trivedi, Pravin K},
	urldate = {2019-01-16},
	date = {2006-01},
	langid = {english},
	file = {zimmer_trivedi_2006_using_trivariate_copulas_to_model_sample_selection_and_treatment_effects.pdf:/home/nathan/Dropbox/njames/zotero_sync/zimmer_trivedi_2006_using_trivariate_copulas_to_model_sample_selection_and_treatment_effects.pdf:application/pdf}
}

@article{chib_analysis_1998,
	title = {Analysis of multivariate probit models},
	volume = {85},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/85.2.347},
	doi = {10.1093/biomet/85.2.347},
	abstract = {This paper provides a practical simulation-based Bayesian and non-Bayesian analysis of correlated binary data using the multivariate probit model. The posterior distribution is simulated by Markov chain Monte Carlo methods and maximum likelihood estimates are obtained by a Monte Carlo version of the {EM} algorithm. A practical approach for the computation of Bayes factors from the simulation output is also developed. The methods are applied to a dataset with a bivariate binary response, to a four-year longitudinal dataset from the Six Cities study of the health effects of air pollution and to a sevenvariate binary response dataset on the labour supply of married women from the Panel Survey of Income Dynamics.},
	pages = {347--361},
	number = {2},
	journaltitle = {Biometrika},
	author = {Chib, S and Greenberg, E},
	urldate = {2019-01-16},
	date = {1998-06-01},
	langid = {english},
	file = {chib_1998_analysis_of_multivariate_probit_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/chib_1998_analysis_of_multivariate_probit_models.pdf:application/pdf}
}

@article{niewiadomska-bugaj_grade_2005,
	title = {On grade transformation and its implications for copulas},
	volume = {19},
	abstract = {As multivariate distributions with uniform one-dimensional margins, copulas provide very convenient models for studying dependence structure with tools that are scale-free. Each copula (n-copula) represents the whole class of continuous bivariate (multivariate) distributions from which it has been obtained when one-dimensional marginals were transformed by their cdf's. The similar property, however, does not hold when the original distributions are discrete, or mixed discrete-continuous. After the transformation by marginal cdf's the copula is not uniquely defined and consequently cannot be used for dependence studies analogously as in the continuous case. In this paper we will discuss grade transformation which, being an extension of probability integral transform, enables unique copula (or n-copula) representation of a multivariate distribution of any type for which cdf can be defined. We will also present how formulas of Kendall's r, Spearman's p, and Gini correlation can be written for variables continuous or not using smoothed cdf's instead of original ones.},
	pages = {125--137},
	number = {2},
	journaltitle = {Brazilian Journal of Probability and Statistics},
	author = {Niewiadomska-Bugaj, Magdalena and Kowalczyk, Teresa},
	date = {2005},
	langid = {english},
	file = {niewiadomska-bugaj_kowalczyk_2005_on_grade_transformation_and_its_implications_for_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/niewiadomska-bugaj_kowalczyk_2005_on_grade_transformation_and_its_implications_for_copulas.pdf:application/pdf}
}

@article{denuit_constraints_2005,
	title = {Constraints on concordance measures in bivariate discrete data},
	volume = {93},
	issn = {0047259X},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0047259X04000144},
	doi = {10.1016/j.jmva.2004.01.004},
	abstract = {This paper aims to investigate the constraints on dependence measures based on the concept of concordance when discrete random variables are involved. The main technical argument consists in a continuous extension of integer-valued random variables by convolution with unit support kernels.},
	pages = {40--57},
	number = {1},
	journaltitle = {Journal of Multivariate Analysis},
	author = {Denuit, Michel and Lambert, Philippe},
	urldate = {2019-01-16},
	date = {2005-03},
	langid = {english},
	file = {denuit_lambert_2005_constraints_on_concordance_measures_in_bivariate_discrete_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/denuit_lambert_2005_constraints_on_concordance_measures_in_bivariate_discrete_data.pdf:application/pdf}
}

@article{ruschendorf_distributional_2009,
	title = {On the distributional transform, Sklar's theorem, and the empirical copula process},
	volume = {139},
	issn = {03783758},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S037837580900158X},
	doi = {10.1016/j.jspi.2009.05.030},
	abstract = {We review the distributional transform of a random variable, some of its applications, and some related multivariate distributional transformations. The distributional transform is a useful tool, which allows in many respects to deal with general distributions in the same way as with continuous distributions. In particular it allows to give a simple proof of Sklar's theorem in the general case. It has been used in the literature for stochastic ordering results. It is also useful for an adequate definition of the conditional value at risk measure and for many further purposes. We also discuss the multivariate quantile transform as well as the multivariate extension of the distributional transform and some of their applications. In the final section we consider an application to an extension of a limit theorem for the empirical copula process, also called empirical dependence function, to general not necessarily continuous distributions. This is useful for constructing and analyzing tests of dependence properties for general distributions.},
	pages = {3921--3927},
	number = {11},
	journaltitle = {Journal of Statistical Planning and Inference},
	author = {Rüschendorf, Ludger},
	urldate = {2019-01-16},
	date = {2009-11},
	langid = {english},
	file = {rüschendorf_2009_on_the_distributional_transform,_sklar's_theorem,_and_the_empirical_copula.pdf:/home/nathan/Dropbox/njames/zotero_sync/rüschendorf_2009_on_the_distributional_transform,_sklar's_theorem,_and_the_empirical_copula.pdf:application/pdf}
}

@article{schmidt_multivariate_2006,
	title = {Multivariate distribution models with generalized hyperbolic margins},
	volume = {50},
	issn = {01679473},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0167947305000629},
	doi = {10.1016/j.csda.2005.03.010},
	abstract = {Multivariate generalized hyperbolic distributions represent an attractive family of distributions (with exponentially decreasing tails) for multivariate data modelling. However, in a limited data environment, robust and fast estimation procedures are rare. An alternative class of multivariate distributions (with exponentially decreasing tails) is proposed which comprises afﬁne-linearly transformed random vectors with stochastically independent and generalized hyperbolic marginals. The latter distributions possess good estimation properties and have attractive dependence structures which are explored in detail. In particular, dependencies of extreme events (tail dependence) can be modelled within this class of multivariate distributions. In addition the necessary estimation and random-number generation procedures are provided. Various advantages and disadvantages of both types of distributions are discussed and illustrated via a simulation study.},
	pages = {2065--2096},
	number = {8},
	journaltitle = {Computational Statistics \& Data Analysis},
	author = {Schmidt, Rafael and Hrycej, Tomas and Stützle, Eric},
	urldate = {2019-01-16},
	date = {2006-04},
	langid = {english},
	file = {schmidt_et_al_2006_multivariate_distribution_models_with_generalized_hyperbolic_margins.pdf:/home/nathan/Dropbox/njames/zotero_sync/schmidt_et_al_2006_multivariate_distribution_models_with_generalized_hyperbolic_margins.pdf:application/pdf}
}

@article{chen_estimation_2006,
	title = {Estimation of copula-based semiparametric time series models},
	volume = {130},
	issn = {03044076},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0304407605000783},
	doi = {10.1016/j.jeconom.2005.03.004},
	abstract = {This paper studies the estimation of a class of copula-based semiparametric stationary Markov models. These models are characterized by nonparametric marginal distributions and parametric copula functions, while the copulas capture all the scale-free temporal dependence of the processes. Simple estimators of the marginal distribution and the copula parameter are provided, and their asymptotic properties are established under easily veriﬁable conditions. These results are used to obtain root-n consistent and asymptotically normal estimators of important features of the transition distribution such as the (nonlinear) conditional moments and conditional quantiles. The semiparametric conditional quantile estimators are automatically monotonic across quantiles, which is attractive for portfolio conditional value-atrisk calculations.},
	pages = {307--335},
	number = {2},
	journaltitle = {Journal of Econometrics},
	author = {Chen, Xiaohong and Fan, Yanqin},
	urldate = {2019-01-16},
	date = {2006-02},
	langid = {english},
	file = {chen_fan_2006_estimation_of_copula-based_semiparametric_time_series_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/chen_fan_2006_estimation_of_copula-based_semiparametric_time_series_models.pdf:application/pdf}
}

@article{escarela_flexible_2006,
	title = {A flexible class of parametric transition regression models based on copulas: application to poliomyelitis incidence},
	volume = {15},
	issn = {0962-2802, 1477-0334},
	url = {http://journals.sagepub.com/doi/10.1177/0962280206070645},
	doi = {10.1177/0962280206070645},
	shorttitle = {A flexible class of parametric transition regression models based on copulas},
	pages = {593--609},
	number = {6},
	journaltitle = {Statistical Methods in Medical Research},
	author = {Escarela, Gabriel and Mena, Ramsés H and Castillo-Morales, Alberto},
	urldate = {2019-01-16},
	date = {2006-12},
	langid = {english},
	file = {escarela_et_al_2006_a_flexible_class_of_parametric_transition_regression_models_based_on_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/escarela_et_al_2006_a_flexible_class_of_parametric_transition_regression_models_based_on_copulas.pdf:application/pdf}
}

@collection{berry_bayesian_2011,
	location = {Boca Raton},
	title = {Bayesian adaptive methods for clinical trials},
	isbn = {978-1-4398-2548-8},
	series = {Chapman \& Hall/{CRC} biostatistics series},
	abstract = {"As has been well-discussed, the explosion of interest in Bayesian methods over the last 10 to 20 years has been the result of the convergence of modern computing power and ełcient Markov chain Monte Carlo ({MCMC}) algo- rithms for sampling from and summarizing posterior distributions. Prac- titioners trained in traditional, frequentist statistical methods appear to have been drawn to Bayesian approaches for three reasons. One is that Bayesian approaches implemented with the majority of their informative content coming from the current data, and not any external prior informa- tion, typically have good frequentist properties (e.g., low mean squared er- ror in repeated use). Second, these methods as now readily implemented in {WinBUGS} and other {MCMC}-driven software packages now oʼer the simplest approach to hierarchical (random eʼects) modeling, as routinely needed in longitudinal, frailty, spatial, time series, and a wide variety of other settings featuring interdependent data. Third, practitioners are attracted by the greater ʻexibility and adaptivity of the Bayesian approach, which permits stopping for ełcacy, toxicity, and futility, as well as facilitates a straightforward solution to a great many other specialized problems such as dose-nding, adaptive randomization, equivalence testing, and others we shall describe. This book presents the Bayesian adaptive approach to the design and analysis of clinical trials"--Provided by publisher},
	pagetotal = {305},
	number = {38},
	publisher = {{CRC} Press},
	editor = {Berry, Scott M.},
	date = {2011},
	note = {{OCLC}: ocn639940808},
	keywords = {Clinical trials, Bayes Theorem, Bayesian statistical decision theory, Statistical methods, Clinical Trials as Topic},
	file = {Berry - 2011 - Bayesian adaptive methods for clinical trials.pdf:/home/nathan/Dropbox/njames/stat/stat_books/Berry - 2011 - Bayesian adaptive methods for clinical trials.pdf:application/pdf}
}

@book{piantadosi_clinical_2005,
	location = {Hoboken, N.J},
	edition = {2nd ed},
	title = {Clinical trials: a methodologic perspective},
	isbn = {978-0-471-72781-1},
	series = {Wiley series in probability and statistics},
	shorttitle = {Clinical trials},
	pagetotal = {687},
	publisher = {Wiley-Interscience},
	author = {Piantadosi, Steven},
	date = {2005},
	keywords = {Clinical trials, Statistical methods, Biomedical Research, Clinical Trials, methods, Research, Statistics},
	file = {Piantadosi - 2005 - Clinical trials a methodologic perspective.pdf:/home/nathan/Dropbox/njames/stat/stat_books/Piantadosi - 2005 - Clinical trials a methodologic perspective.pdf:application/pdf}
}

@article{grambsch_effects_1991,
	title = {The effects of transformations and preliminary tests for non-linearity in regression},
	volume = {10},
	issn = {02776715, 10970258},
	url = {http://doi.wiley.com/10.1002/sim.4780100504},
	doi = {10.1002/sim.4780100504},
	abstract = {Non-linear relationships between two variables are often detected as a result of a preliminary statistical test for linearity. Common approaches to dealing with non-linearity are to (a)make a linearizing transformation in the independent variable or (b) fit a relationship that is non-linear in the independent variable, such as including a quadratic term. With either approach, the resulting test for association between the two variables can have an inflated type I error. We consider testing the significance of the quadratic term in a quadratic model as a preliminary test for non-linearity. Using simulation experiments and asymptotic arguments, we quantify the type I error inflation and suggest simple modifications of standard practice to protect the size of the type I error. In the case of quadratic regression, the type I error will be increased by roughly 50 per cent. The simple strategy of appropriately correcting the a-level is shown to have minimal loss of power if the relationship is truly linear. In the case of a linearizing transformation, the impact on the type I error will depend on the values of the independent variable and on the set of potential linearizing transformations considered. Simulation results suggest that a procedure which adjusts the test statistic according to the results of the preliminary test may offer adequate protection.},
	pages = {697--709},
	number = {5},
	journaltitle = {Statistics in Medicine},
	author = {Grambsch, Patricia M. and O'Brien, Peter C.},
	urldate = {2019-01-17},
	date = {1991-05},
	langid = {english},
	file = {grambsch_o'brien_1991_the_effects_of_transformations_and_preliminary_tests_for_non-linearity_in.pdf:/home/nathan/Dropbox/njames/zotero_sync/grambsch_o'brien_1991_the_effects_of_transformations_and_preliminary_tests_for_non-linearity_in.pdf:application/pdf}
}

@article{frees_credibility_2005,
	title = {Credibility Using Copulas},
	volume = {9},
	issn = {1092-0277, 2325-0453},
	url = {http://www.tandfonline.com/doi/abs/10.1080/10920277.2005.10596196},
	doi = {10.1080/10920277.2005.10596196},
	abstract = {Credibility is a form of insurance pricing that is widely used, particularly in North America. The theory of credibility has been called a “cornerstone” of the field of actuarial science. Students of the North American actuarial bodies also study loss distributions, the process of statistical inference of relating a set of data to a theoretical (loss) distribution. In this work, we develop a direct link between credibility and loss distributions through the notion of a copula, a tool for understanding relationships among multivariate outcomes.},
	pages = {31--48},
	number = {2},
	journaltitle = {North American Actuarial Journal},
	author = {Frees, Edward W. and Wang, Ping},
	urldate = {2019-01-17},
	date = {2005-04},
	langid = {english},
	file = {frees_wang_2005_credibility_using_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/frees_wang_2005_credibility_using_copulas.pdf:application/pdf}
}

@article{frees_copula_2006,
	title = {Copula credibility for aggregate loss models},
	volume = {38},
	issn = {01676687},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S016766870500140X},
	doi = {10.1016/j.insmatheco.2005.10.004},
	abstract = {This paper develops credibility predictors of aggregate losses using a longitudinal data framework. For a model of aggregate losses, the interest is in predicting both the claims number process as well as the claims amount process. In a longitudinal data framework, one encounters data from a cross-section of risk classes with a history of insurance claims available for each risk class. Further, explanatory variables for each risk class over time are available to help explain and predict both the claims number and claims amount process.},
	pages = {360--373},
	number = {2},
	journaltitle = {Insurance: Mathematics and Economics},
	author = {Frees, Edward W. and Wang, Ping},
	urldate = {2019-01-17},
	date = {2006-04},
	langid = {english},
	file = {frees_wang_2006_copula_credibility_for_aggregate_loss_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/frees_wang_2006_copula_credibility_for_aggregate_loss_models.pdf:application/pdf}
}

@article{acar_dependence_2011,
	title = {Dependence Calibration in Conditional Copulas: A Nonparametric Approach},
	volume = {67},
	issn = {1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2010.01472.x},
	doi = {10.1111/j.1541-0420.2010.01472.x},
	shorttitle = {Dependence Calibration in Conditional Copulas},
	abstract = {The study of dependence between random variables is a mainstay in statistics. In many cases, the strength of dependence between two or more random variables varies according to the values of a measured covariate. We propose inference for this type of variation using a conditional copula model where the copula function belongs to a parametric copula family and the copula parameter varies with the covariate. In order to estimate the functional relationship between the copula parameter and the covariate, we propose a nonparametric approach based on local likelihood. Of importance is also the choice of the copula family that best represents a given set of data. The proposed framework naturally leads to a novel copula selection method based on cross-validated prediction errors. We derive the asymptotic bias and variance of the resulting local polynomial estimator, and outline how to construct pointwise confidence intervals. The finite-sample performance of our method is investigated using simulation studies and is illustrated using a subset of the Matched Multiple Birth data.},
	pages = {445--453},
	number = {2},
	journaltitle = {Biometrics},
	author = {Acar, Elif F. and Craiu, Radu V. and Yao, Fang},
	urldate = {2019-01-17},
	date = {2011},
	langid = {english},
	keywords = {Copula parameter, Copula selection, Covariate adjustment, Local likelihood, Local polynomials, Prediction error},
	file = {acar_et_al_2011_dependence_calibration_in_conditional_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/acar_et_al_2011_dependence_calibration_in_conditional_copulas.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/XXZUA8FQ/j.1541-0420.2010.01472.html:text/html}
}

@article{gijbels_conditional_2011,
	title = {Conditional copulas, association measures and their applications},
	volume = {55},
	issn = {01679473},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016794731000438X},
	doi = {10.1016/j.csda.2010.11.010},
	abstract = {One way to model a dependence structure is through the copula function which is a mean to capture the dependence structure in the joint distribution of variables. Association measures such as Kendall’s tau or Spearman’s rho can be expressed as functionals of the copula. The dependence structure between two variables can be highly influenced by a covariate, and it is of real interest to know how this dependence structure changes with the value taken by the covariate. This motivates the need for introducing conditional copulas, and the associated conditional Kendall’s tau and Spearman’s rho association measures. After the introduction and motivation of these concepts, two nonparametric estimators for a conditional copula are proposed and discussed. Then nonparametric estimates for the conditional association measures are derived. A key issue is that these measures are now looked at as functions in the covariate. The performances of all estimators are investigated via a simulation study which also includes a data-driven algorithm for choosing the smoothing parameters. The usefulness of the methods is illustrated on two real data examples.},
	pages = {1919--1932},
	number = {5},
	journaltitle = {Computational Statistics \& Data Analysis},
	author = {Gijbels, Irène and Veraverbeke, Noël and Omelka, Marel},
	urldate = {2019-01-17},
	date = {2011-05},
	langid = {english},
	file = {gijbels_et_al_2011_conditional_copulas,_association_measures_and_their_applications.pdf:/home/nathan/Dropbox/njames/zotero_sync/gijbels_et_al_2011_conditional_copulas,_association_measures_and_their_applications.pdf:application/pdf}
}

@article{veraverbeke_estimation_2011,
	title = {Estimation of a Conditional Copula and Association Measures},
	volume = {38},
	issn = {1467-9469},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9469.2011.00744.x},
	doi = {10.1111/j.1467-9469.2011.00744.x},
	abstract = {This paper is concerned with studying the dependence structure between two random variables Y1 and Y2 conditionally upon a covariate X. The dependence structure is modelled via a copula function, which depends on the given value of the covariate in a general way. Gijbels et al. (Comput. Statist. Data Anal., 55, 2011, 1919) suggested two non-parametric estimators of the ‘conditional’ copula and investigated their numerical performances. In this paper we establish the asymptotic properties of the proposed estimators as well as conditional association measures derived from them. Practical recommendations for their use are then discussed.},
	pages = {766--780},
	number = {4},
	journaltitle = {Scandinavian Journal of Statistics},
	author = {Veraverbeke, Noël and Omelka, Marek and Gijbels, Irène},
	urldate = {2019-01-17},
	date = {2011},
	langid = {english},
	keywords = {asymptotic representation, conditional Kendall's tau, empirical copula process, fixed design, random design, smoothing, weak convergence},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/BMZKIBC3/j.1467-9469.2011.00744.html:text/html;veraverbeke_et_al_2011_estimation_of_a_conditional_copula_and_association_measures.pdf:/home/nathan/Dropbox/njames/zotero_sync/veraverbeke_et_al_2011_estimation_of_a_conditional_copula_and_association_measures.pdf:application/pdf}
}

@article{carroll_generalized_1997,
	title = {Generalized Partially Linear Single-Index Models},
	volume = {92},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1997.10474001},
	doi = {10.1080/01621459.1997.10474001},
	pages = {477--489},
	number = {438},
	journaltitle = {Journal of the American Statistical Association},
	author = {Carroll, R. J. and Fan, Jianqing and Gijbels, Irène and Wand, M. P.},
	urldate = {2019-01-18},
	date = {1997-06},
	langid = {english},
	file = {carroll_et_al_1997_generalized_partially_linear_single-index_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/carroll_et_al_1997_generalized_partially_linear_single-index_models.pdf:application/pdf}
}

@article{chen_generalized_2016,
	title = {Generalized additive and index models with shape constraints},
	volume = {78},
	issn = {13697412},
	url = {http://doi.wiley.com/10.1111/rssb.12137},
	doi = {10.1111/rssb.12137},
	abstract = {We study generalized additive models, with shape restrictions (e.g. monotonicity, convexity and concavity) imposed on each component of the additive prediction function. We show that this framework facilitates a non-parametric estimator of each additive component, obtained by maximizing the likelihood. The procedure is free of tuning parameters and under mild conditions is proved to be uniformly consistent on compact intervals. More generally, our methodology can be applied to generalized additive index models. Here again, the procedure can be justiﬁed on theoretical grounds and, like the original algorithm, has highly competitive ﬁnite sample performance. Practical utility is illustrated through the use of these methods in the analysis of two real data sets. Our algorithms are publicly available in the R package scar, short for shape-constrained additive regression.},
	pages = {729--754},
	number = {4},
	journaltitle = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Chen, Yining and Samworth, Richard J.},
	urldate = {2019-01-18},
	date = {2016-09},
	langid = {english},
	file = {chen_samworth_2016_generalized_additive_and_index_models_with_shape_constraints.pdf:/home/nathan/Dropbox/njames/zotero_sync/chen_samworth_2016_generalized_additive_and_index_models_with_shape_constraints.pdf:application/pdf}
}

@article{zhang_statistical_2010,
	title = {Statistical inference for the index parameter in single-index models},
	volume = {101},
	issn = {0047259X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0047259X09001675},
	doi = {10.1016/j.jmva.2009.09.005},
	abstract = {In this paper, we are concerned with statistical inference for the index parameter α0 in the single-index model Y = g(α0TX) + . Based on the estimates obtained by the local linear method, we extend the generalized likelihood ratio test to the single-index model. We investigate the asymptotic behaviour of the proposed test and demonstrate that its limiting null distribution follows a χ 2-distribution, with the scale constant and the number of degrees of freedom being independent of nuisance parameters or functions, which is called the Wilks phenomenon. A simulated example is used to illustrate the performance of the testing approach.},
	pages = {1026--1041},
	number = {4},
	journaltitle = {Journal of Multivariate Analysis},
	author = {Zhang, Riquan and Huang, Zhensheng and Lv, Yazhao},
	urldate = {2019-01-18},
	date = {2010-04},
	langid = {english},
	file = {zhang_et_al_2010_statistical_inference_for_the_index_parameter_in_single-index_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/zhang_et_al_2010_statistical_inference_for_the_index_parameter_in_single-index_models.pdf:application/pdf}
}

@article{liu_robust_2013,
	title = {A robust and efficient estimation method for single index models},
	volume = {122},
	issn = {0047259X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0047259X13001681},
	doi = {10.1016/j.jmva.2013.08.007},
	abstract = {Single index models are natural extensions of linear models and overcome the so-called curse of dimensionality. They have applications to many fields, such as medicine, economics and finance. However, most existing methods based on least squares or likelihood are sensitive when there are outliers or the error distribution is heavy tailed. Although an M-type regression is often considered as a good alternative to those methods, it may lose efficiency for normal errors. In this paper, we propose a new robust and efficient estimation procedure based on local modal regression for single index models. The asymptotic normality of proposed estimators for both the parametric and nonparametric parts is established. We show that the proposed estimators are as asymptotically efficient as the least-squarebased estimators when there are no outliers and the error distribution is normal. A modified {EM} algorithm is presented for efficient implementation. The simulations and real data analysis are conducted to illustrate the finite sample performance of the proposed method. © 2013 Elsevier Inc. All rights reserved.},
	pages = {226--238},
	journaltitle = {Journal of Multivariate Analysis},
	author = {Liu, Jicai and Zhang, Riquan and Zhao, Weihua and Lv, Yazhao},
	urldate = {2019-01-18},
	date = {2013-11},
	langid = {english},
	file = {liu_et_al_2013_a_robust_and_efficient_estimation_method_for_single_index_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/liu_et_al_2013_a_robust_and_efficient_estimation_method_for_single_index_models.pdf:application/pdf}
}

@article{hardle_optimal_1993,
	title = {Optimal Smoothing in Single-Index Models},
	volume = {21},
	issn = {0090-5364},
	url = {http://projecteuclid.org/euclid.aos/1176349020},
	doi = {10.1214/aos/1176349020},
	pages = {157--178},
	number = {1},
	journaltitle = {The Annals of Statistics},
	author = {Hardle, Wolfgang and Hall, Peter and Ichimura, Hidehiko},
	urldate = {2019-01-18},
	date = {1993-03},
	langid = {english},
	file = {hardle_et_al_1993_optimal_smoothing_in_single-index_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/hardle_et_al_1993_optimal_smoothing_in_single-index_models.pdf:application/pdf}
}

@article{gelman_causality_nodate,
	title = {Causality and Statistical Learning},
	pages = {12},
	journaltitle = {American Journal of Sociology},
	author = {Gelman, Andrew},
	langid = {english},
	file = {gelman_causality_and_statistical_learning.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_causality_and_statistical_learning.pdf:application/pdf}
}

@article{grantham_accounting_nodate,
	title = {Accounting for a decaying correlation structure in cluster randomized trials with continuous recruitment},
	volume = {0},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8089},
	doi = {10.1002/sim.8089},
	abstract = {A requirement for calculating sample sizes for cluster randomized trials ({CRTs}) conducted over multiple periods of time is the specification of a form for the correlation between outcomes of subjects within the same cluster, encoded via the within-cluster correlation structure. Previously proposed within-cluster correlation structures have made strong assumptions; for example, the usual assumption is that correlations between the outcomes of all pairs of subjects are identical (“uniform correlation”). More recently, structures that allow for a decay in correlation between pairs of outcomes measured in different periods have been suggested. However, these structures are overly simple in settings with continuous recruitment and measurement. We propose a more realistic “continuous-time correlation decay” structure whereby correlations between subjects' outcomes decay as the time between these subjects' measurement times increases. We investigate the use of this structure on trial planning in the context of a primary care diabetes trial, where there is evidence of decaying correlation between pairs of patients' outcomes over time. In particular, for a range of different trial designs, we derive the variance of the treatment effect estimator under continuous-time correlation decay and compare this to the variance obtained under uniform correlation. For stepped wedge and cluster randomized crossover designs, incorrectly assuming uniform correlation will underestimate the required sample size under most trial configurations likely to occur in practice. Planning of {CRTs} requires consideration of the most appropriate within-cluster correlation structure to obtain a suitable sample size.},
	number = {0},
	journaltitle = {Statistics in Medicine},
	author = {Grantham, Kelsey L. and Kasza, Jessica and Heritier, Stephane and Hemming, Karla and Forbes, Andrew B.},
	urldate = {2019-01-21},
	langid = {english},
	keywords = {sample size, clinical trial design, cluster randomized trial, crossover design, stepped wedge design, within-cluster correlation},
	file = {grantham_et_al_accounting_for_a_decaying_correlation_structure_in_cluster_randomized_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/grantham_et_al_accounting_for_a_decaying_correlation_structure_in_cluster_randomized_trials.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/CP6VBA5Q/sim.html:text/html}
}

@article{zou_sequential_nodate,
	title = {A sequential density-based empirical likelihood ratio test for treatment effects},
	volume = {0},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8095},
	doi = {10.1002/sim.8095},
	abstract = {In health-related experiments, treatment effects can be identified using paired data that consist of pre- and posttreatment measurements. In this framework, sequential testing strategies are widely accepted statistical tools in practice. Since performances of parametric sequential testing procedures vitally depend on the validity of the parametric assumptions regarding underlying data distributions, we focus on distribution-free mechanisms for sequentially evaluating treatment effects. In fixed sample size designs, the density-based empirical likelihood ({DBEL}) methods provide powerful nonparametric approximations to optimal Neyman-Pearson–type statistics. In this article, we extend the {DBEL} methodology to develop a novel sequential {DBEL} testing procedure for detecting treatment effects based on paired data. The asymptotic consistency of the proposed test is shown. An extensive Monte Carlo study confirms that the proposed test outperforms the conventional sequential Wilcoxon signed-rank test across a variety of alternatives. The excellent applicability of the proposed method is exemplified using the ventilator-associated pneumonia study that evaluates the effect of Chlorhexidine Gluconate treatment in reducing oral colonization by pathogens in ventilated patients.},
	number = {0},
	journaltitle = {Statistics in Medicine},
	author = {Zou, Li and Vexler, Albert and Yu, Jihnhee and Wan, Hongzhi},
	urldate = {2019-01-21},
	langid = {english},
	keywords = {density-based empirical likelihood, empirical likelihood, entropy, likelihood ratio, paired data, sequential signed-rank test, treatment effect, ventilator-associated pneumonia},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/UIRHV64M/sim.html:text/html;zou_et_al_a_sequential_density-based_empirical_likelihood_ratio_test_for_treatment_effects.pdf:/home/nathan/Dropbox/njames/zotero_sync/zou_et_al_a_sequential_density-based_empirical_likelihood_ratio_test_for_treatment_effects.pdf:application/pdf}
}

@article{jorgens_nested_nodate,
	title = {Nested combination tests with a time-to-event endpoint using a short-term endpoint for design adaptations},
	volume = {0},
	issn = {1539-1612},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1926},
	doi = {10.1002/pst.1926},
	abstract = {Adaptive trial methodology for multiarmed trials and enrichment designs has been extensively discussed in the past. A general principle to construct test procedures that control the family-wise Type I error rate in the strong sense is based on combination tests within a closed test. Using survival data, a problem arises when using information of patients for adaptive decision making, which are under risk at interim. With the currently available testing procedures, either no testing of hypotheses in interim analyses is possible or there are restrictions on the interim data that can be used in the adaptation decisions as, essentially, only the interim test statistics of the primary endpoint may be used. We propose a general adaptive testing procedure, covering multiarmed and enrichment designs, which does not have these restrictions. An important application are clinical trials, where short-term surrogate endpoints are used as basis for trial adaptations, and we illustrate how such trials can be designed. We propose statistical models to assess the impact of effect sizes, the correlation structure between the short-term and the primary endpoint, the sample size, the timing of interim analyses, and the selection rule on the operating characteristics.},
	number = {0},
	journaltitle = {Pharmaceutical Statistics},
	author = {Jörgens, Silke and Wassmer, Gernot and König, Franz and Posch, Martin},
	urldate = {2019-01-21},
	langid = {english},
	keywords = {adaptive design, clinical trials, interim analysis, population enrichment, surrogate endpoint, treatment arm selection},
	file = {jörgens_et_al_nested_combination_tests_with_a_time-to-event_endpoint_using_a_short-term.pdf:/home/nathan/Dropbox/njames/zotero_sync/jörgens_et_al_nested_combination_tests_with_a_time-to-event_endpoint_using_a_short-term.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/5GBJCU5B/pst.html:text/html}
}

@article{li_mixtures_2018,
	title = {Mixtures of g-Priors in Generalized Linear Models},
	volume = {113},
	issn = {0162-1459},
	url = {https://doi.org/10.1080/01621459.2018.1469992},
	doi = {10.1080/01621459.2018.1469992},
	abstract = {Mixtures of Zellner’s g-priors have been studied extensively in linear models and have been shown to have numerous desirable properties for Bayesian variable selection and model averaging. Several extensions of g-priors to generalized linear models ({GLMs}) have been proposed in the literature; however, the choice of prior distribution of g and resulting properties for inference have received considerably less attention. In this article, we unify mixtures of g-priors in {GLMs} by assigning the truncated Compound Confluent Hypergeometric ({tCCH}) distribution to 1/(1 + g), which encompasses as special cases several mixtures of g-priors in the literature, such as the hyper-g, Beta-prime, truncated Gamma, incomplete inverse-Gamma, benchmark, robust, hyper-g/n, and intrinsic priors. Through an integrated Laplace approximation, the posterior distribution of 1/(1 + g) is in turn a {tCCH} distribution, and approximate marginal likelihoods are thus available analytically, leading to “Compound Hypergeometric Information Criteria” for model selection. We discuss the local geometric properties of the g-prior in {GLMs} and show how the desiderata for model selection proposed by Bayarri et al., such as asymptotic model selection consistency, intrinsic consistency, and measurement invariance may be used to justify the prior and specific choices of the hyper parameters. We illustrate inference using these priors and contrast them to other approaches via simulation and real data examples. The methodology is implemented in the R package {BAS} and freely available on {CRAN}. Supplementary materials for this article are available online.},
	pages = {1828--1845},
	number = {524},
	journaltitle = {Journal of the American Statistical Association},
	author = {Li, Yingbo and Clyde, Merlise A.},
	urldate = {2019-01-21},
	date = {2018-10-02},
	keywords = {Bayesian model averaging, Bayesian model selection, Hyper-g priors, Linear regression, Variable selection},
	file = {li_clyde_2018_mixtures_of_g-priors_in_generalized_linear_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/li_clyde_2018_mixtures_of_g-priors_in_generalized_linear_models.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/QKRJ8BUU/01621459.2018.html:text/html}
}

@article{rossell_tractable_2018,
	title = {Tractable Bayesian Variable Selection: Beyond Normality},
	volume = {113},
	issn = {0162-1459},
	url = {https://doi.org/10.1080/01621459.2017.1371025},
	doi = {10.1080/01621459.2017.1371025},
	shorttitle = {Tractable Bayesian Variable Selection},
	abstract = {Bayesian variable selection often assumes normality, but the effects of model misspecification are not sufficiently understood. There are sound reasons behind this assumption, particularly for large p: ease of interpretation, analytical, and computational convenience. More flexible frameworks exist, including semi- or nonparametric models, often at the cost of some tractability. We propose a simple extension that allows for skewness and thicker-than-normal tails but preserves tractability. It leads to easy interpretation and a log-concave likelihood that facilitates optimization and integration. We characterize asymptotically parameter estimation and Bayes factor rates, under certain model misspecification. Under suitable conditions, misspecified Bayes factors induce sparsity at the same rates than under the correct model. However, the rates to detect signal change by an exponential factor, often reducing sensitivity. These deficiencies can be ameliorated by inferring the error distribution, a simple strategy that can improve inference substantially. Our work focuses on the likelihood and can be combined with any likelihood penalty or prior, but here we focus on nonlocal priors to induce extra sparsity and ameliorate finite-sample effects caused by misspecification. We show the importance of considering the likelihood rather than solely the prior, for Bayesian variable selection. The methodology is in R package ‘mombf.’ Supplementary materials for this article are available online.},
	pages = {1742--1758},
	number = {524},
	journaltitle = {Journal of the American Statistical Association},
	author = {Rossell, David and Rubio, Francisco J.},
	urldate = {2019-01-21},
	date = {2018-10-02},
	keywords = {Variable selection, Bayes factors, Model misspecification, Robust regression, Two-piece errors},
	file = {rossell_rubio_2018_tractable_bayesian_variable_selection.pdf:/home/nathan/Dropbox/njames/zotero_sync/rossell_rubio_2018_tractable_bayesian_variable_selection.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/A6H5D49A/01621459.2017.html:text/html}
}

@article{rockova_spike-and-slab_2018,
	title = {The Spike-and-Slab {LASSO}},
	volume = {113},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2016.1260469},
	doi = {10.1080/01621459.2016.1260469},
	abstract = {Despite the wide adoption of spike-and-slab methodology for Bayesian variable selection, its potential for penalized likelihood estimation has largely been overlooked. In this article, we bridge this gap by crossfertilizing these two paradigms with the Spike-and-Slab {LASSO} procedure for variable selection and parameter estimation in linear regression. We introduce a new class of self-adaptive penalty functions that arise from a fully Bayes spike-and-slab formulation, ultimately moving beyond the separable penalty framework. A virtue of these nonseparable penalties is their ability to borrow strength across coordinates, adapt to ensemble sparsity information and exert multiplicity adjustment. The Spike-and-Slab {LASSO} procedure harvests efficient coordinate-wise implementations with a path-following scheme for dynamic posterior exploration. We show on simulated data that the fully Bayes penalty mimics oracle performance, providing a viable alternative to cross-validation. We develop theory for the separable and nonseparable variants of the penalty, showing rate-optimality of the global mode as well as optimal posterior concentration when p {\textgreater} n. Supplementary materials for this article are available online.},
	pages = {431--444},
	number = {521},
	journaltitle = {Journal of the American Statistical Association},
	author = {Ročková, Veronika and George, Edward I.},
	urldate = {2019-01-21},
	date = {2018-01-02},
	langid = {english},
	file = {ročková_george_2018_the_spike-and-slab_lasso.pdf:/home/nathan/Dropbox/njames/zotero_sync/ročková_george_2018_the_spike-and-slab_lasso.pdf:application/pdf}
}

@article{linero_bayesian_2018,
	title = {Bayesian Regression Trees for High-Dimensional Prediction and Variable Selection},
	volume = {113},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2016.1264957},
	doi = {10.1080/01621459.2016.1264957},
	abstract = {Decision tree ensembles are an extremely popular tool for obtaining high-quality predictions in nonparametric regression problems. Unmodified, however, many commonly used decision tree ensemble methods do not adapt to sparsity in the regime in which the number of predictors is larger than the number of observations. A recent stream of research concerns the construction of decision tree ensembles that are motivated by a generative probabilistic model, the most influential method being the Bayesian additive regression trees ({BART}) framework. In this article, we take a Bayesian point of view on this problem and show how to construct priors on decision tree ensembles that are capable of adapting to sparsity in the predictors by placing a sparsity-inducing Dirichlet hyperprior on the splitting proportions of the regression tree prior. We characterize the asymptotic distribution of the number of predictors included in the model and show how this prior can be easily incorporated into existing Markov chain Monte Carlo schemes. We demonstrate that our approach yields useful posterior inclusion probabilities for each predictor and illustrate the usefulness of our approach relative to other decision tree ensemble approaches on both simulated and real datasets. Supplementary materials for this article are available online.},
	pages = {626--636},
	number = {522},
	journaltitle = {Journal of the American Statistical Association},
	author = {Linero, Antonio R.},
	urldate = {2019-01-21},
	date = {2018-04-03},
	langid = {english},
	file = {linero_2018_bayesian_regression_trees_for_high-dimensional_prediction_and_variable_selection.pdf:/home/nathan/Dropbox/njames/zotero_sync/linero_2018_bayesian_regression_trees_for_high-dimensional_prediction_and_variable_selection.pdf:application/pdf}
}

@article{rockova_particle_2018,
	title = {Particle {EM} for Variable Selection},
	volume = {113},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1360778},
	doi = {10.1080/01621459.2017.1360778},
	pages = {1684--1697},
	number = {524},
	journaltitle = {Journal of the American Statistical Association},
	author = {Ročková, Veronika},
	urldate = {2019-01-21},
	date = {2018-10-02},
	langid = {english},
	file = {ročková_2018_particle_em_for_variable_selection.pdf:/home/nathan/Dropbox/njames/zotero_sync/ročková_2018_particle_em_for_variable_selection.pdf:application/pdf}
}

@article{ni_bayesian_2017,
	title = {Bayesian Graphical Regression},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1389739},
	doi = {10.1080/01621459.2017.1389739},
	abstract = {We consider the problem of modeling conditional independence structures in heterogenous data in the presence of additional subject-level covariates—termed graphical regression. We propose a novel specification of a conditional (in)dependence function of covariates—which allows the structure of a directed graph to vary flexibly with the covariates; imposes sparsity in both edge and covariate selection; produces both subject-specific and predictive graphs; and is computationally tractable. We provide theoretical justifications of our modeling endeavor, in terms of graphical model selection consistency. We demonstrate the performance of our method through rigorous simulation studies. We illustrate our approach in a cancer genomics-based precision medicine paradigm, where-in we explore gene regulatory networks in multiple myeloma taking prognostic clinical factors into account to obtain both populationlevel and subject-level gene regulatory networks. Supplementary materials for this article are available online.},
	pages = {1--14},
	journaltitle = {Journal of the American Statistical Association},
	author = {Ni, Yang and Stingo, Francesco C. and Baladandayuthapani, Veerabhadran},
	urldate = {2019-01-21},
	date = {2017-10-30},
	langid = {english},
	file = {ni_et_al_2017_bayesian_graphical_regression.pdf:/home/nathan/Dropbox/njames/zotero_sync/ni_et_al_2017_bayesian_graphical_regression.pdf:application/pdf}
}

@book{horowitz_semiparametric_2009,
	location = {Dordrecht ; New York},
	title = {Semiparametric and nonparametric methods in econometrics},
	isbn = {978-0-387-92869-2 978-0-387-92870-8},
	series = {Springer series in statistics},
	pagetotal = {271},
	publisher = {Springer},
	author = {Horowitz, Joel L.},
	date = {2009},
	note = {{OCLC}: ocn401157055},
	keywords = {Econometrics, Estimation theory, Nichtparametrisches Verfahren, Ökonometrie, Semiparametrisches Verfahren, Theorie},
	file = {horowitz_2009_semiparametric_and_nonparametric_methods_in_econometrics.pdf:/home/nathan/Dropbox/njames/zotero_sync/horowitz_2009_semiparametric_and_nonparametric_methods_in_econometrics.pdf:application/pdf}
}

@article{cornfield_sequential_1966,
	title = {Sequential Trials, Sequential Analysis and the Likelihood Principle},
	volume = {20},
	issn = {00031305},
	url = {https://www.jstor.org/stable/2682711?origin=crossref},
	doi = {10.2307/2682711},
	pages = {18},
	number = {2},
	journaltitle = {The American Statistician},
	author = {Cornfield, Jerome},
	urldate = {2019-01-22},
	date = {1966-04},
	langid = {english},
	file = {cornfield_1966_sequential_trials,_sequential_analysis_and_the_likelihood_principle.pdf:/home/nathan/Dropbox/njames/zotero_sync/cornfield_1966_sequential_trials,_sequential_analysis_and_the_likelihood_principle.pdf:application/pdf}
}

@article{little_praise_2013,
	title = {In Praise of Simplicity not Mathematistry! Ten Simple Powerful Ideas for the Statistical Scientist},
	volume = {108},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2013.787932},
	doi = {10.1080/01621459.2013.787932},
	pages = {359--369},
	number = {502},
	journaltitle = {Journal of the American Statistical Association},
	author = {Little, Roderick J.},
	urldate = {2019-01-22},
	date = {2013-06},
	langid = {english},
	file = {little_2013_in_praise_of_simplicity_not_mathematistry.pdf:/home/nathan/Dropbox/njames/zotero_sync/little_2013_in_praise_of_simplicity_not_mathematistry.pdf:application/pdf}
}

@article{noauthor_method_1951,
	title = {A Method of Estimating Comparative Rates from Clinical Data. Applications to Cancer of the Lung, Breast, and Cervix},
	issn = {1460-2105},
	url = {https://academic.oup.com/jnci/article/11/6/1269/966325/A-Method-of-Estimating-Comparative-Rates-from},
	doi = {10.1093/jnci/11.6.1269},
	journaltitle = {{JNCI}: Journal of the National Cancer Institute},
	urldate = {2019-01-22},
	date = {1951-06},
	langid = {english},
	file = {1951_a_method_of_estimating_comparative_rates_from_clinical_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/1951_a_method_of_estimating_comparative_rates_from_clinical_data.pdf:application/pdf;1951_a_method_of_estimating_comparative_rates_from_clinical_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/1951_a_method_of_estimating_comparative_rates_from_clinical_data2.pdf:application/pdf}
}

@article{savage_rereading_1976,
	title = {On Rereading R. A. Fisher},
	volume = {4},
	issn = {0090-5364},
	url = {http://projecteuclid.org/euclid.aos/1176343456},
	doi = {10.1214/aos/1176343456},
	pages = {441--500},
	number = {3},
	journaltitle = {The Annals of Statistics},
	author = {Savage, Leonard J.},
	urldate = {2019-01-22},
	date = {1976-05},
	langid = {english},
	file = {savage_1976_on_rereading_r.pdf:/home/nathan/Dropbox/njames/zotero_sync/savage_1976_on_rereading_r.pdf:application/pdf}
}

@article{johnson_revised_2013,
	title = {Revised standards for statistical evidence},
	volume = {110},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1313476110},
	doi = {10.1073/pnas.1313476110},
	pages = {19313--19317},
	number = {48},
	journaltitle = {Proceedings of the National Academy of Sciences},
	author = {Johnson, V. E.},
	urldate = {2019-01-22},
	date = {2013-11-26},
	langid = {english},
	file = {johnson_2013_revised_standards_for_statistical_evidence.pdf:/home/nathan/Dropbox/njames/zotero_sync/johnson_2013_revised_standards_for_statistical_evidence.pdf:application/pdf;johnson_2013_revised_standards_for_statistical_evidence.pdf:/home/nathan/Dropbox/njames/zotero_sync/johnson_2013_revised_standards_for_statistical_evidence2.pdf:application/pdf;johnson_2013_revised_standards_for_statistical_evidence.pdf:/home/nathan/Dropbox/njames/zotero_sync/johnson_2013_revised_standards_for_statistical_evidence3.pdf:application/pdf;johnson_2013_revised_standards_for_statistical_evidence.pdf:/home/nathan/Dropbox/njames/zotero_sync/johnson_2013_revised_standards_for_statistical_evidence4.pdf:application/pdf}
}

@article{drazen_primary_2016,
	title = {The Primary Outcome Fails — What Next?},
	volume = {375},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/10.1056/NEJMra1510064},
	doi = {10.1056/NEJMra1510064},
	pages = {861--870},
	number = {9},
	journaltitle = {New England Journal of Medicine},
	author = {Pocock, Stuart J. and Stone, Gregg W.},
	editor = {Drazen, Jeffrey M. and Harrington, David P. and {McMurray}, John J.V. and Ware, James H. and Woodcock, Janet},
	urldate = {2019-01-22},
	date = {2016-09},
	langid = {english},
	file = {pocock_stone_2016_the_primary_outcome_fails_—_what_next.pdf:/home/nathan/Dropbox/njames/zotero_sync/pocock_stone_2016_the_primary_outcome_fails_—_what_next.pdf:application/pdf}
}

@article{drazen_primary_2016-1,
	title = {The Primary Outcome Is Positive — Is That Good Enough?},
	volume = {375},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/10.1056/NEJMra1601511},
	doi = {10.1056/NEJMra1601511},
	pages = {971--979},
	number = {10},
	journaltitle = {New England Journal of Medicine},
	author = {Pocock, Stuart J. and Stone, Gregg W.},
	editor = {Drazen, Jeffrey M. and Harrington, David P. and {McMurray}, John J.V. and Ware, James H. and Woodcock, Janet},
	urldate = {2019-01-22},
	date = {2016-09-08},
	langid = {english},
	file = {pocock_stone_2016_the_primary_outcome_is_positive_—_is_that_good_enough.pdf:/home/nathan/Dropbox/njames/zotero_sync/pocock_stone_2016_the_primary_outcome_is_positive_—_is_that_good_enough.pdf:application/pdf}
}

@article{hothorn_most_2018,
	title = {Most Likely Transformations: Most likely transformations},
	volume = {45},
	issn = {03036898},
	url = {http://doi.wiley.com/10.1111/sjos.12291},
	doi = {10.1111/sjos.12291},
	shorttitle = {Most Likely Transformations},
	abstract = {We propose and study properties of maximum likelihood estimators in the class of conditional transformation models. Based on a suitable explicit parameterization of the unconditional or conditional transformation function, we establish a cascade of increasingly complex transformation models that can be estimated, compared and analysed in the maximum likelihood framework. Models for the unconditional or conditional distribution function of any univariate response variable can be set up and estimated in the same theoretical and computational framework simply by choosing an appropriate transformation function and parameterization thereof. The ability to evaluate the distribution function directly allows us to estimate models based on the exact likelihood, especially in the presence of random censoring or truncation. For discrete and continuous responses, we establish the asymptotic normality of the proposed estimators. A reference software implementation of maximum likelihood-based estimation for conditional transformation models that allows the same ﬂexibility as the theory developed here was employed to illustrate the wide range of possible applications.},
	pages = {110--134},
	number = {1},
	journaltitle = {Scandinavian Journal of Statistics},
	author = {Hothorn, Torsten and Möst, Lisa and Bühlmann, Peter},
	urldate = {2019-01-22},
	date = {2018-03},
	langid = {english},
	keywords = {transformation model, censoring, conditional distribution function, conditional quantile function, distribution regression, truncation},
	file = {hothorn_et_al_2018_most_likely_transformations.pdf:/home/nathan/Dropbox/njames/zotero_sync/hothorn_et_al_2018_most_likely_transformations.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/HJ9TAGIY/sjos.html:text/html}
}

@article{sabeti_additive_2014,
	title = {Additive models for conditional copulas},
	volume = {3},
	issn = {2049-1573},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sta4.64},
	doi = {10.1002/sta4.64},
	abstract = {Conditional copulas are flexible statistical tools that couple joint conditional and marginal conditional distributions. In a linear regression setting with more than one covariate and two dependent outcomes, we consider additive models for studying the dependence between covariates and the copula parameter. We examine the computation and model selection tools needed for Bayesian inference. The method is illustrated using simulations and a real example. Copyright © 2014 John Wiley \& Sons, Ltd.},
	pages = {300--312},
	number = {1},
	journaltitle = {Stat},
	author = {Sabeti, Avideh and Wei, Mian and Craiu, Radu V.},
	urldate = {2019-01-22},
	date = {2014},
	langid = {english},
	keywords = {Bayesian inference, additive models, conditional copulas, cross-validated marginal likelihood, cubic splines, Markov chain Monte Carlo},
	file = {sabeti_et_al_2014_additive_models_for_conditional_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/sabeti_et_al_2014_additive_models_for_conditional_copulas.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/MTLYKKDB/sta4.html:text/html}
}

@article{little_subsample_2011,
	title = {Subsample ignorable likelihood for regression analysis with missing data: Subsample Ignorable Likelihood},
	volume = {60},
	issn = {00359254},
	url = {http://doi.wiley.com/10.1111/j.1467-9876.2011.00763.x},
	doi = {10.1111/j.1467-9876.2011.00763.x},
	shorttitle = {Subsample ignorable likelihood for regression analysis with missing data},
	abstract = {Two common approaches to regression with missing covariates are complete-case analysis and ignorable likelihood methods. We review these approaches and propose a hybrid class, called subsample ignorable likelihood methods, which applies an ignorable likelihood method to the subsample of observations that are complete on one set of variables, but possibly incomplete on others. Conditions on the missing data mechanism are presented under which subsample ignorable likelihood gives consistent estimates, but both complete-case analysis and ignorable likelihood methods are inconsistent. We motivate and apply the method proposed to data from the National Health and Nutrition Examination Survey, and we illustrate properties of the methods by simulation. Extensions to non-likelihood analyses are also mentioned.},
	pages = {591--605},
	number = {4},
	journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	author = {Little, Roderick J. and Zhang, Nanhua},
	urldate = {2019-01-23},
	date = {2011-08},
	langid = {english},
	file = {little_zhang_2011_subsample_ignorable_likelihood_for_regression_analysis_with_missing_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/little_zhang_2011_subsample_ignorable_likelihood_for_regression_analysis_with_missing_data.pdf:application/pdf}
}

@article{anderson_maximum_nodate,
	title = {Maximum Likelihood Estimates for a Multivariate Normal Distribution when some Observations are Missing},
	pages = {5},
	author = {Anderson, T W},
	langid = {english},
	file = {anderson_maximum_likelihood_estimates_for_a_multivariate_normal_distribution_when_some.pdf:/home/nathan/Dropbox/njames/zotero_sync/anderson_maximum_likelihood_estimates_for_a_multivariate_normal_distribution_when_some.pdf:application/pdf}
}

@article{rubin_efficiently_1986,
	title = {Efficiently Simulating the Coverage Properties of Interval Estimates},
	volume = {35},
	issn = {00359254},
	url = {https://www.jstor.org/stable/10.2307/2347266?origin=crossref},
	doi = {10.2307/2347266},
	abstract = {Methods of simulating the frequency coverage of an interval estimate by simulating the average Bayesian posterior probability coverage are presented. The methods can be much more efficient than the standard method that simulates the hit rate of the interval. The possible increased efficiency is illustrated using three examples: estimating a binomial probability, bootstrapping a variance, and multiple imputation intervals for the mean.},
	pages = {159},
	number = {2},
	journaltitle = {Applied Statistics},
	author = {Rubin, D. B. and Schenker, N.},
	urldate = {2019-01-23},
	date = {1986},
	langid = {english},
	file = {rubin_schenker_1986_efficiently_simulating_the_coverage_properties_of_interval_estimates.pdf:/home/nathan/Dropbox/njames/zotero_sync/rubin_schenker_1986_efficiently_simulating_the_coverage_properties_of_interval_estimates.pdf:application/pdf}
}

@article{rubin_bayesianly_1984,
	title = {Bayesianly Justifiable and Relevant Frequency Calculations for the Applied Statistician},
	volume = {12},
	issn = {0090-5364},
	url = {http://projecteuclid.org/euclid.aos/1176346785},
	doi = {10.1214/aos/1176346785},
	pages = {1151--1172},
	number = {4},
	journaltitle = {The Annals of Statistics},
	author = {Rubin, Donald B.},
	urldate = {2019-01-23},
	date = {1984-12},
	langid = {english},
	file = {rubin_1984_bayesianly_justifiable_and_relevant_frequency_calculations_for_the_applied.pdf:/home/nathan/Dropbox/njames/zotero_sync/rubin_1984_bayesianly_justifiable_and_relevant_frequency_calculations_for_the_applied.pdf:application/pdf}
}

@article{banjamini_controlling_nodate,
	title = {Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing},
	abstract = {The common approach to the multiplicity problem calls for controlling the familywise error rate ({FWER}). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses -the false discovery rate. This error rate is equivalent to the {FWER} when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the {FWER} is desired, there is potential for a gain in power. A simple sequential Bonferronitype procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.},
	pages = {13},
	author = {Banjamini, Yoav and Hochberg, Yosef},
	langid = {english},
	file = {benjaminit_hochberg_controlling_the_false_discovery_rate.pdf:/home/nathan/Dropbox/njames/zotero_sync/benjaminit_hochberg_controlling_the_false_discovery_rate.pdf:application/pdf}
}

@article{storey_positive_2003,
	title = {The positive false discovery rate: a Bayesian interpretation and the q -value},
	volume = {31},
	issn = {0090-5364},
	url = {http://projecteuclid.org/euclid.aos/1074290335},
	doi = {10.1214/aos/1074290335},
	shorttitle = {The positive false discovery rate},
	pages = {2013--2035},
	number = {6},
	journaltitle = {The Annals of Statistics},
	author = {Storey, John D.},
	urldate = {2019-01-23},
	date = {2003-12},
	langid = {english},
	file = {storey_2003_the_positive_false_discovery_rate.pdf:/home/nathan/Dropbox/njames/zotero_sync/storey_2003_the_positive_false_discovery_rate.pdf:application/pdf}
}

@article{clayton_model_nodate,
	title = {A model for association in bivariate life tables and its application in epidemiological studies of familial tendency in chronic disease incidence},
	pages = {11},
	author = {Clayton, D G},
	langid = {english},
	file = {clayton_a_model_for_association_in_bivariate_life_tables_and_its_application_in.pdf:/home/nathan/Dropbox/njames/zotero_sync/clayton_a_model_for_association_in_bivariate_life_tables_and_its_application_in.pdf:application/pdf}
}

@article{he_flexible_2003,
	title = {Flexible Maximum Likelihood Methods for Bivariate Proportional Hazards Models},
	volume = {59},
	issn = {0006-341X, 1541-0420},
	url = {http://doi.wiley.com/10.1111/j.0006-341X.2003.00098.x},
	doi = {10.1111/j.0006-341X.2003.00098.x},
	abstract = {This article presents methodology for multivariate proportional hazards ({PH}) regression models. The methods employ ﬂexible piecewise constant or spline speciﬁcations for baseline hazard functions in either marginal or conditional {PH} models, along with assumptions about the association among lifetimes. Because the models are parametric, ordinary maximum likelihood can be applied; it is able to deal easily with such data features as interval censoring or sequentially observed lifetimes, unlike existing semiparametric methods. A bivariate Clayton model (1978, Biometrika 65, 141–151) is used to illustrate the approach taken. Because a parametric assumption about association is made, eﬃciency and robustness comparisons are made between estimation based on the bivariate Clayton model and “working independence” methods that specify only marginal distributions for each lifetime variable.},
	pages = {837--848},
	number = {4},
	journaltitle = {Biometrics},
	author = {He, Wenqing and Lawless, Jerald F.},
	urldate = {2019-01-23},
	date = {2003-12},
	langid = {english},
	file = {he_lawless_2003_flexible_maximum_likelihood_methods_for_bivariate_proportional_hazards_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/he_lawless_2003_flexible_maximum_likelihood_methods_for_bivariate_proportional_hazards_models.pdf:application/pdf}
}

@article{lawless_semiparametric_2011,
	title = {Semiparametric estimation in copula models for bivariate sequential survival times},
	volume = {53},
	issn = {1521-4036},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201000131},
	doi = {10.1002/bimj.201000131},
	abstract = {Sequentially observed survival times are of interest in many studies but there are difficulties in analyzing such data using nonparametric or semiparametric methods. First, when the duration of followup is limited and the times for a given individual are not independent, induced dependent censoring arises for the second and subsequent survival times. Non-identifiability of the marginal survival distributions for second and later times is another issue, since they are observable only if preceding survival times for an individual are uncensored. In addition, in some studies a significant proportion of individuals may never have the first event. Fully parametric models can deal with these features, but robustness is a concern. We introduce a new approach to address these issues. We model the joint distribution of the successive survival times by using copula functions, and provide semiparametric estimation procedures in which copula parameters are estimated without parametric assumptions on the marginal distributions. This provides more robust estimates and checks on the fit of parametric models. The methodology is applied to a motivating example involving relapse and survival following colon cancer treatment.},
	pages = {779--796},
	number = {5},
	journaltitle = {Biometrical Journal},
	author = {Lawless, Jerald F. and Yilmaz, Yildiz E.},
	urldate = {2019-01-23},
	date = {2011},
	langid = {english},
	keywords = {Maximum likelihood, Multivariate survival distribution, Nonparametric estimation, Pseudolikelihood},
	file = {lawless_yilmaz_2011_semiparametric_estimation_in_copula_models_for_bivariate_sequential_survival.pdf:/home/nathan/Dropbox/njames/zotero_sync/lawless_yilmaz_2011_semiparametric_estimation_in_copula_models_for_bivariate_sequential_survival.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/LPWPVA6B/bimj.html:text/html}
}

@article{romeo_bivariate_2006,
	title = {Bivariate survival modeling: a Bayesian approach based on Copulas},
	volume = {12},
	issn = {1380-7870, 1572-9249},
	url = {http://link.springer.com/10.1007/s10985-006-9001-5},
	doi = {10.1007/s10985-006-9001-5},
	shorttitle = {Bivariate survival modeling},
	abstract = {Copula models have become increasingly popular for modeling multivariate survival data. In this paper we review some of the recent work that has been appeared for copula model for bivariate survival data and propose a Bayesian modeling. Our approach is very ﬂexible with respect to the choice of marginal distributions and, depending on the copula model employed, it is possible to have a class of variation for the dependence parameter. We compare some of the copula models using a descriptive diagnostic method and three popular Bayesian model selection criteria. Our methodology is illustrated with the Diabetic Retinopathy Study (1976).},
	pages = {205--222},
	number = {2},
	journaltitle = {Lifetime Data Analysis},
	author = {Romeo, José S. and Tanaka, Nelson I. and Pedroso-de-Lima, Antonio C.},
	urldate = {2019-01-23},
	date = {2006-06},
	langid = {english},
	file = {romeo_et_al_2006_bivariate_survival_modeling.pdf:/home/nathan/Dropbox/njames/zotero_sync/romeo_et_al_2006_bivariate_survival_modeling.pdf:application/pdf}
}

@article{chaieb_estimating_2006,
	title = {Estimating survival under a dependent truncation},
	volume = {93},
	issn = {1464-3510, 0006-3444},
	url = {http://academic.oup.com/biomet/article/93/3/655/380713/Estimating-survival-under-a-dependent-truncation},
	doi = {10.1093/biomet/93.3.655},
	pages = {655--669},
	number = {3},
	journaltitle = {Biometrika},
	author = {Chaieb, Lajmi Lakhal and Rivest, Louis-Paul and Abdous, Belkacem},
	urldate = {2019-01-23},
	date = {2006-09-01},
	langid = {english},
	file = {chaieb_et_al_2006_estimating_survival_under_a_dependent_truncation.pdf:/home/nathan/Dropbox/njames/zotero_sync/chaieb_et_al_2006_estimating_survival_under_a_dependent_truncation.pdf:application/pdf}
}

@article{liang_recent_1995,
	title = {Some recent developments for regression analysis of multivariate failure time data},
	volume = {1},
	issn = {1380-7870, 1572-9249},
	url = {http://link.springer.com/10.1007/BF00985452},
	doi = {10.1007/BF00985452},
	abstract = {Cox's seminal 1972 paper on regression methods for possibly censored failure time data popularized the use of time to an event as a primary response in prospective studies. But one key assumption of this and other regression methods is that observations are independent of one another. In many problems, failure times are clustered into small groups where outcomes within a group are correlated. Examples include failure times for two eyes from one person or for members of the same family.},
	pages = {403--415},
	number = {4},
	journaltitle = {Lifetime Data Analysis},
	author = {Liang, Kung-Yee and Self, Steven G. and Bandeen-Roche, Karen J. and Zeger, Scott L.},
	urldate = {2019-01-23},
	date = {1995},
	langid = {english},
	file = {liang_et_al_1995_some_recent_developments_for_regression_analysis_of_multivariate_failure_time.pdf:/home/nathan/Dropbox/njames/zotero_sync/liang_et_al_1995_some_recent_developments_for_regression_analysis_of_multivariate_failure_time.pdf:application/pdf}
}

@article{oakes_bivariate_1989,
	title = {Bivariate Survival Models Induced by Frailties},
	volume = {84},
	pages = {487--493},
	number = {406},
	journaltitle = {Journal of the American Statistical Association},
	author = {Oakes, David},
	date = {1989},
	langid = {english},
	file = {oakes_bivariate_survival_models_induced_by_frailties.pdf:/home/nathan/Dropbox/njames/zotero_sync/oakes_bivariate_survival_models_induced_by_frailties.pdf:application/pdf}
}

@incollection{damien_bayesian_2013,
	title = {Bayesian approaches to copula modelling},
	isbn = {978-0-19-969560-7},
	url = {http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780199695607.001.0001/acprof-9780199695607-chapter-17},
	pages = {336--358},
	booktitle = {Bayesian Theory and Applications},
	publisher = {Oxford University Press},
	author = {Smith, Michael Stanley},
	editor = {Damien, Paul and Dellaportas, Petros and Polson, Nicholas G. and Stephens, David A.},
	urldate = {2019-01-25},
	date = {2013-01-24},
	doi = {10.1093/acprof:oso/9780199695607.003.0017},
	file = {smith_2013_bayesian_approaches_to_copula_modelling.pdf:/home/nathan/Dropbox/njames/zotero_sync/smith_2013_bayesian_approaches_to_copula_modelling.pdf:application/pdf}
}

@book{hofert_elements_2018,
	location = {New York, {NY}},
	edition = {1st edition},
	title = {Elements of copula modeling with R},
	isbn = {978-3-319-89634-2},
	publisher = {Springer Berlin Heidelberg},
	author = {Hofert, Marius},
	date = {2018}
}

@article{goldstein_moving_2016,
	title = {Moving beyond regression techniques in cardiovascular risk prediction: applying machine learning to address analytic challenges},
	issn = {0195-668X, 1522-9645},
	url = {http://eurheartj.oxfordjournals.org/lookup/doi/10.1093/eurheartj/ehw302},
	doi = {10.1093/eurheartj/ehw302},
	shorttitle = {Moving beyond regression techniques in cardiovascular risk prediction},
	pages = {ehw302},
	journaltitle = {European Heart Journal},
	author = {Goldstein, Benjamin A. and Navar, Ann Marie and Carter, Rickey E.},
	urldate = {2019-01-25},
	date = {2016-07-19},
	langid = {english},
	file = {goldstein_et_al_2016_moving_beyond_regression_techniques_in_cardiovascular_risk_prediction.pdf:/home/nathan/Dropbox/njames/zotero_sync/goldstein_et_al_2016_moving_beyond_regression_techniques_in_cardiovascular_risk_prediction.pdf:application/pdf}
}

@article{betancourt_conceptual_2017,
	title = {A Conceptual Introduction to Hamiltonian Monte Carlo},
	url = {http://arxiv.org/abs/1701.02434},
	abstract = {Hamiltonian Monte Carlo has proven a remarkable empirical success, but only recently have we begun to develop a rigorous understanding of why it performs so well on diﬃcult problems and how it is best applied in practice. Unfortunately, that understanding is conﬁned within the mathematics of diﬀerential geometry which has limited its dissemination, especially to the applied communities for which it is particularly important.},
	journaltitle = {{arXiv}:1701.02434 [stat]},
	author = {Betancourt, Michael},
	urldate = {2019-01-25},
	date = {2017-01-09},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1701.02434},
	keywords = {Statistics - Methodology},
	file = {betancourt_2017_a_conceptual_introduction_to_hamiltonian_monte_carlo.pdf:/home/nathan/Dropbox/njames/zotero_sync/betancourt_2017_a_conceptual_introduction_to_hamiltonian_monte_carlo.pdf:application/pdf}
}

@article{henderson_individual_2005,
	title = {Individual survival time prediction using statistical models},
	volume = {31},
	issn = {0306-6800},
	url = {http://jme.bmj.com/cgi/doi/10.1136/jme.2005.012427},
	doi = {10.1136/jme.2005.012427},
	pages = {703--706},
	number = {12},
	journaltitle = {Journal of Medical Ethics},
	author = {Henderson, R},
	urldate = {2019-01-25},
	date = {2005-12-01},
	langid = {english},
	file = {henderson_2005_individual_survival_time_prediction_using_statistical_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/henderson_2005_individual_survival_time_prediction_using_statistical_models.pdf:application/pdf}
}

@article{schwertman_simple_1990,
	title = {A Simple Noncalculus Proof That the Median Minimizes the Sum of the Absolute Deviations},
	volume = {44},
	issn = {00031305},
	url = {https://www.jstor.org/stable/2684955?origin=crossref},
	doi = {10.2307/2684955},
	pages = {38},
	number = {1},
	journaltitle = {The American Statistician},
	author = {Schwertman, Neil C. and Gilks, A. J. and Cameron, J.},
	urldate = {2019-01-25},
	date = {1990-02},
	file = {schwertman_et_al_1990_a_simple_noncalculus_proof_that_the_median_minimizes_the_sum_of_the_absolute.pdf:/home/nathan/Dropbox/njames/zotero_sync/schwertman_et_al_1990_a_simple_noncalculus_proof_that_the_median_minimizes_the_sum_of_the_absolute.pdf:application/pdf}
}

@article{greevy_optimal_2004,
	title = {Optimal multivariate matching before randomization},
	volume = {5},
	issn = {1465-4644, 1468-4357},
	url = {https://academic.oup.com/biostatistics/article-lookup/doi/10.1093/biostatistics/5.2.263},
	doi = {10.1093/biostatistics/5.2.263},
	abstract = {Although blocking or pairing before randomization is a basic principle of experimental design, the principle is almost invariably applied to at most one or two blocking variables. Here, we discuss the use of optimal multivariate matching prior to randomization to improve covariate balance for many variables at the same time, presenting an algorithm and a case-study of its performance. The method is useful when all subjects, or large groups of subjects, are randomized at the same time. Optimal matching divides a single group of 2n subjects into n pairs to minimize covariate differences within pairs—the so-called nonbipartite matching problem—then one subject in each pair is picked at random for treatment, the other being assigned to control. Using the baseline covariate data for 132 patients from an actual, unmatched, randomized experiment, we construct 66 pairs matching for 14 covariates. We then create 10 000 unmatched and 10 000 matched randomized experiments by repeatedly randomizing the 132 patients, and compare the covariate balance with and without matching. By every measure, every one of the 14 covariates was substantially better balanced when randomization was performed within matched pairs. Even after covariance adjustment for chance imbalances in the 14 covariates, matched randomizations provided more accurate estimates than unmatched randomizations, the increase in accuracy being equivalent to, on average, a 7\% increase in sample size. In randomization tests of no treatment effect, matched randomizations using the signed rank test had substantially higher power than unmatched randomizations using the rank sum test, even when only 2 of 14 covariates were relevant to a simulated response. Unmatched randomizations experienced rare disasters which were consistently avoided by matched randomizations.},
	pages = {263--275},
	number = {2},
	journaltitle = {Biostatistics},
	author = {Greevy, R.},
	urldate = {2019-01-25},
	date = {2004-04-01},
	langid = {english},
	file = {greevy_2004_optimal_multivariate_matching_before_randomization.pdf:/home/nathan/Dropbox/njames/zotero_sync/greevy_2004_optimal_multivariate_matching_before_randomization.pdf:application/pdf}
}

@article{marsaglia_ratios_2006,
	title = {Ratios of Normal Variables},
	volume = {16},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v16/i04/},
	doi = {10.18637/jss.v016.i04},
	abstract = {This article extends and ampliﬁes on results from a paper of over forty years ago. It provides software for evaluating the density and distribution functions of the ratio z/w for any two jointly normal variates z, w, and provides details on methods for transforming a general ratio z/w into a standard form, (a+x)/(b+y) , with x and y independent standard normal and a, b non-negative constants. It discusses handling general ratios when, in theory, none of the moments exist yet practical considerations suggest there should be approximations whose adequacy can be veriﬁed by means of the included software. These approximations show that many of the ratios of normal variates encountered in practice can themselves be taken as normally distributed. A practical rule is developed: If a {\textless} 2.256 and 4 {\textless} b then the ratio (a+x)/(b+y) is itself approximately normally distributed with mean µ = a/(1.01b − .2713) and variance σ2 = (a2 + 1)/(b2 + .108b − 3.795) − µ2.},
	number = {4},
	journaltitle = {Journal of Statistical Software},
	author = {Marsaglia, George},
	urldate = {2019-01-25},
	date = {2006},
	langid = {english},
	file = {marsaglia_2006_ratios_of_normal_variables.pdf:/home/nathan/Dropbox/njames/zotero_sync/marsaglia_2006_ratios_of_normal_variables.pdf:application/pdf}
}

@article{harrell_multivariable_1996,
	title = {Multivariable Prognostic Models: Issues in Developing Models, Evaluating Assumptions and Adequacy, and Measuring and Reducing Errors},
	volume = {15},
	issn = {02776715, 10970258},
	url = {http://doi.wiley.com/10.1002/%28SICI%291097-0258%2819960229%2915%3A4%3C361%3A%3AAID-SIM168%3E3.0.CO%3B2-4},
	doi = {10.1002/(SICI)1097-0258(19960229)15:4<361::AID-SIM168>3.0.CO;2-4},
	shorttitle = {{MULTIVARIABLE} {PROGNOSTIC} {MODELS}},
	abstract = {Multivariable regression models are powerful tools that are used frequently in studies of clinical outcomes. These models can use a mixture of categorical and continuous variables and can handle partially observed (censored) responses. However, uncritical application of modelling techniques can result in models that poorly fit the dataset at hand, or, even more likely, inaccurately predict outcomes on new subjects. One must know how to measure qualities of a model's fit in order to avoid poorly fitted or overfitted models. Measurement of predictive accuracy can be difficult for survival time data in the presence of censoring. We discuss an easily interpretable index of predictive discrimination as well as methods for assessingcalibration of predicted survival probabilities. Both types of predictive accuracy should be unbiasedly validated using bootstrapping or cross-validation, before using predictions in a new data series. We discuss some of the hazards of poorly fitted and overfitted regression models and present one modelling strategy that avoids many of the problems discussed. The methods described are applicable to all regression models, but are particularly needed for binary, ordinal, and time-to-event outcomes. Methods are illustrated with a survival analysis in prostate cancer using Cox regression.},
	pages = {361--387},
	number = {4},
	journaltitle = {Statistics in Medicine},
	author = {Harrell, Frank E. and Lee, Kerry L. and Mark, Daniel B.},
	urldate = {2019-01-25},
	date = {1996-02-29},
	langid = {english},
	file = {harrell_et_al_1996_multivariable_prognostic_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/harrell_et_al_1996_multivariable_prognostic_models.pdf:application/pdf}
}

@article{sklar_fonctions_1959,
	title = {Fonctions de répartition à n dimensions et leurs marges},
	volume = {8},
	pages = {229--231},
	journaltitle = {Publications de l'Institut de Statistique de l'Université de Paris},
	author = {Sklar, Abe},
	date = {1959}
}

@article{lin_association_2010,
	title = {Association Models for Clustered Data with Binary and Continuous Responses},
	volume = {66},
	issn = {0006341X},
	url = {http://doi.wiley.com/10.1111/j.1541-0420.2008.01232.x},
	doi = {10.1111/j.1541-0420.2008.01232.x},
	abstract = {We consider analysis of clustered data with mixed bivariate responses, i.e., where each member of the cluster has a binary and a continuous outcome. We propose a new bivariate random effects model that induces associations among the binary outcomes within a cluster, among the continuous outcomes within a cluster, between a binary outcome and a continuous outcome from different subjects within a cluster, as well as the direct association between the binary and continuous outcomes within the same subject. For the ease of interpretations of the regression effects, the marginal model of the binary response probability integrated over the random effects preserves the logistic form and the marginal expectation of the continuous response preserves the linear form. We implement maximum likelihood estimation of our model parameters using standard software such as {PROC} {NLMIXED} of {SAS}. Our simulation study demonstrates the robustness of our method with respect to the misspecification of the regression model as well as the random effects model. We illustrate our methodology by analyzing a developmental toxicity study of ethylene glycol in mice.},
	pages = {287--293},
	number = {1},
	journaltitle = {Biometrics},
	author = {Lin, Lanjia and Bandyopadhyay, Dipankar and Lipsitz, Stuart R. and Sinha, Debajyoti},
	urldate = {2019-01-26},
	date = {2010-03},
	langid = {english},
	file = {lin_et_al_2010_association_models_for_clustered_data_with_binary_and_continuous_responses.pdf:/home/nathan/Dropbox/njames/zotero_sync/lin_et_al_2010_association_models_for_clustered_data_with_binary_and_continuous_responses.pdf:application/pdf}
}

@article{meester_parametric_1994,
	title = {A Parametric Model for Cluster Correlated Categorical Data},
	volume = {50},
	issn = {0006341X},
	url = {https://www.jstor.org/stable/2533435?origin=crossref},
	doi = {10.2307/2533435},
	abstract = {A fully parametric copula model for symmetric dependent clustered categorical data is discussed. The model accommodates any marginal regression models of interest and admits a broad range of within-cluster association. The form of the distribution is independent of cluster size and may be used to model data with varying cluster sizes. The model contains an association parameter that is estimated from the data to give a measure of the strength of the within-cluster association and also a test of independence. Two examples are given to illustrate the methods.},
	pages = {954--963},
	number = {4},
	journaltitle = {Biometrics},
	author = {Meester, Steven G. and {MacKay}, Jock},
	urldate = {2019-01-26},
	date = {1994-12},
	langid = {english},
	file = {meester_mackay_1994_a_parametric_model_for_cluster_correlated_categorical_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/meester_mackay_1994_a_parametric_model_for_cluster_correlated_categorical_data.pdf:application/pdf}
}

@article{fitzmaurice_regression_1995,
	title = {Regression Models for a Bivariate Discrete and Continuous Outcome with Clustering},
	volume = {90},
	abstract = {Developmental toxicity studies of laboratory animals play a crucial role in the testing and regulation of chemicals and pharmaceutical
 compounds. Exposure to developmental toxicants typically causes a variety of adverse effects, such as fetal malformations and reduced
 fetal weight at term. In this article, we discuss regression methods for jointly analyzing bivariate discrete and continuous outcomes
 that are motivated by the statistical problems that arise in analyzing data from developmental toxicity studies. We focus on marginal
 regression models; that is, models in which the marginal expectation of the bivariate response vector is related to a set of covariates
 by some known link functions. In these models the regression parameters for the marginal expectation are of primary scientific
 interest, whereas the association between the binary and continuous response is considered to be a nuisance characteristic of the data.
 We describe a likelihood-based approach, based on the general location model of Olkin and Tate, that yields maximum likelihood
 estimates of the marginal mean parameters that are robuit to misspecification of distributional assumptions. Finally, we describe an
 extension of this model to allow for clustering, using generalized estimating equations, a multivariate analog of quasi-likelihood. A
 motivating example, using fetal weight and malformation data from a developmental toxicity study of ethylene glycol in mice,
 illustrates this methodology},
	pages = {845--852},
	number = {341},
	journaltitle = {Journal of the American Statistical Association},
	author = {Fitzmaurice, Garrett M and Laird, Nan M},
	date = {1995-09},
	langid = {english},
	file = {fitzmaurice_laird_regression_models_for_a_bivariate_discrete_and_continuous_outcome_with.pdf:/home/nathan/Dropbox/njames/zotero_sync/fitzmaurice_laird_regression_models_for_a_bivariate_discrete_and_continuous_outcome_with.pdf:application/pdf}
}

@article{olkin_multivariate_1961,
	title = {Multivariate Correlation Models with Mixed Discrete and Continuous Variables},
	volume = {32},
	issn = {0003-4851},
	url = {http://projecteuclid.org/euclid.aoms/1177705052},
	doi = {10.1214/aoms/1177705052},
	pages = {448--465},
	number = {2},
	journaltitle = {The Annals of Mathematical Statistics},
	author = {Olkin, I. and Tate, R. F.},
	urldate = {2019-01-26},
	date = {1961-06},
	langid = {english},
	file = {olkin_tate_1961_multivariate_correlation_models_with_mixed_discrete_and_continuous_variables.pdf:/home/nathan/Dropbox/njames/zotero_sync/olkin_tate_1961_multivariate_correlation_models_with_mixed_discrete_and_continuous_variables.pdf:application/pdf}
}

@article{cox_response_1992,
	title = {Response Models for Mixed Binary and Quantitative Variables},
	volume = {79},
	abstract = {A number of special representations are considered for the joint distribution of qualitative, mostly binary, and quantitative variables. In addition to the conditional Gaussian models and to conditional Gaussian regression chain models some emphasis is placed on models derived from an underlying multivariate normal distribution and on models in which discrete probabilities are specified linearly in terms of unknown parameters. The possibilities for choosing between the models empirically are examined, as well as the testing of independence and conditional independence and the estimation of parameters. Often the testing of independence is exactly or nearly the same for a number of different models.},
	pages = {441--461},
	number = {3},
	journaltitle = {Biometrika},
	author = {Cox, D R and Wermuth, Nanny},
	date = {1992-09},
	langid = {english},
	file = {cox_wermuth_response_models_for_mixed_binary_and_quantitative_variables.pdf:/home/nathan/Dropbox/njames/zotero_sync/cox_wermuth_response_models_for_mixed_binary_and_quantitative_variables.pdf:application/pdf}
}

@article{catalano_bivariate_1992,
	title = {Bivariate Latent Variable Models for Clustered Discrete and Continuous Outcomes},
	volume = {87},
	abstract = {We use the concept of a latent variable to derive the joint distribution of a continuous and a discrete outcome, and then extend the
 model to allow for clustered data. The model can be parameterized in a way that allows one to write the joint distribution as a
 product of a standard random effects model for the continuous variable and a correlated probit model for the discrete variable. This
 factorization suggests a convenient approach to parameter estimation using quasi-likelihood techniques. Our approach is motivated
 by the analysis of developmental toxicity experiments for which a number of discrete and continuous outcomes are measured on
 offspring clustered within litters. Fetal weight and malformation data illustrate the results.},
	pages = {651--658},
	number = {419},
	journaltitle = {Journal of the American Statistical Association},
	author = {Catalano, Paul J and Ryan, Louise M},
	date = {1992-09},
	langid = {english},
	file = {catalano_ryan_bivariate_latent_variable_models_for_clustered_discrete_and_continuous_outcomes.pdf:/home/nathan/Dropbox/njames/zotero_sync/catalano_ryan_bivariate_latent_variable_models_for_clustered_discrete_and_continuous_outcomes.pdf:application/pdf}
}

@article{molenberghs_evaluation_2001,
	title = {Evaluation of surrogate endpoints in randomized experiments with mixed discrete and continuous outcomes},
	volume = {20},
	issn = {0277-6715, 1097-0258},
	url = {http://doi.wiley.com/10.1002/sim.923},
	doi = {10.1002/sim.923},
	abstract = {A statistical definition of surrogate endpoints as well as validation criteria was first presented by Prentice. Freedman et al. supplemented these criteria with the so‐called proportion explained. Buyse and Molenberghs pointed to inadequacies of these criteria and suggested a new definition of surrogacy based on (i) the relative effect linking the overall effect of treatment on both endpoints and (ii) an individual‐level measure of agreement between both endpoints. Using data from a randomized trial, they showed how a potential surrogate endpoint can be studied using a joint model for the surrogate and the true endpoint. Whereas Buyse and Molenberghs restricted themselves to the fairly simple cases of jointly normal and jointly binary outcomes, we treat the situation where the surrogate is binary and the true endpoint is continuous, or vice versa. In addition, we consider the case of ordinal endpoints. Further, Buyse et al. extended the approach of Buyse and Molenberghs to a meta‐analytic context. We will adopt a similar approach for responses of a mixed data type.},
	pages = {3023--3038},
	number = {20},
	journaltitle = {Statistics in Medicine},
	author = {Molenberghs, Geert and Geys, Helena and Buyse, Marc},
	urldate = {2019-01-26},
	date = {2001-10-30},
	langid = {english}
}

@article{schweizer_nonparametric_1981,
	title = {On Nonparametric Measures of Dependence for Random Variables},
	volume = {9},
	issn = {0090-5364},
	url = {http://projecteuclid.org/euclid.aos/1176345528},
	doi = {10.1214/aos/1176345528},
	abstract = {In 1959 A. Renyi proposed a set of axioms for a measure of dependence for pairs of random variables. In the same year A. Sklar introduced the general notion of a copula. This is a function which links an n-dimensional distribution function to its one-dimensional margins and is itself a continuous distribution function on the unit n-cube, with uniform margins. We show that the copula of a pair of random variables X,Y is invariant under a.s. strictly increasing transformations of X and Y, and that any property of the joint distribution function of X and Y which is invariant under such transformations is solely a function of their copula. Exploiting these facts, we use copulas to define several natural nonparametric measures of dependence for pairs of random variables. We show that these measures satisfy reasonable modifications of Renyi's conditions and compare them to various known measures of dependence, e.g., the correlation coefficient and Spearman's ρ.},
	pages = {879--885},
	number = {4},
	journaltitle = {The Annals of Statistics},
	author = {Schweizer, B. and Wolff, E. F.},
	urldate = {2019-01-26},
	date = {1981-07},
	langid = {english},
	file = {schweizer_wolff_1981_on_nonparametric_measures_of_dependence_for_random_variables.pdf:/home/nathan/Dropbox/njames/zotero_sync/schweizer_wolff_1981_on_nonparametric_measures_of_dependence_for_random_variables.pdf:application/pdf}
}

@article{liang_longitudinal_1986,
	title = {Longitudinal data analysis using generalized linear models},
	volume = {73},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/73.1.13},
	doi = {10.1093/biomet/73.1.13},
	pages = {13--22},
	number = {1},
	journaltitle = {Biometrika},
	author = {Liang, Kung-Yee and Zeger, Scott L.},
	urldate = {2019-01-26},
	date = {1986},
	langid = {english},
	file = {liang_zeger_1986_longitudinal_data_analysis_using_generalized_linear_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/liang_zeger_1986_longitudinal_data_analysis_using_generalized_linear_models.pdf:application/pdf}
}

@software{stan_development_team_rstan:_2018,
	title = {{RStan}: the R interface to Stan},
	url = {http://mc-stan.org/},
	version = {R package version 2.17.3},
	author = {{Stan Development Team}},
	date = {2018}
}

@article{eluru_modeling_2010,
	title = {Modeling Injury Severity of Multiple Occupants of Vehicles: Copula-Based Multivariate Approach},
	volume = {2165},
	issn = {0361-1981, 2169-4052},
	url = {http://journals.sagepub.com/doi/10.3141/2165-01},
	doi = {10.3141/2165-01},
	shorttitle = {Modeling Injury Severity of Multiple Occupants of Vehicles},
	pages = {1--11},
	number = {1},
	journaltitle = {Transportation Research Record: Journal of the Transportation Research Board},
	author = {Eluru, Naveen and Paleti, Rajesh and Pendyala, Ram M. and Bhat, Chandra R.},
	urldate = {2019-01-27},
	date = {2010-01},
	langid = {english},
	file = {eluru_et_al_2010_modeling_injury_severity_of_multiple_occupants_of_vehicles.pdf:/home/nathan/Dropbox/njames/zotero_sync/eluru_et_al_2010_modeling_injury_severity_of_multiple_occupants_of_vehicles.pdf:application/pdf}
}

@article{asakura_sample_2014,
	title = {Sample size determination in group-sequential clinical trials with two co-primary endpoints},
	volume = {33},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.6154},
	doi = {10.1002/sim.6154},
	abstract = {We discuss sample size determination in group-sequential designs with two endpoints as coprimary. We derive the power and sample size within two decision-making frameworks. One is to claim the test intervention’s benefit relative to control when superiority is achieved for the two endpoints at the same interim timepoint of the trial. The other is when the superiority is achieved for the two endpoints at any interim timepoint, not necessarily simultaneously. We evaluate the behaviors of sample size and power with varying design elements and provide a real example to illustrate the proposed sample size methods. In addition, we discuss sample size recalculation based on observed data and evaluate the impact on the power and Type I error rate.},
	pages = {2897--2913},
	number = {17},
	journaltitle = {Statistics in Medicine},
	author = {Asakura, Koko and Hamasaki, Toshimitsu and Sugimoto, Tomoyuki and Hayashi, Kenichi and Evans, Scott R. and Sozu, Takashi},
	urldate = {2019-01-27},
	date = {2014-07-30},
	langid = {english},
	file = {asakura_et_al_2014_sample_size_determination_in_group-sequential_clinical_trials_with_two.pdf:/home/nathan/Dropbox/njames/zotero_sync/asakura_et_al_2014_sample_size_determination_in_group-sequential_clinical_trials_with_two.pdf:application/pdf}
}

@article{sugimoto_logrank_2013,
	title = {A logrank test-based method for sizing clinical trials with two co-primary time-to-event endpoints},
	volume = {14},
	issn = {1468-4357, 1465-4644},
	url = {https://academic.oup.com/biostatistics/article/14/3/409/260022},
	doi = {10.1093/biostatistics/kxs057},
	abstract = {We discuss sample size determination for clinical trials evaluating the joint effects of an intervention on two potentially correlated co-primary time-to-event endpoints. For illustration, we consider the most common case, a comparison of two randomized groups, and use typical copula families to model the bivariate endpoints. A correlation structure of the bivariate logrank statistic is specified to account for the correlation among the endpoints, although the between-group comparison is performed using the univariate logrank statistic. We propose methods to calculate the required sample size to compare the two groups and evaluate the performance of the methods and the behavior of required sample sizes via simulation.},
	pages = {409--421},
	number = {3},
	journaltitle = {Biostatistics},
	author = {Sugimoto, Tomoyuki and Sozu, Takashi and Hamasaki, Toshimitsu and Evans, Scott R.},
	urldate = {2019-01-27},
	date = {2013-07-01},
	langid = {english},
	file = {sugimoto_et_al_2013_a_logrank_test-based_method_for_sizing_clinical_trials_with_two_co-primary.pdf:/home/nathan/Dropbox/njames/zotero_sync/sugimoto_et_al_2013_a_logrank_test-based_method_for_sizing_clinical_trials_with_two_co-primary.pdf:application/pdf}
}

@article{sozu_sample_2012,
	title = {Sample size determination in clinical trials with multiple co-primary endpoints including mixed continuous and binary variables},
	volume = {54},
	issn = {1521-4036},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201100221},
	doi = {10.1002/bimj.201100221},
	abstract = {In the field of pharmaceutical drug development, there have been extensive discussions on the establishment of statistically significant results that demonstrate the efficacy of a new treatment with multiple co-primary endpoints. When designing a clinical trial with such multiple co-primary endpoints, it is critical to determine the appropriate sample size for indicating the statistical significance of all the co-primary endpoints with preserving the desired overall power because the type {II} error rate increases with the number of co-primary endpoints. We consider overall power functions and sample size determinations with multiple co-primary endpoints that consist of mixed continuous and binary variables, and provide numerical examples to illustrate the behavior of the overall power functions and sample sizes. In formulating the problem, we assume that response variables follow a multivariate normal distribution, where binary variables are observed in a dichotomized normal distribution with a certain point of dichotomy. Numerical examples show that the sample size decreases as the correlation increases when the individual powers of each endpoint are approximately and mutually equal.},
	pages = {716--729},
	number = {5},
	journaltitle = {Biometrical Journal},
	author = {Sozu, Takashi and Sugimoto, Tomoyuki and Hamasaki, Toshimitsu},
	urldate = {2019-01-27},
	date = {2012},
	langid = {english},
	keywords = {Biserial correlation, Intersection-union test, Latent variable, Multiplicity, Multivariate normal},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/659NEF94/bimj.html:text/html;sozu_et_al_2012_sample_size_determination_in_clinical_trials_with_multiple_co-primary_endpoints.pdf:/home/nathan/Dropbox/njames/zotero_sync/sozu_et_al_2012_sample_size_determination_in_clinical_trials_with_multiple_co-primary_endpoints.pdf:application/pdf}
}

@article{sozu_sample_2010,
	title = {Sample size determination in clinical trials with multiple co-primary binary endpoints},
	volume = {29},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.3972},
	doi = {10.1002/sim.3972},
	abstract = {Clinical trials often employ two or more primary efficacy endpoints. One of the major problems in such trials is how to determine a sample size suitable for multiple co-primary correlated endpoints. We provide fundamental formulae for the calculation of power and sample size in order to achieve statistical significance for all the multiple primary endpoints given as binary variables. On the basis of three association measures among primary endpoints, we discuss five methods of power and sample size calculation: the asymptotic normal method with and without continuity correction, the arcsine method with and without continuity correction, and Fisher's exact method. For all five methods, the achieved sample size decreases as the value of association measure increases when the effect sizes among endpoints are approximately equal. In particular, a high positive association has a greater effect on the decrease in the sample size. On the other hand, such a relationship is not very strong when the effect sizes are different. Copyright © 2010 John Wiley \& Sons, Ltd.},
	pages = {2169--2179},
	number = {21},
	journaltitle = {Statistics in Medicine},
	author = {Sozu, Takashi and Sugimoto, Tomoyuki and Hamasaki, Toshimitsu},
	urldate = {2019-01-27},
	date = {2010},
	langid = {english},
	keywords = {correlated endpoints, arcsine transformation, association measures, continuity correction, Fisher's exact method, multivariate Bernoulli},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/7TVFRNUY/sim.html:text/html;sozu_et_al_2010_sample_size_determination_in_clinical_trials_with_multiple_co-primary_binary.pdf:/home/nathan/Dropbox/njames/zotero_sync/sozu_et_al_2010_sample_size_determination_in_clinical_trials_with_multiple_co-primary_binary.pdf:application/pdf}
}

@article{xiong_power_2005,
	title = {Power and sample size for clinical trials when efficacy is required in multiple endpoints: application to an Alzheimer's treatment trial},
	volume = {2},
	issn = {1740-7745, 1740-7753},
	url = {http://journals.sagepub.com/doi/10.1191/1740774505cn112oa},
	doi = {10.1191/1740774505cn112oa},
	shorttitle = {Power and sample size for clinical trials when efficacy is required in multiple endpoints},
	abstract = {Background When the efficacy of a treatment in a randomized controlled trial is required for multiple primary endpoints, trial design and analysis differ from trial requiring efficacy in only one of the multiple endpoints.
Methods We consider a two-arm clinical trial requiring efficacy analysis for multiple primary endpoints, formulating the appropriate null and alternative hypotheses for the test of treatment efficacy. We study the significance level/statistical power of an intersection-union test ({IUT}) in this situation. We compare {IUT} with the intuitive approach (selecting the maximum sample size over those obtained from testing individual primary endpoints one by one) for determination of sample size.
Results The proposed {IUT} reserves the same Type I error rate as shared by all endpoint-specific tests. The statistical power of the proposed {IUT} is no more than the minimum from the individual tests. The maximum sample size from multiple endpoint-specific tests is often inadequate for the test of treatment efficacy, especially when the standardized effect sizes are similar. Finally, the {IUT} can be applied to Alzheimer’s disease treatment trials in which two primary endpoints are typically used.
Conclusions The {IUT} is a valid method for use in the design and analysis of clinical trials requiring efficacy at multiple primary endpoints. Clinical Trials 2005; 2: 387–393. www.{SCTjournal}.com},
	pages = {387--393},
	number = {5},
	journaltitle = {Clinical Trials: Journal of the Society for Clinical Trials},
	author = {Xiong, Chengjie and Yu, Kai and Gao, Feng and Yan, Yan and Zhang, Zhengjun},
	urldate = {2019-01-27},
	date = {2005-10},
	langid = {english},
	file = {xiong_et_al_2005_power_and_sample_size_for_clinical_trials_when_efficacy_is_required_in_multiple.pdf:/home/nathan/Dropbox/njames/zotero_sync/xiong_et_al_2005_power_and_sample_size_for_clinical_trials_when_efficacy_is_required_in_multiple.pdf:application/pdf}
}

@article{hung_controversial_2009,
	title = {Some Controversial Multiple Testing Problems in Regulatory Applications},
	volume = {19},
	issn = {10543406},
	url = {http://proxy.library.vanderbilt.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=35951194&site=ehost-live&scope=site},
	doi = {10.1080/10543400802541693},
	abstract = {Multiple testing problems in regulatory applications are often more challenging than the problems of handling a set of mathematical symbols representing multiple null hypotheses under testing. In the union-intersection setting, it is important to define a family of null hypotheses relevant to the clinical questions at issue. The distinction between primary endpoint and secondary endpoint needs to be considered properly in different clinical applications. Without proper consideration, the widely used sequential gate keeping strategies often impose too many logical restrictions to make sense, particularly to deal with the problem of testing multiple doses and multiple endpoints, the problem of testing a composite endpoint and its component endpoints, and the problem of testing superiority and noninferiority in the presence of multiple endpoints. Partitioning the null hypotheses involved in closed testing into clinical relevant orderings or sets can be a viable alternative to resolving the illogical problems requiring more attention from clinical trialists in defining the clinical hypotheses or clinical question(s) at the design stage. In the intersection-union setting there is little room for alleviating the stringency of the requirement that each endpoint must meet the same intended alpha level, unless the parameter space under the null hypothesis can be substantially restricted. Such restriction often requires insurmountable justification and usually cannot be supported by the internal data. Thus, a possible remedial approach to alleviate the possible conservatism as a result of this requirement is a group-sequential design strategy that starts with a conservative sample size planning and then utilizes an alpha spending function to possibly reach the conclusion early.},
	pages = {1--11},
	number = {1},
	journaltitle = {Journal of Biopharmaceutical Statistics},
	author = {Hung, H. M. James and {Sue-Jane Wang}},
	urldate = {2019-01-28},
	date = {2009-02-01},
	keywords = {Biopharmaceutics, Composite endpoint, Group-sequential, Intersection-union, Multiple comparisons (Statistics), Noninferiority, Sample size (Statistics), Sequential gate keeping, Statistical hypothesis testing, Statistical sampling, Studywise, Superiority, Union-intersection},
	file = {hung_sue-jane_wang_2009_some_controversial_multiple_testing_problems_in_regulatory_applications.pdf:/home/nathan/Dropbox/njames/zotero_sync/hung_sue-jane_wang_2009_some_controversial_multiple_testing_problems_in_regulatory_applications.pdf:application/pdf}
}

@article{bretz_discussion_2009,
	title = {Discussion of “Some Controversial Multiple Testing Problems in Regulatory Applications” by H. M. J. Hung and S.-J. Wang},
	volume = {19},
	issn = {1054-3406, 1520-5711},
	url = {http://www.tandfonline.com/doi/abs/10.1080/10543400802541834},
	doi = {10.1080/10543400802541834},
	pages = {25--34},
	number = {1},
	journaltitle = {Journal of Biopharmaceutical Statistics},
	author = {Bretz, Frank and Maurer, Willi and Gallo, Paul},
	urldate = {2019-01-28},
	date = {2009-01-02},
	langid = {english},
	file = {bretz_et_al_2009_discussion_of_“some_controversial_multiple_testing_problems_in_regulatory.pdf:/home/nathan/Dropbox/njames/zotero_sync/bretz_et_al_2009_discussion_of_“some_controversial_multiple_testing_problems_in_regulatory.pdf:application/pdf}
}

@article{chuang-stein_discussion_2009,
	title = {Discussion of “Some Controversial Multiple Testing Problems in Regulatory Applications”},
	volume = {19},
	issn = {1054-3406, 1520-5711},
	url = {http://www.tandfonline.com/doi/abs/10.1080/10543400802541719},
	doi = {10.1080/10543400802541719},
	pages = {14--21},
	number = {1},
	journaltitle = {Journal of Biopharmaceutical Statistics},
	author = {Chuang-stein, Christy and Dmitrienko, Alex and Offen, Walter},
	urldate = {2019-01-28},
	date = {2009-01-02},
	langid = {english},
	file = {chuang-stein_et_al_2009_discussion_of_“some_controversial_multiple_testing_problems_in_regulatory.pdf:/home/nathan/Dropbox/njames/zotero_sync/chuang-stein_et_al_2009_discussion_of_“some_controversial_multiple_testing_problems_in_regulatory.pdf:application/pdf}
}

@article{wright_discussion_2009,
	title = {Discussion of “Some Controversial Multiple Testing Problems in Regulatory Applications”},
	volume = {19},
	issn = {1054-3406, 1520-5711},
	url = {http://www.tandfonline.com/doi/abs/10.1080/10543400802541701},
	doi = {10.1080/10543400802541701},
	pages = {12--13},
	number = {1},
	journaltitle = {Journal of Biopharmaceutical Statistics},
	author = {Wright, David Jonathan},
	urldate = {2019-01-28},
	date = {2009-01-02},
	langid = {english},
	file = {wright_2009_discussion_of_“some_controversial_multiple_testing_problems_in_regulatory.pdf:/home/nathan/Dropbox/njames/zotero_sync/wright_2009_discussion_of_“some_controversial_multiple_testing_problems_in_regulatory.pdf:application/pdf}
}

@article{chang_discussion_2009,
	title = {Discussion of “Some Controversial Multiple Testing Problems in Regulatory Applications”},
	volume = {19},
	issn = {1054-3406, 1520-5711},
	url = {http://www.tandfonline.com/doi/abs/10.1080/10543400802541842},
	doi = {10.1080/10543400802541842},
	pages = {35--41},
	number = {1},
	journaltitle = {Journal of Biopharmaceutical Statistics},
	author = {Chang, Mark},
	urldate = {2019-01-28},
	date = {2009-01-02},
	langid = {english},
	file = {chang_2009_discussion_of_“some_controversial_multiple_testing_problems_in_regulatory.pdf:/home/nathan/Dropbox/njames/zotero_sync/chang_2009_discussion_of_“some_controversial_multiple_testing_problems_in_regulatory.pdf:application/pdf}
}

@article{hsu_discussion_2009,
	title = {Discussion of “Some Controversial Multiple Testing Problems in Regulatory Applications”},
	volume = {19},
	issn = {1054-3406, 1520-5711},
	url = {http://www.tandfonline.com/doi/abs/10.1080/10543400802541727},
	doi = {10.1080/10543400802541727},
	pages = {22--24},
	number = {1},
	journaltitle = {Journal of Biopharmaceutical Statistics},
	author = {Hsu, Jason and Liu, Yi},
	urldate = {2019-01-28},
	date = {2009-01-02},
	langid = {english},
	file = {hsu_liu_2009_discussion_of_“some_controversial_multiple_testing_problems_in_regulatory.pdf:/home/nathan/Dropbox/njames/zotero_sync/hsu_liu_2009_discussion_of_“some_controversial_multiple_testing_problems_in_regulatory.pdf:application/pdf}
}

@article{holt_performance_2009,
	title = {Performance and Sample Size Requirements of Bayesian Methods for Binary Outcomes in Fixed-Dose Combination Drug Studies},
	volume = {19},
	issn = {1054-3406, 1520-5711},
	url = {http://www.tandfonline.com/doi/abs/10.1080/10543400802527916},
	doi = {10.1080/10543400802527916},
	pages = {120--132},
	number = {1},
	journaltitle = {Journal of Biopharmaceutical Statistics},
	author = {Holt, Melinda M. and Stamey, James D. and Seaman, John W. and Young, Dean M.},
	urldate = {2019-01-28},
	date = {2009-01-02},
	langid = {english},
	file = {holt_et_al_2009_performance_and_sample_size_requirements_of_bayesian_methods_for_binary.pdf:/home/nathan/Dropbox/njames/zotero_sync/holt_et_al_2009_performance_and_sample_size_requirements_of_bayesian_methods_for_binary.pdf:application/pdf}
}

@article{johnson_uniformly_2013,
	title = {Uniformly most powerful Bayesian tests},
	volume = {41},
	issn = {0090-5364},
	url = {http://projecteuclid.org/euclid.aos/1378386237},
	doi = {10.1214/13-AOS1123},
	abstract = {Uniformly most powerful tests are statistical hypothesis tests that provide the greatest power against a fixed null hypothesis among all tests of a given size. In this article, the notion of uniformly most powerful tests is extended to the Bayesian setting by defining uniformly most powerful Bayesian tests to be tests that maximize the probability that the Bayes factor, in favor of the alternative hypothesis, exceeds a specified threshold. Like their classical counterpart, uniformly most powerful Bayesian tests are most easily defined in one-parameter exponential family models, although extensions outside of this class are possible. The connection between uniformly most powerful tests and uniformly most powerful Bayesian tests can be used to provide an approximate calibration between p-values and Bayes factors. Finally, issues regarding the strong dependence of resulting Bayes factors and p-values on sample size are discussed.},
	pages = {1716--1741},
	number = {4},
	journaltitle = {The Annals of Statistics},
	author = {Johnson, Valen E.},
	urldate = {2019-01-30},
	date = {2013-08},
	langid = {english},
	file = {johnson_2013_uniformly_most_powerful_bayesian_tests.pdf:/home/nathan/Dropbox/njames/zotero_sync/johnson_2013_uniformly_most_powerful_bayesian_tests.pdf:application/pdf}
}

@article{blackwell_bayes_1982,
	title = {A Bayes but Not Classically Sufficient Statistic},
	volume = {10},
	issn = {0090-5364},
	url = {http://projecteuclid.org/euclid.aos/1176345895},
	doi = {10.1214/aos/1176345895},
	pages = {1025--1026},
	number = {3},
	journaltitle = {The Annals of Statistics},
	author = {Blackwell, D. and Ramamoorthi, R. V.},
	urldate = {2019-01-30},
	date = {1982-09},
	langid = {english},
	file = {blackwell_ramamoorthi_1982_a_bayes_but_not_classically_sufficient_statistic.pdf:/home/nathan/Dropbox/njames/zotero_sync/blackwell_ramamoorthi_1982_a_bayes_but_not_classically_sufficient_statistic.pdf:application/pdf}
}

@article{marden_hypothesis_2000,
	title = {Hypothesis Testing: From \textit{p} Values to Bayes Factors},
	volume = {95},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2000.10474339},
	doi = {10.1080/01621459.2000.10474339},
	shorttitle = {Hypothesis Testing},
	pages = {1316--1320},
	number = {452},
	journaltitle = {Journal of the American Statistical Association},
	author = {Marden, John I.},
	urldate = {2019-01-30},
	date = {2000-12},
	langid = {english},
	file = {marden_2000_hypothesis_testing.pdf:/home/nathan/Dropbox/njames/zotero_sync/marden_2000_hypothesis_testing.pdf:application/pdf}
}

@article{ince_statistical_2017,
	title = {A statistical framework for neuroimaging data analysis based on mutual information estimated via a gaussian copula: Gaussian Copula Mutual Information},
	volume = {38},
	issn = {10659471},
	url = {http://doi.wiley.com/10.1002/hbm.23471},
	doi = {10.1002/hbm.23471},
	shorttitle = {A statistical framework for neuroimaging data analysis based on mutual information estimated via a gaussian copula},
	abstract = {We begin by reviewing the statistical framework of information theory as applicable to neuroimaging data analysis. A major factor hindering wider adoption of this framework in neuroimaging is the difﬁculty of estimating information theoretic quantities in practice. We present a novel estimation technique that combines the statistical theory of copulas with the closed form solution for the entropy of Gaussian variables. This results in a general, computationally efﬁcient, ﬂexible, and robust multivariate statistical framework that provides effect sizes on a common meaningful scale, allows for uniﬁed treatment of discrete, continuous, unidimensional and multidimensional variables, and enables direct comparisons of representations from behavioral and brain responses across any recording modality. We validate the use of this estimate as a statistical test within a neuroimaging context, considering both discrete stimulus classes and continuous stimulus features. We also present examples of analyses facilitated by these developments, including application of multivariate analyses to {MEG} planar magnetic ﬁeld gradients, and pairwise temporal interactions in evoked {EEG} responses. We show the beneﬁt of considering the instantaneous temporal derivative together with the raw values of M/{EEG} signals as a multivariate response, how we can separately quantify modulations of amplitude and direction for vector quantities, and how we can measure the emergence of novel information over time in evoked responses. Opensource Matlab and Python code implementing the new methods accompanies this article. Hum Brain Mapp 38:1541–1573, 2017. {VC} 2016 The Authors Human Brain Mapping Published by Wiley Periodicals, Inc.},
	pages = {1541--1573},
	number = {3},
	journaltitle = {Human Brain Mapping},
	author = {Ince, Robin A.A. and Giordano, Bruno L. and Kayser, Christoph and Rousselet, Guillaume A. and Gross, Joachim and Schyns, Philippe G.},
	urldate = {2019-02-02},
	date = {2017-03},
	langid = {english},
	file = {ince_et_al_2017_a_statistical_framework_for_neuroimaging_data_analysis_based_on_mutual.pdf:/home/nathan/Dropbox/njames/zotero_sync/ince_et_al_2017_a_statistical_framework_for_neuroimaging_data_analysis_based_on_mutual.pdf:application/pdf}
}

@article{shan_statistical_2018,
	title = {Statistical advances in clinical trials and clinical research},
	volume = {4},
	issn = {23528737},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352873718300246},
	doi = {10.1016/j.trci.2018.04.006},
	pages = {366--371},
	journaltitle = {Alzheimer's \& Dementia: Translational Research \& Clinical Interventions},
	author = {Shan, Guogen and Banks, Sarah and Miller, Justin B. and Ritter, Aaron and Bernick, Charles and Lombardo, Joseph and Cummings, Jeffrey L.},
	urldate = {2019-02-02},
	date = {2018},
	langid = {english},
	file = {shan_et_al_2018_statistical_advances_in_clinical_trials_and_clinical_research.pdf:/home/nathan/Dropbox/njames/zotero_sync/shan_et_al_2018_statistical_advances_in_clinical_trials_and_clinical_research.pdf:application/pdf}
}

@article{chow_controversial_2015,
	title = {On controversial statistical issues in clinical research},
	issn = {1179-1519},
	url = {http://www.dovepress.com/on-controversial-statistical-issues-in-clinical-research-peer-reviewed-article-OAJCT},
	doi = {10.2147/OAJCT.S63266},
	abstract = {In clinical development of a test treatment under investigation, clinical trials are often conducted for evaluation of safety and efficacy of the test treatment. To provide an accurate and reliable assessment, adequate and well-controlled clinical trials using valid study designs are necessarily conducted for obtaining substantial evidence of safety and efficacy of the test treatment under investigation. In practice, however, some debatable issues are commonly encountered regardless compliance with good statistics practice and good clinical practice. These issues include, but are not limited to: 1) appropriateness of statistical hypotheses for clinical investigation; 2) correctness of power analysis assumptions; 3) integrity of randomization and blinding; 4) post hoc endpoint selection; 5) impact of protocol amendments on the characteristics of the trial population; 6) multiplicity in clinical trials; 7) missing data imputation; 8) adaptive design methods; and 9) independence of a data monitoring committee. In this article, these issues are briefly described. The impact of these issues on the evaluation of the safety and efficacy of the test treatment under investigation are discussed with examples whenever applicable. Some recommendations regarding possible resolutions of these issues are also provided.},
	pages = {43},
	journaltitle = {Open Access Journal of Clinical Trials},
	author = {Chow, Shein-Chung and Song, Fuyu},
	urldate = {2019-02-02},
	date = {2015-05},
	langid = {english},
	file = {chow_song_2015_on_controversial_statistical_issues_in_clinical_research.pdf:/home/nathan/Dropbox/njames/zotero_sync/chow_song_2015_on_controversial_statistical_issues_in_clinical_research.pdf:application/pdf}
}

@book{cherubini_copula_2004,
	location = {Hoboken, {NJ}},
	title = {Copula methods in finance},
	isbn = {978-0-470-86344-2},
	series = {Wiley finance series},
	pagetotal = {293},
	publisher = {John Wiley \& Sons},
	author = {Cherubini, Umberto and Luciano, Elisa and Vecchiato, Walter},
	date = {2004},
	keywords = {Finance, Mathematical models}
}

@book{ibragimov_heavy_2017,
	location = {New Jersey},
	title = {Heavy tails and copulas: topics in dependence modelling in economics and finance},
	isbn = {978-981-4689-79-3},
	shorttitle = {Heavy tails and copulas},
	publisher = {World Scientific},
	author = {Ibragimov, Rustam and Prokhorov, Artem},
	date = {2017},
	keywords = {Statistical methods, Econometrics, Finance, Economics}
}

@article{birnbaum_foundations_1962,
	title = {On the Foundations of Statistical Inference},
	volume = {57},
	pages = {269--306},
	number = {298},
	journaltitle = {Journal of the American Statistical Association},
	author = {Birnbaum, Allan},
	date = {1962-06},
	langid = {english},
	file = {birnbaum_on_the_foundations_of_statistical_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/birnbaum_on_the_foundations_of_statistical_inference.pdf:application/pdf}
}

@article{fienberg_when_2006,
	title = {When did Bayesian inference become "Bayesian"?},
	volume = {1},
	issn = {1936-0975},
	url = {http://projecteuclid.org/euclid.ba/1340371071},
	doi = {10.1214/06-BA101},
	abstract = {While Bayes’ theorem has a 250-year history, and the method of inverse probability that ﬂowed from it dominated statistical thinking into the twentieth century, the adjective “Bayesian” was not part of the statistical lexicon until relatively recently. This paper provides an overview of key Bayesian developments, beginning with Bayes’ posthumously published 1763 paper and continuing up through approximately 1970, including the period of time when “Bayesian” emerged as the label of choice for those who advocated Bayesian methods.},
	pages = {1--40},
	number = {1},
	journaltitle = {Bayesian Analysis},
	author = {Fienberg, Stephen E.},
	urldate = {2019-02-04},
	date = {2006-03},
	langid = {english},
	file = {fienberg_2006_when_did_bayesian_inference_become_bayesian.pdf:/home/nathan/Dropbox/njames/zotero_sync/fienberg_2006_when_did_bayesian_inference_become_bayesian.pdf:application/pdf}
}

@article{savage_foundations_nodate,
	title = {The Foundations of Statistics Reconsidered},
	pages = {12},
	author = {Savage, Leonard J},
	langid = {english},
	file = {savage_the_foundations_of_statistics_reconsidered.pdf:/home/nathan/Dropbox/njames/zotero_sync/savage_the_foundations_of_statistics_reconsidered.pdf:application/pdf}
}

@article{baydin_automatic_nodate,
	title = {Automatic Diﬀerentiation in Machine Learning: a Survey},
	abstract = {Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic diﬀerentiation ({AD}), also called algorithmic diﬀerentiation or simply “autodiﬀ”, is a family of techniques similar to but more general than backpropagation for eﬃciently and accurately evaluating derivatives of numeric functions expressed as computer programs. {AD} is a small but established ﬁeld with applications in areas including computational ﬂuid dynamics, atmospheric sciences, and engineering design optimization. Until very recently, the ﬁelds of machine learning and {AD} have largely been unaware of each other and, in some cases, have independently discovered each other’s results. Despite its relevance, general-purpose {AD} has been missing from the machine learning toolbox, a situation slowly changing with its ongoing adoption under the names “dynamic computational graphs” and “diﬀerentiable programming”. We survey the intersection of {AD} and machine learning, cover applications where {AD} has direct relevance, and address the main implementation techniques. By precisely deﬁning the main diﬀerentiation techniques and their interrelationships, we aim to bring clarity to the usage of the terms “autodiﬀ”, “automatic diﬀerentiation”, and “symbolic diﬀerentiation” as these are encountered more and more in machine learning settings.},
	pages = {43},
	author = {Baydin, Atılım Gunes and Pearlmutter, Barak A and Radul, Alexey Andreyevich and Siskind, Jeﬀrey Mark},
	langid = {english},
	file = {baydin_et_al_automatic_diﬀerentiation_in_machine_learning.pdf:/home/nathan/Dropbox/njames/zotero_sync/baydin_et_al_automatic_diﬀerentiation_in_machine_learning.pdf:application/pdf}
}

@article{nadarajah_compendium_2018,
	title = {A Compendium of Copulas},
	volume = {Vol 77},
	url = {https://rivista-statistica.unibo.it/article/view/7202},
	doi = {10.6092/issn.1973-2201/7202},
	abstract = {Copulas are used to specify dependence between two or more random variables. The last few years have seen a surge of developments of parametric models for copulas. Here, we provide an up-to-date and a comprehensive review of known parametric copulas as well as applications and open problems. This review is believed to be the first of its kind.},
	pages = {No 4 (2017)--},
	journaltitle = {Statistica},
	author = {Nadarajah, Saralees and Afuecheta, Emmanuel and Chan, Stephen},
	urldate = {2019-02-05},
	date = {2018-03-29},
	langid = {english},
	file = {nadarajah_et_al_2018_a_compendium_of_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/nadarajah_et_al_2018_a_compendium_of_copulas.pdf:application/pdf}
}

@article{joe_estimation_1996,
	title = {The Estimation Method of Inference Functions for Margins for Multivariate Models},
	url = {https://doi.library.ubc.ca/10.14288/1.0225985},
	doi = {10.14288/1.0225985},
	abstract = {An estimation approach is proposed for models for a multivariate (non-normal) response with covariates  when each of the parameters (either a univariate or a dependence parameter) of the model can be  associated with a marginal distribution. The approach consists of estimating univariate parameters from  separately maximizing univariate likelihoods, and then estimating dependence parameters from separate bivariate  likelihoods or from a multivariate likelihood. The analysis of this method is done through the theory  of inference or estimating functions, and the jackknife method is proposed for obtaining standard errors of  the parameters and functions of the parameters. The approach proposed here make a large contribution  to the computational feasibility of carrying out inference with multivariate models. Examples illustrate the  approach, and simulation results are used to indicate the efficiency.},
	journaltitle = {The University of British Columbia},
	author = {Joe, Harry and Xu, James Jianmeng},
	urldate = {2019-02-06},
	date = {1996},
	langid = {english},
	file = {joe_xu_1996_the_estimation_method_of_inference_functions_for_margins_for_multivariate_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/joe_xu_1996_the_estimation_method_of_inference_functions_for_margins_for_multivariate_models.pdf:application/pdf}
}

@article{yang_using_2018,
	title = {Using survival information in truncation by death problems without the monotonicity assumption},
	volume = {74},
	issn = {1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12883},
	doi = {10.1111/biom.12883},
	abstract = {In some randomized clinical trials, patients may die before the measurement time point of their outcomes. Even though randomization generates comparable treatment and control groups, the remaining survivors often differ significantly in background variables that are prognostic to the outcomes. This is called the truncation by death problem. Under the potential outcomes framework, the only well-defined causal effect on the outcome is within the subgroup of patients who would always survive under both treatment and control. Because the definition of the subgroup depends on the potential values of the survival status that could not be observed jointly, without making strong parametric assumptions, we cannot identify the causal effect of interest and consequently can only obtain bounds of it. Unfortunately, however, many bounds are too wide to be useful. We propose to use detailed survival information before and after the measurement time point of the outcomes to sharpen the bounds of the subgroup causal effect. Because survival times contain useful information about the final outcome, carefully utilizing them could improve statistical inference without imposing strong parametric assumptions. Moreover, we propose to use a copula model to relax the commonly-invoked but often doubtful monotonicity assumption that the treatment extends the survival time for all patients.},
	pages = {1232--1239},
	number = {4},
	journaltitle = {Biometrics},
	author = {Yang, Fan and Ding, Peng},
	urldate = {2019-02-08},
	date = {2018},
	langid = {english},
	keywords = {Bounds, Causal inference, Principal stratification, Survivor average causal effect, Copula},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/PWNT35UJ/biom.html:text/html;yang_ding_2018_using_survival_information_in_truncation_by_death_problems_without_the.pdf:/home/nathan/Dropbox/njames/zotero_sync/yang_ding_2018_using_survival_information_in_truncation_by_death_problems_without_the.pdf:application/pdf}
}

@article{yan_new_2017,
	title = {A New Family of Error Distributions for Bayesian Quantile Regression},
	url = {http://arxiv.org/abs/1701.05666},
	abstract = {We propose a new family of error distributions for model-based quantile regression, which is constructed through a structured mixture of normal distributions. The construction enables ﬁxing speciﬁc percentiles of the distribution while, at the same time, allowing for varying mode, skewness and tail behavior. It thus overcomes the severe limitation of the asymmetric Laplace distribution – the most commonly used error model for parametric quantile regression – for which the skewness of the error density is fully speciﬁed when a particular percentile is ﬁxed. We develop a Bayesian formulation for the proposed quantile regression model, including conditional lasso regularized quantile regression based on a hierarchical Laplace prior for the regression coefﬁcients, and a Tobit quantile regression model. Posterior inference is implemented via Markov Chain Monte Carlo methods. The ﬂexibility of the new model relative to the asymmetric Laplace distribution is studied through relevant model properties, and through a simulation experiment to compare the two error distributions in regularized quantile regression. Moreover, model performance in linear quantile regression, regularized quantile regression, and Tobit quantile regression is illustrated with data examples that have been previously considered in the literature.},
	journaltitle = {{arXiv}:1701.05666 [stat]},
	author = {Yan, Yifei and Kottas, Athanasios},
	urldate = {2019-02-11},
	date = {2017-01-19},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1701.05666},
	keywords = {Statistics - Methodology},
	file = {yan_kottas_2017_a_new_family_of_error_distributions_for_bayesian_quantile_regression.pdf:/home/nathan/Dropbox/njames/zotero_sync/yan_kottas_2017_a_new_family_of_error_distributions_for_bayesian_quantile_regression.pdf:application/pdf}
}

@article{sanchez_likelihood_nodate,
	title = {Likelihood Based Inference for Quantile Regression Using the Asymmetric Laplace Distribution},
	abstract = {To make inferences about the shape of a population distribution, the widely popular mean regression model, for example, is inadequate if the distribution is not approximately Gaussian (or symmetric). Compared to conventional mean regression ({MR}), quantile regression ({QR}) can characterize the entire conditional distribution of the outcome variable, and is more robust to outliers and misspeciﬁcation of the error distribution. We present a likelihood-based approach to the estimation of the regression quantiles based on the asymmetric Laplace distribution ({ALD}), a choice that turns out to be natural in this context. The {ALD} has a nice hierarchical representation which facilitates the implementation of the {EM} algorithm for maximumlikelihood estimation of the parameters at the pth level with the observed information matrix as a byproduct. Inspired by the {EM} algorithm, we develop case-deletion diagnostics analysis for {QR} models, following the approach of Zhu et al. (2001). This is because the observed data log–likelihood function associated with the proposed model is somewhat complex (e.g., not differentiable at zero) and by using Cook’s well-known approach it can be very difﬁcult to obtain case-deletion measures. The techniques are illustrated with both simulated and real data. In particular, in an empirical comparison, our approach out-performed other common classic estimators under a wide array of simulated data models and is ﬂexible enough to easily accommodate changes in their assumed distribution. The proposed algorithm and methods are implemented in the R package {ALDqr}().},
	pages = {19},
	author = {Sánchez, Luis B and Lachos, Victor H and Labra, Filidor V},
	langid = {english},
	file = {sánchez_et_al_likelihood_based_inference_for_quantile_regression_using_the_asymmetric_laplace.pdf:/home/nathan/Dropbox/njames/zotero_sync/sánchez_et_al_likelihood_based_inference_for_quantile_regression_using_the_asymmetric_laplace.pdf:application/pdf}
}

@article{li_mixtures_2018-1,
	title = {Mixtures of g-Priors in Generalized Linear Models},
	volume = {113},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2018.1469992},
	doi = {10.1080/01621459.2018.1469992},
	abstract = {Mixtures of Zellner’s g-priors have been studied extensively in linear models and have been shown to have numerous desirable properties for Bayesian variable selection and model averaging. Several extensions of g-priors to generalized linear models ({GLMs}) have been proposed in the literature; however, the choice of prior distribution of g and resulting properties for inference have received considerably less attention. In this article, we unify mixtures of g-priors in {GLMs} by assigning the truncated Compound Confluent Hypergeometric ({tCCH}) distribution to 1/(1 + g), which encompasses as special cases several mixtures of g-priors in the literature, such as the hyper-g, Beta-prime, truncated Gamma, incomplete inverse-Gamma, benchmark, robust, hyper-g/n, and intrinsic priors. Through an integrated Laplace approximation, the posterior distribution of 1/(1 + g) is in turn a {tCCH} distribution, and approximate marginal likelihoods are thus available analytically, leading to “Compound Hypergeometric Information Criteria” for model selection. We discuss the local geometric properties of the g-prior in {GLMs} and show how the desiderata for model selection proposed by Bayarri et al., such as asymptotic model selection consistency, intrinsic consistency, and measurement invariance may be used to justify the prior and specific choices of the hyper parameters. We illustrate inference using these priors and contrast them to other approaches via simulation and real data examples. The methodology is implemented in the R package {BAS} and freely available on {CRAN}. Supplementary materials for this article are available online.},
	pages = {1828--1845},
	number = {524},
	journaltitle = {Journal of the American Statistical Association},
	author = {Li, Yingbo and Clyde, Merlise A.},
	urldate = {2019-02-11},
	date = {2018-10-02},
	langid = {english},
	file = {li_clyde_2018_mixtures_of_g-priors_in_generalized_linear_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/li_clyde_2018_mixtures_of_g-priors_in_generalized_linear_models.pdf:application/pdf}
}

@article{xiao_robust_nodate,
	title = {Robust regression for optimal individualized treatment rules},
	volume = {0},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8102},
	doi = {10.1002/sim.8102},
	abstract = {Because different patients may respond quite differently to the same drug or treatment, there is an increasing interest in discovering individualized treatment rules. In particular, there is an emerging need to find optimal individualized treatment rules, which would lead to the “best” clinical outcome. In this paper, we propose a new class of loss functions and estimators based on robust regression to estimate the optimal individualized treatment rules. Compared to existing estimation methods in the literature, the new estimators are novel and advantageous in the following aspects. First, they are robust against skewed, heterogeneous, heavy-tailed errors or outliers in data. Second, they are robust against a misspecification of the baseline function. Third, under some general situations, the new estimator coupled with the pinball loss approximately maximizes the outcome's conditional quantile instead of the conditional mean, which leads to a more robust optimal individualized treatment rule than the traditional mean-based estimators. Consistency and asymptotic normality of the proposed estimators are established. Their empirical performance is demonstrated via extensive simulation studies and an analysis of an {AIDS} data set.},
	number = {0},
	journaltitle = {Statistics in Medicine},
	author = {Xiao, W. and Zhang, H. H. and Lu, W.},
	urldate = {2019-02-11},
	langid = {english},
	keywords = {optimal individualized treatment rules, personalized medicine, quantile regression, robust regression},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/VMBG67U2/sim.html:text/html;xiao_et_al_robust_regression_for_optimal_individualized_treatment_rules.pdf:/home/nathan/Dropbox/njames/zotero_sync/xiao_et_al_robust_regression_for_optimal_individualized_treatment_rules.pdf:application/pdf}
}

@article{tomlinson_composite_2010,
	title = {Composite End Points in Randomized Trials: There Is No Free Lunch},
	volume = {303},
	issn = {0098-7484},
	url = {http://jama.jamanetwork.com/article.aspx?doi=10.1001/jama.2009.2017},
	doi = {10.1001/jama.2009.2017},
	shorttitle = {Composite End Points in Randomized Trials},
	pages = {267},
	number = {3},
	journaltitle = {{JAMA}},
	author = {Tomlinson, George and Detsky, Allan S.},
	urldate = {2019-02-12},
	date = {2010-01-20},
	langid = {english},
	file = {tomlinson_detsky_2010_composite_end_points_in_randomized_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/tomlinson_detsky_2010_composite_end_points_in_randomized_trials.pdf:application/pdf}
}

@online{harrell_musings_2018,
	title = {Musings on Multiple Endpoints in {RCTs}},
	url = {http://www.fharrell.com/post/ymult/},
	titleaddon = {Statistical Thinking},
	author = {Harrell, Frank E.},
	urldate = {2018-02-10},
	date = {2018-04-04}
}

@online{harrell_bayesian_2018,
	title = {Bayesian vs. Frequentist Statements About Treatment Efficacy},
	url = {http://www.fharrell.com/post/bayes-freq-stmts/},
	abstract = {To avoid “false positives” do away with “positive”.

A good poker player plays the odds by thinking to herself “The probability I can win with this hand is 0.91” and not “I’m going to win this game” when deciding the next move.

State conclusions honestly, completely deferring judgments and actions to the ultimate decision makers. Just as it is better to make predictions than classifications in prognosis and diagnosis, use the word “probably” liberally, and avoid thinking “the evidence against the null hypothesis is strong, so we conclude the treatment works” which creates the opportunity of a false positive.

Propagation of uncertainties throughout research, reporting, and implementation will result in better decision making and getting more data when needed. Imagine a physician saying to a patient “The chance this drug will lower your blood pressure by more than 3mmHg is 0.93.”},
	titleaddon = {Statistical Thinking},
	author = {Harrell, Frank E.},
	urldate = {2018-02-10},
	date = {2018-05-21}
}

@article{button_power_2013,
	title = {Power failure: why small sample size undermines the reliability of neuroscience},
	volume = {14},
	issn = {1471-003X, 1471-0048},
	url = {http://www.nature.com/articles/nrn3475},
	doi = {10.1038/nrn3475},
	shorttitle = {Power failure},
	abstract = {A study with low statistical power has a reduced chance of detecting a true effect, but it is less well appreciated that low power also reduces the likelihood that a statistically significant result reflects a true effect. Here, we show that the average statistical power of studies in the neurosciences is very low. The consequences of this include overestimates of effect size and low reproducibility of results. There are also ethical dimensions to this problem, as unreliable research is inefficient and wasteful. Improving reproducibility in neuroscience is a key priority and requires attention to well-established but often ignored methodological principles.},
	pages = {365--376},
	number = {5},
	journaltitle = {Nature Reviews Neuroscience},
	author = {Button, Katherine S. and Ioannidis, John P. A. and Mokrysz, Claire and Nosek, Brian A. and Flint, Jonathan and Robinson, Emma S. J. and Munafò, Marcus R.},
	urldate = {2019-02-12},
	date = {2013-05},
	langid = {english},
	file = {button_et_al_2013_power_failure.pdf:/home/nathan/Dropbox/njames/zotero_sync/button_et_al_2013_power_failure.pdf:application/pdf}
}

@article{mullins_its_2002,
	title = {'It's a {PhD}, not a Nobel Prize': How experienced examiners assess research theses},
	volume = {27},
	issn = {0307-5079, 1470-174X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/0307507022000011507},
	doi = {10.1080/0307507022000011507},
	shorttitle = {'It's a {PhD}, not a Nobel Prize'},
	abstract = {Research to date on the examination process for postgraduate research theses has focused largely on the deconstruction of examiners’ reports. This article reports on a study of the processes that experienced examiners go through, and the judgements they make before writing their reports. A sample of 30 experienced examiners (de ned as having examined the equivalent of at least ve research theses over the last ve years), from a range of disciplines in ve universities was interviewed. Clear trends emerged with regard to: the criteria used by examiners and the levels of student performance expected by them; critical judgement points in the examination process; the examiners’ perceptions of their own role in the process; the in uence on examiners of previously published work, the views of the other examiner(s) and their knowledge of the student’s supervisor and/or department, and the level of perceived responsibility between student and supervisor.},
	pages = {369--386},
	number = {4},
	journaltitle = {Studies in Higher Education},
	author = {Mullins, Gerry and Kiley, Margaret},
	urldate = {2019-02-12},
	date = {2002-10},
	langid = {english},
	file = {mullins_kiley_2002_'it's_a_phd,_not_a_nobel_prize'.pdf:/home/nathan/Dropbox/njames/zotero_sync/mullins_kiley_2002_'it's_a_phd,_not_a_nobel_prize'.pdf:application/pdf}
}

@article{hellmuth_rise_2019,
	title = {The Rise of Pseudomedicine for Dementia and Brain Health},
	volume = {321},
	issn = {0098-7484},
	url = {http://jama.jamanetwork.com/article.aspx?doi=10.1001/jama.2018.21560},
	doi = {10.1001/jama.2018.21560},
	pages = {543},
	number = {6},
	journaltitle = {{JAMA}},
	author = {Hellmuth, Joanna and Rabinovici, Gil D. and Miller, Bruce L.},
	urldate = {2019-02-12},
	date = {2019-02-12},
	langid = {english},
	file = {hellmuth_et_al_2019_the_rise_of_pseudomedicine_for_dementia_and_brain_health.pdf:/home/nathan/Dropbox/njames/zotero_sync/hellmuth_et_al_2019_the_rise_of_pseudomedicine_for_dementia_and_brain_health.pdf:application/pdf}
}

@article{scarsini_measures_1984,
	title = {On Measures of Concordance},
	volume = {8},
	url = {http://eudml.org/doc/38916},
	abstract = {We give a general definition of concordance and a set of axioms for measures of concordance. We then consider a family of measures satisfying these axioms. We compare our results with known results, in the discrete case.},
	pages = {201--218},
	number = {3},
	journaltitle = {Stochastica},
	author = {Scarsini, Marco},
	date = {1984},
	file = {scarsini_1984_on_measures_of_concordance.pdf:/home/nathan/Dropbox/njames/zotero_sync/scarsini_1984_on_measures_of_concordance.pdf:application/pdf}
}

@article{doi_introduction_2019,
	title = {Introduction to Intersection-Union Tests},
	url = {https://www.researchgate.net/publication/255609707_INTRODUCTION_TO_INTERSECTION-UNION_TESTS},
	abstract = {The Intersection-Union Test ({IU} T ) has become increasingly popular, especially through its application in bioequivalence testing. Here we will provide a basic introduction and discuss some properties of the {IU} T . Since this method is based upon a combination of tests, there may be a concern for the need of a multiplicity adjustment to adequately control the overall type-I error rate. We will address this issue by considering two theorems. The ﬁrst describes how the {IU} T can be level-α and the second shows under what conditions the test is size-α. Both results do not require any multiplicity adjustment. A simple example from acceptance sampling will be used to apply these theorems, and we will examine Monte Carlo simulations to verify the expected results.},
	pages = {11},
	author = {Doi, Jimmy A},
	date = {2019},
	langid = {english},
	file = {doi_introduction_to_intersection-union_tests.pdf:/home/nathan/Dropbox/njames/zotero_sync/doi_introduction_to_intersection-union_tests.pdf:application/pdf}
}

@article{swihart_unifying_2014,
	title = {A Unifying Framework for Marginalised Random-Intercept Models of Correlated Binary Outcomes: Framework for Marginalised Random-Intercept Models},
	volume = {82},
	issn = {03067734},
	url = {http://doi.wiley.com/10.1111/insr.12035},
	doi = {10.1111/insr.12035},
	shorttitle = {A Unifying Framework for Marginalised Random-Intercept Models of Correlated Binary Outcomes},
	abstract = {We demonstrate that many current approaches for marginal modeling of correlated binary outcomes produce likelihoods that are equivalent to the copula-based models herein. These general copula models of underlying latent threshold random variables yield likelihood-based models for marginal fixed effects estimation and interpretation in the analysis of correlated binary data with exchangeable correlation structures. Moreover, we propose a nomenclature and set of model relationships that substantially elucidates the complex area of marginalized random intercept models for binary data. A diverse collection of didactic mathematical and numerical examples are given to illustrate concepts.},
	pages = {275--295},
	number = {2},
	journaltitle = {International Statistical Review},
	author = {Swihart, Bruce J. and Caffo, Brian S. and Crainiceanu, Ciprian M.},
	urldate = {2019-02-23},
	date = {2014-08},
	langid = {english},
	file = {swihart_et_al_2014_a_unifying_framework_for_marginalised_random-intercept_models_of_correlated.pdf:/home/nathan/Dropbox/njames/zotero_sync/swihart_et_al_2014_a_unifying_framework_for_marginalised_random-intercept_models_of_correlated.pdf:application/pdf}
}

@article{parzen_writing_nodate,
	title = {Writing the Gaussian Copula as a non-linear mixed eﬀects model},
	abstract = {A popular modern approach for modelling correlated non-normal outcome data, where the outcome data is assumed to follow a speciﬁed non-normal marginal distribution is through use of a Gaussian Copula, with estimation via maximum likelihood. Unfortunately, no simple software exists in the literature to obtain the maximum likelihood estimates. In this note, we show that, by rewriting the underlying normal variables of the copula as a linear mixed model, easily available software such as {PROC} {NLMIXED} in {SAS} or the {NLME} function in {SPLUS} can be used to estimate the parameters of the Gaussian Copula via maximum likelihood.},
	pages = {7},
	author = {Parzen, Michael and Lipsitz, Stuart R and Ibrahim, Joseph G and Sinha, Debajyoti},
	langid = {english},
	file = {parzen_et_al_writing_the_gaussian_copula_as_a_non-linear_mixed_eﬀects_model.pdf:/home/nathan/Dropbox/njames/zotero_sync/parzen_et_al_writing_the_gaussian_copula_as_a_non-linear_mixed_eﬀects_model.pdf:application/pdf}
}

@article{das_skew-normal_2016,
	title = {A Skew-Normal Copula-Driven {GLMM}},
	volume = {70},
	issn = {00390402},
	url = {http://arxiv.org/abs/1707.09565},
	doi = {10.1111/stan.12092},
	abstract = {This paper presents a method for ﬁtting a copula-driven generalized linear mixed models. For added ﬂexibility, the skew-normal copula is adopted for ﬁtting. The correlation matrix of the skew-normal copula is used to capture the dependence structure within units, while the ﬁxed and random eﬀects coeﬃcients are estimated through the mean of the copula. For estimation, a Monte Carlo expectation-maximization algorithm is developed. Simulations are shown alongside a real data example from the Framingham Heart Study.},
	pages = {396--413},
	number = {4},
	journaltitle = {Statistica Neerlandica},
	author = {Das, Kalyan and Elmasri, Mohamad and Sen, Arusharka},
	urldate = {2019-02-23},
	date = {2016-11},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1707.09565},
	keywords = {Statistics - Methodology},
	file = {Das et al. - 2016 - A Skew-Normal Copula-Driven GLMM.pdf:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/SR4CAVR9/Das et al. - 2016 - A Skew-Normal Copula-Driven GLMM.pdf:application/pdf}
}

@article{nikoloulopoulos_mixed_2015,
	title = {A mixed effect model for bivariate meta-analysis of diagnostic test accuracy studies using a copula representation of the random effects distribution},
	volume = {34},
	issn = {02776715},
	url = {http://arxiv.org/abs/1502.07505},
	doi = {10.1002/sim.6595},
	abstract = {Diagnostic test accuracy studies typically report the number of true positives, false positives, true negatives and false negatives. There usually exists a negative association between the number of true positives and true negatives, because studies that adopt less stringent criterion for declaring a test positive invoke higher sensitivities and lower speciﬁcities. A generalized linear mixed model ({GLMM}) is currently recommended to synthesize diagnostic test accuracy studies. We propose a copula mixed model for bivariate meta-analysis of diagnostic test accuracy studies. Our general model includes the {GLMM} as a special case and can also operate on the original scale of sensitivity and speciﬁcity. Summary receiver operating characteristic curves are deduced for the proposed model through quantile regression techniques and different characterizations of the bivariate random effects distribution. Our general methodology is demonstrated with an extensive simulation study and illustrated by re-analysing the data of two published meta-analyses. Our study suggests that there can be an improvement on {GLMM} in ﬁt to data and makes the argument for moving to copula random effects models. Our modelling framework is implemented in the package {CopulaREMADA} within the open source statistical environment R.},
	pages = {3842--3865},
	number = {29},
	journaltitle = {Statistics in Medicine},
	author = {Nikoloulopoulos, Aristidis K.},
	urldate = {2019-02-23},
	date = {2015-12-20},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1502.07505},
	keywords = {Statistics - Methodology, Statistics - Applications},
	file = {nikoloulopoulos_2015_a_mixed_effect_model_for_bivariate_meta-analysis_of_diagnostic_test_accuracy.pdf:/home/nathan/Dropbox/njames/zotero_sync/nikoloulopoulos_2015_a_mixed_effect_model_for_bivariate_meta-analysis_of_diagnostic_test_accuracy.pdf:application/pdf}
}

@article{mondol_bias-reduced_nodate,
	title = {Bias-reduced and separation-proof {GEE} with small or sparse longitudinal binary data},
	volume = {0},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8126},
	doi = {10.1002/sim.8126},
	abstract = {Generalized estimating equation ({GEE}) is a popular approach for analyzing correlated binary data. However, the problems of separation in {GEE} are still unknown. The separation created by a covariate often occurs in small correlated binary data and even in large data with rare outcome and/or high intra-cluster correlation and a number of influential covariates. This paper investigated the consequences of separation in {GEE} and addressed them by introducing a penalized {GEE}, termed as {PGEE}. The {PGEE} is obtained by adding Firth-type penalty term, which was originally proposed for generalized linear model score equation, to standard {GEE} and shown to achieve convergence and provide finite estimate of the regression coefficient in the presence of separation, which are not often possible in {GEE}. Further, a small-sample bias correction to the sandwich covariance estimator of the {PGEE} estimator is suggested. Simulations also showed that the {GEE} failed to achieve convergence and/or provided infinitely large estimate of the regression coefficient in the presence of complete or quasi-complete separation, whereas the {PGEE} showed significant improvement by achieving convergence and providing finite estimate. Even in the presence of near-to-separation, the {PGEE} also showed superior properties over the {GEE}. Furthermore, the bias-corrected sandwich estimator for the {PGEE} estimator showed substantial improvement over the standard sandwich estimator by reducing bias in estimating type I error rate. An illustration using real data also supported the findings of simulation. The {PGEE} with bias-corrected sandwich covariance estimator is recommended to use for small-to-moderate size sample (N ≤ 50) and even can be used for large sample if there is any evidence of separation or near-to-separation.},
	number = {0},
	journaltitle = {Statistics in Medicine},
	author = {Mondol, Momenul Haque and Rahman, M. Shafiqur},
	urldate = {2019-02-25},
	langid = {english},
	keywords = {bias reduction, marginal model, quasi-likelihood, separation, strong risk factors},
	file = {mondol_rahman_bias-reduced_and_separation-proof_gee_with_small_or_sparse_longitudinal_binary.pdf:/home/nathan/Dropbox/njames/zotero_sync/mondol_rahman_bias-reduced_and_separation-proof_gee_with_small_or_sparse_longitudinal_binary.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/IBCAAKBK/sim.html:text/html}
}

@article{gewandter_demonstrating_nodate,
	title = {Demonstrating heterogeneity of treatment effects among patients: an overlooked but important step toward precision medicine},
	volume = {0},
	issn = {1532-6535},
	url = {https://ascpt.onlinelibrary.wiley.com/doi/abs/10.1002/cpt.1372},
	doi = {10.1002/cpt.1372},
	shorttitle = {Demonstrating heterogeneity of treatment effects among patients},
	abstract = {Although heterogeneity in the observed outcomes in clinical trials is often assumed to reflect a true heterogeneous response, it could actually be due to random variability. This retrospective analysis of 4 randomized, double-blind, placebo-controlled multi-period (i.e., episode) cross-over trials of fentanyl for breakthrough cancer pain illustrates the use of multi-period cross-over trials to examine heterogeneity of treatment response. A mixed effects model including fixed effects for treatment and episode and random effects for patient and treatment-by-patient interaction was used to assess the heterogeneity in patients’ responses to treatment during each episode. A significant treatment-by-patient interaction was found for 3 of 4 trials (p {\textless} 0.05), suggesting heterogeneity of the effect of fentanyl among different patients in each trial. Similar analyses in other therapeutic areas could identify conditions and therapies that should be investigated further for predictors of treatment response in efforts to maximize the efficiency of developing precision medicine strategies. This article is protected by copyright. All rights reserved.},
	issue = {ja},
	journaltitle = {Clinical Pharmacology \& Therapeutics},
	author = {Gewandter, Jennifer S. and {McDermott}, Michael P. and He, Hua and Gao, Shan and Cai, Xueya and Farrar, John T. and Katz, Nathaniel P. and Markman, John D. and Senn, Stephen and Turk, Dennis C. and Dworkin, Robert H.},
	urldate = {2019-03-12},
	langid = {english},
	keywords = {heterogeneity, multi-period cross-over trials, Precision or personalized medicine},
	file = {gewandter_et_al_demonstrating_heterogeneity_of_treatment_effects_among_patients.pdf:/home/nathan/Dropbox/njames/zotero_sync/gewandter_et_al_demonstrating_heterogeneity_of_treatment_effects_among_patients.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/TF55UW3U/cpt.html:text/html}
}

@article{larremore_efficiently_2014,
	title = {Efficiently inferring community structure in bipartite networks},
	volume = {90},
	issn = {1539-3755, 1550-2376},
	url = {http://arxiv.org/abs/1403.2933},
	doi = {10.1103/PhysRevE.90.012805},
	abstract = {Bipartite networks are a common type of network data in which there are two types of vertices, and only vertices of different types can be connected. While bipartite networks exhibit community structure like their unipartite counterparts, existing approaches to bipartite community detection have drawbacks, including implicit parameter choices, loss of information through one-mode projections, and lack of interpretability. Here we solve the community detection problem for bipartite networks by formulating a bipartite stochastic block model, which explicitly includes vertex type information and may be trivially extended to \$k\$-partite networks. This bipartite stochastic block model yields a projection-free and statistically principled method for community detection that makes clear assumptions and parameter choices and yields interpretable results. We demonstrate this model's ability to efficiently and accurately find community structure in synthetic bipartite networks with known structure and in real-world bipartite networks with unknown structure, and we characterize its performance in practical contexts.},
	number = {1},
	journaltitle = {Physical Review E},
	author = {Larremore, Daniel B. and Clauset, Aaron and Jacobs, Abigail Z.},
	urldate = {2019-03-12},
	date = {2014-07-10},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1403.2933},
	keywords = {Statistics - Machine Learning, Computer Science - Social and Information Networks, Physics - Data Analysis, Statistics and Probability, Physics - Physics and Society, Quantitative Biology - Quantitative Methods},
	file = {larremore_et_al_2014_efficiently_inferring_community_structure_in_bipartite_networks.pdf:/home/nathan/Dropbox/njames/zotero_sync/larremore_et_al_2014_efficiently_inferring_community_structure_in_bipartite_networks.pdf:application/pdf}
}

@article{rosenbaum_central_1983-1,
	title = {The Central Role of the Propensity Score in Observational Studies for Causal Effects},
	volume = {70},
	issn = {00063444},
	url = {https://www.jstor.org/stable/2335942?origin=crossref},
	doi = {10.2307/2335942},
	pages = {41},
	number = {1},
	journaltitle = {Biometrika},
	author = {Rosenbaum, Paul R. and Rubin, Donald B.},
	urldate = {2019-03-21},
	date = {1983-04},
	file = {rosenbaum_rubin_1983_the_central_role_of_the_propensity_score_in_observational_studies_for_causal.pdf:/home/nathan/Dropbox/njames/zotero_sync/rosenbaum_rubin_1983_the_central_role_of_the_propensity_score_in_observational_studies_for_causal.pdf:application/pdf}
}

@article{rubin_bayesian_1978,
	title = {Bayesian Inference for Causal Effects: The Role of Randomization},
	volume = {6},
	url = {http://www.jstor.org/stable/2958688},
	pages = {34--58},
	number = {1},
	journaltitle = {The Annals of Statistics},
	author = {Rubin, Donald B.},
	date = {1978},
	langid = {english},
	file = {rubin_1978_bayesian_inference_for_causal_effects.pdf:/home/nathan/Dropbox/njames/zotero_sync/rubin_1978_bayesian_inference_for_causal_effects.pdf:application/pdf}
}

@article{renfro_impact_2015,
	title = {Impact of Copula Directional Specification on Multi-Trial Evaluation of Surrogate End Points},
	volume = {25},
	issn = {1054-3406, 1520-5711},
	url = {http://www.tandfonline.com/doi/full/10.1080/10543406.2014.920870},
	doi = {10.1080/10543406.2014.920870},
	abstract = {Evaluation of surrogate endpoints using patient-level data from multiple trials is the gold standard, where multi-trial copula models are used to quantify both patient-level and trial-level surrogacy. While limited consideration has been given in the literature to copula choice (e.g., Clayton), no prior consideration has been given to direction of implementation (via survival versus distribution functions). We demonstrate that evenwith the “correct” copula family, directional misspecification leads to biased estimates of patient-level and trial-level surrogacy. We illustrate with a simulation study and a re-analysis of disease-free survival as a surrogate for overall survival in early stage colon cancer.},
	pages = {857--877},
	number = {4},
	journaltitle = {Journal of Biopharmaceutical Statistics},
	author = {Renfro, Lindsay A. and Shang, Hongwei and Sargent, Daniel J.},
	urldate = {2019-03-26},
	date = {2015-07-04},
	langid = {english},
	file = {renfro_et_al_2015_impact_of_copula_directional_specification_on_multi-trial_evaluation_of.pdf:/home/nathan/Dropbox/njames/zotero_sync/renfro_et_al_2015_impact_of_copula_directional_specification_on_multi-trial_evaluation_of.pdf:application/pdf}
}

@article{blume_introduction_2019,
	title = {An Introduction to Second-Generation p-Values},
	volume = {73},
	issn = {0003-1305, 1537-2731},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1537893},
	doi = {10.1080/00031305.2018.1537893},
	abstract = {Second generation p-values preserve the simplicity that has made p-values popular while resolving critical flaws that promote misinterpretation of data, distraction by trivial effects, and unreproducible assessments of data. The second-generation p-value ({SGPV}) is an extension that formally accounts for scientific relevance by using a composite null hypothesis that captures null and scientifically trivial effects. Because the majority of spurious findings are small effects that are technically nonnull but practically indistinguishable from the null, the second-generation approach greatly reduces the likelihood of a false discovery. {SGPVs} promote transparency, rigor and reproducibility of scientific results by a priori identifying which candidate hypotheses are practically meaningful and by providing a more reliable statistical summary of when the data are compatible with the candidate hypotheses or null hypotheses, or when the data are inconclusive. We illustrate the importance of these advances using a dataset of 247,000 single-nucleotide polymorphisms, i.e., genetic markers that are potentially associated with prostate cancer.},
	pages = {157--167},
	issue = {sup1},
	journaltitle = {The American Statistician},
	author = {Blume, Jeffrey D. and Greevy, Robert A. and Welty, Valerie F. and Smith, Jeffrey R. and Dupont, William D.},
	urldate = {2019-03-29},
	date = {2019-03-29},
	langid = {english},
	file = {blume_et_al_2019_an_introduction_to_second-generation_p-values.pdf:/home/nathan/Dropbox/njames/zotero_sync/blume_et_al_2019_an_introduction_to_second-generation_p-values.pdf:application/pdf}
}

@article{blume_second-generation_2018,
	title = {Second-generation p-values: Improved rigor, reproducibility, \& transparency in statistical analyses},
	volume = {13},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0188299},
	doi = {10.1371/journal.pone.0188299},
	shorttitle = {Second-generation p-values},
	pages = {e0188299},
	number = {3},
	journaltitle = {{PLOS} {ONE}},
	author = {Blume, Jeffrey D. and D’Agostino {McGowan}, Lucy and Dupont, William D. and Greevy, Robert A.},
	editor = {Smalheiser, Neil R.},
	urldate = {2019-03-29},
	date = {2018-03-22},
	langid = {english},
	file = {blume_et_al_2018_second-generation_p-values.pdf:/home/nathan/Dropbox/njames/zotero_sync/blume_et_al_2018_second-generation_p-values.pdf:application/pdf}
}

@article{chapple_bayesian_2017,
	title = {Bayesian variable selection for a semi-competing risks model with three hazard functions},
	volume = {112},
	issn = {01679473},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167947317300464},
	doi = {10.1016/j.csda.2017.03.002},
	abstract = {A variable selection procedure is developed for a semi-competing risks regression model with three hazard functions that uses spike-and-slab priors and stochastic search variable selection algorithms for posterior inference. A rule is devised for choosing the threshold on the marginal posterior probability of variable inclusion based on the Deviance Information Criterion ({DIC}) that is examined in a simulation study. The method is applied to data from esophageal cancer patients from the {MD} Anderson Cancer Center, Houston, {TX}, where the most important covariates are selected in each of the hazards of effusion, death before effusion, and death after effusion. The {DIC} procedure that is proposed leads to similar selected models regardless of the choices of some of the hyperparameters. The application results show that patients with intensity-modulated radiation therapy have significantly reduced risks of pericardial effusion, pleural effusion, and death before either effusion type. © 2017 Elsevier B.V. All rights reserved.},
	pages = {170--185},
	journaltitle = {Computational Statistics \& Data Analysis},
	author = {Chapple, Andrew G. and Vannucci, Marina and Thall, Peter F. and Lin, Steven},
	urldate = {2019-03-29},
	date = {2017-08},
	langid = {english},
	file = {chapple_et_al_2017_bayesian_variable_selection_for_a_semi-competing_risks_model_with_three_hazard.pdf:/home/nathan/Dropbox/njames/zotero_sync/chapple_et_al_2017_bayesian_variable_selection_for_a_semi-competing_risks_model_with_three_hazard.pdf:application/pdf}
}

@article{faes_effective_2009,
	title = {The Effective Sample Size and an Alternative Small-Sample Degrees-of-Freedom Method},
	volume = {63},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1198/tast.2009.08196},
	doi = {10.1198/tast.2009.08196},
	pages = {389--399},
	number = {4},
	journaltitle = {The American Statistician},
	author = {Faes, Christel and Molenberghs, Geert and Aerts, Marc and Verbeke, Geert and Kenward, Michael G.},
	urldate = {2019-03-31},
	date = {2009-11},
	langid = {english},
	file = {faes_et_al_2009_the_effective_sample_size_and_an_alternative_small-sample_degrees-of-freedom.pdf:/home/nathan/Dropbox/njames/zotero_sync/faes_et_al_2009_the_effective_sample_size_and_an_alternative_small-sample_degrees-of-freedom.pdf:application/pdf}
}

@article{van_der_pas_merged_2019,
	title = {Merged block randomisation: A novel randomisation procedure for small clinical trials},
	issn = {1740-7745, 1740-7753},
	url = {http://journals.sagepub.com/doi/10.1177/1740774519827957},
	doi = {10.1177/1740774519827957},
	shorttitle = {Merged block randomisation},
	abstract = {Background/Aims: Randomisation in small clinical trials is a delicate matter, due to the tension between the conflicting aims of balanced groups and unpredictable allocations. The commonly used method of permuted block randomisation has been heavily criticised for its high predictability. This article introduces merged block randomisation, a novel and conceptually simple restricted randomisation design for small clinical trials (less than 100 patients per stratum). Merged block randomisation is a simple procedure that can be carried out without need for a computer. Merged block randomisation is not restricted to 1:1 randomisation, but is readily applied to unequal target allocations and to more than two treatment groups.
Methods: The position of merged block randomisation on the spectrum of balance and predictability is investigated in a simulation study, in two common situations: a single-centre study and a multicentre study (with sampling stratified per centre). Methods included for comparison were permuted block randomisation, Efron’s biased coin design, the maximal procedure, the block urn design and the big stick design.
Results: Compared to permuted block randomisation with blocks of size 4, merged block randomisation has the same maximum tolerated imbalance and is thus as impervious to chronological bias, with the added benefit of being less predictable. Each method in the study takes a different position on the balance/determinism spectrum, and none was uniformly best. Merged block randomisation was either less predictable or more balanced than the other methods, in all simulation settings.
Conclusion: Merged block randomisation is a versatile restricted randomisation method that outperforms permuted block randomisation and is a good choice for small clinical trials where imbalance is a main concern, especially in multicentre trials where the number of patients per centre may be small.},
	pages = {174077451982795},
	journaltitle = {Clinical Trials},
	author = {van der Pas, Stéphanie L},
	urldate = {2019-04-02},
	date = {2019-02-14},
	langid = {english},
	file = {van_der_pas_2019_merged_block_randomisation.pdf:/home/nathan/Dropbox/njames/zotero_sync/van_der_pas_2019_merged_block_randomisation.pdf:application/pdf}
}

@article{choodari-oskooei_adding_2019,
	title = {Adding new experimental arms to randomised clinical trials: impact on error rates},
	url = {http://arxiv.org/abs/1902.05336},
	shorttitle = {Adding new experimental arms to randomised clinical trials},
	abstract = {Background: Experimental treatments pass through various stages of development. If a treatment passes through early phase experiments, the investigators may want to assess it in a late phase randomised controlled trial. An eﬃcient way to do this is adding it as a new research arm to an ongoing trial. This allows to add the new treatment while the existing arms continue. The familywise type I error rate ({FWER}) is often a key quantity of interest in any multi-arm trial. We set out to clarify how it should be calculated when new arms are added to a trial some time after it has started.
Methods: We show how the {FWER}, any-pair and all-pairs powers can be calculated when a new arm is added to a platform trial. We extend the Dunnett probability and derive analytical formulae for the correlation between the test statistics of the existing pairwise comparison and that of the newly added arm. We also verify our analytical derivation via simulations.
Results: Our results indicate that the {FWER} depends on the shared control arm information (i.e. individuals in continuous and binary outcomes and primary outcome events in time-to-event outcomes) from the common control arm patients and the allocation ratio. The {FWER} is driven more by the number of pairwise comparisons and the corresponding (pairwise) Type I error rates than by the timing of the addition of the new arms. The {FWER} can be estimated using Sˇid´ak’s correction if the correlation between the test statistics of pairwise comparisons is less than 0.30.
Conclusions: The ﬁndings we present in this article can be used to design trials with pre-planned deferred arms or to design new pairwise comparisons within an ongoing platform trial where control of the pairwise error rate ({PWER}) or {FWER} (for a subset of pairwise comparisons) is required.},
	journaltitle = {{arXiv}:1902.05336 [stat]},
	author = {Choodari-Oskooei, Babak and Bratton, Daniel J. and Gannon, Melissa R. and Meade, Angela M. and Sydes, Matthew R. and Parmar, Mahesh {KB}},
	urldate = {2019-04-02},
	date = {2019-02-14},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1902.05336},
	keywords = {Statistics - Methodology},
	file = {choodari-oskooei_et_al_2019_adding_new_experimental_arms_to_randomised_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/choodari-oskooei_et_al_2019_adding_new_experimental_arms_to_randomised_clinical_trials.pdf:application/pdf}
}

@article{kroncke_bayesian_2019,
	title = {A Bayesian method using sparse data to estimate penetrance of disease-associated genetic variants},
	url = {http://biorxiv.org/lookup/doi/10.1101/571158},
	doi = {10.1101/571158},
	abstract = {Purpose: A major challenge in genomic medicine is how to best predict risk of disease from rare variants discovered in Mendelian disease genes but with limited phenotypic data. We have recently used Bayesian methods to show that in vitro functional measurements and computational pathogenicity classification of variants in the cardiac gene {SCN}5A correlate with rare arrhythmia penetrance. We hypothesized that similar predictors could be used to impute variant-specific penetrance prior probabilities.
Methods: From a review of 756 publications, we developed a pattern mixture algorithm, based on a Bayesian Beta-Binomial model, to generate {SCN}5A variant-specific penetrance priors for the heart arrhythmia Brugada syndrome ({BrS}).
Results: The resulting priors correlate with mean {BrS} penetrance posteriors (cross validated R2 = 0.41). {SCN}5A variant function and structural context provide the most information predictive of {BrS} penetrance. The resulting priors are interpretable as equivalent to the observation of affected and unaffected carriers.
Conclusions: Bayesian estimates of penetrance can efficiently integrate variant-specific data (e.g. functional, structural, and sequence) to accurately estimate disease risk attributable to individual variants. We suggest this formulation of penetrance is quantitative, probabilistic, and more precise than, but consistent with, discrete pathogenicity classification approaches.},
	journaltitle = {{bioRxiv}},
	author = {Kroncke, Brett M. and Smith, Derek K. and Glazer, Andrew M. and Roden, Dan M. and Blume, Jeffrey D.},
	urldate = {2019-04-02},
	date = {2019-03-07},
	langid = {english},
	file = {kroncke_et_al_2019_a_bayesian_method_using_sparse_data_to_estimate_penetrance_of.pdf:/home/nathan/Dropbox/njames/zotero_sync/kroncke_et_al_2019_a_bayesian_method_using_sparse_data_to_estimate_penetrance_of.pdf:application/pdf}
}

@article{vehtari_rank-normalization_2019,
	title = {Rank-normalization, folding, and localization: An improved \${\textbackslash}widehat\{R\}\$ for assessing convergence of {MCMC}},
	url = {http://arxiv.org/abs/1903.08008},
	shorttitle = {Rank-normalization, folding, and localization},
	abstract = {Markov chain Monte Carlo is a key computational tool in Bayesian statistics, but it can be challenging to monitor the convergence of an iterative stochastic algorithm. In this paper we show that the convergence diagnostic R of Gelman and Rubin (1992) has serious ﬂaws and we propose an alternative that ﬁxes them. We also introduce a collection of quantile-based local eﬃciency measures, along with a practical approach for computing Monte Carlo error estimates for quantiles. We suggest that common trace plots should be replaced with rank plots from multiple chains. Finally, we give concrete recommendations for how these methods should be used in practice.},
	journaltitle = {{arXiv}:1903.08008 [stat]},
	author = {Vehtari, Aki and Gelman, Andrew and Simpson, Daniel and Carpenter, Bob and Bürkner, Paul-Christian},
	urldate = {2019-04-02},
	date = {2019-03-19},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1903.08008},
	keywords = {Statistics - Methodology, Statistics - Computation},
	file = {vehtari_et_al_2019_rank-normalization,_folding,_and_localization.pdf:/home/nathan/Dropbox/njames/zotero_sync/vehtari_et_al_2019_rank-normalization,_folding,_and_localization.pdf:application/pdf}
}

@article{quartey_statistical_2012,
	title = {Statistical aspects in comparative benefit-risk assessment: challenges and opportunities for pharmaceutical statisticians},
	volume = {11},
	issn = {1539-1612},
	url = {https://www.onlinelibrary.wiley.com/doi/abs/10.1002/pst.497},
	doi = {10.1002/pst.497},
	shorttitle = {Statistical aspects in comparative benefit-risk assessment},
	abstract = {{AbstractBenefit}–risk assessment is a fundamental element of drug development with the aim to strengthen decision making for the benefit of public health. Appropriate benefit-risk assessment can provide useful information for proactive intervention in health care settings, which could save lives, reduce litigation, improve patient safety and health care outcomes, and furthermore, lower overall health care costs. Recent development in this area presents challenges and opportunities to statisticians in the pharmaceutical industry. We review the development and examine statistical issues in comparative benefit-risk assessment. We argue that a structured benefit-risk assessment should be a multi-disciplinary effort involving experts in clinical science, safety assessment, decision science, health economics, epidemiology and statistics. Well planned and conducted analyses with clear consideration on benefit and risk are critical for appropriate benefit–risk assessment. Pharmaceutical statisticians should extend their knowledge to relevant areas such as pharmaco-epidemiology, decision analysis, modeling, and simulation to play an increasingly important role in comparative benefit–risk assessment. Copyright © 2011 John Wiley \& Sons, Ltd.},
	pages = {82--85},
	number = {1},
	journaltitle = {Pharmaceutical Statistics},
	author = {Quartey, George and Wang, Jixian},
	urldate = {2019-04-03},
	date = {2012},
	langid = {english},
	keywords = {benefit-risk, comparative benefit-risk, quantitative benefit-risk methods},
	file = {quartey_wang_2012_statistical_aspects_in_comparative_benefit-risk_assessment.pdf:/home/nathan/Dropbox/njames/zotero_sync/quartey_wang_2012_statistical_aspects_in_comparative_benefit-risk_assessment.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/PEMGV9GT/pst.html:text/html}
}

@article{leong_is_2013,
	title = {Is there a need for a universal benefit–risk assessment framework for medicines? Regulatory and industry perspectives},
	volume = {22},
	issn = {1099-1557},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pds.3464},
	doi = {10.1002/pds.3464},
	shorttitle = {Is there a need for a universal benefit–risk assessment framework for medicines?},
	abstract = {Purpose To explore the current status and need for a universal benefit–risk framework for medicines in regulatory agencies and pharmaceutical companies. Methods A questionnaire was developed and sent to 14 mature regulatory agencies and 24 major companies. The data were analysed using descriptive statistics, for a minority of questions preceded by manual grouping of the responses. Results Overall response rate was 82\%, and study participants included key decision makers from agencies and companies. None used a fully quantitative system, most companies preferring a qualitative method. The major reasons for this group not using semi-quantitative or quantitative systems were lack of a universal and scientifically validated framework. The main advantages of a benefit–risk framework were that it provided a systematic standardised approach to decision-making and that it acted as a tool to enhance quality of communication. It was also reported that a framework should be of value to both agencies and companies throughout the life cycle of a product. They believed that it is possible to develop an overarching benefit–risk framework that should involve relevant stakeholders in the development, validation and application of a universal framework. The entire cohort indicated common barriers to implementing a framework were resource limitations, a lack of knowledge and a scientifically validated and acceptable framework. Conclusions Stakeholders prefer a semi-quantitative, overarching framework that incorporates a toolbox of different methodologies. A coordinating committee of relevant stakeholders should be formed to guide its development and implementation. Through engaging the stakeholders, these outcomes confirm sentiments and need for developing a universal benefit–risk assessment framework. Copyright © 2013 John Wiley \& Sons, Ltd.},
	pages = {1004--1012},
	number = {9},
	journaltitle = {Pharmacoepidemiology and Drug Safety},
	author = {Leong, James and {McAuslane}, Neil and Walker, Stuart and Salek, Sam},
	urldate = {2019-04-03},
	date = {2013},
	langid = {english},
	keywords = {benefit–risk assessment, benefit–risk methodologies, framework, pharmaceutical industry, pharmacoepidemiology, regulatory agency, universal},
	file = {leong_et_al_2013_is_there_a_need_for_a_universal_benefit–risk_assessment_framework_for_medicines.pdf:/home/nathan/Dropbox/njames/zotero_sync/leong_et_al_2013_is_there_a_need_for_a_universal_benefit–risk_assessment_framework_for_medicines.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/AX72HTHZ/pds.html:text/html}
}

@article{walker_refining_2011,
	title = {Refining the Benefit–Risk Framework for the Assessment of Medicines: Valuing and Weighting Benefit and Risk Parameters},
	volume = {89},
	issn = {1532-6535},
	url = {https://ascpt.onlinelibrary.wiley.com/doi/abs/10.1038/clpt.2010.290},
	doi = {10.1038/clpt.2010.290},
	shorttitle = {Refining the Benefit–Risk Framework for the Assessment of Medicines},
	abstract = {A common framework is necessary for the transparent articulation of the benefits and risks of a therapeutic product across disparate stakeholders. The assignment of value and weighting to each component parameter presents challenges deriving from different stakeholder objectives, methods, and perspectives. Building on prior experiences with a validated framework approach, this forum focused on identifying challenges and approaches to the assignment of values and weightings using a case study applied to a hypothetical medicinal product. Clinical Pharmacology \& Therapeutics (2011) 89 2, 179–182. doi:10.1038/clpt.2010.290},
	pages = {179--182},
	number = {2},
	journaltitle = {Clinical Pharmacology \& Therapeutics},
	author = {Walker, S. and Liberti, L. and {McAuslane}, N.},
	urldate = {2019-04-03},
	date = {2011},
	langid = {english},
	file = {2011_corrigendum.pdf:/home/nathan/Dropbox/njames/zotero_sync/2011_corrigendum.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/R8IRZK3U/clpt.2010.html:text/html;walker_et_al_2011_refining_the_benefit–risk_framework_for_the_assessment_of_medicines.pdf:/home/nathan/Dropbox/njames/zotero_sync/walker_et_al_2011_refining_the_benefit–risk_framework_for_the_assessment_of_medicines.pdf:application/pdf}
}

@article{aaron_risk_nodate,
	title = {Risk and Benefit Evaluation in Development of Pharmaceutical Products},
	pages = {6},
	author = {Aaron, C S and Mayo, J K},
	langid = {english},
	file = {aaron_mayo_risk_and_benefit_evaluation_in_development_of_pharmaceutical_products.pdf:/home/nathan/Dropbox/njames/zotero_sync/aaron_mayo_risk_and_benefit_evaluation_in_development_of_pharmaceutical_products.pdf:application/pdf}
}

@article{xu_bayesian_nodate,
	title = {A Bayesian Nonparametric Approach for Evaluating the Eﬀect of Treatment in Randomized Trials with Semi-Competing Risks},
	abstract = {We develop a Bayesian nonparametric ({BNP}) approach to evaluate the eﬀect of treatment in a randomized trial where a nonterminal event may be censored by a terminal event, but not vice versa (i.e., semi-competing risks). Based on the idea of principal stratiﬁcation, we deﬁne a novel estimand for the causal eﬀect of treatment on the non-terminal event. We introduce identiﬁcation assumptions, indexed by a sensitivity parameter, and show how to draw inference using our {BNP} approach. We conduct a simulation study and illustrate our methodology using data from a brain cancer trial.},
	pages = {27},
	author = {Xu, Yanxun and Scharfstein, Daniel and Muller, Peter and Daniels, Michael},
	langid = {english},
	file = {xu_et_al_a_bayesian_nonparametric_approach_for_evaluating_the_eﬀect_of_treatment_in.pdf:/home/nathan/Dropbox/njames/zotero_sync/xu_et_al_a_bayesian_nonparametric_approach_for_evaluating_the_eﬀect_of_treatment_in.pdf:application/pdf}
}

@article{bashir_conditioning_2019,
	title = {Conditioning with busulfan plus melphalan versus melphalan alone before autologous haemopoietic cell transplantation for multiple myeloma: an open-label, randomised, phase 3 trial},
	issn = {23523026},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352302619300237},
	doi = {10.1016/S2352-3026(19)30023-7},
	shorttitle = {Conditioning with busulfan plus melphalan versus melphalan alone before autologous haemopoietic cell transplantation for multiple myeloma},
	abstract = {Background Retrospective studies suggest that conditioning therapy with busulfan plus melphalan could result in longer progression-free survival compared with melphalan alone in patients with multiple myeloma undergoing autologous haemopoietic cell transplantation (auto-{HCT}). We aimed to test this hypothesis in a randomised trial.},
	journaltitle = {The Lancet Haematology},
	author = {Bashir, Qaiser and Thall, Peter F and Milton, Denái R and Fox, Patricia S and Kawedia, Jitesh D and Kebriaei, Partow and Shah, Nina and Patel, Krina and Andersson, Borje S and Nieto, Yago L and Valdez, Ben C and Parmar, Simrit and Rondon, Gabriela and Delgado, Ruby and Hosing, Chitra and Popat, Uday R and Oran, Betul and Ciurea, Stefan O and Lin, Pei and Weber, Donna M and Thomas, Sheeba K and Lee, Hans C and Manasanch, Elisabet E and Orlowski, Robert Z and Williams, Loretta A and Champlin, Richard E and Qazilbash, Muzaffar H},
	urldate = {2019-04-03},
	date = {2019-03},
	langid = {english},
	file = {bashir_et_al_2019_conditioning_with_busulfan_plus_melphalan_versus_melphalan_alone_before.pdf:/home/nathan/Dropbox/njames/zotero_sync/bashir_et_al_2019_conditioning_with_busulfan_plus_melphalan_versus_melphalan_alone_before.pdf:application/pdf}
}

@article{park_phase_2019,
	title = {A phase I/{II}, open-label, prospective, multicenter study to evaluate the efficacy and safety of lower doses of bortezomib plus busulfan and melphalan as a conditioning regimen in patients with multiple myeloma undergoing autologous peripheral blood stem cell transplantation: The {KMM}103 study},
	issn = {10838791},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1083879119301922},
	doi = {10.1016/j.bbmt.2019.03.016},
	shorttitle = {A phase I/{II}, open-label, prospective, multicenter study to evaluate the efficacy and safety of lower doses of bortezomib plus busulfan and melphalan as a conditioning regimen in patients with multiple myeloma undergoing autologous peripheral blood stem cell transplantation},
	abstract = {A phase I/{II} trial was conducted to explore the safety and activity of addition of bortezomib on days -6, -3, and +1 relative to the day of autologous stem cell transplantation to a conditioning regimen with busulfan and melphalan ({BuMel}; 3.2 mg/kg/day busulfan on days -5 to -3 and 140 mg/m2/day melphalan on day -2) in patients with multiple myeloma ({MM}) following bortezomib-based induction chemotherapy. In phase I, doses of bortezomib (0.7, 1.0, and 1.3 mg/m2) with {BuMel} were administered to groups of three patients each. No dose-limiting toxicities were observed. The maximum tolerated dose of bortezomib was 1.3 mg/m2/day. A subsequent cohort with 41 patients was analyzed in a phase {II} trial to identify safety and efficacy. The phase {II} trial showed 75\% of response rates including very good partial response ({VGPR}) or better, and 55\% of complete response ({CR}) rates at 3 months; For post-transplant best response, 83\% of {VGPR} or better response rate (68\% of {CR} rate) was observed. With a median follow-up duration of 31.4 months, median progression-free survival ({PFS}) was 26.8 months. The probability of 2 year-{PFS} was 56.5\%, and median overall survival was unable to be calculated. Specifically, high-risk cytogenetics were associated with adverse survival outcomes compared to standard-risk cytogenetics (median {PFS}, 12.2 vs. 35.7 months, p=0.039; median {OS}, 26.7 vs. 73.3 months, p=0.086). With a median of 11 days and 10 days for neutrophil and platelet engraftments, respectively, no graft failure or delayed engraft was observed. The most common grade 3 or severe nonhematological adverse events included neutropenic fever (73.2\%) and stomatitis (14.6\%). Except for three cases with transplant-related mortality due to sepsis, other adverse events were manageable. These results demonstrate that bortezomib is safe and has a potential role in a conditioning regimen in combination with {BuMel} for patients with transplant-eligible {MM}. (This trial was registered at http://www.clinicaltrials.gov {NCT}01255527).},
	journaltitle = {Biology of Blood and Marrow Transplantation},
	author = {Park, Sung-Soo and Kim, Kihyun and Kim, Seok-Jin and Lee, Jae Hoon and Yoon, Sung Soo and Mun, Yeung Chul and Lee, Je-Jung and Eom, Hyeon-Seok and Kim, Jin Seok and Min, Chang-Ki},
	urldate = {2019-04-03},
	date = {2019-03},
	langid = {english},
	file = {park_et_al_2019_a_phase_i-ii,_open-label,_prospective,_multicenter_study_to_evaluate_the.pdf:/home/nathan/Dropbox/njames/zotero_sync/park_et_al_2019_a_phase_i-ii,_open-label,_prospective,_multicenter_study_to_evaluate_the.pdf:application/pdf}
}

@article{shaw_use_2018,
	title = {Use of composite outcomes to assess risk–benefit in clinical trials},
	volume = {15},
	issn = {1740-7745, 1740-7753},
	url = {http://journals.sagepub.com/doi/10.1177/1740774518784010},
	doi = {10.1177/1740774518784010},
	abstract = {Before a novel treatment can be deemed a clinical success, an assessment of its risk–benefit profile must be made. One of the inherent challenges for this assessment comes from the multiplicity that arises from comparing treatment groups across multiple outcomes. Composite outcomes that summarize a patient’s clinical status, or severity, across a prioritized list of safety and efficacy outcomes have become increasing popular. In this article, we review these approaches and illustrate through examples some of the challenges and complexities of a composite derived from prioritized outcomes, such as the win ratio. These challenges include the difficult tension between the analytical validity that comes from choosing a pre-specified outcome and an evaluation that is responsive to unexpected safety events that arise during the course of a trial. Other challenges include a sensitivity of the resulting test statistic to the underlying censoring distribution and other nuisance parameters. Approaches that resolve some of the difficulties of the analytical challenges associated with prioritized outcomes are then discussed. Ultimately, a composite outcome of net clinical benefit is another decision tool, but one to be used alongside more traditional analyses of efficacy and safety, and with the broader perspective that investigators, the data safety monitoring board, and regulators bring to an evaluation of risk–benefit.},
	pages = {352--358},
	number = {4},
	journaltitle = {Clinical Trials},
	author = {Shaw, Pamela A},
	urldate = {2019-04-03},
	date = {2018-08},
	langid = {english},
	file = {shaw_2018_use_of_composite_outcomes_to_assess_risk–benefit_in_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/shaw_2018_use_of_composite_outcomes_to_assess_risk–benefit_in_clinical_trials.pdf:application/pdf}
}

@article{marsh_research_nodate,
	title = {Research Note: Adaptive trials},
	pages = {4},
	author = {Marsh, Julie A},
	langid = {english},
	file = {marsh_research_note.pdf:/home/nathan/Dropbox/njames/zotero_sync/marsh_research_note.pdf:application/pdf}
}

@article{nguyen_use_2019,
	title = {The use of prognostic scores for causal inference with general treatment regimes},
	volume = {38},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8084},
	doi = {10.1002/sim.8084},
	abstract = {In nonrandomised studies, inferring causal effects requires appropriate methods for addressing confounding bias. Although it is common to adopt propensity score analysis to this purpose, prognostic score analysis has recently been proposed as an alternative strategy. While both approaches were originally introduced to estimate causal effects for binary interventions, the theory of propensity score has since been extended to the case of general treatment regimes. Indeed, many treatments are not assigned in a binary fashion and require a certain extent of dosing. Hence, researchers may often be interested in estimating treatment effects across multiple exposures. To the best of our knowledge, the prognostic score analysis has not been yet generalised to this case. In this article, we describe the theory of prognostic scores for causal inference with general treatment regimes. Our methods can be applied to compare multiple treatments using nonrandomised data, a topic of great relevance in contemporary evaluations of clinical interventions. We propose estimators for the average treatment effects in different populations of interest, the validity of which is assessed through a series of simulations. Finally, we present an illustrative case in which we estimate the effect of the delay to Aspirin administration on a composite outcome of death or dependence at 6 months in stroke patients.},
	pages = {2013--2029},
	number = {11},
	journaltitle = {Statistics in Medicine},
	author = {Nguyen, Tri-Long and Debray, Thomas P. A.},
	urldate = {2019-04-09},
	date = {2019},
	langid = {english},
	keywords = {causal inference, multiple treatment exposures, observational study, prognostic score},
	file = {nguyen_debray_2019_the_use_of_prognostic_scores_for_causal_inference_with_general_treatment_regimes.pdf:/home/nathan/Dropbox/njames/zotero_sync/nguyen_debray_2019_the_use_of_prognostic_scores_for_causal_inference_with_general_treatment_regimes.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/384HQ2DF/sim.html:text/html}
}

@article{morris_using_2019,
	title = {Using simulation studies to evaluate statistical methods},
	volume = {38},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8086},
	doi = {10.1002/sim.8086},
	abstract = {Simulation studies are computer experiments that involve creating data by pseudo-random sampling. A key strength of simulation studies is the ability to understand the behavior of statistical methods because some “truth” (usually some parameter/s of interest) is known from the process of generating the data. This allows us to consider properties of methods, such as bias. While widely used, simulation studies are often poorly designed, analyzed, and reported. This tutorial outlines the rationale for using simulation studies and offers guidance for design, execution, analysis, reporting, and presentation. In particular, this tutorial provides a structured approach for planning and reporting simulation studies, which involves defining aims, data-generating mechanisms, estimands, methods, and performance measures (“{ADEMP}”); coherent terminology for simulation studies; guidance on coding simulation studies; a critical discussion of key performance measures and their estimation; guidance on structuring tabular and graphical presentation of results; and new graphical presentations. With a view to describing recent practice, we review 100 articles taken from Volume 34 of Statistics in Medicine, which included at least one simulation study and identify areas for improvement.},
	pages = {2074--2102},
	number = {11},
	journaltitle = {Statistics in Medicine},
	author = {Morris, Tim P. and White, Ian R. and Crowther, Michael J.},
	urldate = {2019-04-09},
	date = {2019},
	langid = {english},
	keywords = {graphics for simulation, Monte Carlo, simulation design, simulation reporting, simulation studies},
	file = {morris_et_al_2019_using_simulation_studies_to_evaluate_statistical_methods.pdf:/home/nathan/Dropbox/njames/zotero_sync/morris_et_al_2019_using_simulation_studies_to_evaluate_statistical_methods.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/9LJHXTW2/sim.html:text/html}
}

@article{burger_generalized_nodate,
	title = {A generalized Bayesian nonlinear mixed-effects regression model for zero-inflated longitudinal count data in tuberculosis trials},
	volume = {0},
	issn = {1539-1612},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1933},
	doi = {10.1002/pst.1933},
	abstract = {In this paper, we investigate Bayesian generalized nonlinear mixed-effects ({NLME}) regression models for zero-inflated longitudinal count data. The methodology is motivated by and applied to colony forming unit ({CFU}) counts in extended bactericidal activity tuberculosis ({TB}) trials. Furthermore, for model comparisons, we present a generalized method for calculating the marginal likelihoods required to determine Bayes factors. A simulation study shows that the proposed zero-inflated negative binomial regression model has good accuracy, precision, and credibility interval coverage. In contrast, conventional normal {NLME} regression models applied to log-transformed count data, which handle zero counts as left censored values, may yield credibility intervals that undercover the true bactericidal activity of anti-{TB} drugs. We therefore recommend that zero-inflated {NLME} regression models should be fitted to {CFU} count on the original scale, as an alternative to conventional normal {NLME} regression models on the logarithmic scale.},
	number = {0},
	journaltitle = {Pharmaceutical Statistics},
	author = {Burger, Divan Aristo and Schall, Robert and Jacobs, Rianne and Chen, Ding-Geng},
	urldate = {2019-04-09},
	langid = {english},
	keywords = {bactericidal activity, Bayesian, longitudinal, mixed-effects, zero inflated},
	file = {burger_et_al_a_generalized_bayesian_nonlinear_mixed-effects_regression_model_for.pdf:/home/nathan/Dropbox/njames/zotero_sync/burger_et_al_a_generalized_bayesian_nonlinear_mixed-effects_regression_model_for.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/5IP5AWYK/pst.html:text/html}
}

@article{loaiza-maya_variational_2019,
	title = {Variational Bayes Estimation of Discrete-Margined Copula Models With Application to Time Series},
	issn = {1061-8600, 1537-2715},
	url = {https://www.tandfonline.com/doi/full/10.1080/10618600.2018.1562936},
	doi = {10.1080/10618600.2018.1562936},
	abstract = {We propose a new variational Bayes ({VB}) estimator for high-dimensional copulas with discrete, or a combination of discrete and continuous, margins. The method is based on a variational approximation to a tractable augmented posterior and is faster than previous likelihood-based approaches. We use it to estimate drawable vine copulas for univariate and multivariate Markov ordinal and mixed time series. These have dimension {rT}, where T is the number of observations and r is the number of series, and are difficult to estimate using previous methods. The vine pair-copulas are carefully selected to allow for heteroscedasticity, which is a feature of most ordinal time series data. When combined with flexible margins, the resulting time series models also allow for other common features of ordinal data, such as zero inflation, multiple modes, and under or overdispersion. Using six example series, we illustrate both the flexibility of the time series copula models and the efficacy of the {VB} estimator for copulas of up to 792 dimensions and 60 parameters. This far exceeds the size and complexity of copula models for discrete data that can be estimated using previous methods. An online appendix and {MATLAB} code implementing the method are available as supplementary materials.},
	pages = {1--17},
	journaltitle = {Journal of Computational and Graphical Statistics},
	author = {Loaiza-Maya, Rubén and Smith, Michael Stanley},
	urldate = {2019-04-11},
	date = {2019-01-14},
	langid = {english},
	file = {loaiza-maya_smith_2019_variational_bayes_estimation_of_discrete-margined_copula_models_with.pdf:/home/nathan/Dropbox/njames/zotero_sync/loaiza-maya_smith_2019_variational_bayes_estimation_of_discrete-margined_copula_models_with.pdf:application/pdf}
}

@article{carvalho_handling_nodate,
	title = {Handling Sparsity via the Horseshoe},
	abstract = {This paper presents a general, fully Bayesian framework for sparse supervised-learning problems based on the horseshoe prior. The horseshoe prior is a member of the family of multivariate scale mixtures of normals, and is therefore closely related to widely used approaches for sparse Bayesian learning, including, among others, Laplacian priors (e.g. the {LASSO}) and Student-t priors (e.g. the relevance vector machine). The advantages of the horseshoe are its robustness at handling unknown sparsity and large outlying signals. These properties are justiﬁed theoretically via a representation theorem and accompanied by comprehensive empirical experiments that compare its performance to benchmark alternatives.},
	pages = {8},
	author = {Carvalho, Carlos M and Polson, Nicholas G and Scott, James G},
	langid = {english},
	file = {carvalho_et_al_handling_sparsity_via_the_horseshoe.pdf:/home/nathan/Dropbox/njames/zotero_sync/carvalho_et_al_handling_sparsity_via_the_horseshoe.pdf:application/pdf}
}

@article{carvalho_horseshoe_2010,
	title = {The horseshoe estimator for sparse signals},
	volume = {97},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/asq017},
	doi = {10.1093/biomet/asq017},
	abstract = {This paper proposes a new approach to sparsity, called the horseshoe estimator, which arises from a prior based on multivariate-normal scale mixtures. We describe the estimator’s advantages over existing approaches, including its robustness, adaptivity to different sparsity patterns and analytical tractability. We prove two theorems: one that characterizes the horseshoe estimator’s tail robustness and the other that demonstrates a super-efﬁcient rate of convergence to the correct estimate of the sampling density in sparse situations. Finally, using both real and simulated data, we show that the horseshoe estimator corresponds quite closely to the answers obtained by Bayesian model averaging under a point-mass mixture prior.},
	pages = {465--480},
	number = {2},
	journaltitle = {Biometrika},
	author = {Carvalho, C. M. and Polson, N. G. and Scott, J. G.},
	urldate = {2019-04-11},
	date = {2010-06-01},
	langid = {english},
	file = {carvalho_et_al_2010_the_horseshoe_estimator_for_sparse_signals.pdf:/home/nathan/Dropbox/njames/zotero_sync/carvalho_et_al_2010_the_horseshoe_estimator_for_sparse_signals.pdf:application/pdf}
}

@article{varadhan_treatment_2016,
	title = {Treatment effect heterogeneity for univariate subgroups in clinical trials: Shrinkage, standardization, or else},
	volume = {58},
	issn = {1521-4036},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201400102},
	doi = {10.1002/bimj.201400102},
	shorttitle = {Treatment effect heterogeneity for univariate subgroups in clinical trials},
	abstract = {Treatment effect heterogeneity is a well-recognized phenomenon in randomized controlled clinical trials. In this paper, we discuss subgroup analyses with prespecified subgroups of clinical or biological importance. We explore various alternatives to the naive (the traditional univariate) subgroup analyses to address the issues of multiplicity and confounding. Specifically, we consider a model-based Bayesian shrinkage (Bayes-{DS}) and a nonparametric, empirical Bayes shrinkage approach (Emp-Bayes) to temper the optimism of traditional univariate subgroup analyses; a standardization approach (standardization) that accounts for correlation between baseline covariates; and a model-based maximum likelihood estimation ({MLE}) approach. The Bayes-{DS} and Emp-Bayes methods model the variation in subgroup-specific treatment effect rather than testing the null hypothesis of no difference between subgroups. The standardization approach addresses the issue of confounding in subgroup analyses. The {MLE} approach is considered only for comparison in simulation studies as the “truth” since the data were generated from the same model. Using the characteristics of a hypothetical large outcome trial, we perform simulation studies and articulate the utilities and potential limitations of these estimators. Simulation results indicate that Bayes-{DS} and Emp-Bayes can protect against optimism present in the naïve approach. Due to its simplicity, the naïve approach should be the reference for reporting univariate subgroup-specific treatment effect estimates from exploratory subgroup analyses. Standardization, although it tends to have a larger variance, is suggested when it is important to address the confounding of univariate subgroup effects due to correlation between baseline covariates. The Bayes-{DS} approach is available as an R package ({DSBayes}).},
	pages = {133--153},
	number = {1},
	journaltitle = {Biometrical Journal},
	author = {Varadhan, Ravi and Wang, Sue-Jane},
	urldate = {2019-04-11},
	date = {2016},
	langid = {english},
	keywords = {Bayesian shrinkage estimate, Confounding, Empirical Bayes, Marginal subgroup analysis, Maximum likelihood estimate, Naïve estimate, Standardization, Subgroup analysis},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/HBWSCPES/bimj.html:text/html;varadhan_wang_2016_treatment_effect_heterogeneity_for_univariate_subgroups_in_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/varadhan_wang_2016_treatment_effect_heterogeneity_for_univariate_subgroups_in_clinical_trials.pdf:application/pdf}
}

@article{henderson_bayesian_2016,
	title = {Bayesian analysis of heterogeneous treatment effects for patient-centered outcomes research},
	volume = {16},
	issn = {1387-3741, 1572-9400},
	url = {http://link.springer.com/10.1007/s10742-016-0159-3},
	doi = {10.1007/s10742-016-0159-3},
	abstract = {Evaluation of heterogeneity of treatment effect ({HTE}) is an essential aspect of personalized medicine and patient-centered outcomes research. Our goal in this article is to promote the use of Bayesian methods for subgroup analysis and to lower the barriers to their implementation by describing the ways in which the companion software beanz can facilitate these types of analyses. To advance this goal, we describe several key Bayesian models for investigating {HTE} and outline the ways in which they are well-suited to address many of the commonly cited challenges in the study of {HTE}. Topics highlighted include shrinkage estimation, model choice, sensitivity analysis, and posterior predictive checking. A case study is presented in which we demonstrate the use of the methods discussed.},
	pages = {213--233},
	number = {4},
	journaltitle = {Health Services and Outcomes Research Methodology},
	author = {Henderson, Nicholas C. and Louis, Thomas A. and Wang, Chenguang and Varadhan, Ravi},
	urldate = {2019-04-11},
	date = {2016-12},
	langid = {english},
	file = {henderson_et_al_2016_bayesian_analysis_of_heterogeneous_treatment_effects_for_patient-centered.pdf:/home/nathan/Dropbox/njames/zotero_sync/henderson_et_al_2016_bayesian_analysis_of_heterogeneous_treatment_effects_for_patient-centered.pdf:application/pdf}
}

@article{gelman_parameterization_2004,
	title = {Parameterization and Bayesian Modeling},
	volume = {99},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1198/016214504000000458},
	doi = {10.1198/016214504000000458},
	pages = {537--545},
	number = {466},
	journaltitle = {Journal of the American Statistical Association},
	author = {Gelman, Andrew},
	urldate = {2019-04-11},
	date = {2004-06},
	langid = {english},
	file = {gelman_2004_parameterization_and_bayesian_modeling.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_2004_parameterization_and_bayesian_modeling.pdf:application/pdf}
}

@article{scheike_mean_2019,
	title = {The mean, variance and correlation for bivariate recurrent event data with a terminal event},
	issn = {0035-9254, 1467-9876},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/rssc.12350},
	doi = {10.1111/rssc.12350},
	abstract = {Recurrent events in the presence of a terminal event are often encountered in a biomedical setting. The marginal mean of the number of recurrent events in a speciﬁed time period is a useful non-parametric summary of recurrent events data also in the presence of a terminal event. Other useful non-parametric summaries, that are simple to compute, are the distribution function of the number of recurrent events for each point in time and the variance of the number of recurrent events. For bivariate recurrent events, still in the presence of a terminal event, we suggest a simple non-parametric estimator of the covariance or correlation of the marginal number of events for both processes. When there is no terminal event the correlation is useful, but when there is an important terminal event we suggest an adjustment for correlation induced by the terminal event to obtain a measure that reﬂects the dependence in the recurrent event processes among survivors only. Our estimators can be used for deciding whether the two recurrent events are correlated and in what way. We provide large sample properties of our estimators and show their performance in small samples by simulations. The estimators are applied in a study of catheter complications among patients receiving home parenteral nutrition through a central venous catheter, and we show a positive correlation between the number of infections and the number of occlusion defects.},
	pages = {rssc.12350},
	journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	author = {Scheike, Thomas H. and Eriksson, Frank and Tribler, Siri},
	urldate = {2019-04-16},
	date = {2019-04-03},
	langid = {english},
	file = {scheike_et_al_2019_the_mean,_variance_and_correlation_for_bivariate_recurrent_event_data_with_a.pdf:/home/nathan/Dropbox/njames/zotero_sync/scheike_et_al_2019_the_mean,_variance_and_correlation_for_bivariate_recurrent_event_data_with_a.pdf:application/pdf}
}

@article{roig_new_2019,
	title = {A new approach for sizing trials with composite binary endpoints using anticipated marginal values and accounting for the correlation between components},
	volume = {38},
	issn = {0277-6715, 1097-0258},
	url = {http://arxiv.org/abs/1807.01305},
	doi = {10.1002/sim.8092},
	abstract = {Composite binary endpoints are increasingly used as primary endpoints in clinical trials. When designing a trial, it is crucial to determine the appropriate sample size for testing the statistical diﬀerences between treatment groups for the primary endpoint. As shown in this work, when using a composite binary endpoint to size a trial, one needs to specify the event rates and the eﬀect sizes of the composite components as well as the correlation between them. In practice, the marginal parameters of the components can be obtained from previous studies or pilot trials, however, the correlation is often not previously reported and thus usually unknown. We ﬁrst show that the sample size for composite binary endpoints is strongly dependent on the correlation and, second, that slight deviations in the prior information on the marginal parameters may result in underpowered trials for achieving the study objectives at a pre-speciﬁed signiﬁcance level.},
	pages = {1935--1956},
	number = {11},
	journaltitle = {Statistics in Medicine},
	author = {Roig, Marta Bofill and Melis, Guadalupe Gómez},
	urldate = {2019-04-16},
	date = {2019-05-20},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1807.01305},
	keywords = {Statistics - Applications},
	file = {roig_melis_2019_a_new_approach_for_sizing_trials_with_composite_binary_endpoints_using.pdf:/home/nathan/Dropbox/njames/zotero_sync/roig_melis_2019_a_new_approach_for_sizing_trials_with_composite_binary_endpoints_using.pdf:application/pdf}
}

@article{bastian_seventy-five_2010,
	title = {Seventy-Five Trials and Eleven Systematic Reviews a Day: How Will We Ever Keep Up?},
	volume = {7},
	issn = {1549-1676},
	url = {https://dx.plos.org/10.1371/journal.pmed.1000326},
	doi = {10.1371/journal.pmed.1000326},
	shorttitle = {Seventy-Five Trials and Eleven Systematic Reviews a Day},
	pages = {e1000326},
	number = {9},
	journaltitle = {{PLoS} Medicine},
	author = {Bastian, Hilda and Glasziou, Paul and Chalmers, Iain},
	urldate = {2019-04-17},
	date = {2010-09-21},
	langid = {english},
	file = {bastian_et_al_2010_seventy-five_trials_and_eleven_systematic_reviews_a_day.pdf:/home/nathan/Dropbox/njames/zotero_sync/bastian_et_al_2010_seventy-five_trials_and_eleven_systematic_reviews_a_day.pdf:application/pdf}
}

@article{noauthor_evidence_nodate,
	title = {Evidence based medicine manifesto for better healthcare},
	pages = {3},
	langid = {english},
	file = {evidence_based_medicine_manifesto_for_better_healthcare.pdf:/home/nathan/Dropbox/njames/zotero_sync/evidence_based_medicine_manifesto_for_better_healthcare.pdf:application/pdf}
}

@article{kairalla_adaptive_2012,
	title = {Adaptive trial designs: a review of barriers and opportunities},
	volume = {13},
	issn = {1745-6215},
	url = {http://trialsjournal.biomedcentral.com/articles/10.1186/1745-6215-13-145},
	doi = {10.1186/1745-6215-13-145},
	shorttitle = {Adaptive trial designs},
	abstract = {Adaptive designs allow planned modifications based on data accumulating within a study. The promise of greater flexibility and efficiency stimulates increasing interest in adaptive designs from clinical, academic, and regulatory parties. When adaptive designs are used properly, efficiencies can include a smaller sample size, a more efficient treatment development process, and an increased chance of correctly answering the clinical question of interest. However, improper adaptations can lead to biased studies. A broad definition of adaptive designs allows for countless variations, which creates confusion as to the statistical validity and practical feasibility of many designs. Determining properties of a particular adaptive design requires careful consideration of the scientific context and statistical assumptions. We first review several adaptive designs that garner the most current interest. We focus on the design principles and research issues that lead to particular designs being appealing or unappealing in particular applications. We separately discuss exploratory and confirmatory stage designs in order to account for the differences in regulatory concerns. We include adaptive seamless designs, which combine stages in a unified approach. We also highlight a number of applied areas, such as comparative effectiveness research, that would benefit from the use of adaptive designs. Finally, we describe a number of current barriers and provide initial suggestions for overcoming them in order to promote wider use of appropriate adaptive designs. Given the breadth of the coverage all mathematical and most implementation details are omitted for the sake of brevity. However, the interested reader will find that we provide current references to focused reviews and original theoretical sources which lead to details of the current state of the art in theory and practice.},
	pages = {145},
	number = {1},
	journaltitle = {Trials},
	author = {Kairalla, John A and Coffey, Christopher S and Thomann, Mitchell A and Muller, Keith E},
	urldate = {2019-04-17},
	date = {2012-12},
	langid = {english},
	file = {kairalla_et_al_2012_adaptive_trial_designs.pdf:/home/nathan/Dropbox/njames/zotero_sync/kairalla_et_al_2012_adaptive_trial_designs.pdf:application/pdf}
}

@article{berry_adaptive_2012,
	title = {Adaptive clinical trials in oncology},
	volume = {9},
	issn = {1759-4774, 1759-4782},
	url = {http://www.nature.com/articles/nrclinonc.2011.165},
	doi = {10.1038/nrclinonc.2011.165},
	abstract = {Modern oncology drug development faces challenges very different from those of the past and it must adapt accordingly. The size and expense of phase {III} clinical trials continue to increase, but the success rate remains unacceptably low. Adaptive trial designs can make development more informative, addressing whether a drug is safe and effective while showing how it should be delivered and to whom. An adaptive design is one in which the accumulating data are used to modify the trial’s course. Adaptive designs are ideal for addressing many questions at once. For example, a single trial might identify the appropriate patient population, dose and regimen, and therapeutic combinations, and then switch seamlessly into a phase {III} confirmatory trial. Adaptive designs rely on information, including from patients who have not achieved the trial’s primary end point. Longitudinal models of biomarkers (including tumor burden assessed via imaging) enable predictions of primary end points. Taking a Bayesian perspective facilitates building an efficient and accurate trial, including using longitudinal information. A wholly new paradigm for drug development exemplifying personalized medicine is evinced by an adaptive trial called I‑{SPY}2, in which drugs from many companies are evaluated in the same trial—a phase {II} screening process.},
	pages = {199--207},
	number = {4},
	journaltitle = {Nature Reviews Clinical Oncology},
	author = {Berry, Donald A.},
	urldate = {2019-04-17},
	date = {2012-04},
	langid = {english},
	file = {berry_2012_adaptive_clinical_trials_in_oncology.pdf:/home/nathan/Dropbox/njames/zotero_sync/berry_2012_adaptive_clinical_trials_in_oncology.pdf:application/pdf}
}

@article{drazen_adaptive_2016,
	title = {Adaptive Designs for Clinical Trials},
	volume = {375},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/10.1056/NEJMra1510061},
	doi = {10.1056/NEJMra1510061},
	pages = {65--74},
	number = {1},
	journaltitle = {New England Journal of Medicine},
	author = {Bhatt, Deepak L. and Mehta, Cyrus},
	editor = {Drazen, Jeffrey M. and Harrington, David P. and {McMurray}, John J.V. and Ware, James H. and Woodcock, Janet},
	urldate = {2019-04-17},
	date = {2016-07-07},
	langid = {english},
	file = {bhatt_mehta_2016_adaptive_designs_for_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/bhatt_mehta_2016_adaptive_designs_for_clinical_trials.pdf:application/pdf}
}

@article{pallmann_adaptive_2018,
	title = {Adaptive designs in clinical trials: why use them, and how to run and report them},
	volume = {16},
	issn = {1741-7015},
	url = {https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-018-1017-7},
	doi = {10.1186/s12916-018-1017-7},
	shorttitle = {Adaptive designs in clinical trials},
	abstract = {Adaptive designs can make clinical trials more flexible by utilising results accumulating in the trial to modify the trial’s course in accordance with pre-specified rules. Trials with an adaptive design are often more efficient, informative and ethical than trials with a traditional fixed design since they often make better use of resources such as time and money, and might require fewer participants. Adaptive designs can be applied across all phases of clinical research, from early-phase dose escalation to confirmatory trials. The pace of the uptake of adaptive designs in clinical research, however, has remained well behind that of the statistical literature introducing new methods and highlighting their potential advantages. We speculate that one factor contributing to this is that the full range of adaptations available to trial designs, as well as their goals, advantages and limitations, remains unfamiliar to many parts of the clinical community. Additionally, the term adaptive design has been misleadingly used as an all-encompassing label to refer to certain methods that could be deemed controversial or that have been inadequately implemented. We believe that even if the planning and analysis of a trial is undertaken by an expert statistician, it is essential that the investigators understand the implications of using an adaptive design, for example, what the practical challenges are, what can (and cannot) be inferred from the results of such a trial, and how to report and communicate the results. This tutorial paper provides guidance on key aspects of adaptive designs that are relevant to clinical triallists. We explain the basic rationale behind adaptive designs, clarify ambiguous terminology and summarise the utility and pitfalls of adaptive designs. We discuss practical aspects around funding, ethical approval, treatment supply and communication with stakeholders and trial participants. Our focus, however, is on the interpretation and reporting of results from adaptive design trials, which we consider vital for anyone involved in medical research. We emphasise the general principles of transparency and reproducibility and suggest how best to put them into practice.},
	pages = {29},
	number = {1},
	journaltitle = {{BMC} Medicine},
	author = {Pallmann, Philip and Bedding, Alun W. and Choodari-Oskooei, Babak and Dimairo, Munyaradzi and Flight, Laura and Hampson, Lisa V. and Holmes, Jane and Mander, Adrian P. and Odondi, Lang’o and Sydes, Matthew R. and Villar, Sofía S. and Wason, James M. S. and Weir, Christopher J. and Wheeler, Graham M. and Yap, Christina and Jaki, Thomas},
	urldate = {2019-04-17},
	date = {2018-12},
	langid = {english},
	file = {pallmann_et_al_2018_adaptive_designs_in_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/pallmann_et_al_2018_adaptive_designs_in_clinical_trials.pdf:application/pdf}
}

@article{thorlund_key_2018,
	title = {Key design considerations for adaptive clinical trials: a primer for clinicians},
	issn = {0959-8138, 1756-1833},
	url = {http://www.bmj.com/lookup/doi/10.1136/bmj.k698},
	doi = {10.1136/bmj.k698},
	shorttitle = {Key design considerations for adaptive clinical trials},
	pages = {k698},
	journaltitle = {{BMJ}},
	author = {Thorlund, Kristian and Haggstrom, Jonas and Park, Jay {JH} and Mills, Edward J},
	urldate = {2019-04-17},
	date = {2018-03-08},
	langid = {english},
	file = {thorlund_et_al_2018_key_design_considerations_for_adaptive_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/thorlund_et_al_2018_key_design_considerations_for_adaptive_clinical_trials.pdf:application/pdf}
}

@article{renfro_statistical_2016,
	title = {Statistical controversies in clinical research: basket trials, umbrella trials, and other master protocols: a review and examples},
	issn = {0923-7534, 1569-8041},
	url = {https://academic.oup.com/annonc/article-lookup/doi/10.1093/annonc/mdw413},
	doi = {10.1093/annonc/mdw413},
	shorttitle = {Statistical controversies in clinical research},
	pages = {mdw413},
	journaltitle = {Annals of Oncology},
	author = {Renfro, L. A. and Sargent, D. J.},
	urldate = {2019-04-17},
	date = {2016-10-11},
	langid = {english},
	file = {renfro_sargent_2016_statistical_controversies_in_clinical_research.pdf:/home/nathan/Dropbox/njames/zotero_sync/renfro_sargent_2016_statistical_controversies_in_clinical_research.pdf:application/pdf}
}

@article{coffey_adaptive_2008,
	title = {Adaptive Clinical Trials: Progress and Challenges},
	volume = {9},
	issn = {1174-5886},
	url = {http://link.springer.com/10.2165/00126839-200809040-00003},
	doi = {10.2165/00126839-200809040-00003},
	shorttitle = {Adaptive Clinical Trials},
	pages = {229--242},
	number = {4},
	journaltitle = {Drugs in R \& D},
	author = {Coffey, Christopher S and Kairalla, John A},
	urldate = {2019-04-17},
	date = {2008},
	langid = {english},
	file = {coffey_kairalla_2008_adaptive_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/coffey_kairalla_2008_adaptive_clinical_trials.pdf:application/pdf}
}

@article{wason_comparison_2014,
	title = {A comparison of Bayesian adaptive randomization and multi-stage designs for multi-arm clinical trials},
	volume = {33},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6086},
	doi = {10.1002/sim.6086},
	abstract = {When several experimental treatments are available for testing, multi-arm trials provide gains in efficiency over separate trials. Including interim analyses allows the investigator to effectively use the data gathered during the trial. Bayesian adaptive randomization ({AR}) and multi-arm multi-stage ({MAMS}) designs are two distinct methods that use patient outcomes to improve the efficiency and ethics of the trial. {AR} allocates a greater proportion of future patients to treatments that have performed well; {MAMS} designs use pre-specified stopping boundaries to determine whether experimental treatments should be dropped. There is little consensus on which method is more suitable for clinical trials, and so in this paper, we compare the two under several simulation scenarios and in the context of a real multi-arm phase {II} breast cancer trial. We compare the methods in terms of their efficiency and ethical properties. We also consider the practical problem of a delay between recruitment of patients and assessment of their treatment response. Both methods are more efficient and ethical than a multi-arm trial without interim analyses. Delay between recruitment and response assessment attenuates this efficiency gain. We also consider futility stopping rules for response adaptive trials that add efficiency when all treatments are ineffective. Our comparisons show that {AR} is more efficient than {MAMS} designs when there is an effective experimental treatment, whereas if none of the experimental treatments is effective, then {MAMS} designs slightly outperform {AR}. © 2014 The Authors Statistics in Medicine Published by John Wiley \& Sons, Ltd.},
	pages = {2206--2221},
	number = {13},
	journaltitle = {Statistics in Medicine},
	author = {Wason, James M. S. and Trippa, Lorenzo},
	urldate = {2019-04-17},
	date = {2014},
	langid = {english},
	keywords = {adaptive randomization, group-sequential designs, multi-arm trials, multiple testing},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/KTKCJQY5/sim.html:text/html;wason_trippa_2014_a_comparison_of_bayesian_adaptive_randomization_and_multi-stage_designs_for.pdf:/home/nathan/Dropbox/njames/zotero_sync/wason_trippa_2014_a_comparison_of_bayesian_adaptive_randomization_and_multi-stage_designs_for.pdf:application/pdf}
}

@article{dmitrienko_bayesian_2006,
	title = {Bayesian predictive approach to interim monitoring in clinical trials},
	volume = {25},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.2204},
	doi = {10.1002/sim.2204},
	abstract = {This paper reviews Bayesian strategies for monitoring clinical trial data. It focuses on a Bayesian stochastic curtailment method based on the predictive probability of observing a clinically significant outcome at the scheduled end of the study given the observed data. The proposed method is applied to derive efficacy and futility stopping rules in clinical trials with continuous, normally distributed and binary endpoints. The sensitivity of the resulting stopping rules to the choice of prior distributions is examined and guidelines for choosing a prior distribution of the treatment effect are discussed. The Bayesian predictive approach is compared to the frequentist (conditional power) and mixed Bayesian-frequentist (predictive power) approaches. The interim monitoring strategies discussed in the paper are illustrated using examples from a small proof-of-concept study and a large mortality trial. Copyright © 2005 John Wiley \& Sons, Ltd.},
	pages = {2178--2195},
	number = {13},
	journaltitle = {Statistics in Medicine},
	author = {Dmitrienko, Alexei and Wang, Ming-Dauh},
	urldate = {2019-04-17},
	date = {2006},
	langid = {english},
	keywords = {clinical trials, interim analysis, Bayesian predictive inference, predictive distribution, stopping rule},
	file = {dmitrienko_wang_2006_bayesian_predictive_approach_to_interim_monitoring_in_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/dmitrienko_wang_2006_bayesian_predictive_approach_to_interim_monitoring_in_clinical_trials.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/58PTX293/sim.html:text/html}
}

@article{li_periodic_2018,
	title = {Periodic benefit-risk assessment using Bayesian stochastic multi-criteria acceptability analysis},
	volume = {67},
	issn = {15517144},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1551714417307759},
	doi = {10.1016/j.cct.2018.02.016},
	abstract = {Benefit-risk ({BR}) assessment is essential to ensure the best decisions are made for a medical product in the clinical development process, regulatory marketing authorization, post-market surveillance, and coverage and reimbursement decisions. One challenge of {BR} assessment in practice is that the benefit and risk profile may keep evolving while new evidence is accumulating. Regulators and the International Conference on Harmonization ({ICH}) recommend performing periodic benefit-risk evaluation report ({PBRER}) through the product's lifecycle. In this paper, we propose a general statistical framework for periodic benefit-risk assessment, in which Bayesian meta-analysis and stochastic multi-criteria acceptability analysis ({SMAA}) will be combined to synthesize the accumulating evidence. The proposed approach allows us to compare the acceptability of different drugs dynamically and effectively and accounts for the uncertainty of clinical measurements and imprecise or incomplete preference information of decision makers. We apply our approaches to two real examples in a post-hoc way for illustration purpose. The proposed method may easily be modified for other pre and post market settings, and thus be an important complement to the current structured benefit-risk assessment ({sBRA}) framework to improve the transparent and consistency of the decision-making process.},
	pages = {100--108},
	journaltitle = {Contemporary Clinical Trials},
	author = {Li, Kan and Yuan, Shuai Sammy and Wang, William and Wan, Shuyan Sabrina and Ceesay, Paulette and Heyse, Joseph F. and Mt-Isa, Shahrul and Luo, Sheng},
	urldate = {2019-04-17},
	date = {2018-04},
	langid = {english},
	file = {li_et_al_2018_periodic_benefit-risk_assessment_using_bayesian_stochastic_multi-criteria.pdf:/home/nathan/Dropbox/njames/zotero_sync/li_et_al_2018_periodic_benefit-risk_assessment_using_bayesian_stochastic_multi-criteria.pdf:application/pdf}
}

@article{li_bayesian_nodate-1,
	title = {A Bayesian approach for individual-level drug benefit-risk assessment},
	volume = {0},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8166},
	doi = {10.1002/sim.8166},
	abstract = {In existing benefit-risk assessment ({BRA}) methods, benefit and risk criteria are usually identified and defined separately based on aggregated clinical data and therefore ignore the individual-level differences as well as the association among the criteria. We proposed a Bayesian multicriteria decision-making method for {BRA} of drugs using individual-level data. We used a multidimensional latent trait model to account for the heterogeneity of treatment effects with latent variables introducing the dependencies among outcomes. We then applied the stochastic multicriteria acceptability analysis approach for {BRA} incorporating imprecise and heterogeneous patient preference information. We adopted an efficient Markov chain Monte Carlo algorithm when implementing the proposed method. We applied our method to a case study to illustrate how individual-level benefit-risk profiles could inform decision-making.},
	number = {0},
	journaltitle = {Statistics in Medicine},
	author = {Li, Kan and Luo, Sheng and Yuan, Sammy and Mt‐Isa, Shahrul},
	urldate = {2019-04-17},
	langid = {english},
	keywords = {latent trait model, {MCMC}, patient centered approach, {SMAA}},
	file = {li_et_al_a_bayesian_approach_for_individual-level_drug_benefit-risk_assessment.pdf:/home/nathan/Dropbox/njames/zotero_sync/li_et_al_a_bayesian_approach_for_individual-level_drug_benefit-risk_assessment.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/V3CLIIZK/sim.html:text/html}
}

@misc{velentgas_developing_2013,
	title = {Developing a Protocol for Observational Comparative Effectiveness Research: A User's Guide},
	url = {www.effectivehealthcare.ahrq.gov/Methods-OCER.cfm},
	publisher = {{AHRQ}},
	editor = {Velentgas, P and Dreyer, {NA} and Nourjah, P and Smith, {SR} and Torchia, {MM}},
	date = {2013-01},
	note = {{AHRQ} Publication No. 12(13)-{EHC}099},
	file = {2013_developing_a_protocol_for_observational_comparative_effectiveness_research.pdf:/home/nathan/Dropbox/njames/zotero_sync/2013_developing_a_protocol_for_observational_comparative_effectiveness_research.pdf:application/pdf}
}

@article{simon_bayesian_1997,
	title = {Bayesian Design and Analysis of Two x Two Factorial Clinical Trials},
	volume = {53},
	issn = {0006341X},
	url = {https://www.jstor.org/stable/2533949?origin=crossref},
	doi = {10.2307/2533949},
	abstract = {The 2 x 2 factorial design has been advocated for improving the efficiency of clinical trials. Most such trials are designed on the assumption that there is no interaction between the levels of the factors and outcome. This assumption is often problematic, however, because interactions are usually possible in clinical trials and the sample sizes often used provide little power in testing for interactions. We consider the use of Bayesian methods for the design and analysis of 2 x 2 factorial clinical trials. This approach avoids the need to dichotomize one's assumptions that interactions either do or do not exist and provides a flexible approach to the design and analysis of such clinical trials. Exact results are developed for balanced factorial designs with normal response. Approximations are then presented for factorial designs based on the logistic model for binary response or the proportional hazards model for time-to-event data. The resulting approximate posterior distributions are normal and hence no extensive computations are required. Suggestions for specification of prior distributions are presented.},
	pages = {456},
	number = {2},
	journaltitle = {Biometrics},
	author = {Simon, Richard and Freedman, Laurence S.},
	urldate = {2019-04-18},
	date = {1997-06},
	langid = {english},
	file = {simon_freedman_1997_bayesian_design_and_analysis_of_two_x_two_factorial_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/simon_freedman_1997_bayesian_design_and_analysis_of_two_x_two_factorial_clinical_trials.pdf:application/pdf}
}

@article{lewandowski_generating_2009,
	title = {Generating random correlation matrices based on vines and extended onion method},
	volume = {100},
	issn = {0047259X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0047259X09000876},
	doi = {10.1016/j.jmva.2009.04.008},
	abstract = {We extend and improve two existing methods of generating random correlation matrices, the onion method of Ghosh and Henderson [S. Ghosh, S.G. Henderson, Behavior of the norta method for correlated random vector generation as the dimension increases, {ACM} Transactions on Modeling and Computer Simulation ({TOMACS}) 13 (3) (2003) 276–294] and the recently proposed method of Joe [H. Joe, Generating random correlation matrices based on partial correlations, Journal of Multivariate Analysis 97 (2006) 2177–2189] based on partial correlations. The latter is based on the so-called D-vine. We extend the methodology to any regular vine and study the relationship between the multiple correlation and partial correlations on a regular vine. We explain the onion method in terms of elliptical distributions and extend it to allow generating random correlation matrices from the same joint distribution as the vine method. The methods are compared in terms of time necessary to generate 5000 random correlation matrices of given dimensions.},
	pages = {1989--2001},
	number = {9},
	journaltitle = {Journal of Multivariate Analysis},
	author = {Lewandowski, Daniel and Kurowicka, Dorota and Joe, Harry},
	urldate = {2019-04-19},
	date = {2009-10},
	langid = {english},
	file = {lewandowski_et_al_2009_generating_random_correlation_matrices_based_on_vines_and_extended_onion_method.pdf:/home/nathan/Dropbox/njames/zotero_sync/lewandowski_et_al_2009_generating_random_correlation_matrices_based_on_vines_and_extended_onion_method.pdf:application/pdf}
}

@article{jones_bayesian_2011,
	title = {Bayesian information criterion for longitudinal and clustered data},
	volume = {30},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.4323},
	doi = {10.1002/sim.4323},
	abstract = {When a number of models are fit to the same data set, one method of choosing the ‘best’ model is to select the model for which Akaike's information criterion ({AIC}) is lowest. {AIC} applies when maximum likelihood is used to estimate the unknown parameters in the model. The value of −2 log likelihood for each model fit is penalized by adding twice the number of estimated parameters. The number of estimated parameters includes both the linear parameters and parameters in the covariance structure. Another criterion for model selection is the Bayesian information criterion ({BIC}). {BIC} penalizes −2 log likelihood by adding the number of estimated parameters multiplied by the log of the sample size. For large sample sizes, {BIC} penalizes −2 log likelihood much more than {AIC} making it harder to enter new parameters into the model. An assumption in {BIC} is that the observations are independent. In mixed models, the observations are not independent. This paper develops a method for calculating the ‘effective sample size’ for mixed models based on Fisher's information. The effective sample size replaces the sample size in {BIC} and can vary from the number of subjects to the number of observations. A number of error models are considered based on a general mixed model including unstructured, compound symmetry (random intercept), first-order autoregression with observational error and random intercept and slope. Copyright © 2011 John Wiley \& Sons, Ltd.},
	pages = {3050--3056},
	number = {25},
	journaltitle = {Statistics in Medicine},
	author = {Jones, Richard H.},
	urldate = {2019-04-24},
	date = {2011},
	langid = {english},
	keywords = {{AIC}, effective sample size, information criteria, maximum likelihood, mixed models},
	file = {jones_2011_bayesian_information_criterion_for_longitudinal_and_clustered_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/jones_2011_bayesian_information_criterion_for_longitudinal_and_clustered_data.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/3YNTYBQY/sim.html:text/html}
}

@article{saville_efficiencies_2016,
	title = {Efficiencies of platform clinical trials: A vision of the future},
	volume = {13},
	issn = {1740-7745, 1740-7753},
	url = {http://journals.sagepub.com/doi/10.1177/1740774515626362},
	doi = {10.1177/1740774515626362},
	shorttitle = {Efficiencies of platform clinical trials},
	abstract = {Background: A ‘‘platform trial’’ is a clinical trial with a single master protocol in which multiple treatments are evaluated simultaneously. Adaptive platform designs offer flexible features such as dropping treatments for futility, declaring one or more treatments superior, or adding new treatments to be tested during the course of a trial.
Methods: A simulation study explores the efficiencies of various platform trial designs relative to a traditional two-arm strategy.
Results: Platform trials can find beneficial treatments with fewer patients, fewer patient failures, less time, and with greater probability of success than a traditional two-arm strategy.
Conclusion: In an era of personalized medicine, platform trials provide the innovation needed to efficiently evaluate modern treatments.},
	pages = {358--366},
	number = {3},
	journaltitle = {Clinical Trials: Journal of the Society for Clinical Trials},
	author = {Saville, Benjamin R and Berry, Scott M},
	urldate = {2019-04-24},
	date = {2016-06},
	langid = {english},
	file = {saville_berry_2016_efficiencies_of_platform_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/saville_berry_2016_efficiencies_of_platform_clinical_trials.pdf:application/pdf}
}

@article{zhao_bayesian_2014,
	title = {A Bayesian Approach for Benefit-Risk Assessment},
	volume = {6},
	issn = {1946-6315},
	url = {http://www.tandfonline.com/doi/abs/10.1080/19466315.2014.965845},
	doi = {10.1080/19466315.2014.965845},
	pages = {326--337},
	number = {4},
	journaltitle = {Statistics in Biopharmaceutical Research},
	author = {Zhao, Yueqin and Zalkikar, Jyoti and Tiwari, Ram C. and {LaVange}, Lisa M.},
	urldate = {2019-04-24},
	date = {2014-10-02},
	langid = {english},
	file = {zhao_et_al_2014_a_bayesian_approach_for_benefit-risk_assessment.pdf:/home/nathan/Dropbox/njames/zotero_sync/zhao_et_al_2014_a_bayesian_approach_for_benefit-risk_assessment.pdf:application/pdf}
}

@article{cui_bayesian_2016,
	title = {Bayesian Approach to Personalized Benefit-Risk Assessment},
	volume = {8},
	issn = {1946-6315},
	url = {https://www.tandfonline.com/doi/full/10.1080/19466315.2016.1193045},
	doi = {10.1080/19466315.2016.1193045},
	abstract = {Benefit-risk assessment is critical in evaluating the effectiveness of a new drug before and after the approval. Some benefit-risk measures depend on the probabilities of benefit-risk categories in which the subject-level benefit and risk outcomes are characterized. The existing benefit-risk methods for analyzing the categorical data depend only on the frequencies of mutually exclusive and collectively exhaustive categories that the subjects fall in, and thus ignore the subject-level differences. We propose a Bayesian method for analyzing the subject-level data with multiple visits. A generalized linear model is used to model the subject-level response probability, with respect to a “reference” category, assuming a logit model with subject-level category effects and multiple visit effects. The random longitudinal visit effects are modeled by a multivariate normal distribution with zero means and first-order autoregressive structured variance-covariance matrices. In the proposed Bayesian setup, a Dirichlet process is used as a prior for the subject-level category effect to catch the similarity among the subject responses. We develop an efficient Markov chain Monte Carlo algorithm for implementing the proposed method, and illustrate the estimation of individual benefitrisk profiles through simulation. The performance of the proposed model fit is evaluated using two model selection approaches, namely, the deviance information criterion ({DIC}) and the log-pseudo marginal likelihood ({LPML}). We analyze a clinical trial data using the proposed method to assess the subject-level or personalized benefit-risk in each arm, and to evaluate the aggregated benefit-risk difference between the treatments at different visits.},
	pages = {316--324},
	number = {3},
	journaltitle = {Statistics in Biopharmaceutical Research},
	author = {Cui, Shiqi and Zhao, Yueqin and Tiwari, Ram C.},
	urldate = {2019-04-24},
	date = {2016-07-02},
	langid = {english},
	file = {cui_et_al_2016_bayesian_approach_to_personalized_benefit-risk_assessment.pdf:/home/nathan/Dropbox/njames/zotero_sync/cui_et_al_2016_bayesian_approach_to_personalized_benefit-risk_assessment.pdf:application/pdf}
}

@article{schultz_trial_2019,
	title = {Trial Refresh: A Case for an Adaptive Platform Trial for Pulmonary Exacerbations of Cystic Fibrosis},
	volume = {10},
	issn = {1663-9812},
	url = {https://www.frontiersin.org/article/10.3389/fphar.2019.00301/full},
	doi = {10.3389/fphar.2019.00301},
	shorttitle = {Trial Refresh},
	pages = {301},
	journaltitle = {Front. Pharmacol.},
	author = {Schultz, Andre and Marsh, Julie A. and Saville, Benjamin R. and Norman, Richard and Middleton, Peter G. and Greville, Hugh W. and Bellgard, Matthew I. and Berry, Scott M. and Snelling, Tom},
	urldate = {2019-04-30},
	date = {2019-03-28},
	langid = {english},
	file = {schultz_et_al_2019_trial_refresh.pdf:/home/nathan/Dropbox/njames/zotero_sync/schultz_et_al_2019_trial_refresh.pdf:application/pdf}
}

@article{chapple_hybrid_2019,
	title = {A hybrid phase I‐{II}/{III} clinical trial design allowing dose re‐optimization in phase {III}},
	issn = {0006-341X, 1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12994},
	doi = {10.1111/biom.12994},
	abstract = {Conventionally, evaluation of a new drug, ������, is done in three phases. Phase I is based on toxicity to determine a “maximum tolerable dose” ({MTD}) of ������, phase {II} is conducted to decide whether ������ at the {MTD} is promising in terms of response probability, and if so a large randomized phase {III} trial is conducted to compare ������ to a control treatment, ������, usually based on survival time or progression free survival time. It is widely recognized that this paradigm has many ﬂaws. A recent approach combines the ﬁrst two phases by conducting a phase I-{II} trial, which chooses an optimal dose based on both eﬃcacy and toxicity, and evaluation of ������ at the selected optimal phase I-{II} dose then is done in a phase {III} trial. This paper proposes a new design paradigm, motivated by the possibility that the optimal phase I-{II} dose may not maximize mean survival time with ������. We propose a hybridized design, which we call phase I-{II}/{III}, that combines phase I-{II} and phase {III} by allowing the chosen optimal phase I-{II} dose of ������ to be re-optimized based on survival time data from phase I-{II} patients and the ﬁrst portion of phase {III}. The phase I-{II}/{III} design uses adaptive randomization in phase I-{II}, and relies on a mixture model for the survival time distribution as a function of eﬃcacy, toxicity, and dose. A simulation study is presented to evaluate the phase I-{II}/{III} design and compare it to the usual approach that does not re-optimize the dose of ������ in phase {III}.},
	pages = {biom.12994},
	journaltitle = {Biom},
	author = {Chapple, Andrew G. and Thall, Peter F.},
	urldate = {2019-04-30},
	date = {2019-04-03},
	langid = {english},
	file = {chapple_thall_2019_a_hybrid_phase_i‐ii-iii_clinical_trial_design_allowing_dose_re‐optimization_in.pdf:/home/nathan/Dropbox/njames/zotero_sync/chapple_thall_2019_a_hybrid_phase_i‐ii-iii_clinical_trial_design_allowing_dose_re‐optimization_in.pdf:application/pdf}
}

@article{brard_incorporating_2019,
	title = {Incorporating individual historical controls and aggregate treatment effect estimates into a Bayesian survival trial: a simulation study},
	volume = {19},
	issn = {1471-2288},
	url = {https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-019-0714-z},
	doi = {10.1186/s12874-019-0714-z},
	shorttitle = {Incorporating individual historical controls and aggregate treatment effect estimates into a Bayesian survival trial},
	abstract = {Background: Performing well-powered randomised controlled trials ({RCTs}) of new treatments for rare diseases is often infeasible. However, with the increasing availability of historical data, incorporating existing information into trials with small sample sizes is appealing in order to increase the power. Bayesian approaches enable one to incorporate historical data into a trial’s analysis through a prior distribution.
Methods: Motivated by a {RCT} intended to evaluate the impact on event-free survival of mifamurtide in patients with osteosarcoma, we performed a simulation study to evaluate the impact on trial operating characteristics of incorporating historical individual control data and aggregate treatment effect estimates. We used power priors derived from historical individual control data for baseline parameters of Weibull and piecewise exponential models, while we used a mixture prior to summarise aggregate information obtained on the relative treatment effect. The impact of prior-data conflicts, both with respect to the parameters and survival models, was evaluated for a set of pre-specified weights assigned to the historical information in the prior distributions.
Results: The operating characteristics varied according to the weights assigned to each source of historical information, the variance of the informative and vague component of the mixture prior and the level of commensurability between the historical and new data. When historical and new controls follow different survival distributions, we did not observe any advantage of choosing a piecewise exponential model compared to a Weibull model for the new trial analysis. However, we think that it remains appealing given the uncertainty that will often surround the shape of the survival distribution of the new data.
Conclusion: In the setting of Sarcome-13 trial, and other similar studies in rare diseases, the gains in power and accuracy made possible by incorporating different types of historical information commensurate with the new trial data have to be balanced against the risk of biased estimates and a possible loss in power if data are not commensurate. The weights allocated to the historical data have to be carefully chosen based on this trade-off. Further simulation studies investigating methods for incorporating historical data are required to generalise the findings.},
	pages = {85},
	number = {1},
	journaltitle = {{BMC} Med Res Methodol},
	author = {Brard, Caroline and Hampson, Lisa V. and Gaspar, Nathalie and Le Deley, Marie-Cécile and Le Teuff, Gwénaël},
	urldate = {2019-04-30},
	date = {2019-12},
	langid = {english},
	file = {brard_et_al_2019_incorporating_individual_historical_controls_and_aggregate_treatment_effect.pdf:/home/nathan/Dropbox/njames/zotero_sync/brard_et_al_2019_incorporating_individual_historical_controls_and_aggregate_treatment_effect.pdf:application/pdf}
}

@article{lee_bayesian_2019,
	title = {Bayesian semiparametric joint regression analysis of recurrent adverse events and survival in esophageal cancer patients},
	volume = {13},
	issn = {1932-6157},
	url = {https://projecteuclid.org/euclid.aoas/1554861647},
	doi = {10.1214/18-AOAS1182},
	pages = {221--247},
	number = {1},
	journaltitle = {Ann. Appl. Stat.},
	author = {Lee, Juhee and Thall, Peter F. and Lin, Steven H.},
	urldate = {2019-05-02},
	date = {2019-03},
	langid = {english},
	file = {lee_et_al_2019_bayesian_semiparametric_joint_regression_analysis_of_recurrent_adverse_events.pdf:/home/nathan/Dropbox/njames/zotero_sync/lee_et_al_2019_bayesian_semiparametric_joint_regression_analysis_of_recurrent_adverse_events.pdf:application/pdf}
}

@article{altzerinakou_adaptive_2019,
	title = {An adaptive design for the identification of the optimal dose using joint modeling of continuous repeated biomarker measurements and time-to-toxicity in phase I/{II} clinical trials in oncology},
	issn = {0962-2802, 1477-0334},
	url = {http://journals.sagepub.com/doi/10.1177/0962280219837737},
	doi = {10.1177/0962280219837737},
	abstract = {We present a new adaptive dose-finding method, based on a joint modeling of longitudinal continuous biomarker activity measurements and time to first dose limiting toxicity, with a shared random effect. Estimation relies on likelihood that does not require approximation, an important property in the context of small sample sizes, typical of phase I/{II} trials. We address the important case of missing at random data that stem from unacceptable toxicity, lack of activity and rapid deterioration of phase I patients. The objective is to determine the lowest dose within a range of highly active doses, under the constraint of not exceeding the maximum tolerated dose. The maximum tolerated dose is associated to some cumulative risk of dose limiting toxicity over a predefined number of treatment cycles. Operating characteristics are explored via simulations in various scenarios.},
	pages = {096228021983773},
	journaltitle = {Stat Methods Med Res},
	author = {Altzerinakou, Maria-Athina and Paoletti, Xavier},
	urldate = {2019-05-02},
	date = {2019-04-04},
	langid = {english},
	file = {altzerinakou_paoletti_2019_an_adaptive_design_for_the_identification_of_the_optimal_dose_using_joint.pdf:/home/nathan/Dropbox/njames/zotero_sync/altzerinakou_paoletti_2019_an_adaptive_design_for_the_identification_of_the_optimal_dose_using_joint.pdf:application/pdf}
}

@article{boulet_integration_2019,
	title = {Integration of elicited expert information via a power prior in Bayesian variable selection: Application to colon cancer data},
	issn = {0962-2802, 1477-0334},
	url = {http://journals.sagepub.com/doi/10.1177/0962280219841082},
	doi = {10.1177/0962280219841082},
	shorttitle = {Integration of elicited expert information via a power prior in Bayesian variable selection},
	abstract = {Background: Building tools to support personalized medicine needs to model medical decision-making. For this purpose, both expert and real world data provide a rich source of information. Currently, machine learning techniques are developing to select relevant variables for decision-making. Rather than using data-driven analysis alone, eliciting prior information from physicians related to their medical decision-making processes can be useful in variable selection. Our framework is electronic health records data on repeated dose adjustment of Irinotecan for the treatment of metastatic colorectal cancer. We propose a method that incorporates elicited expert weights associated with variables involved in dose reduction decisions into the Stochastic Search Variable Selection ({SSVS}), a Bayesian variable selection method, by using a power prior.
Methods: Clinician experts were first asked to provide numerical clinical relevance weights to express their beliefs about the importance of each variable in their medical decision making. Then, we modeled the link between repeated dose reduction, patient characteristics, and toxicities by assuming a logistic mixed-effects model. Simulated data were generated based on the elicited weights and combined with the observed dose reduction data via a power prior. We compared the Bayesian power prior-based {SSVS} performance to the usual {SSVS} in our case study, including a sensitivity analysis using the power prior parameter.
Results: The selected variables differ when using only expert knowledge, only the usual {SSVS}, or combining both. Our method enables one to select rare variables that may be missed using only the observed data and to discard variables that appear to be relevant based on the data but not relevant from the expert perspective.
Conclusion: We introduce an innovative Bayesian variable selection method that adaptively combines elicited expert information and real world data. The method selects a set of variables relevant to model medical decision process.},
	pages = {096228021984108},
	journaltitle = {Stat Methods Med Res},
	author = {Boulet, Sandrine and Ursino, Moreno and Thall, Peter and Landi, Bruno and Lepère, Céline and Pernot, Simon and Burgun, Anita and Taieb, Julien and Zaanan, Aziz and Zohar, Sarah and Jannot, Anne-Sophie},
	urldate = {2019-05-02},
	date = {2019-04-09},
	langid = {english},
	file = {boulet_et_al_2019_integration_of_elicited_expert_information_via_a_power_prior_in_bayesian.pdf:/home/nathan/Dropbox/njames/zotero_sync/boulet_et_al_2019_integration_of_elicited_expert_information_via_a_power_prior_in_bayesian.pdf:application/pdf}
}

@article{cheung_prioritized_2019,
	title = {Prioritized concordance index for hierarchical survival outcomes},
	issn = {0277-6715, 1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8157},
	doi = {10.1002/sim.8157},
	pages = {sim.8157},
	journaltitle = {Statistics in Medicine},
	author = {Cheung, Li C. and Pan, Qing and Hyun, Noorie and Katki, Hormuzd A.},
	urldate = {2019-05-07},
	date = {2019-04-07},
	langid = {english},
	file = {cheung_et_al_2019_prioritized_concordance_index_for_hierarchical_survival_outcomes.pdf:/home/nathan/Dropbox/njames/zotero_sync/cheung_et_al_2019_prioritized_concordance_index_for_hierarchical_survival_outcomes.pdf:application/pdf}
}

@article{charlesnelson_how_2019,
	title = {How to analyze and interpret recurrent events data in the presence of a terminal event: An application on readmission after colorectal cancer surgery},
	issn = {0277-6715, 1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8168},
	doi = {10.1002/sim.8168},
	shorttitle = {How to analyze and interpret recurrent events data in the presence of a terminal event},
	pages = {sim.8168},
	journaltitle = {Statistics in Medicine},
	author = {Charles‐Nelson, Anaïs and Katsahian, Sandrine and Schramm, Catherine},
	urldate = {2019-05-07},
	date = {2019-04-23},
	langid = {english},
	file = {charles‐nelson_et_al_2019_how_to_analyze_and_interpret_recurrent_events_data_in_the_presence_of_a.pdf:/home/nathan/Dropbox/njames/zotero_sync/charles‐nelson_et_al_2019_how_to_analyze_and_interpret_recurrent_events_data_in_the_presence_of_a.pdf:application/pdf}
}

@report{anandkumar_tensor_2012,
	location = {Fort Belvoir, {VA}},
	title = {Tensor Decompositions for Learning Latent Variable Models:},
	url = {http://www.dtic.mil/docs/citations/ADA604494},
	shorttitle = {Tensor Decompositions for Learning Latent Variable Models},
	abstract = {This work considers a computationally and statistically eﬃcient parameter estimation method for a wide class of latent variable models—including Gaussian mixture models, hidden Markov models, and latent Dirichlet allocation—which exploits a certain tensor structure in their low-order observable moments (typically, of second- and third-order). Speciﬁcally, parameter estimation is reduced to the problem of extracting a certain (orthogonal) decomposition of a symmetric tensor derived from the moments; this decomposition can be viewed as a natural generalization of the singular value decomposition for matrices. Although tensor decompositions are generally intractable to compute, the decomposition of these specially structured tensors can be eﬃciently obtained by a variety of approaches, including power iterations and maximization approaches (similar to the case of matrices). A detailed analysis of a robust tensor power method is provided, establishing an analogue of Wedin’s perturbation theorem for the singular vectors of matrices. This implies a robust and computationally tractable estimation approach for several popular latent variable models.},
	institution = {Defense Technical Information Center},
	author = {Anandkumar, Anima and Ge, Rong and Hsu, Daniel and Kakade, Sham M. and Telgarsky, Matus},
	urldate = {2019-05-13},
	date = {2012-12-08},
	langid = {english},
	doi = {10.21236/ADA604494},
	file = {anandkumar_et_al_2012_tensor_decompositions_for_learning_latent_variable_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/anandkumar_et_al_2012_tensor_decompositions_for_learning_latent_variable_models.pdf:application/pdf}
}

@article{saunders_regression_2019,
	title = {A Regression Framework for Causal Mediation Analysis with Applications to Behavioral Science},
	issn = {0027-3171, 1532-7906},
	url = {https://www.tandfonline.com/doi/full/10.1080/00273171.2018.1552109},
	doi = {10.1080/00273171.2018.1552109},
	abstract = {We introduce and extend the classical regression framework for conducting mediation analysis from the fit of only one model. Using the essential mediation components ({EMCs}) allows us to estimate causal mediation effects and their analytical variance. This singleequation approach reduces computation time and permits the use of a rich suite of regression tools that are not easily implemented on a system of three equations. Additionally, we extend this framework to non-nested mediation systems, provide a joint measure of mediation for complex mediation hypotheses, propose new visualizations for mediation effects, and explain why estimates of the total effect may differ depending on the approach used. Using data from social science studies, we also provide extensive illustrations of the usefulness of this framework and its advantages over traditional approaches to mediation analysis. The example data are freely available for download online and we include the R code necessary to reproduce our results.},
	pages = {1--23},
	journaltitle = {Multivariate Behavioral Research},
	author = {Saunders, Christina T. and Blume, Jeffrey D.},
	urldate = {2019-05-15},
	date = {2019-04},
	langid = {english},
	file = {2019 Paper2 Examples_to_Submit.pdf:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/QB2QG5PD/2019 Paper2 Examples_to_Submit.pdf:application/pdf;saunders_blume_2019_a_regression_framework_for_causal_mediation_analysis_with_applications_to.pdf:/home/nathan/Dropbox/njames/zotero_sync/saunders_blume_2019_a_regression_framework_for_causal_mediation_analysis_with_applications_to.pdf:application/pdf}
}

@article{smith_high-dimensional_2019,
	title = {High-dimensional copula variational approximation through transformation},
	url = {http://arxiv.org/abs/1904.07495},
	abstract = {Variational methods are attractive for computing Bayesian inference for highly parametrized models and large datasets where exact inference is impractical. They approximate a target distribution—either the posterior or an augmented posterior—using a simpler distribution that is selected to balance accuracy with computational feasibility. Here we approximate an element-wise parametric transformation of the target distribution as multivariate Gaussian or skew-normal. Approximations of this kind are implicit copula models for the original parameters, with a Gaussian or skew-normal copula function and ﬂexible parametric margins. A key observation is that their adoption can improve the accuracy of variational inference in high dimensions at limited or no additional computational cost. We consider the Yeo-Johnson and G\&H transformations, along with sparse factor structures for the scale matrix of the Gaussian or skew-normal. We also show how to implement eﬃcient reparametrization gradient methods for these copula-based approximations. The eﬃcacy of the approach is illustrated by computing posterior inference for three diﬀerent models using six real datasets. In each case, we show that our proposed copula model distributions are more accurate variational approximations than Gaussian or skew-normal distributions, but at only a minor or no increase in computational cost.},
	journaltitle = {{arXiv}:1904.07495 [stat]},
	author = {Smith, Michael Stanley and Loaiza-Maya, Ruben and Nott, David J.},
	urldate = {2019-05-15},
	date = {2019-04-16},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1904.07495},
	keywords = {Statistics - Computation},
	file = {smith_et_al_2019_high-dimensional_copula_variational_approximation_through_transformation.pdf:/home/nathan/Dropbox/njames/zotero_sync/smith_et_al_2019_high-dimensional_copula_variational_approximation_through_transformation.pdf:application/pdf}
}

@article{chandereng_robust_2019,
	title = {Robust Response-Adaptive Randomization Design},
	url = {http://arxiv.org/abs/1904.07758},
	abstract = {In clinical trials, patients are randomized with equal probability among treatments to obtain an unbiased estimate of the treatment effect. However, response-adaptive randomization has been proposed due to ethical reasons, especially in rare diseases where randomization ratio is tilted to favor the better performing treatment. The substantial disagreement regarding time-trends in adaptive randomization is not fully addressed. The type I error is inﬂated in the traditional Bayesian adaptive randomization approach when time-trend is present. In our approach, patients are assigned in blocks and the randomization ratio is recomputed for blocks rather than traditional adaptive randomization where it is done per patient. We further investigate the design with a range of scenario for both frequentist and Bayesian design. We compare our method with equal randomization and with different number of blocks including traditional responseadaptive randomization design where randomization ratio is altered patient by patient basis. The analysis is done in stratiﬁcation if there is two or more patient in each block. Having a large number of blocks or randomizing a few subjects into a block should be avoided due to the possibility of not acquiring any information from the block(s). On the other hand, response-adaptive randomization with a small number of blocks has a good balance between efﬁciency and treating more subjects to the better-performing treatment.},
	journaltitle = {{arXiv}:1904.07758 [stat]},
	author = {Chandereng, Thevaa and Chappell, Rick},
	urldate = {2019-05-15},
	date = {2019-04-16},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1904.07758},
	keywords = {Statistics - Applications},
	file = {chandereng_chappell_2019_robust_response-adaptive_randomization_design.pdf:/home/nathan/Dropbox/njames/zotero_sync/chandereng_chappell_2019_robust_response-adaptive_randomization_design.pdf:application/pdf}
}

@article{van_der_bles_communicating_2019,
	title = {Communicating uncertainty about facts, numbers and science},
	volume = {6},
	issn = {2054-5703, 2054-5703},
	url = {http://www.royalsocietypublishing.org/doi/10.1098/rsos.181870},
	doi = {10.1098/rsos.181870},
	pages = {181870},
	number = {5},
	journaltitle = {R. Soc. open sci.},
	author = {van der Bles, Anne Marthe and van der Linden, Sander and Freeman, Alexandra L. J. and Mitchell, James and Galvao, Ana B. and Zaval, Lisa and Spiegelhalter, David J.},
	urldate = {2019-05-15},
	date = {2019-05-31},
	langid = {english},
	file = {van_der_bles_et_al_2019_communicating_uncertainty_about_facts,_numbers_and_science.pdf:/home/nathan/Dropbox/njames/zotero_sync/van_der_bles_et_al_2019_communicating_uncertainty_about_facts,_numbers_and_science.pdf:application/pdf}
}

@article{lin_time--event_2019,
	title = {Time-to-event model-assisted designs for dose-finding trials with delayed toxicity},
	issn = {1465-4644, 1468-4357},
	url = {https://academic.oup.com/biostatistics/advance-article/doi/10.1093/biostatistics/kxz007/5460289},
	doi = {10.1093/biostatistics/kxz007},
	abstract = {Two useful strategies to speed up drug development are to increase the patient accrual rate and use novel adaptive designs. Unfortunately, these two strategies often conﬂict when the evaluation of the outcome cannot keep pace with the patient accrual rate and thus the interim data cannot be observed in time to make adaptive decisions. A similar logistic difﬁculty arises when the outcome is late-onset. Based on a novel formulation and approximation of the likelihood of the observed data, we propose a general methodology for model-assisted designs to handle toxicity data that are pending due to fast accrual or late-onset toxicity and facilitate seamless decision making in phase I dose-ﬁnding trials. The proposed time-to-event model-assisted designs consider each dose separately and the dose-escalation/de-escalation rules can be tabulated before the trial begins, which greatly simpliﬁes trial conduct in practice compared to that under existing methods. We show that the proposed designs have desirable ﬁnite and large-sample properties and yield performance that is comparable to that of more complicated model-based designs. We provide user-friendly software for implementing the designs.},
	journaltitle = {Biostatistics},
	author = {Lin, Ruitao and Yuan, Ying},
	urldate = {2019-05-15},
	date = {2019-04-15},
	langid = {english},
	file = {lin_yuan_2019_time-to-event_model-assisted_designs_for_dose-finding_trials_with_delayed.pdf:/home/nathan/Dropbox/njames/zotero_sync/lin_yuan_2019_time-to-event_model-assisted_designs_for_dose-finding_trials_with_delayed.pdf:application/pdf}
}

@article{zhou_pod-tpi:_2019,
	title = {{PoD}-{TPI}: Probability-of-Decision Toxicity Probability Interval Design to Accelerate Phase I Trials},
	url = {http://arxiv.org/abs/1904.12981},
	shorttitle = {{PoD}-{TPI}},
	abstract = {Cohort-based enrollment can slow down dose-ﬁnding trials since the outcomes of the previous cohort must be fully evaluated before the next cohort can be enrolled. This results in frequent suspension of patient enrollment. The issue is exacerbated in recent immune oncology trials where toxicity outcomes can take a long time to observe. We propose a novel phase I design, the probability-of-decision toxicity probability interval ({PoD}-{TPI}) design, to accelerate phase I trials. {PoD}-{TPI} enables dose assignment in real time in the presence of pending toxicity outcomes. With uncertain outcomes, the dose assignment decision is treated as a random variable, and we calculate the posterior distribution of the decision. The posterior distribution reﬂects the variability in the pending outcomes and allows a direct and intuitive evaluation of the conﬁdence of all possible decisions. Optimal decisions are calculated based on 0-1 loss, and extra safety rules are constructed to enforce suﬃcient protection from exposing patients to risky doses. A new and useful feature of {PoD}-{TPI} is that it allows investigators to balance the trade-oﬀ between enrollment speed and making risky decisions by tuning a pair of intuitive design parameters. Through numerical studies, we evaluate the operating characteristics of {PoD}-{TPI} and demonstrate that {PoD}-{TPI} shortens trial duration and maintains desirable safety and eﬃciency compared to existing time-to-event designs.},
	journaltitle = {{arXiv}:1904.12981 [stat]},
	author = {Zhou, Tianjian and Guo, Wentian and Ji, Yuan},
	urldate = {2019-05-15},
	date = {2019-04-29},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1904.12981},
	keywords = {Statistics - Methodology, Statistics - Applications},
	file = {zhou_et_al_2019_pod-tpi.pdf:/home/nathan/Dropbox/njames/zotero_sync/zhou_et_al_2019_pod-tpi.pdf:application/pdf}
}

@article{tang_copulabased_2019,
	title = {Copula‐based semiparametric models for spatio‐temporal data},
	issn = {0006-341X, 1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13066},
	doi = {10.1111/biom.13066},
	abstract = {The joint analysis of spatial and temporal processes poses computational challenges due to the data’s high dimensionality. Furthermore, such data are commonly non-Gaussian. In this paper, we introduce a copula-based spatio-temporal model for analyzing spatio-temporal data and propose a semiparametric estimator. The proposed algorithm is computationally simple, since it models the marginal distribution and the spatiotemporal dependence separately. Instead of assuming a parametric distribution, the proposed method models the marginal distributions nonparametrically and thus oﬀers more ﬂexibility. The method also provides a convenient way to construct both point and interval predictions at new times and new locations, based on the estimated conditional quantiles. Through a simulation study and an analysis of wind speeds observed along the border between Oregon and Washington, we show that our method produces more accurate point and interval predictions for skewed data than those based on normality assumptions.},
	pages = {biom.13066},
	journaltitle = {Biom},
	author = {Tang, Yanlin and Wang, Huixia Judy and Sun, Ying and Hering, Amanda S.},
	urldate = {2019-05-22},
	date = {2019-04-22},
	langid = {english},
	file = {tang_et_al_2019_copula‐based_semiparametric_models_for_spatio‐temporal_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/tang_et_al_2019_copula‐based_semiparametric_models_for_spatio‐temporal_data.pdf:application/pdf}
}

@article{krueger_variational_2019,
	title = {Variational Bayesian Inference for Mixed Logit Models with Unobserved Inter- and Intra-Individual Heterogeneity},
	url = {http://arxiv.org/abs/1905.00419},
	abstract = {Variational Bayes ({VB}) methods have emerged as a fast and computationally-efficient alternative to Markov chain Monte Carlo ({MCMC}) methods for Bayesian estimation of mixed logit models. In this paper, we derive a {VB} method for posterior inference in mixed multinomial logit models with unobserved inter- and intra-individual heterogeneity. The proposed {VB} method is benchmarked against {MCMC} in a simulation study. The results suggest that {VB} is substantially faster than {MCMC} but also noticeably less accurate, because the mean-field assumption of {VB} is too restrictive. Future research should thus focus on enhancing the expressiveness and flexibility of the variational approximation.},
	journaltitle = {{arXiv}:1905.00419 [econ, stat]},
	author = {Krueger, Rico and Bansal, Prateek and Bierlaire, Michel and Daziano, Ricardo A. and Rashidi, Taha H.},
	urldate = {2019-05-28},
	date = {2019-05-01},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1905.00419},
	keywords = {Statistics - Methodology, Economics - Econometrics},
	file = {krueger_et_al_2019_variational_bayesian_inference_for_mixed_logit_models_with_unobserved_inter-.pdf:/home/nathan/Dropbox/njames/zotero_sync/krueger_et_al_2019_variational_bayesian_inference_for_mixed_logit_models_with_unobserved_inter-.pdf:application/pdf}
}

@article{horton_consequences_2019,
	title = {Consequences of performing parallel dose finding trials in heterogeneous groups of patients},
	issn = {2515-5091},
	url = {https://academic.oup.com/jncics/advance-article/doi/10.1093/jncics/pkz013/5486339},
	doi = {10.1093/jncics/pkz013},
	abstract = {Patient heterogeneity, in which patients can be grouped by risk of toxicity, is a design challenge in early phase dose finding trials. Carrying out independent trials for each group is a readily available approach for dose finding. However, this often leads to dose recommendations that violate the known order of toxicity risk by group, or reversals in dose recommendation. In this manuscript, trials for partially ordered groups are simulated using four approaches: independent parallel trials using the {CRM}, {BOIN}, and 3+3 methods, as well as {CRM} for partially ordered groups. Multiple group order structures are considered, allowing for varying amounts of group frailty order information. These simulations find that parallel trials in the presence of partially ordered groups display a high frequency of trials resulting in reversals. Reversals occur when dose recommendations do not follow known order of toxicity risk by group, such as recommending a higher dose level in a group of patients known to have a higher risk of toxicity. {CRM} for partially ordered groups eliminates the issue of reversals and simulation results indicate improved frequency of maximum tolerated dose selection as well as treating a greater proportion of trial patients at this dose, compared to parallel trials. When information is available on differences in toxicity risk by patient subgroup, methods designed to account for known group ordering should be considered to avoid reversals in dose recommendations and improve operating characteristics.},
	pages = {pkz013},
	journaltitle = {{JNCI} Cancer Spectrum},
	author = {Horton, Bethany Jablonski and O'Quigley, John and Conaway, Mark R},
	urldate = {2019-05-28},
	date = {2019-05-07},
	langid = {english},
	file = {horton_et_al_2019_consequences_of_performing_parallel_dose_finding_trials_in_heterogeneous_groups.pdf:/home/nathan/Dropbox/njames/zotero_sync/horton_et_al_2019_consequences_of_performing_parallel_dose_finding_trials_in_heterogeneous_groups.pdf:application/pdf}
}

@article{ye_efficacy_2019,
	title = {On the Efficacy of Monte Carlo Implementation of {CAVI}},
	url = {http://arxiv.org/abs/1905.03760},
	abstract = {In Variational Inference ({VI}), coordinate-ascent and gradient-based approaches are two major types of algorithms for approximating diﬃcult-to-compute probability densities. In real-world implementations of complex models, Monte Carlo methods are widely used to estimate expectations in coordinate-ascent approaches and gradients in derivative-driven ones. We discuss a Monte Carlo Co-ordinate Ascent {VI} ({MC}-{CAVI}) algorithm that makes use of Markov chain Monte Carlo ({MCMC}) methods in the calculation of expectations required within Co-ordinate Ascent {VI} ({CAVI}). We show that, under regularity conditions, an {MC}-{CAVI} recursion will get arbitrarily close to a maximiser of the evidence lower bound ({ELBO}) with any given high probability. In numerical examples, the performance of {MC}-{CAVI} algorithm is compared with that of {MCMC} and – as a representative of derivative-based {VI} methods – of Black Box {VI} ({BBVI}). We discuss and demonstrate {MC}-{CAVI}’s suitability for models with hard constraints in simulated and real examples. We compare {MC}-{CAVI}’s performance with that of {MCMC} in an important complex model used in Nuclear Magnetic Resonance ({NMR}) spectroscopy data analysis – {BBVI} is nearly impossible to be employed in this setting due to the hard constraints involved in the model.},
	journaltitle = {{arXiv}:1905.03760 [stat]},
	author = {Ye, Lifeng and Beskos, Alexandros and De Iorio, Maria and Hao, Jie},
	urldate = {2019-05-28},
	date = {2019-05-09},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1905.03760},
	keywords = {Statistics - Computation},
	file = {ye_et_al_2019_on_the_efficacy_of_monte_carlo_implementation_of_cavi.pdf:/home/nathan/Dropbox/njames/zotero_sync/ye_et_al_2019_on_the_efficacy_of_monte_carlo_implementation_of_cavi.pdf:application/pdf}
}

@article{tatsioni_lost_2019,
	title = {Lost Evidence From Registered Large Long-Unpublished Randomized Controlled Trials: A Survey},
	issn = {0003-4819},
	url = {http://annals.org/article.aspx?doi=10.7326/M19-0440},
	doi = {10.7326/M19-0440},
	shorttitle = {Lost Evidence From Registered Large Long-Unpublished Randomized Controlled Trials},
	journaltitle = {Ann Intern Med},
	author = {Tatsioni, Athina and Karassa, Fotini B. and Goodman, Steven N. and Zarin, Deborah A. and Fanelli, Daniele and Ioannidis, John P.A.},
	urldate = {2019-05-28},
	date = {2019-05-07},
	langid = {english},
	file = {tatsioni_et_al_2019_lost_evidence_from_registered_large_long-unpublished_randomized_controlled.pdf:/home/nathan/Dropbox/njames/zotero_sync/tatsioni_et_al_2019_lost_evidence_from_registered_large_long-unpublished_randomized_controlled.pdf:application/pdf}
}

@article{senn_mastering_2016-1,
	title = {Mastering variation: variance components and personalised medicine},
	volume = {35},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6739},
	doi = {10.1002/sim.6739},
	shorttitle = {Mastering variation},
	abstract = {Various sources of variation in observed response in clinical trials and clinical practice are considered, and ways in which the corresponding components of variation might be estimated are discussed. Although the issues have been generally well-covered in the statistical literature, they seem to be poorly understood in the medical literature and even the statistical literature occasionally shows some confusion. To increase understanding and communication, some simple graphical approaches to illustrating issues are proposed. It is also suggested that reducing variation in medical practice might make as big a contribution to improving health outcome as personalising its delivery according to the patient. It is concluded that the common belief that there is a strong personal element in response to treatment is not based on sound statistical evidence. © 2015 The Authors. Statistics in Medicine published by John Wiley \& Sons Ltd.},
	pages = {966--977},
	number = {7},
	journaltitle = {Statistics in Medicine},
	author = {Senn, Stephen},
	urldate = {2019-05-28},
	date = {2016},
	langid = {english},
	keywords = {components of variation, cross-over trials, n-of-1 trials, personalised medicine, random effects},
	file = {senn_2016_mastering_variation.pdf:/home/nathan/Dropbox/njames/zotero_sync/senn_2016_mastering_variation2.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/6CM3R827/sim.html:text/html}
}

@article{snapinn_clinical_2011,
	title = {On the clinical meaningfulness of a treatment's effect on a time-to-event variable},
	volume = {30},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.4256},
	doi = {10.1002/sim.4256},
	pages = {2341--2348},
	number = {19},
	journaltitle = {Statist. Med.},
	author = {Snapinn, Steven and Jiang, Qi},
	urldate = {2019-05-28},
	date = {2011-08-30},
	langid = {english},
	file = {snapinn_jiang_2011_on_the_clinical_meaningfulness_of_a_treatment's_effect_on_a_time-to-event.pdf:/home/nathan/Dropbox/njames/zotero_sync/snapinn_jiang_2011_on_the_clinical_meaningfulness_of_a_treatment's_effect_on_a_time-to-event.pdf:application/pdf}
}

@article{yang_variational_2019,
	title = {Variational approximations using Fisher divergence},
	url = {http://arxiv.org/abs/1905.05284},
	abstract = {Modern applications of Bayesian inference involve models that are suﬃciently complex that the corresponding posterior distributions are intractable and must be approximated. The most common approximation is based on Markov chain Monte Carlo, but these can be expensive when the data set is large and/or the model is complex, so more eﬃcient variational approximations have recently received considerable attention. The traditional variational methods, that seek to minimize the Kullback–Leibler divergence between the posterior and a relatively simple parametric family, provide accurate and eﬃcient estimation of the posterior mean, but often does not capture other moments, and have limitations in terms of the models to which they can be applied. Here we propose the construction of variational approximations based on minimizing the Fisher divergence, and develop an eﬃcient computational algorithm that can be applied to a wide range of models without conjugacy or potentially unrealistic mean-ﬁeld assumptions. We demonstrate the superior performance of the proposed method for the benchmark case of logistic regression.},
	journaltitle = {{arXiv}:1905.05284 [cs, stat]},
	author = {Yang, Yue and Martin, Ryan and Bondell, Howard},
	urldate = {2019-05-28},
	date = {2019-05-13},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1905.05284},
	keywords = {Statistics - Methodology, Statistics - Computation, Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {yang_et_al_2019_variational_approximations_using_fisher_divergence.pdf:/home/nathan/Dropbox/njames/zotero_sync/yang_et_al_2019_variational_approximations_using_fisher_divergence.pdf:application/pdf}
}

@article{starling_targeted_2019,
	title = {Targeted Smooth Bayesian Causal Forests: An analysis of heterogeneous treatment effects for simultaneous versus interval medical abortion regimens over gestation},
	url = {http://arxiv.org/abs/1905.09405},
	shorttitle = {Targeted Smooth Bayesian Causal Forests},
	abstract = {This article introduces Targeted Smooth Bayesian Causal Forests, or tsbcf, a semi-parametric Bayesian approach for estimating heterogeneous treatment effects which vary smoothly over a single covariate in the observational data setting. The tsbcf method induces smoothness in estimated treamtent effects over the target covariate by parameterizing each tree's terminal nodes with smooth functions. The model allows for separate regularization of treatement effects versus prognostic effect of control covariates; this approach informatively shrinks towards homogeneity while avoiding biased treatment effect estimates. We provide smoothing parameters for prognostic and treatment effects which can be chosen to reflect prior knowledge or tuned in a data-dependent way. We apply tsbcf to early medical abortion outcomes data from British Pregnancy Advisory Service. Our aim is to assess relative effectiveness of simultaneous versus interval administration of mifepristone and misoprostol over the first nine weeks of gestation, where we define successful outcome as complete abortion requiring neither surgical evacuation nor continuing pregnancy. We expect the relative effectiveness of simultaneous administration to vary smoothly over gestational age, but not necessarily other covariates, and our model reflects this. We demonstrate the performance of the tsbcf method on benchmarking experiments. The R package tsbcf implements our method.},
	journaltitle = {{arXiv}:1905.09405 [stat]},
	author = {Starling, Jennifer E. and Murray, Jared S. and Lohr, Patricia A. and Aiken, Abigail R. A. and Carvalho, Carlos M. and Scott, James G.},
	urldate = {2019-05-29},
	date = {2019-05-22},
	eprinttype = {arxiv},
	eprint = {1905.09405},
	keywords = {Statistics - Applications},
	file = {arXiv.org Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/9RGJ5H5G/1905.html:text/html;starling_et_al_2019_targeted_smooth_bayesian_causal_forests.pdf:/home/nathan/Dropbox/njames/zotero_sync/starling_et_al_2019_targeted_smooth_bayesian_causal_forests.pdf:application/pdf}
}

@article{mcculloch_joint_2008,
	title = {Joint modelling of mixed outcome types using latent variables},
	volume = {17},
	issn = {0962-2802, 1477-0334},
	url = {http://journals.sagepub.com/doi/10.1177/0962280207081240},
	doi = {10.1177/0962280207081240},
	pages = {53--73},
	number = {1},
	journaltitle = {Stat Methods Med Res},
	author = {{McCulloch}, Charles},
	urldate = {2019-05-29},
	date = {2008-02},
	langid = {english},
	file = {mcculloch_2008_joint_modelling_of_mixed_outcome_types_using_latent_variables.pdf:/home/nathan/Dropbox/njames/zotero_sync/mcculloch_2008_joint_modelling_of_mixed_outcome_types_using_latent_variables.pdf:application/pdf}
}

@article{kass_ten_2016,
	title = {Ten Simple Rules for Effective Statistical Practice},
	volume = {12},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1004961},
	doi = {10.1371/journal.pcbi.1004961},
	pages = {e1004961},
	number = {6},
	journaltitle = {{PLoS} Comput Biol},
	author = {Kass, Robert E. and Caffo, Brian S. and Davidian, Marie and Meng, Xiao-Li and Yu, Bin and Reid, Nancy},
	editor = {Lewitter, Fran},
	urldate = {2019-05-30},
	date = {2016-06-09},
	langid = {english},
	file = {kass_et_al_2016_ten_simple_rules_for_effective_statistical_practice.pdf:/home/nathan/Dropbox/njames/zotero_sync/kass_et_al_2016_ten_simple_rules_for_effective_statistical_practice.pdf:application/pdf}
}

@article{greenland_nonsignificance_2012,
	title = {Nonsignificance Plus High Power Does Not Imply Support for the Null Over the Alternative},
	volume = {22},
	issn = {10472797},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1047279712000221},
	doi = {10.1016/j.annepidem.2012.02.007},
	abstract = {This article summarizes arguments against the use of power to analyze data, and illustrates a key pitfall: Lack of statistical signiﬁcance (e.g., p O .05) combined with high power (e.g., 90\%) can occur even if the data support the alternative more than the null. This problem arises via selective choice of parameters at which power is calculated, but can also arise if one computes power at a prespeciﬁed alternative. As noted by earlier authors, power computed using sample estimates (‘‘observed power’’) replaces this problem with even more counterintuitive behavior, because observed power effectively double counts the data and increases as the P value declines. Use of power to analyze and interpret data thus needs more extensive discouragement. Ann Epidemiol 2012;22:364–368. Ó 2012 Elsevier Inc. All rights reserved.},
	pages = {364--368},
	number = {5},
	journaltitle = {Annals of Epidemiology},
	author = {Greenland, Sander},
	urldate = {2019-05-30},
	date = {2012-05},
	langid = {english},
	file = {greenland_2012_nonsignificance_plus_high_power_does_not_imply_support_for_the_null_over_the.pdf:/home/nathan/Dropbox/njames/zotero_sync/greenland_2012_nonsignificance_plus_high_power_does_not_imply_support_for_the_null_over_the.pdf:application/pdf}
}

@article{marino_reflections_2017,
	title = {Reflections From a Statistical Editor: Elements of Great Manuscripts},
	volume = {15},
	issn = {1544-1709, 1544-1717},
	url = {http://www.annfammed.org/lookup/doi/10.1370/afm.2157},
	doi = {10.1370/afm.2157},
	shorttitle = {Reflections From a Statistical Editor},
	pages = {504--506},
	number = {6},
	journaltitle = {Ann Fam Med},
	author = {Marino, Miguel},
	urldate = {2019-05-30},
	date = {2017-11},
	langid = {english},
	file = {marino_2017_reflections_from_a_statistical_editor.pdf:/home/nathan/Dropbox/njames/zotero_sync/marino_2017_reflections_from_a_statistical_editor.pdf:application/pdf}
}

@report{nosek_scientific_2013,
	title = {Scientific Utopia: Restructuring Incentives and Practices to Promote  Truth Over Publishability},
	url = {http://doi.apa.org/get-pe-doi.cfm?doi=10.1037/e636952013-027},
	shorttitle = {Scientific Utopia: Restructuring Incentives and Practices to Promote  Truth Over Publishability},
	abstract = {An academic scientist’s professional success depends on publishing. Publishing norms emphasize novel, positive results. As such, disciplinary incentives encourage design, analysis, and reporting decisions that elicit positive results and ignore negative results. Prior reports demonstrate how these incentives inflate the rate of false effects in published science.When incentives favor novelty over replication, false results persist in the literature unchallenged, reducing efficiency in knowledge accumulation. Previous suggestions to address this problem are unlikely to be effective. For example, a journal of negative results publishes otherwise unpublishable reports.This enshrines the low status of the journal and its content.The persistence of false findings can be meliorated with strategies that make the fundamental but abstract accuracy motive—getting it right—competitive with the more tangible and concrete incentive—getting it published.This article develops strategies for improving scientific practices and knowledge accumulation that account for ordinary human motivations and biases.},
	institution = {American Psychological Association},
	author = {Nosek, B.},
	urldate = {2019-05-30},
	date = {2013},
	langid = {english},
	doi = {10.1037/e636952013-027},
	note = {type: dataset},
	file = {nosek_2013_scientific_utopia.pdf:/home/nathan/Dropbox/njames/zotero_sync/nosek_2013_scientific_utopia.pdf:application/pdf}
}

@article{seibold_model-based_2016,
	title = {Model-Based Recursive Partitioning for Subgroup Analyses},
	volume = {12},
	issn = {2194-573X, 1557-4679},
	url = {http://www.degruyter.com/view/j/ijb.2016.12.issue-1/ijb-2015-0032/ijb-2015-0032.xml},
	doi = {10.1515/ijb-2015-0032},
	abstract = {The identification of patient subgroups with differential treatment effects is the first step towards individualised treatments. A current draft guideline by the {EMA} discusses potentials and problems in subgroup analyses and formulated challenges to the development of appropriate statistical procedures for the data-driven identification of patient subgroups. We introduce model-based recursive partitioning as a procedure for the automated detection of patient subgroups that are identifiable by predictive factors. The method starts with a model for the overall treatment effect as defined for the primary analysis in the study protocol and uses measures for detecting parameter instabilities in this treatment effect. The procedure produces a segmented model with differential treatment parameters corresponding to each patient subgroup. The subgroups are linked to predictive factors by means of a decision tree. The method is applied to the search for subgroups of patients suffering from amyotrophic lateral sclerosis that differ with respect to their Riluzole treatment effect, the only currently approved drug for this disease.},
	pages = {45--63},
	number = {1},
	journaltitle = {The International Journal of Biostatistics},
	author = {Seibold, Heidi and Zeileis, Achim and Hothorn, Torsten},
	urldate = {2019-05-31},
	date = {2016-05-01},
	langid = {english},
	file = {seibold_et_al_2016_model-based_recursive_partitioning_for_subgroup_analyses.pdf:/home/nathan/Dropbox/njames/zotero_sync/seibold_et_al_2016_model-based_recursive_partitioning_for_subgroup_analyses.pdf:application/pdf}
}

@article{seibold_model4you:_2019,
	title = {model4you: An R Package for Personalised Treatment Effect Estimation},
	volume = {7},
	issn = {2049-9647},
	url = {http://openresearchsoftware.metajnl.com/articles/10.5334/jors.219/},
	doi = {10.5334/jors.219},
	shorttitle = {model4you},
	pages = {17},
	journaltitle = {Journal of Open Research Software},
	author = {Seibold, Heidi and Zeileis, Achim and Hothorn, Torsten},
	urldate = {2019-05-31},
	date = {2019-05-15},
	langid = {english},
	file = {seibold_et_al_2019_model4you.pdf:/home/nathan/Dropbox/njames/zotero_sync/seibold_et_al_2019_model4you.pdf:application/pdf}
}

@article{zhu_evaluating_2019,
	title = {Evaluating the effects of design parameters on the performances of phase I trial designs},
	volume = {15},
	issn = {24518654},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2451865418301704},
	doi = {10.1016/j.conctc.2019.100379},
	abstract = {Numerous designs have been proposed for phase I clinical trials. Although studies have compared their performances, few have considered the effects of changing design parameters. In this article, we review a few popular designs, including the 3 + 3, continuous reassessment method ({CRM}), Bayesian optimal interval ({BOIN}) design, and Keyboard design, and evaluate how varying design parameters (such as number of dose levels, target toxicity rate, maximum sample size, and cohort size) could impact the performances of each design through simulations. Excluded from our analysis is the {mTPI}-2 design, which operates in the same way as the Keyboard. Our results suggest that regardless of the choices of design parameters, the 3 + 3 design performs worse than the other ones, and {BOIN} and Keyboard have comparable performance to {CRM}. For any design, the performance varies with the choice of parameters. In particular, it improves as sample sizes increase, but the magnitude of benefit from increasing sample sizes varies substantially across scenarios. The impact of cohort size on design performances seems to have no clear direction. Therefore, {BOIN} and Keyboard designs are generally recommended due to their simplicity and good performance. With regard to choices of sample size and cohort size in designing a trial, it is recommend that simulations be performed for the particular clinical settings to aid decision making.},
	pages = {100379},
	journaltitle = {Contemporary Clinical Trials Communications},
	author = {Zhu, Yaqian and Hwang, Wei-Ting and Li, Yimei},
	urldate = {2019-06-05},
	date = {2019-09},
	langid = {english},
	file = {zhu_et_al_2019_evaluating_the_effects_of_design_parameters_on_the_performances_of_phase_i.pdf:/home/nathan/Dropbox/njames/zotero_sync/zhu_et_al_2019_evaluating_the_effects_of_design_parameters_on_the_performances_of_phase_i.pdf:application/pdf}
}

@article{ferreira_bivariate_2019,
	title = {Bivariate Copula-based Linear Mixed-effects Models: An Application to Longitudinal Child Growth Data},
	volume = {20},
	issn = {2179-8451, 1677-1966},
	url = {https://tema.sbmac.org.br/tema/article/view/1211},
	doi = {10.5540/tema.2019.020.01.37},
	shorttitle = {Bivariate Copula-based Linear Mixed-effects Models},
	abstract = {Multiple longitudinal outcomes are common in public health research and adequate methods are required when there is interest in the joint evolution of response variables over time. However, the main drawback of joint modeling procedures is the requirement to specify the joint density of all outcomes and their correlation structure, as well as numerical difﬁculties in statistical inference, when the dimension of these outcomes increases. To overcome such difﬁculty, we present two procedures to deal with multivariate longitudinal data. We ﬁrst present an univariate approach, for which linear mixed-effects models are considered for each response variable separately. Then, a novel copula-based modeling is presented, in order to characterize relationships among the response variables. Both methodologies are applied to a real Brazilian data set on child growth.},
	pages = {37},
	number = {1},
	journaltitle = {Tend. Mat. Apl. Comput.},
	author = {Ferreira, Paulo Henrique and Fiaccone, Rosemeire L and Lordelo, Jairo S and Sena, Samila O. L. and Duran, Victor R.},
	urldate = {2019-06-05},
	date = {2019-05-20},
	langid = {english},
	file = {ferreira_et_al_2019_bivariate_copula-based_linear_mixed-effects_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/ferreira_et_al_2019_bivariate_copula-based_linear_mixed-effects_models.pdf:application/pdf}
}

@article{egorov_maxentropy_2019,
	title = {{MaxEntropy} Pursuit Variational Inference},
	url = {http://arxiv.org/abs/1905.07855},
	abstract = {One of the core problems in variational inference is a choice of approximate posterior distribution. It is crucial to trade-oﬀ between eﬃcient inference with simple families as mean-ﬁeld models and accuracy of inference. We propose a variant of a greedy approximation of the posterior distribution with tractable base learners. Using Max-Entropy approach, we obtain a well-deﬁned optimization problem. We demonstrate the ability of the method to capture complex multimodal posterior via continual learning setting for neural networks.},
	journaltitle = {{arXiv}:1905.07855 [cs, stat]},
	author = {Egorov, Evgenii and Neklydov, Kirill and Kostoev, Ruslan and Burnaev, Evgeny},
	urldate = {2019-06-05},
	date = {2019-05-19},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1905.07855},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {egorov_et_al_2019_maxentropy_pursuit_variational_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/egorov_et_al_2019_maxentropy_pursuit_variational_inference.pdf:application/pdf}
}

@article{levi_finding_2019,
	title = {Finding our Way in the Dark: Approximate {MCMC} for Approximate Bayesian Methods},
	url = {http://arxiv.org/abs/1905.06680},
	shorttitle = {Finding our Way in the Dark},
	abstract = {With larger amounts of data at their disposal, scientists are emboldened to tackle complex questions that require sophisticated statistical models. It is not unusual for the latter to have likelihood functions that elude analytical formulations. Even under such adversity, when one can simulate from the sampling distribution, Bayesian analysis can be conducted using approximate methods such as Approximate Bayesian Computation ({ABC}) or Bayesian Synthetic Likelihood ({BSL}). A signiﬁcant drawback of these methods is that the number of required simulations can be prohibitively large, thus severely limiting their scope. In this paper we design perturbed {MCMC} samplers that can be used within the {ABC} and {BSL} paradigms to signiﬁcantly accelerate computation while maintaining control on computational eﬃciency. The proposed strategy relies on recycling samples from the chain’s past. The algorithmic design is supported by a theoretical analysis while practical performance is examined via a series of simulation examples and data analyses.},
	journaltitle = {{arXiv}:1905.06680 [stat]},
	author = {Levi, Evgeny and Craiu, Radu V.},
	urldate = {2019-06-05},
	date = {2019-05-16},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1905.06680},
	keywords = {Statistics - Computation},
	file = {levi_craiu_2019_finding_our_way_in_the_dark.pdf:/home/nathan/Dropbox/njames/zotero_sync/levi_craiu_2019_finding_our_way_in_the_dark.pdf:application/pdf}
}

@article{gelman_many_nodate,
	title = {Many perspectives on Deborah Mayo’s “Statistical Inference as Severe Testing: How to Get Beyond the Statistics Wars”},
	abstract = {The new book by philosopher Deborah Mayo is relevant to data science for topical reasons, as she takes various controversial positions regarding hypothesis testing and statistical practice, and also as an entry point to thinking about the philosophy of statistics. The present article is a slightly expanded version of a series of informal reviews and comments on Mayo’s book. We hope this discussion will introduce people to Mayo’s ideas along with other perspectives on the topics she addresses.},
	pages = {23},
	author = {Gelman, Andrew and Haig, Brian and Hennig, Christian and Owen, Art and Cousins, Robert and Young, Stan and Robert, Christian and Yanofsky, Corey and Wagenmakers, E J and Kenett, Ron and Lakeland, Daniel},
	langid = {english},
	file = {gelman_et_al_many_perspectives_on_deborah_mayo’s_“statistical_inference_as_severe_testing.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_et_al_many_perspectives_on_deborah_mayo’s_“statistical_inference_as_severe_testing.pdf:application/pdf}
}

@article{tuyl_method_2019,
	title = {A Method to Handle Zero Counts in the Multinomial Model},
	volume = {73},
	issn = {0003-1305, 1537-2731},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1444673},
	doi = {10.1080/00031305.2018.1444673},
	abstract = {In the context of an objective Bayesian approach to the multinomial model, Dirichlet(a, . . . , a) priors with a {\textless} 1 have previously been shown to be inadequate in the presence of zero counts, suggesting that the uniform prior (a = 1) is the preferred candidate. In the presence of many zero counts, however, this prior may not be satisfactory either. A model selection approach is proposed, allowing for the possibility of zero parameters corresponding to zero count categories. This approach results in a posterior mixture of Dirichlet distributions and marginal mixtures of beta distributions, which seem to avoid the problems that potentially result from the various proposed Dirichlet priors, in particular in the context of extreme data with zero counts.},
	pages = {151--158},
	number = {2},
	journaltitle = {The American Statistician},
	author = {Tuyl, Frank},
	urldate = {2019-06-06},
	date = {2019-04-03},
	langid = {english},
	file = {tuyl_2019_a_method_to_handle_zero_counts_in_the_multinomial_model.pdf:/home/nathan/Dropbox/njames/zotero_sync/tuyl_2019_a_method_to_handle_zero_counts_in_the_multinomial_model.pdf:application/pdf}
}

@article{stander_analysis_2019,
	title = {Analysis of paediatric visual acuity using Bayesian copula models with sinh-arcsinh marginal densities},
	volume = {0},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8176},
	doi = {10.1002/sim.8176},
	abstract = {We analyse paediatric ophthalmic data from a large sample of children aged between 3 and 8 years. We use a Bayesian additive conditional bivariate copula regression model with sinh-arcsinh marginal densities with location, scale, and shape parameters that depend smoothly on a covariate. We perform Bayesian inference about the unknown quantities of our model using a specially tailored Markov chain Monte Carlo algorithm. We gain new insights about the processes, which determine transformations in visual acuity with respect to age, including the nature of joint changes in both eyes as modelled with the age-related copula dependence parameter. We analyse posterior predictive distributions to identify children with unusual sight characteristics, distinguishing those who are bivariate, but not univariate outliers. In this way, we provide an innovative tool that enables clinicians to identify children with unusual sight who may otherwise be missed. We compare our simultaneous Bayesian method with a two-step frequentist generalised additive modelling approach.},
	number = {0},
	journaltitle = {Statistics in Medicine},
	author = {Stander, Julian and Valle, Luciana Dalla and Taglioni, Charlotte and Liseo, Brunero and Wade, Angie and Cortina‐Borja, Mario},
	urldate = {2019-06-11},
	date = {2019-05},
	langid = {english},
	keywords = {conditional copulas, Bayesian dependence modelling, generalised additive models for location, scale and shape (gamlss), sinh-arcsinh distribution, visual acuity},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/GMXM62UR/sim.html:text/html;stander_et_al_analysis_of_paediatric_visual_acuity_using_bayesian_copula_models_with.pdf:/home/nathan/Dropbox/njames/zotero_sync/stander_et_al_analysis_of_paediatric_visual_acuity_using_bayesian_copula_models_with.pdf:application/pdf}
}

@article{muller_dependence_2017,
	title = {Dependence Modeling in Ultra High Dimensions with Vine Copulas and the Graphical Lasso},
	url = {http://arxiv.org/abs/1709.05119},
	abstract = {To model high dimensional data, Gaussian methods are widely used since they remain tractable and yield parsimonious models by imposing strong assumptions on the data. Vine copulas are more ﬂexible by combining arbitrary marginal distributions and (conditional) bivariate copulas. Yet, this adaptability is accompanied by sharply increasing computational eﬀort as the dimension increases. The approach proposed in this paper overcomes this burden and makes the ﬁrst step into ultra high dimensional non-Gaussian dependence modeling by using a divide-and-conquer approach. First, we apply Gaussian methods to split datasets into feasibly small subsets and second, apply parsimonious and ﬂexible vine copulas thereon. Finally, we reconcile them into one joint model. We provide numerical results demonstrating the feasibility of our approach in moderate dimensions and showcase its ability to estimate ultra high dimensional non-Gaussian dependence models in thousands of dimensions.},
	journaltitle = {{arXiv}:1709.05119 [stat]},
	author = {Müller, Dominik and Czado, Claudia},
	urldate = {2019-06-11},
	date = {2017-09-15},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1709.05119},
	keywords = {Statistics - Machine Learning},
	file = {müller_czado_2017_dependence_modeling_in_ultra_high_dimensions_with_vine_copulas_and_the.pdf:/home/nathan/Dropbox/njames/zotero_sync/müller_czado_2017_dependence_modeling_in_ultra_high_dimensions_with_vine_copulas_and_the.pdf:application/pdf}
}

@article{elidan_copula_nodate,
	title = {Copula Bayesian Networks},
	abstract = {We present the Copula Bayesian Network model for representing multivariate continuous distributions, while taking advantage of the relative ease of estimating univariate distributions. Using a novel copula-based reparameterization of a conditional density, joined with a graph that encodes independencies, our model offers great ﬂexibility in modeling high-dimensional densities, while maintaining control over the form of the univariate marginals. We demonstrate the advantage of our framework for generalization over standard Bayesian networks as well as tree structured copula models for varied real-life domains that are of substantially higher dimension than those typically considered in the copula literature.},
	pages = {9},
	author = {Elidan, Gal},
	langid = {english},
	file = {elidan_copula_bayesian_networks.pdf:/home/nathan/Dropbox/njames/zotero_sync/elidan_copula_bayesian_networks.pdf:application/pdf}
}

@article{mayer_simulation_2019,
	title = {Simulation Practices for Adaptive Trial Designs in Drug and Device Development},
	issn = {1946-6315},
	url = {https://www.tandfonline.com/doi/full/10.1080/19466315.2018.1560359},
	doi = {10.1080/19466315.2018.1560359},
	abstract = {Adaptive clinical trials are the cornerstone of modern drug and device development. The most recent {US} legislation calls for higher efficiency in designing clinical trials with emphasis on expanding the utilization of complex innovative designs that cannot be developed without simulations. It is well recognized that clinical trial simulation is a fundamental tool to explore, compare, and understand the operating characteristics, statistical properties, and adaptive decisions embedded in different designs to answer the given research questions. This article provides insights from industry on the development of a simulation report from a group of statisticians brought together under the sponsorship of the Drug Information Association Adaptive Design Scientific Working Group. This effort intends to illustrate the key common elements required to ensure higher consistency and clarity in conducting and reporting simulations of adaptive clinical trials, eliminate unnecessary barriers in communicating technical design aspects to different audiences, and facilitate the assessment of pros and cons of candidate designs. The design-dependent elements of a simulation report applicable to specific types of adaptive trials are presented with the examples of doseescalation designs, dose-ranging studies, trials with sample size re-estimation and early stopping rules, and confirmatory multistage designs.},
	pages = {1--25},
	journaltitle = {Statistics in Biopharmaceutical Research},
	author = {Mayer, Cristiana and Perevozskaya, Inna and Leonov, Sergei and Dragalin, Vladimir and Pritchett, Yili and Bedding, Alun and Hartford, Alan and Fardipour, Parvin and Cicconetti, Greg},
	urldate = {2019-06-11},
	date = {2019-01-28},
	langid = {english},
	file = {mayer_et_al_2019_simulation_practices_for_adaptive_trial_designs_in_drug_and_device_development.pdf:/home/nathan/Dropbox/njames/zotero_sync/mayer_et_al_2019_simulation_practices_for_adaptive_trial_designs_in_drug_and_device_development.pdf:application/pdf}
}

@article{ross_dirichletprocess:_nodate,
	title = {dirichletprocess: An R Package for Fitting Complex Bayesian Nonparametric Models},
	abstract = {The dirichletprocess package provides software for creating ﬂexible Dirichlet processes objects in R. Users can perform nonparametric Bayesian analysis using Dirichlet processes without the need to program their own inference algorithms. Instead, the user can utilise our pre-built models or specify their own models whilst allowing the dirichletprocess package to handle the Markov chain Monte Carlo sampling. Our Dirichlet process objects can act as building blocks for a variety of statistical models including and not limited to: density estimation, clustering and prior distributions in hierarchical models.},
	pages = {41},
	author = {Ross, Gordon J and Markwick, Dean},
	langid = {english},
	file = {ross_markwick_dirichletprocess.pdf:/home/nathan/Dropbox/njames/zotero_sync/ross_markwick_dirichletprocess.pdf:application/pdf}
}

@article{sennhenn-reulen_bayesian_nodate,
	title = {Bayesian Regression for a Dirichlet Distributed Response using Stan},
	abstract = {For an observed response that is composed by a set – or vector – of positive values that sum up to 1, the Dirichlet distribution [1] is a helpful mathematical construction for the quantiﬁcation of the data-generating mechanics underlying this process. In applications, these response-sets are usually denoted as proportions, or compositions of proportions, and by means of covariates, one wishes to manifest the underlying signal –by changes in the value of these covariates – leading to differently distributed response compositions.},
	pages = {13},
	author = {Sennhenn-Reulen, Holger},
	langid = {english},
	file = {sennhenn-reulen_bayesian_regression_for_a_dirichlet_distributed_response_using_stan.pdf:/home/nathan/Dropbox/njames/zotero_sync/sennhenn-reulen_bayesian_regression_for_a_dirichlet_distributed_response_using_stan.pdf:application/pdf}
}

@article{shi_low_2019,
	title = {Low Information Omnibus ({LIO}) Priors for Dirichlet Process Mixture Models},
	volume = {14},
	issn = {1936-0975},
	url = {https://projecteuclid.org/euclid.ba/1560240023},
	doi = {10.1214/18-BA1119},
	abstract = {Dirichlet process mixture ({DPM}) models provide ﬂexible modeling for distributions of data as an inﬁnite mixture of distributions from a chosen collection. Specifying priors for these models in individual data contexts can be challenging. In this paper, we introduce a scheme which requires the investigator to specify only simple scaling information. This is used to transform the data to a ﬁxed scale on which a low information prior is constructed. Samples from the posterior with the rescaled data are transformed back for inference on the original scale. The low information prior is selected to provide a wide variety of components for the {DPM} to generate ﬂexible distributions for the data on the ﬁxed scale. The method can be applied to all {DPM} models with kernel functions closed under a suitable scaling transformation. Construction of the low information prior, however, is kernel dependent. Using {DPM}-of-Gaussians and {DPM}-of-Weibulls models as examples, we show that the method provides accurate estimates of a diverse collection of distributions that includes skewed, multimodal, and highly dispersed members. With the recommended priors, repeated data simulations show performance comparable to that of standard empirical estimates. Finally, we show weak convergence of posteriors with the proposed priors for both kernels considered.},
	pages = {677--702},
	number = {3},
	journaltitle = {Bayesian Anal.},
	author = {Shi, Yushu and Martens, Michael and Banerjee, Anjishnu and Laud, Purushottam},
	urldate = {2019-06-13},
	date = {2019-09},
	langid = {english},
	file = {shi_et_al_2019_low_information_omnibus_(lio)_priors_for_dirichlet_process_mixture_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/shi_et_al_2019_low_information_omnibus_(lio)_priors_for_dirichlet_process_mixture_models.pdf:application/pdf}
}

@article{seth_model_2019,
	title = {Model Criticism in Latent Space},
	volume = {14},
	issn = {1936-0975},
	url = {https://projecteuclid.org/euclid.ba/1560240024},
	doi = {10.1214/18-BA1124},
	abstract = {Model criticism is usually carried out by assessing if replicated data generated under the ﬁtted model looks similar to the observed data, see e.g. Gelman, Carlin, Stern, and Rubin (2004, p. 165). This paper presents a method for latent variable models by pulling back the data into the space of latent variables, and carrying out model criticism in that space. Making use of a model’s structure enables a more direct assessment of the assumptions made in the prior and likelihood. We demonstrate the method with examples of model criticism in latent space applied to factor analysis, linear dynamical systems and Gaussian processes.},
	pages = {703--725},
	number = {3},
	journaltitle = {Bayesian Anal.},
	author = {Seth, Sohan and Murray, Iain and Williams, Christopher K. I.},
	urldate = {2019-06-13},
	date = {2019-09},
	langid = {english},
	file = {seth_et_al_2019_model_criticism_in_latent_space.pdf:/home/nathan/Dropbox/njames/zotero_sync/seth_et_al_2019_model_criticism_in_latent_space.pdf:application/pdf}
}

@article{gutierrez_bayesian_2019,
	title = {A Bayesian Nonparametric Multiple Testing Procedure for Comparing Several Treatments Against a Control},
	volume = {14},
	issn = {1936-0975},
	url = {https://projecteuclid.org/euclid.ba/1537258138},
	doi = {10.1214/18-BA1122},
	abstract = {We propose a Bayesian nonparametric strategy to test for diﬀerences between a control group and several treatment regimes. Most of the existing tests for this type of comparison are based on the diﬀerences between location parameters. In contrast, our approach identiﬁes diﬀerences across the entire distribution, avoids strong modeling assumptions over the distributions for each treatment, and accounts for multiple testing through the prior distribution on the space of hypotheses. The proposal is compared to other commonly used hypothesis testing procedures under simulated scenarios. Two real applications are also analyzed with the proposed methodology.},
	pages = {649--675},
	number = {2},
	journaltitle = {Bayesian Anal.},
	author = {Gutiérrez, Luis and Barrientos, Andrés F. and González, Jorge and Taylor-Rodríguez, Daniel},
	urldate = {2019-06-13},
	date = {2019-06},
	langid = {english},
	file = {gutiérrez_et_al_2019_a_bayesian_nonparametric_multiple_testing_procedure_for_comparing_several.pdf:/home/nathan/Dropbox/njames/zotero_sync/gutiérrez_et_al_2019_a_bayesian_nonparametric_multiple_testing_procedure_for_comparing_several.pdf:application/pdf}
}

@article{psioda_bayesian_2019,
	title = {Bayesian adaptive basket trial design using model averaging},
	issn = {1465-4644, 1468-4357},
	url = {https://academic.oup.com/biostatistics/advance-article/doi/10.1093/biostatistics/kxz014/5492127},
	doi = {10.1093/biostatistics/kxz014},
	abstract = {In this article, we develop a Bayesian adaptive design methodology for oncology basket trials with binary endpoints using a Bayesian model averaging framework. Most existing methods seek to borrow information based on the degree of homogeneity of estimated response rates across all baskets. In reality, an investigational product may only demonstrate activity for a subset of baskets, and the degree of activity may vary across the subset. A key beneﬁt of our Bayesian model averaging approach is that it explicitly accounts for the possibility that any subset of baskets may have similar activity and that some may not. Our proposed approach performs inference on the basket-speciﬁc response rates by averaging over the complete model space for the response rates, which can include thousands of models. We present results that demonstrate that this computationally feasible Bayesian approach performs favorably compared to existing state-of-the-art approaches, even when held to stringent requirements regarding false positive rates.},
	pages = {kxz014},
	journaltitle = {Biostatistics},
	author = {Psioda, Matthew A and Xu, Jiawei and Jiang, Qi and Ke, Chunlei and Yang, Zhao and Ibrahim, Joseph G},
	urldate = {2019-06-13},
	date = {2019-05-20},
	langid = {english},
	file = {psioda_et_al_2019_bayesian_adaptive_basket_trial_design_using_model_averaging.pdf:/home/nathan/Dropbox/njames/zotero_sync/psioda_et_al_2019_bayesian_adaptive_basket_trial_design_using_model_averaging.pdf:application/pdf}
}

@article{mahani_bayesian_2019,
	title = {Bayesian, and Non-Bayesian, Cause-Specific Competing-Risk Analysis for Parametric and Nonparametric Survival Functions: The \textit{R} Package \textbf{{CFC}}},
	volume = {89},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v89/i09/},
	doi = {10.18637/jss.v089.i09},
	shorttitle = {Bayesian, and Non-Bayesian, Cause-Specific Competing-Risk Analysis for Parametric and Nonparametric Survival Functions},
	abstract = {The R package {CFC} performs cause-speciﬁc, competing-risk survival analysis by computing cumulative incidence functions from unadjusted, cause-speciﬁc survival functions. A high-level {API} in {CFC} enables end-to-end survival and competing-risk analysis, using a single-line function call, based on the parametric survival regression models in the survival package. A low-level {API} allows users to achieve more ﬂexibility by supplying their custom survival functions, perhaps in a Bayesian setting. Utility methods for summarizing and plotting the output allow population-average cumulative incidence functions to be calculated, visualized and compared to unadjusted survival curves. Numerical and computational optimization strategies are employed for eﬃcient and reliable computation of the coupled integrals involved. To address potential integrable singularities caused by inﬁnite cause-speciﬁc hazards, particularly near time-from-index of zero, integrals are transformed to remove their dependency on hazard functions, making them solely functions of causespeciﬁc, unadjusted survival functions. This implicit variable transformation also provides for easier extensibility of {CFC} to handle custom survival models since it only requires the users to implement a maximum of one function per cause. The transformed integrals are numerically calculated using a generalization of Simpson’s rule to handle the implicit change of variable from time to survival, while a generalized trapezoidal rule is used as reference for error calculation. An {OpenMP}-parallelized, eﬃcient C++ implementation – using packages Rcpp and {RcppArmadillo} – makes the application of {CFC} in Bayesian settings practical, where a potentially large number of samples represent the posterior distribution of cause-speciﬁc survival functions.},
	number = {9},
	journaltitle = {J. Stat. Soft.},
	author = {Mahani, Alireza S. and Sharabiani, Mansour T. A.},
	urldate = {2019-06-13},
	date = {2019},
	langid = {english},
	file = {mahani_sharabiani_2019_bayesian,_and_non-bayesian,_cause-specific_competing-risk_analysis_for.pdf:/home/nathan/Dropbox/njames/zotero_sync/mahani_sharabiani_2019_bayesian,_and_non-bayesian,_cause-specific_competing-risk_analysis_for.pdf:application/pdf}
}

@article{ball_importance_nodate,
	title = {The importance of cross-disciplinary scientific engagement in the development of quantitative procedures for aggregate safety assessments},
	volume = {0},
	issn = {1539-1612},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1949},
	doi = {10.1002/pst.1949},
	abstract = {Recent guidance on safety monitoring during drug development, issued by regulatory authorities in the United States and European Union, indicate a shift in focus towards aggregate safety monitoring and scientific evaluation of integrated safety data. The call for program-level reviews of accumulating safety data, including from ongoing studies, provides an opportunity to leverage the scientific expertise and medical judgment of safety management teams with (a) a multidisciplinary approach, (b) quantitative frameworks to measure level of evidence, and (c) assessments that are product-specific and driven by medical judgment. A multidisciplinary team, regularly reviewing aggregate safety data throughout the development program, is vital not only for early signal detection but also for generating a better understanding of the accumulating data and context needed for decreasing false alarms.},
	number = {0},
	journaltitle = {Pharmaceutical Statistics},
	author = {Ball, Greg and Lievano, Fabio},
	urldate = {2019-06-13},
	langid = {english},
	keywords = {medical judgment, multidisciplinary, quantitative frameworks, safety assessments},
	file = {ball_lievano_the_importance_of_cross-disciplinary_scientific_engagement_in_the_development.pdf:/home/nathan/Dropbox/njames/zotero_sync/ball_lievano_the_importance_of_cross-disciplinary_scientific_engagement_in_the_development.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/IWZDGVIH/pst.html:text/html}
}

@article{sinha_adaptive_2019,
	title = {Adaptive group-sequential design with population enrichment in phase 3 randomized controlled trials with two binary co-primary endpoints},
	volume = {0},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8216},
	doi = {10.1002/sim.8216},
	abstract = {The use of co-primary endpoints in drug development allows investigators to capture an experimental intervention's multidimensional effect more comprehensively than a single primary endpoint. We propose the theoretical basis and development of an adaptive population enrichment design with co-primary endpoints, provide stage-wise boundary values for futility and efficacy, and discuss power under different efficacy configurations, subgroup prevalence, and analysis times using a pre-specified decision criterion. We considered a two-arm, two-stage, parallel group design where population enrichment occurs at the interim analysis by dropping any non-responsive subgroups. A test for efficacy is conducted only in the enriched population. Two binary endpoints are evaluated as co-primary endpoints. Our trial objective is to determine whether the experimental intervention is superior to the control intervention, with superiority required in both endpoints. We define the stopping boundary using alpha spending functions. Using a 0.025 significance level for each endpoint, we obtain the stage I threshold boundary values for futility and efficacy as −0.1040 and 2.2761, respectively, and the stage {II} boundary value for futility and efficacy is 2.2419. We show that in the presence of substantial heterogeneity of treatment effect, we gain more power to observe an effect in the subgroup where the benefits are greater. By allowing the dropping of non-responsive subgroups at an early stage, our design reduces the likelihood of obtaining false-negative results due to inclusion of the heterogeneous treatment effects of both subgroups, which would dilute the responsive subgroup's results.},
	pages = {1--12},
	number = {0},
	journaltitle = {Statistics in Medicine},
	author = {Sinha, Arup K. and Moye, Lemuel and Piller, Linda B. and Yamal, Jose-Miguel and Barcenas, Carlos H. and Lin, Jianchang and Davis, Barry R.},
	urldate = {2019-06-13},
	date = {2019},
	langid = {english},
	keywords = {adaptive, co-primary, enrichment, group-sequential, phase 3, subgroup},
	file = {sinha_et_al_adaptive_group-sequential_design_with_population_enrichment_in_phase_3.pdf:/home/nathan/Dropbox/njames/zotero_sync/sinha_et_al_adaptive_group-sequential_design_with_population_enrichment_in_phase_3.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/P8KLTDF8/sim.html:text/html}
}

@article{anoke_approaches_2019,
	title = {Approaches to treatment effect heterogeneity in the presence of confounding},
	volume = {38},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8143},
	doi = {10.1002/sim.8143},
	abstract = {The literature on causal effect estimation tends to focus on the population mean estimand, which is less informative as medical treatments are becoming more personalized and there is increasing awareness that subpopulations of individuals may experience a group-specific effect that differs from the population average. In fact, it is possible that there is underlying systematic effect heterogeneity that is obscured by focusing on the population mean estimand. In this context, understanding which covariates contribute to this treatment effect heterogeneity ({TEH}) and how these covariates determine the differential treatment effect ({TE}) is an important consideration. Towards such an understanding, this paper briefly reviews three approaches used in making causal inferences and conducts a simulation study to compare these approaches according to their performance in an exploratory evaluation of {TEH} when the heterogeneous subgroups are not known a priori. Performance metrics include the detection of any heterogeneity, the identification and characterization of heterogeneous subgroups, and unconfounded estimation of the {TE} within subgroups. The methods are then deployed in a comparative effectiveness evaluation of drug-eluting versus bare-metal stents among 54 099 Medicare beneficiaries in the continental United States admitted to a hospital with acute myocardial infarction in 2008.},
	pages = {2797--2815},
	number = {15},
	journaltitle = {Statistics in Medicine},
	author = {Anoke, Sarah C. and Normand, Sharon-Lise and Zigler, Corwin M.},
	urldate = {2019-06-13},
	date = {2019},
	langid = {english},
	keywords = {causal inference, confounding, effect modification, observational data, subgroup estimation, treatment effect heterogeneity},
	file = {anoke_et_al_2019_approaches_to_treatment_effect_heterogeneity_in_the_presence_of_confounding.pdf:/home/nathan/Dropbox/njames/zotero_sync/anoke_et_al_2019_approaches_to_treatment_effect_heterogeneity_in_the_presence_of_confounding.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/STK6PLRJ/sim.html:text/html}
}

@article{su_analysis_nodate,
	title = {Analysis of clustered failure time data with cure fraction using copula},
	volume = {0},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8213},
	doi = {10.1002/sim.8213},
	abstract = {Clustered survival data in the presence of cure has received increasing attention. In this paper, we consider a semiparametric mixture cure model which incorporates a logistic regression model for the cure fraction and a semiparametric regression model for the failure time. We utilize Archimedean copula ({AC}) models to assess the strength of association for both susceptibility and failure times between susceptible individuals in the same cluster. Instead of using the full likelihood approach, we consider a composite likelihood function and a two-stage estimation procedure for both marginal and association parameters. A Jackknife procedure that takes out one cluster at a time is proposed for the variance estimation of the estimators. Akaike information criterion is applied to select the best model among {ACs}. Simulation studies are performed to validate our estimating procedures, and two real data sets are analyzed to demonstrate the practical use of our proposed method.},
	number = {0},
	journaltitle = {Statistics in Medicine},
	author = {Su, Chien-Lin and Lin, Feng-Chang},
	urldate = {2019-06-13},
	langid = {english},
	keywords = {accelerated failure time model, Archimedean copula, composite likelihood, Cox proportional hazards model, two-stage estimation},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/83YJTUJ2/sim.html:text/html;su_lin_analysis_of_clustered_failure_time_data_with_cure_fraction_using_copula.pdf:/home/nathan/Dropbox/njames/zotero_sync/su_lin_analysis_of_clustered_failure_time_data_with_cure_fraction_using_copula.pdf:application/pdf}
}

@article{steingrimsson_subgroup_nodate,
	title = {Subgroup identification using covariate-adjusted interaction trees},
	volume = {0},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8214},
	doi = {10.1002/sim.8214},
	abstract = {We consider the problem of identifying subgroups of participants in a clinical trial that have enhanced treatment effect. Recursive partitioning methods that recursively partition the covariate space based on some measure of between groups treatment effect difference are popular for such subgroup identification. The most commonly used recursive partitioning method, the classification and regression tree algorithm, first creates a large tree by recursively partitioning the covariate space using some splitting criteria and then selects the final tree from all the subtrees of the large tree. In the context of subgroup identification, calculation of the splitting criteria and the evaluation measure used for final tree selection rely on comparing differences in means between the treatment and control arm. When covariates are prognostic for the outcome, covariate adjusted estimators have the ability to improve efficiency compared to using differences in averages between the treatment and control group. This manuscript develops two covariate adjusted estimators that can be used to both make splitting decisions and for final tree selection. The performance of the resulting covariate adjusted recursive partitioning algorithm is evaluated using simulations and by analyzing a clinical trial that evaluates if motivational interviews improve treatment engagement for substance abusers.},
	number = {0},
	journaltitle = {Statistics in Medicine},
	author = {Steingrimsson, Jon Arni and Yang, Jiabei},
	urldate = {2019-06-13},
	langid = {english},
	keywords = {classification and regression trees, model standardization, randomized controlled trials},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/PF36RHUG/sim.html:text/html;steingrimsson_yang_subgroup_identification_using_covariate-adjusted_interaction_trees.pdf:/home/nathan/Dropbox/njames/zotero_sync/steingrimsson_yang_subgroup_identification_using_covariate-adjusted_interaction_trees.pdf:application/pdf}
}

@article{park_ensemble_nodate,
	title = {Ensemble confidence intervals for binomial proportions},
	volume = {0},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8189},
	doi = {10.1002/sim.8189},
	abstract = {We propose two measures of performance for a confidence interval for a binomial proportion p: the root mean squared error and the mean absolute deviation. We also devise a confidence interval for p based on the actual coverage function that combines several existing approximate confidence intervals. This “Ensemble” confidence interval has improved statistical properties over the constituent confidence intervals. Software in an R package, which can be used in devising and assessing these confidence intervals, is available on {CRAN}.},
	number = {0},
	journaltitle = {Statistics in Medicine},
	author = {Park, Hayeon and Leemis, Lawrence M.},
	urldate = {2019-06-13},
	langid = {english},
	keywords = {binomial distribution, confidence interval, coverage, statistical computing},
	file = {park_leemis_ensemble_confidence_intervals_for_binomial_proportions.pdf:/home/nathan/Dropbox/njames/zotero_sync/park_leemis_ensemble_confidence_intervals_for_binomial_proportions.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/RHRKTI55/sim.html:text/html}
}

@article{lawrence_familywise_nodate,
	title = {Familywise and per-family error rates of multiple comparison procedures},
	volume = {0},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8190},
	doi = {10.1002/sim.8190},
	abstract = {In multiple testing scenarios, one of the more popular definitions of the error rate is the familywise error rate ({FWER}). The per-family error rate ({PFER}) is often not considered. The {PFER} deserves more attention than it currently receives. Both of these concepts were formulated by Tukey. We highlight some of the good and bad qualities of the {FWER} and the {PFER}. We find the {FWER} and {PFER} for four commonly used multiple comparison procedures.},
	number = {0},
	journaltitle = {Statistics in Medicine},
	author = {Lawrence, John},
	urldate = {2019-06-13},
	langid = {english},
	keywords = {closed testing, linear programming, partitioning principle, Simes test, simultaneous inference},
	file = {lawrence_familywise_and_per-family_error_rates_of_multiple_comparison_procedures.pdf:/home/nathan/Dropbox/njames/zotero_sync/lawrence_familywise_and_per-family_error_rates_of_multiple_comparison_procedures.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/XL5WYUYS/sim.html:text/html}
}

@article{lesaffre_multivariate_1991,
	title = {Multivariate probit analysis: A neglected procedure in medical statistics},
	volume = {10},
	issn = {02776715, 10970258},
	url = {http://doi.wiley.com/10.1002/sim.4780100907},
	doi = {10.1002/sim.4780100907},
	shorttitle = {Multivariate probit analysis},
	abstract = {The multivariate probit model is designed to regress a vector of correlated quanta1 variables on a mixture of continuous and discrete predictors. Various applications can be found in the biological, economical and psychosociologicalliterature, but the method is not yet widely used in medical applications. We reintroduce this model thereby showing its usefulness in medical problems. Software for this model is, however, not widely available. We have written a {PC} program to select predictors and estimate parameters in the multivariate probit framework. The performance and characteristics of the program are briefly illustrated.},
	pages = {1391--1403},
	number = {9},
	journaltitle = {Statist. Med.},
	author = {Lesaffre, E. and Molenberghs, G.},
	urldate = {2019-06-13},
	date = {1991-09},
	langid = {english},
	file = {lesaffre_molenberghs_1991_multivariate_probit_analysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/lesaffre_molenberghs_1991_multivariate_probit_analysis.pdf:application/pdf}
}

@article{fitzmaurice_regression_1997,
	title = {Regression Models for Mixed Discrete and Continuous Responses with Potentially Missing Values},
	volume = {53},
	issn = {0006341X},
	url = {https://www.jstor.org/stable/2533101?origin=crossref},
	doi = {10.2307/2533101},
	abstract = {In this paper a likelihood-based method for analyzing mixed discrete and continuous regression models is proposed. We focus on marginal regression models, that is, models in which the marginal expectation of the response vector is related to covariates by known link functions. The proposed model is based on an extension of the general location model of Olkin and Tate (1961, Annals of Mathematical Statistics 32, 448-465), and can accommodate missing responses. When there are no missing data, our particular choice of parameterization yields maximum likelihood estimates of the marginal mean parameters that are robust to misspecification of the association between the responses. This robustness property does not, in general, hold for the case of incomplete data. There are a number of potential benefits of a multivariate approach over separate analyses of the distinct responses. First, a multivariate analysis can exploit the correlation structure of the response vector to address intrinsically multivariate questions. Second, multivariate test statistics allow for control over the inflation of the type I error that results when separate analyses of the distinct responses are performed without accounting for multiple comparisons. Third, it is generally possible to obtain more precise parameter estimates by accounting for the association between the responses. Finally, separate analyses of the distinct responses may be difficult to interpret when there is nonresponse because different sets of individuals contribute to each analysis. Furthermore, separate analyses can introduce bias when the missing responses are missing at random ({MAR}). A multivariate analysis can circumvent both of these problems. The proposed methods are applied to two biomedical datasets.},
	pages = {110},
	number = {1},
	journaltitle = {Biometrics},
	author = {Fitzmaurice, Garrett M. and Laird, Nan M.},
	urldate = {2019-06-13},
	date = {1997-03},
	langid = {english},
	file = {fitzmaurice_laird_1997_regression_models_for_mixed_discrete_and_continuous_responses_with_potentially.pdf:/home/nathan/Dropbox/njames/zotero_sync/fitzmaurice_laird_1997_regression_models_for_mixed_discrete_and_continuous_responses_with_potentially.pdf:application/pdf}
}

@article{gueorguieva_correlated_2001,
	title = {A Correlated Probit Model for Joint Modeling of Clustered Binary and Continuous Responses},
	volume = {96},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1198/016214501753208762},
	doi = {10.1198/016214501753208762},
	pages = {1102--1112},
	number = {455},
	journaltitle = {Journal of the American Statistical Association},
	author = {Gueorguieva, Ralitza V and Agresti, Alan},
	urldate = {2019-06-13},
	date = {2001-09},
	langid = {english},
	file = {gueorguieva_agresti_2001_a_correlated_probit_model_for_joint_modeling_of_clustered_binary_and_continuous.pdf:/home/nathan/Dropbox/njames/zotero_sync/gueorguieva_agresti_2001_a_correlated_probit_model_for_joint_modeling_of_clustered_binary_and_continuous.pdf:application/pdf}
}

@article{gueorguieva_joint_2006,
	title = {Joint analysis of repeatedly observed continuous and ordinal measures of disease severity},
	volume = {25},
	issn = {02776715, 10970258},
	url = {http://doi.wiley.com/10.1002/sim.2270},
	doi = {10.1002/sim.2270},
	abstract = {In biomedical studies often multiple measures of disease severity are recorded over time. Although correlated, such measures are frequently analysed separately of one another. Joint analysis of the outcomes variables has several potential advantages over separate analyses. However, models for response variables of di erent types (discrete and continuous) are challenging to deÿne and to ÿt. Herein we propose correlated probit models for joint analysis of repeated measurements on ordinal and continuous variables measuring the same underlying disease severity over time. We demonstrate how to rewrite the models so that maximum-likelihood estimation and inference can be performed with standard software. Simulation studies are performed to assess e ciency gains in ÿtting the responses together rather than separately and to guide response variable selection for future studies. Data from a depression clinical trial are used for illustration. Copyright ? 2005 John Wiley \& Sons, Ltd.},
	pages = {1307--1322},
	number = {8},
	journaltitle = {Statist. Med.},
	author = {Gueorguieva, R. V. and Sanacora, G.},
	urldate = {2019-06-13},
	date = {2006-04-30},
	langid = {english},
	file = {gueorguieva_sanacora_2006_joint_analysis_of_repeatedly_observed_continuous_and_ordinal_measures_of.pdf:/home/nathan/Dropbox/njames/zotero_sync/gueorguieva_sanacora_2006_joint_analysis_of_repeatedly_observed_continuous_and_ordinal_measures_of.pdf:application/pdf}
}

@article{oh_raking_2019,
	title = {Raking and Regression Calibration: Methods to Address Bias from Correlated Covariate and Time-to-Event Error},
	url = {http://arxiv.org/abs/1905.08330},
	shorttitle = {Raking and Regression Calibration},
	abstract = {Medical studies that depend on electronic health records ({EHR}) data are often subject to measurement error as the data are not collected to support research questions under study. Methodology to address covariate measurement error has been well developed; however, time-to-event error has also been shown to cause significant bias but methods to address it are relatively underdeveloped. More generally, it is possible to observe errors in both the covariate and the time-to-event outcome that are correlated. We propose regression calibration ({RC}) estimators to simultaneously address correlated error in the covariates and the censored event time. Although {RC} can perform well in many settings with covariate measurement error, it is biased for nonlinear regression models, such as the Cox model. Thus, we additionally propose raking estimators which are consistent estimators of the parameter defined by the population estimating equations, can improve upon {RC} in certain settings with failure-time data, require no explicit modeling of the error structure, and can be utilized under outcome-dependent sampling designs. We discuss features of the underlying estimation problem that affect the degree of improvement the raking estimator has over the {RC} approach. Detailed simulation studies are presented to examine the performance of the proposed estimators under varying levels of signal, error, and censoring. The methodology is illustrated on observational {EHR} data on {HIV} outcomes from the Vanderbilt Comprehensive Care Clinic.},
	journaltitle = {{arXiv}:1905.08330 [stat]},
	author = {Oh, Eric J. and Shepherd, Bryan E. and Lumley, Thomas and Shaw, Pamela A.},
	urldate = {2019-06-14},
	date = {2019-05-20},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1905.08330},
	keywords = {Statistics - Methodology},
	file = {oh_et_al_2019_raking_and_regression_calibration.pdf:/home/nathan/Dropbox/njames/zotero_sync/oh_et_al_2019_raking_and_regression_calibration.pdf:application/pdf}
}

@article{shepherd_probability-scale_2016,
	title = {Probability-scale residuals for continuous, discrete, and censored data},
	volume = {44},
	issn = {03195724},
	url = {http://doi.wiley.com/10.1002/cjs.11302},
	doi = {10.1002/cjs.11302},
	abstract = {We describe a new residual for general regression models, defined as pr(Y* {\textless} y) − pr(Y* {\textgreater} y), where y is the observed outcome and Y* is a random variable from the fitted distribution. This probability-scale residual can be written as E \{sign(y, Y*)\} whereas the popular observed-minusexpected residual can be thought of as E(y − Y*). Therefore, the probability-scale residual is useful in settings where differences are not meaningful or where the expectation of the fitted distribution cannot be calculated. We present several desirable properties of the probability-scale residual that make it useful for diagnostics and measuring residual correlation, especially across different outcome types. We demonstrate its utility for continuous, ordered discrete, and censored outcomes, including current status data, and with various models including Cox regression, quantile regression, and ordinal cumulative probability models, for which fully specified distributions are not desirable or needed, and in some cases suitable residuals are not available. The residual is illustrated with simulated data and real datasets from {HIV}-infected patients on therapy in the southeastern United States and Latin America.},
	pages = {463--479},
	number = {4},
	journaltitle = {Can. J. Statistics},
	author = {Shepherd, Bryan E. and Li, Chun and Liu, Qi},
	urldate = {2019-06-24},
	date = {2016-12},
	langid = {english},
	file = {shepherd_et_al_2016_probability-scale_residuals_for_continuous,_discrete,_and_censored_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/shepherd_et_al_2016_probability-scale_residuals_for_continuous,_discrete,_and_censored_data.pdf:application/pdf}
}

@article{zhang_bayesian_2016,
	title = {“A Bayesian sensitivity analysis to evaluate the impact of unmeasured confounding with external data: a real world comparative effectiveness study in osteoporosis”: A Bayesian Approach to Unmeasured Confounding},
	volume = {25},
	issn = {10538569},
	url = {http://doi.wiley.com/10.1002/pds.4053},
	doi = {10.1002/pds.4053},
	shorttitle = {“A Bayesian sensitivity analysis to evaluate the impact of unmeasured confounding with external data},
	abstract = {Purpose Observational studies are frequently used to assess the effectiveness of medical interventions in routine clinical practice. However, the use of observational data for comparative effectiveness is challenged by selection bias and the potential of unmeasured confounding. This is especially problematic for analyses using a health care administrative database, in which key clinical measures are often not available. This paper provides an approach to conducting a sensitivity analyses to investigate the impact of unmeasured confounding in observational studies.
Methods In a real world osteoporosis comparative effectiveness study, the bone mineral density ({BMD}) score, an important predictor of fracture risk and a factor in the selection of osteoporosis treatments, is unavailable in the data base and lack of baseline {BMD} could potentially lead to signiﬁcant selection bias. We implemented Bayesian twin-regression models, which simultaneously model both the observed outcome and the unobserved unmeasured confounder, using information from external sources. A sensitivity analysis was also conducted to assess the robustness of our conclusions to changes in such external data.
Results The use of Bayesian modeling in this study suggests that the lack of baseline {BMD} did have a strong impact on the analysis, reversing the direction of the estimated effect (odds ratio of fracture incidence at 24 months: 0.40 vs. 1.36, with/without adjusting for unmeasured baseline {BMD}).
Conclusions The Bayesian twin-regression models provide a ﬂexible sensitivity analysis tool to quantitatively assess the impact of unmeasured confounding in observational studies. Copyright © 2016 John Wiley \& Sons, Ltd.},
	pages = {982--992},
	number = {9},
	journaltitle = {Pharmacoepidemiol Drug Saf},
	author = {Zhang, Xiang and Faries, Douglas E. and Boytsov, Natalie and Stamey, James D. and Seaman, John W.},
	urldate = {2019-06-24},
	date = {2016-09},
	langid = {english},
	file = {zhang_et_al_2016_“a_bayesian_sensitivity_analysis_to_evaluate_the_impact_of_unmeasured.pdf:/home/nathan/Dropbox/njames/zotero_sync/zhang_et_al_2016_“a_bayesian_sensitivity_analysis_to_evaluate_the_impact_of_unmeasured.pdf:application/pdf}
}

@article{gelman_prior_nodate,
	title = {Prior distributions for variance parameters in hierarchical models},
	abstract = {Various noninformative prior distributions have been suggested for scale parameters in hierarchical models. We construct a new folded-noncentral-t family of conditionally conjugate priors for hierarchical standard deviation parameters, and then consider noninformative and weakly informative priors in this family. We use an example to illustrate serious problems with the inverse-gamma family of “noninformative” prior distributions. We suggest instead to use a uniform prior on the hierarchical standard deviation, using the half-t family when the number of groups is small and in other settings where a weakly informative prior is desired. We also illustrate the use of the half-t family for hierarchical modeling of multiple variance parameters such as arise in the analysis of variance.},
	pages = {19},
	author = {Gelman, Andrew},
	langid = {english},
	file = {gelman_prior_distributions_for_variance_parameters_in_hierarchical_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_prior_distributions_for_variance_parameters_in_hierarchical_models.pdf:application/pdf}
}

@article{dawid_well-calibrated_1982,
	title = {The Well-Calibrated Bayesian},
	volume = {77},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1982.10477856},
	doi = {10.1080/01621459.1982.10477856},
	pages = {605--610},
	number = {379},
	journaltitle = {Journal of the American Statistical Association},
	author = {Dawid, A. P.},
	urldate = {2019-06-24},
	date = {1982-09},
	langid = {english},
	file = {dawid_1982_the_well-calibrated_bayesian.pdf:/home/nathan/Dropbox/njames/zotero_sync/dawid_1982_the_well-calibrated_bayesian.pdf:application/pdf}
}

@article{bassetti_bayesian_2018,
	title = {Bayesian Nonparametric Calibration and Combination of Predictive Distributions},
	volume = {113},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2016.1273117},
	doi = {10.1080/01621459.2016.1273117},
	pages = {675--685},
	number = {522},
	journaltitle = {Journal of the American Statistical Association},
	author = {Bassetti, Federico and Casarin, Roberto and Ravazzolo, Francesco},
	urldate = {2019-06-24},
	date = {2018-04-03},
	langid = {english},
	file = {bassetti_et_al_2018_bayesian_nonparametric_calibration_and_combination_of_predictive_distributions.pdf:/home/nathan/Dropbox/njames/zotero_sync/bassetti_et_al_2018_bayesian_nonparametric_calibration_and_combination_of_predictive_distributions.pdf:application/pdf}
}

@article{hoeting_bayesian_nodate,
	title = {Bayesian Model Averaging: A Tutorial},
	abstract = {Standard statistical practice ignores model uncertainty. Data analysts typically select a model from some class of models and then proceed as if the selected model had generated the data. This approach ignores the uncertainty in model selection, leading to over-confident inferences and decisions that are more risky than one thinks they are. Bayesian model averaging ({BMA}) provides a coherent mechanism for accounting for this model uncertainty. Several methods for implementing {BMA} have recently emerged. We discuss these methods and present a number of examples. In these examples, {BMA} provides improved out-ofsample predictive performance. We also provide a catalogue of currently available {BMA} software.},
	pages = {22},
	author = {Hoeting, Jennifer A and Madigan, David and Raftery, Adrian E and Volinsky, Chris T},
	langid = {english},
	file = {hoeting_et_al_bayesian_model_averaging.pdf:/home/nathan/Dropbox/njames/zotero_sync/hoeting_et_al_bayesian_model_averaging.pdf:application/pdf}
}

@article{browne_comparison_2006,
	title = {A comparison of Bayesian and likelihood-based methods for fitting multilevel models},
	volume = {1},
	issn = {1936-0975},
	url = {http://projecteuclid.org/euclid.ba/1340371047},
	doi = {10.1214/06-BA117},
	abstract = {We use simulation studies, whose design is realistic for educational and medical research (as well as other ﬁelds of inquiry), to compare Bayesian and likelihood-based methods for ﬁtting variance-components ({VC}) and random-eﬀects logistic regression ({RELR}) models. The likelihood (and approximate likelihood) approaches we examine are based on the methods most widely used in current applied multilevel (hierarchical) analyses: maximum likelihood ({ML}) and restricted {ML} ({REML}) for Gaussian outcomes, and marginal and penalized quasi-likelihood ({MQL} and {PQL}) for Bernoulli outcomes. Our Bayesian methods use Markov chain Monte Carlo ({MCMC}) estimation, with adaptive hybrid Metropolis-Gibbs sampling for {RELR} models, and several diﬀuse prior distributions (Γ−1( , ) and U (0, 1 ) priors for variance components). For evaluation criteria we consider bias of point estimates and nominal versus actual coverage of interval estimates in repeated sampling. In two-level {VC} models we ﬁnd that (a) both likelihood-based and Bayesian approaches can be made to produce approximately unbiased estimates, although the automatic manner in which {REML} accomplishes this is an advantage, but (b) both approaches had diﬃculty achieving nominal coverage in small samples and with small values of the intraclass correlation. With the threelevel {RELR} models we examine we ﬁnd that (c) quasi-likelihood methods for estimating random-eﬀects variances perform badly with respect to bias and coverage in the example we simulated, and (d) Bayesian diﬀuse-prior methods lead to wellcalibrated point and interval {RELR} estimates. While it is true that the likelihoodbased methods we study are considerably faster computationally than {MCMC}, (i) steady improvements in recent years in both hardware speed and eﬃciency of Monte Carlo algorithms and (ii) the lack of calibration of likelihood-based methods in some common hierarchical settings combine to make {MCMC}-based Bayesian ﬁtting of multilevel models an attractive approach, even with rather large data sets. Other analytic strategies based on less approximate likelihood methods are also possible but would beneﬁt from further study of the type summarized here.},
	pages = {473--514},
	number = {3},
	journaltitle = {Bayesian Anal.},
	author = {Browne, William J. and Draper, David},
	urldate = {2019-06-24},
	date = {2006-09},
	langid = {english},
	file = {browne_draper_2006_a_comparison_of_bayesian_and_likelihood-based_methods_for_fitting_multilevel.pdf:/home/nathan/Dropbox/njames/zotero_sync/browne_draper_2006_a_comparison_of_bayesian_and_likelihood-based_methods_for_fitting_multilevel.pdf:application/pdf}
}

@article{alber_calibrating_2015,
	title = {Calibrating the prior distribution for a normal model with conjugate prior},
	volume = {85},
	issn = {0094-9655, 1563-5163},
	url = {http://www.tandfonline.com/doi/full/10.1080/00949655.2014.951855},
	doi = {10.1080/00949655.2014.951855},
	abstract = {For a normal model with a conjugate prior, we provide an in depth examination of the effects of the hyperparameters on the long-run frequentist properties of posterior point and interval estimates. Under an assumed sampling model for the data generating mechanism, we examine how hyperparameter values affect the mean squared error ({MSE}) of posterior means and the true coverage of credible intervals. We develop two types of hyperparameter optimality. {MSE} optimal hyperparameters minimize the {MSE} of posterior point estimates. Credible interval optimal hyperparameters result in credible intervals that have minimum length while still retaining nominal coverage. A poor choice of hyperparameters has a worse consequence on the credible interval coverage than on the {MSE} of posterior point estimates. We give an example to demonstrate how our results can be used to evaluate the potential consequences of hyperparameter choices.},
	pages = {3108--3128},
	number = {15},
	journaltitle = {Journal of Statistical Computation and Simulation},
	author = {Alber, Susan A. and Lee, J. Jack},
	urldate = {2019-06-24},
	date = {2015-10-13},
	langid = {english},
	file = {alber_lee_2015_calibrating_the_prior_distribution_for_a_normal_model_with_conjugate_prior.pdf:/home/nathan/Dropbox/njames/zotero_sync/alber_lee_2015_calibrating_the_prior_distribution_for_a_normal_model_with_conjugate_prior.pdf:application/pdf}
}

@article{little_calibrated_2006,
	title = {Calibrated Bayes: A Bayes/Frequentist Roadmap},
	volume = {60},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1198/000313006X117837},
	doi = {10.1198/000313006X117837},
	shorttitle = {Calibrated Bayes},
	pages = {213--223},
	number = {3},
	journaltitle = {The American Statistician},
	author = {Little, Roderick J},
	urldate = {2019-06-24},
	date = {2006-08},
	langid = {english},
	file = {little_2006_calibrated_bayes.pdf:/home/nathan/Dropbox/njames/zotero_sync/little_2006_calibrated_bayes.pdf:application/pdf}
}

@article{papageorgiou_bayesian_2019,
	title = {Bayesian semiparametric analysis of multivariate continuous responses, with variable selection},
	url = {http://arxiv.org/abs/1905.08393},
	abstract = {We develop models for multivariate Gaussian responses with nonparametric models for the means, the variances and the correlation matrix, with automatic variable selection based on spike-slab priors. We use the separation strategy to factorize the covariance matrix of the multivariate responses into a product of matrices involving the variances and the correlation matrix. We model the means and the logarithm of the variances nonparametrically, utilizing radial basis function expansion. We describe parametric and nonparametric models for the correlation matrix. The parametric model assumes a normal prior for the elements of the correlation matrix, constrained to lie in the space of correlation matrices while the nonparametric model is utilizes Dirichlet process mixtures of normal distributions. We discuss methods for posterior sampling and inference and present results from a simulation study and two applications. The software we implemented can handle response vectors of arbitrary dimension and it is freely available via R package {BNSP}.},
	journaltitle = {{arXiv}:1905.08393 [stat]},
	author = {Papageorgiou, Georgios and Marshall, Benjamin C.},
	urldate = {2019-06-25},
	date = {2019-05-20},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1905.08393},
	keywords = {Statistics - Methodology},
	file = {papageorgiou_marshall_2019_bayesian_semiparametric_analysis_of_multivariate_continuous_responses,_with.pdf:/home/nathan/Dropbox/njames/zotero_sync/papageorgiou_marshall_2019_bayesian_semiparametric_analysis_of_multivariate_continuous_responses,_with.pdf:application/pdf}
}

@article{maneejuk_modeling_2019,
	title = {Modeling Nonlinear Dependence Structure Using Logistic Smooth Transition Copula Model},
	abstract = {This study introduces a new measure of dependence for ﬁnancial studies in the context of nonlinear modelling, termed as the logistic smooth transition ({LST}) copula. The model is based on a bivariate copula incorporated with a threshold and smooth parameter. A Monte Carlo simulation shows that this dependence measure exhibits better performance than the classical copulas. Finally, this study applies the {LST} copula to measure the dependence structure between bond yields in advanced economies.},
	pages = {14},
	author = {Maneejuk, Paravee and Yamaka, Woraphon and Leeahtam, Pisit},
	date = {2019},
	langid = {english},
	file = {maneejuk_et_al_2019_modeling_nonlinear_dependence_structure_using_logistic_smooth_transition_copula.pdf:/home/nathan/Dropbox/njames/zotero_sync/maneejuk_et_al_2019_modeling_nonlinear_dependence_structure_using_logistic_smooth_transition_copula.pdf:application/pdf}
}

@article{cooke_vine_2019,
	title = {Vine copula regression for observational studies},
	issn = {1863-8171, 1863-818X},
	url = {http://link.springer.com/10.1007/s10182-019-00353-5},
	doi = {10.1007/s10182-019-00353-5},
	abstract = {If explanatory variables and a response variable of interest are simultaneously observed, then ﬁtting a joint multivariate density to all variables would enable prediction via conditional distributions. Regular vines or vine copulas with arbitrary univariate margins provide a rich and ﬂexible class of multivariate densities for Gaussian or non-Gaussian dependence structures. The density enables calculation of all regression functions for any subset of variables conditional on any disjoint set of variables, thereby avoiding issues of transformations, heteroscedasticity, interactions, and higher-order terms. Only the question of ﬁnding an adequate vine copula remains. Heteroscedastic prediction inferences based on vine copulas are illustrated with two data sets, including one from the National Longitudinal Study of Youth relating breastfeeding to {IQ}. Some usual methods based on linear and quadratic equations are shown to have some undesirable inferences.},
	journaltitle = {{AStA} Adv Stat Anal},
	author = {Cooke, Roger M. and Joe, Harry and Chang, Bo},
	urldate = {2019-06-25},
	date = {2019-06-05},
	langid = {english},
	file = {cooke_et_al_2019_vine_copula_regression_for_observational_studies.pdf:/home/nathan/Dropbox/njames/zotero_sync/cooke_et_al_2019_vine_copula_regression_for_observational_studies.pdf:application/pdf}
}

@article{yamaka_modeling_2019,
	title = {Modeling Dependence of Agricultural Commodity Futures through Markov Switching Copula with Mixture Distribution Regimes},
	abstract = {Proposed is a Markov Switching copula with mixture distribution regimes for modeling the dependence of agricultural commodity futures. This model involves different dependence structures that can characterize the dependence behaviors in different regimes as the copula function in each regime can be different from that in another regime. By permitting different copula structure, this model is able to capture more complex dynamic patterns of daily movement of agricultural commodity futures (sugar, coffee, corn, wheat and soybean). The criteria as Akaike Information Criterion({AIC}), Bayesian Information Criterion ({BIC}) and Log-Likelihood ({LL}) are based in-sample statistical performance have suggested that our model is superior to the single regime copula and two-regime Markov Switching copula in 9 out of 10 cases. This result reveals that the high and the low dependence of agricultural commodity futures exhibit a different dependence structure.},
	pages = {15},
	author = {Yamaka, Woraphon and Phadkantha, Rungrapee and Sriboonchitta, Songsak},
	date = {2019},
	langid = {english},
	file = {yamaka_et_al_2019_modeling_dependence_of_agricultural_commodity_futures_through_markov_switching.pdf:/home/nathan/Dropbox/njames/zotero_sync/yamaka_et_al_2019_modeling_dependence_of_agricultural_commodity_futures_through_markov_switching.pdf:application/pdf}
}

@article{campbell_universal_2019,
	title = {Universal Boosting Variational Inference},
	url = {http://arxiv.org/abs/1906.01235},
	abstract = {Boosting variational inference ({BVI}) approximates an intractable probability density by iteratively building up a mixture of simple component distributions one at a time, using techniques from sparse convex optimization to provide both computational scalability and approximation error guarantees. But the guarantees have strong conditions that do not often hold in practice, resulting in degenerate component optimization problems; and we show that the ad-hoc regularization used to prevent degeneracy in practice can cause {BVI} to fail in unintuitive ways. We thus develop universal boosting variational inference ({UBVI}), a {BVI} scheme that exploits the simple geometry of probability densities under the Hellinger metric to prevent the degeneracy of other gradient-based {BVI} methods, avoid difﬁcult joint optimizations of both component and weight, and simplify fully-corrective weight optimizations. We show that for any target density and any mixture component family, the output of {UBVI} converges to the best possible approximation in the mixture family, even when the mixture family is misspeciﬁed. We develop a scalable implementation based on exponential family mixture components and standard stochastic optimization techniques. Finally, we discuss statistical beneﬁts of the Hellinger distance as a variational objective through bounds on posterior probability, moment, and importance sampling errors. Experiments on multiple datasets and models show that {UBVI} provides reliable, accurate posterior approximations.},
	journaltitle = {{arXiv}:1906.01235 [cs, math, stat]},
	author = {Campbell, Trevor and Li, Xinglong},
	urldate = {2019-06-25},
	date = {2019-06-04},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1906.01235},
	keywords = {Statistics - Computation, Mathematics - Statistics Theory, Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {campbell_li_2019_universal_boosting_variational_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/campbell_li_2019_universal_boosting_variational_inference.pdf:application/pdf}
}

@article{oyeyemi_comparison_2019,
	title = {Comparison of Some Spike-and-Slab Priors for Bayesian Variable Selection in Multiple Linear Regression},
	volume = {20},
	abstract = {Variable selection has been a very essential challenge in building a multiple regression model. Exclusion of influential covariates or including covariate with zero effect will no doubt affect the estimation precision and as well the predictive accuracy of the model. “Spike-and-Slab prior” is an increasingly popular variable selection approach used in the Bayesian framework, which aids the variable selection and the estimation of regression parameters.},
	pages = {10},
	number = {1},
	journaltitle = {. Number},
	author = {Oyeyemi, G M and Olanrewaju, Y A and Kolawole, R O},
	date = {2019},
	langid = {english},
	file = {oyeyemi_et_al_2019_comparison_of_some_spike-and-slab_priors_for_bayesian_variable_selection_in.pdf:/home/nathan/Dropbox/njames/zotero_sync/oyeyemi_et_al_2019_comparison_of_some_spike-and-slab_priors_for_bayesian_variable_selection_in.pdf:application/pdf}
}

@article{morrell_mind_2019,
	title = {Mind the gap? The platform trial as a working environment},
	volume = {20},
	issn = {1745-6215},
	url = {https://trialsjournal.biomedcentral.com/articles/10.1186/s13063-019-3377-5},
	doi = {10.1186/s13063-019-3377-5},
	shorttitle = {Mind the gap?},
	abstract = {Background: Trials have become bigger and more complicated due to the complexity introduced by biomarker stratification, and the advent of multi-arm multi-stage trials, and umbrella and basket platform designs. The trials unit at University College London has been at the forefront of this work, with ground-breaking trials such as {STAMPEDE} and {FOCUS}4. The trial management and data management teams on these trials have summarised the operational challenges, to enable the broader clinical trials community to learn from their experiences. In a smallscale qualitative study, we examined the personal experience of individual researchers working on these trials. Commentary: We found reports of high workloads, with potentially significant stress for individuals and with an impact on their career choices. We conclude that there was an initial underestimation of the work required and of the inherent, largely unanticipated, challenges. We discuss the importance of fully understanding these trials’ resource requirements, both for those writing grant applications and critically, for those with responsibility for deciding on funding. The working environment was characterised by three features: complexity, scale and heightened expectations. These features are highly attractive for professional development and engender high levels of loyalty and commitment. We observed a trade-off between these intrinsic rewards and the continuous demands of overlapping tasks, balancing a mix of routine and high-profile work, and the changing nature of pivotal roles. Such demands present challenges for colleague relationships, by enhancing the potential for competition and by disrupting the natural opportunities to pause, review and celebrate team achievements. In addition, molecular stratification in effect brings the patient into the trial office, as a specific individual, despite anonymisation, who is owed test results and a treatment decision. We discuss these observations with a view to interconnecting the need for compassion for patients with caring for the researchers engaged in the research ecosystem who are aiming to produce much hoped-for advances in medical science. Conclusions: There is a need for increased awareness of the challenge these studies place on those throughout the team delivering the study. Such considerations must influence leaders and funders, both in their initial budget considerations and throughout delivery.},
	pages = {297},
	number = {1},
	journaltitle = {Trials},
	author = {Morrell, Liz and Hordern, Joshua and Brown, Louise and Sydes, Matthew R. and Amos, Claire L. and Kaplan, Richard S. and Parmar, Mahesh K. B. and Maughan, Timothy S.},
	urldate = {2019-06-25},
	date = {2019-12},
	langid = {english},
	file = {morrell_et_al_2019_mind_the_gap.pdf:/home/nathan/Dropbox/njames/zotero_sync/morrell_et_al_2019_mind_the_gap.pdf:application/pdf}
}

@article{for_the_stampede_and_focus4_investigators_changing_2019,
	title = {Changing platforms without stopping the train: experiences of data management and data management systems when adapting platform protocols by adding and closing comparisons},
	volume = {20},
	issn = {1745-6215},
	url = {https://trialsjournal.biomedcentral.com/articles/10.1186/s13063-019-3322-7},
	doi = {10.1186/s13063-019-3322-7},
	shorttitle = {Changing platforms without stopping the train},
	abstract = {Discussion: We found similar adaptive protocol-specific challenges in both trials. Adding comparisons to and removing them from open trials provides extra layers of complexity to {CRF} and database development. At the start of an adaptive trial, {CRFs} and databases must be designed to be flexible and scalable in order to cope with the continuous changes, ensuring future data requirements are considered where possible. When adding or stopping a comparison, the challenge is to incorporate new data requirements while ensuring data collection within ongoing comparisons is unaffected. Some changes may apply to all comparisons; others may be comparison-specific or applicable only to patients recruited during a specific time period. We discuss the advantages and disadvantages of the different approaches to {CRF} and database design we implemented in these trials, particularly in relation to use and maintenance of generic versus comparison-specific {CRFs} and databases. The work required to add or remove a comparison, including the development and testing of changes, updating of documentation, and training of sites, must be undertaken alongside data management of ongoing comparisons. Adequate resource is required for these competing data management tasks, especially in trials with long follow-up. A plan is needed for regular and preanalysis data cleaning for multiple comparisons that could recruit at different rates and periods of time. Data-cleaning activities may need to be split and prioritised, especially if analyses for different comparisons overlap in time. Conclusions: Adaptive trials offer an efficient model to run randomised controlled trials, but setting up and conducting the data management activities in these trials can be operationally challenging. Trialists and funders must plan for scalability in data collection and the resource required to cope with additional competing data management tasks.},
	pages = {294},
	number = {1},
	journaltitle = {Trials},
	author = {{for the STAMPEDE and FOCUS4 investigators} and Hague, Dominic and Townsend, Stephen and Masters, Lindsey and Rauchenberger, Mary and Van Looy, Nadine and Diaz-Montana, Carlos and Gannon, Melissa and James, Nicholas and Maughan, Tim and Parmar, Mahesh K. B. and Brown, Louise and Sydes, Matthew R.},
	urldate = {2019-06-25},
	date = {2019-12},
	langid = {english},
	file = {for_the_stampede_and_focus4_investigators_et_al_2019_changing_platforms_without_stopping_the_train.pdf:/home/nathan/Dropbox/njames/zotero_sync/for_the_stampede_and_focus4_investigators_et_al_2019_changing_platforms_without_stopping_the_train.pdf:application/pdf}
}

@article{on_behalf_of_past_and_present_members_of_the_stampede_and_focus4_trial_management_group_this_2019,
	title = {This is a platform alteration: a trial management perspective on the operational aspects of adaptive and platform and umbrella protocols},
	volume = {20},
	issn = {1745-6215},
	url = {https://trialsjournal.biomedcentral.com/articles/10.1186/s13063-019-3216-8},
	doi = {10.1186/s13063-019-3216-8},
	shorttitle = {This is a platform alteration},
	abstract = {Conclusions: Understanding the operational complexities associated with running adaptive platform protocols is paramount for their conduct, adaptive platform trials offer an efficient model to run randomised controlled trials and we are continuing to work to reduce further the effort required from an operational perspective. Trial registration: {FOCUS}4: {ISRCTN} Registry, {ISRCTN}90061546. Registered on 16 October 2013. {STAMPEDE}: {ISRCTN} Registry, {ISRCTN}78818544. Registered on 2 February 2004.},
	pages = {264},
	number = {1},
	journaltitle = {Trials},
	author = {{On behalf of past and present members of the STAMPEDE and FOCUS4 Trial Management Group} and Schiavone, Francesca and Bathia, Riya and Letchemanan, Krishna and Masters, Lindsey and Amos, Claire and Bara, Anna and Brown, Louise and Gilson, Clare and Pugh, Cheryl and Atako, Nafisah and Hudson, Fleur and Parmar, Mahesh and Langley, Ruth and Kaplan, Richard S. and Parker, Chris and Attard, Gert and Clarke, Noel W. and Gillessen, Silke and James, Nicholas D. and Maughan, Tim and Sydes, Matthew R.},
	urldate = {2019-06-25},
	date = {2019-12},
	langid = {english},
	file = {on_behalf_of_past_and_present_members_of_the_stampede_and_focus4_trial_management_group_et_al_2019_this_is_a_platform_alteration.pdf:/home/nathan/Dropbox/njames/zotero_sync/on_behalf_of_past_and_present_members_of_the_stampede_and_focus4_trial_management_group_et_al_2019_this_is_a_platform_alteration.pdf:application/pdf}
}

@article{tian_joint_2018,
	title = {Joint modeling for mixed-effects quantile regression of longitudinal data with detection limits and covariates measured with error, with application to {AIDS} studies},
	volume = {33},
	issn = {0943-4062, 1613-9658},
	url = {http://link.springer.com/10.1007/s00180-018-0812-0},
	doi = {10.1007/s00180-018-0812-0},
	abstract = {It is very common in {AIDS} studies that response variable (e.g., {HIV} viral load) may be subject to censoring due to detection limits while covariates (e.g., {CD}4 cell count) may be measured with error. Failure to take censoring in response variable and measurement errors in covariates into account may introduce substantial bias in estimation and thus lead to unreliable inference. Moreover, with non-normal and/or heteroskedastic data, traditional mean regression models are not robust to tail reactions. In this case, one may ﬁnd it attractive to estimate extreme causal relationship of covariates to a dependent variable, which can be suitably studied in quantile regression framework. In this paper, we consider joint inference of mixed-effects quantile regression model with right-censored responses and errors in covariates. The inverse censoring probability weighted method and the orthogonal regression method are combined to reduce the biases of estimation caused by censored data and measurement errors. Under some regularity conditions, the consistence and asymptotic normality of estimators are derived. Finally, some simulation studies are implemented and a {HIV}/{AIDS} clinical data set is analyzed to to illustrate the proposed procedure.},
	pages = {1563--1587},
	number = {4},
	journaltitle = {Comput Stat},
	author = {Tian, Yuzhu and Tang, Manlai and Tian, Maozai},
	urldate = {2019-06-25},
	date = {2018-12},
	langid = {english},
	file = {tian_et_al_2018_joint_modeling_for_mixed-effects_quantile_regression_of_longitudinal_data_with.pdf:/home/nathan/Dropbox/njames/zotero_sync/tian_et_al_2018_joint_modeling_for_mixed-effects_quantile_regression_of_longitudinal_data_with.pdf:application/pdf}
}

@article{calabrese_new_2019,
	title = {A new approach to measure systemic risk: a bivariate copula model for dependent censored data},
	issn = {03772217},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221719305193},
	doi = {10.1016/j.ejor.2019.06.027},
	shorttitle = {A new approach to measure systemic risk},
	abstract = {We propose a novel approach based on the Marshall-Olkin ({MO}) copula to estimate the impact of systematic and idiosyncratic components on crossborder systemic risk. To use the data on non-failed banks in the suggested method, we consider the time to bank failure as a censored variable. Therefore, we propose a pseudo-maximum likelihood estimation procedure for the {MO} copula for a Type I censored sample. We derive the log-likelihood function, the copula parameter estimator and the bootstrap conﬁdence intervals. Empirical data on the banking system of three European countries (Germany, Italy and the {UK}) shows that the proposed censored model can accurately estimate the systematic component of cross-border systemic risk.},
	pages = {S0377221719305193},
	journaltitle = {European Journal of Operational Research},
	author = {Calabrese, Raffaella and Osmetti, Silvia Angela},
	urldate = {2019-06-25},
	date = {2019-06},
	langid = {english},
	file = {calabrese_osmetti_2019_a_new_approach_to_measure_systemic_risk.pdf:/home/nathan/Dropbox/njames/zotero_sync/calabrese_osmetti_2019_a_new_approach_to_measure_systemic_risk.pdf:application/pdf}
}

@article{klein_multivariate_2019,
	title = {Multivariate Conditional Transformation Models},
	url = {http://arxiv.org/abs/1906.03151},
	abstract = {Regression models describing the joint distribution of multivariate response variables conditional on covariate information have become an important aspect of contemporary regression analysis. However, a limitation of such models is that they often rely on rather simplistic assumptions, e.g. a constant dependency structure that is not allowed to vary with the covariates. We propose a general framework for multivariate conditional transformation models that overcomes such limitations and describes the full joint distribution in simple, interpretable terms. Among the particular merits of the framework are that it can be embedded into likelihood-based inference and allows the dependence structure to vary with the covariates. In addition, the framework scales beyond bivariate response situations, which were the main focus of most earlier investigations. We illustrate the application of multivariate conditional transformation models in a trivariate analysis of childhood undernutrition and demonstrate empirically that even complex multivariate data-generating processes can be inferred from observations.},
	journaltitle = {{arXiv}:1906.03151 [stat]},
	author = {Klein, Nadja and Hothorn, Torsten and Kneib, Thomas},
	urldate = {2019-06-25},
	date = {2019-06-07},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1906.03151},
	keywords = {Statistics - Methodology},
	file = {klein_et_al_2019_multivariate_conditional_transformation_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/klein_et_al_2019_multivariate_conditional_transformation_models.pdf:application/pdf}
}

@report{jihan_streaming_2019,
	title = {Streaming stochastic variational Bayes; An improved approach for Bayesian inference with data streams},
	url = {https://peerj.com/preprints/27790},
	abstract = {Online learning is an essential tool for predictive analysis based on continuous, endless data streams. Adopting Bayesian inference for online settings allows hierarchical modeling while representing the uncertainty of model parameters. Existing online inference techniques are motivated by either the traditional Bayesian updating or the stochastic optimizations. However, traditional Bayesian updating suffers from overconfidence posteriors, where posterior variance becomes too inadequate to adapt to new changes to the posterior. On the other hand, stochastic optimization of variational objective demands exhausting additional analysis to optimize a hyperparameter that controls the posterior variance. In this paper, we present ''Streaming Stochastic Variational Bayes" ({SSVB})—a novel online approximation inference framework for data streaming to address the aforementioned shortcomings of the current state-of-the-art. {SSVB} adjusts its posterior variance duly without any user-specified hyperparameters while efficiently accommodating the drifting patterns to the posteriors. Moreover, {SSVB} can be easily adopted by practitioners for a wide range of models (i.e. simple regression models to complex hierarchical models) with little additional analysis. We appraised the performance of {SSVB} against Population Variational Inference ({PVI}), Stochastic Variational Inference ({SVI}) and Black-box Streaming Variational Bayes ({BB}-{SVB}) using two non-conjugate probabilistic models; multinomial logistic regression and linear mixed effect model. Furthermore, we also discuss the significant accuracy gain with {SSVB} based inference against conventional online learning models for each task.},
	institution = {{PeerJ} Preprints},
	type = {preprint},
	author = {Jihan, Nadheesh and Jayasinghe, Malith and Perera, Srinath},
	urldate = {2019-06-25},
	date = {2019-06-10},
	langid = {english},
	doi = {10.7287/peerj.preprints.27790v1},
	file = {jihan_et_al_2019_streaming_stochastic_variational_bayes\;_an_improved_approach_for_bayesian.pdf:/home/nathan/Dropbox/njames/zotero_sync/jihan_et_al_2019_streaming_stochastic_variational_bayes\;_an_improved_approach_for_bayesian.pdf:application/pdf}
}

@article{ko_model_2019,
	title = {Model robust inference with two-stage maximum likelihood estimation for copulas},
	volume = {171},
	issn = {0047259X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0047259X18302495},
	doi = {10.1016/j.jmva.2019.01.004},
	abstract = {This article is concerned with inference in parametric copula setups, where both the marginals and the copula have parametric forms. For such models, two-stage maximum likelihood estimation, often referred to as inference function for margins, is used as an attractive alternative to the full maximum likelihood estimation strategy. Previous studies of the two-stage maximum likelihood estimator have largely been based on the assumption that the chosen parametric model captures the true model that generated data. We study the impact of dropping this true model assumption, both theoretically and numerically. We first show that the two-stage maximum likelihood estimator is consistent for a welldefined least false parameter value, different from the analogous least false parameter associated with the full maximum likelihood procedure. Then we demonstrate limiting normality of the full vector of estimators, with concise matrix notation for the variance matrices involved. Along with consistent estimators for these, we have built a modelrobust machinery for inference in parametric copula models. The special case where the parametric model is assumed to hold corresponds to situations studied earlier in the literature, with simpler formulas for variance matrices. As a numerical illustration, we perform a set of simulations. We also analyze five-dimensional Norwegian precipitation data. We find that the variance of the copula parameter estimate can both increase and decrease, by dropping the true model assumption. In addition, we observe that the two-stage maximum likelihood estimator is still highly efficient when the true model assumption is dropped and thus the model robust asymptotic variance formulas are used. Additionally, we discover that using highly misspecified models can lead to situations where the asymptotic variance of the two-stage maximum likelihood estimator is lower than that of full maximum likelihood estimator. Our results are also used to analyze the mean squared error properties for both the full and the two-stage maximum likelihood estimators of any focus parameter.},
	pages = {362--381},
	journaltitle = {Journal of Multivariate Analysis},
	author = {Ko, Vinnie and Hjort, Nils Lid},
	urldate = {2019-06-25},
	date = {2019-05},
	langid = {english},
	file = {ko_hjort_2019_model_robust_inference_with_two-stage_maximum_likelihood_estimation_for_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/ko_hjort_2019_model_robust_inference_with_two-stage_maximum_likelihood_estimation_for_copulas.pdf:application/pdf}
}

@article{knollmuller_metric_2019,
	title = {Metric Gaussian Variational Inference},
	url = {http://arxiv.org/abs/1901.11033},
	abstract = {A variational Gaussian approximation of the posterior distribution can be an excellent way to infer posterior quantities. However, to capture all posterior correlations the parametrization of the full covariance is required, which scales quadratic with the problem size. This scaling prohibits full-covariance approximations for large-scale problems. As a solution to this limitation we propose Metric Gaussian Variational Inference ({MGVI}). This procedure approximates the variational covariance such that it requires no parameters on its own and still provides reliable posterior correlations and uncertainties for all model parameters. We approximate the variational covariance with the inverse Fisher metric, a local estimate of the true posterior uncertainty. This covariance is only stored implicitly and all necessary quantities can be extracted from it by independent samples drawn from the approximating Gaussian. {MGVI} requires the minimization of a stochastic estimate of the Kullback-Leibler divergence only with respect to the mean of the variational Gaussian, a quantity that scales linearly with the problem size. We motivate the choice of this covariance from an information geometric perspective. We validate the method against established approaches, demonstrate its scalability into the regime over a million parameters and capability to capture posterior distributions over complex models with multiple components and strongly non-Gaussian prior distributions.},
	journaltitle = {{arXiv}:1901.11033 [astro-ph, physics:physics, stat]},
	author = {Knollmüller, Jakob and Enßlin, Torsten A.},
	urldate = {2019-06-25},
	date = {2019-01-30},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1901.11033},
	keywords = {Statistics - Methodology, Statistics - Machine Learning, Computer Science - Machine Learning, Physics - Data Analysis, Statistics and Probability, Astrophysics - Instrumentation and Methods for Astrophysics},
	file = {knollmüller_enßlin_2019_metric_gaussian_variational_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/knollmüller_enßlin_2019_metric_gaussian_variational_inference.pdf:application/pdf}
}

@article{domke_provable_2019,
	title = {Provable Smoothness Guarantees for Black-Box Variational Inference},
	url = {http://arxiv.org/abs/1901.08431},
	abstract = {Black-box variational inference tries to approximate a complex target distribution though a gradient-based optimization of the parameters of a simpler distribution. Provable convergence guarantees require structural properties of the objective. This paper shows that for locationscale family approximations, if the target is {MLipschitz} smooth, then so is the objective, if the entropy is excluded. The key proof idea is to describe gradients in a certain inner-product space, thus permitting use of Bessel’s inequality. This result gives insight into how to parameterize distributions, gives bounds the location of the optimal parameters, and is a key ingredient for convergence guarantees.},
	journaltitle = {{arXiv}:1901.08431 [cs, stat]},
	author = {Domke, Justin},
	urldate = {2019-06-25},
	date = {2019-01-24},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1901.08431},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {domke_2019_provable_smoothness_guarantees_for_black-box_variational_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/domke_2019_provable_smoothness_guarantees_for_black-box_variational_inference.pdf:application/pdf}
}

@article{barajas-solano_approximate_2019,
	title = {Approximate Bayesian Model Inversion for {PDEs} with Heterogeneous and State-Dependent Coefficients},
	url = {http://arxiv.org/abs/1902.06718},
	abstract = {We present two approximate Bayesian inference methods for parameter estimation in partial diﬀerential equation ({PDE}) models with space-dependent and state-dependent parameters. We demonstrate that these methods provide accurate and cost-eﬀective alternatives to Markov Chain Monte Carlo simulation. We assume a parameterized Gaussian prior on the unknown functions, and approximate the posterior density by a parameterized multivariate Gaussian density. The parameters of the prior and posterior are estimated from sparse observations of the {PDE} model’s states and the unknown functions themselves by maximizing the evidence lower bound ({ELBO}), a lower bound on the log marginal likelihood of the observations. The ﬁrst method, Laplace-{EM}, employs the expectation maximization algorithm to maximize the {ELBO}, with a Laplace approximation of the posterior on the Estep, and minimization of a Kullback-Leibler divergence on the M-step. The second method, {DSVI}-{EB}, employs the doubly stochastic variational inference ({DSVI}) algorithm, in which the {ELBO} is maximized via gradient-based stochastic optimization, with nosiy gradients computed via simple Monte Carlo sampling and Gaussian backpropagation. We apply these methods to identifying diﬀusion coeﬃcients in linear and nonlinear diﬀusion equations, and we ﬁnd that both methods provide accurate estimates of posterior densities and the hyperparameters of Gaussian priors. While the {LaplaceEM} method is more accurate, it requires computing Hessians of the physics model. The {DSVI}-{EB} method is found to be less accurate but only requires gradients of the physics model.},
	journaltitle = {{arXiv}:1902.06718 [stat]},
	author = {Barajas-Solano, David A. and Tartakovsky, Alexandre M.},
	urldate = {2019-06-25},
	date = {2019-02-18},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1902.06718},
	keywords = {Statistics - Methodology},
	file = {barajas-solano_tartakovsky_2019_approximate_bayesian_model_inversion_for_pdes_with_heterogeneous_and.pdf:/home/nathan/Dropbox/njames/zotero_sync/barajas-solano_tartakovsky_2019_approximate_bayesian_model_inversion_for_pdes_with_heterogeneous_and.pdf:application/pdf}
}

@article{ko_copula_2019,
	title = {Copula information criterion for model selection with two-stage maximum likelihood estimation},
	issn = {24523062},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S245230621930005X},
	doi = {10.1016/j.ecosta.2019.01.001},
	abstract = {In parametric copula setups, where both the margins and copula have parametric forms, two-stage maximum likelihood estimation, often referred to as inference functions for margins, is used as an attractive alternative to the full maximum likelihood estimation strategy. Exploiting the existing model robust inference of two-stage maximum likelihood estimation, a copula information criterion ({CIC}) for model selection is developed. In a nutshell, {CIC} aims for the model that minimizes the Kullback–Leibler divergence from the real data generating mechanism. {CIC} does not assume that the chosen parametric model captures this true model, unlike what is assumed for {AIC}. In this sense, {CIC} is analogous to the Takeuchi Information Criterion ({TIC}), which is deﬁned for the full maximum likelihood. If the additional assumption that a candidate model is correctly speciﬁed is made, then {CIC} for that model simpliﬁes to {AIC}. Additionally, {CIC} can easily be extended to the conditional copula setup where covariates are parametrically linked to the copula model. As a numerical illustration, simulation studies were performed to show that the better model according to {CIC} also has better prediction performance in general. The result also shows that the bias correction term of {CIC} penalizes the misspeciﬁed model more heavily. This bias correction term has a strong positive relationship with the prediction performance of the model. So, a model with bad prediction performance is being penalized more by {CIC}. Although this behavior of the bias correction part is an important conceptual advance of {CIC}, this is not suﬃcient to make {CIC} outperform {AIC} in practice. This is because each misspeciﬁed model has the bias correction term and they grow at different speeds, depending on the model. The difference between {CIC} and {AIC} becomes minimal as sample size grows because the log-likelihood part outgrows the bias correction part.},
	pages = {S245230621930005X},
	journaltitle = {Econometrics and Statistics},
	author = {Ko, Vinnie and Hjort, Nils Lid},
	urldate = {2019-06-25},
	date = {2019-02},
	langid = {english},
	file = {ko_hjort_2019_copula_information_criterion_for_model_selection_with_two-stage_maximum.pdf:/home/nathan/Dropbox/njames/zotero_sync/ko_hjort_2019_copula_information_criterion_for_model_selection_with_two-stage_maximum.pdf:application/pdf}
}

@article{hirt_copula-like_2019,
	title = {Copula-like Variational Inference},
	url = {http://arxiv.org/abs/1904.07153},
	abstract = {This paper considers a new family of variational distributions motivated by Sklar’s theorem. This family is based on new copula-like densities on the hypercube with non-uniform marginals which can be sampled efﬁciently, i.e. with a complexity linear in the dimension of state space. Then, the proposed variational densities that we suggest can be seen as arising from these copula-like densities used as base distributions on the hypercube with Gaussian quantile functions and sparse rotation matrices as normalizing ﬂows. The latter correspond to a rotation of the marginals with complexity O(d log d). We provide some empirical evidence that such a variational family can also approximate non-Gaussian posteriors and can be beneﬁcial compared to Gaussian approximations. Our method performs largely comparably to state-of-the-art variational approximations on standard regression and classiﬁcation benchmarks for Bayesian Neural Networks.},
	journaltitle = {{arXiv}:1904.07153 [cs, stat]},
	author = {Hirt, Marcel and Dellaportas, Petros and Durmus, Alain},
	urldate = {2019-06-25},
	date = {2019-04-15},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1904.07153},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {hirt_et_al_2019_copula-like_variational_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/hirt_et_al_2019_copula-like_variational_inference.pdf:application/pdf}
}

@article{storlie_prediction_2017,
	title = {Prediction and Inference with Missing Data in Patient Alert Systems},
	url = {http://arxiv.org/abs/1704.07904},
	abstract = {We describe the Bedside Patient Rescue ({BPR}) project, the goal of which is risk prediction of adverse events for non-{ICU} patients using ∼200 variables (vitals, lab results, assessments, ...). There are several missing predictor values for most patients, which in the health sciences is the norm, rather than the exception. A Bayesian approach is presented that addresses many of the shortcomings to standard approaches to missing predictors: (i) treatment of the uncertainty due to imputation is straight-forward in the Bayesian paradigm, (ii) the predictor distribution is ﬂexibly modeled as an inﬁnite normal mixture with latent variables to explicitly account for discrete predictors (i.e., as in multivariate probit regression models), and (iii) certain missing not at random situations can be handled eﬀectively by allowing the indicator of missingness into the predictor distribution only to inform the distribution of the missing variables. The proposed approach also has the beneﬁt of providing a distribution for the prediction, including the uncertainty inherent in the imputation. Therefore, we can ask questions such as: is it possible this individual is at high risk but we are missing too much information to know for sure? How much would we reduce the uncertainty in our risk prediction by obtaining a particular missing value? This approach is applied to the {BPR} problem resulting in excellent predictive capability to identify deteriorating patients.},
	journaltitle = {{arXiv}:1704.07904 [stat]},
	author = {Storlie, Curtis B. and Therneau, Terry M. and Carter, Rickey E. and Chia, Nicholas and Bergquist, John R. and Huddleston, Jeanne M. and Romero-Brufau, Santiago},
	urldate = {2019-06-25},
	date = {2017-04-25},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1704.07904},
	keywords = {Statistics - Applications},
	file = {storlie_et_al_2017_prediction_and_inference_with_missing_data_in_patient_alert_systems.pdf:/home/nathan/Dropbox/njames/zotero_sync/storlie_et_al_2017_prediction_and_inference_with_missing_data_in_patient_alert_systems.pdf:application/pdf}
}

@article{piironen_comparison_2017,
	title = {Comparison of Bayesian predictive methods for model selection},
	volume = {27},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-016-9649-y},
	doi = {10.1007/s11222-016-9649-y},
	abstract = {The goal of this paper is to compare several widely used Bayesian model selection methods in practical model selection problems, highlight their differences and give recommendations about the preferred approaches. We focus on the variable subset selection for regression and classiﬁcation and perform several numerical experiments using both simulated and real world data. The results show that the optimization of a utility estimate such as the cross-validation ({CV}) score is liable to ﬁnding overﬁtted models due to relatively high variance in the utility estimates when the data is scarce. This can also lead to substantial selection induced bias and optimism in the performance evaluation for the selected model. From a predictive viewpoint, best results are obtained by accounting for model uncertainty by forming the full encompassing model, such as the Bayesian model averaging solution over the candidate models. If the encompassing model is too complex, it can be robustly simpliﬁed by the projection method, in which the information of the full model is projected onto the submodels. This approach is substantially less prone to overﬁtting than selection based on {CV}-score. Overall, the projection method appears to outperform also the maximum a posteriori model and the selection of the most probable variables. The study also demonstrates that the model selection can greatly beneﬁt from using crossvalidation outside the searching process both for guiding the model size selection and assessing the predictive performance of the ﬁnally selected model.},
	pages = {711--735},
	number = {3},
	journaltitle = {Stat Comput},
	author = {Piironen, Juho and Vehtari, Aki},
	urldate = {2019-06-25},
	date = {2017-05},
	langid = {english},
	file = {piironen_vehtari_2017_comparison_of_bayesian_predictive_methods_for_model_selection.pdf:/home/nathan/Dropbox/njames/zotero_sync/piironen_vehtari_2017_comparison_of_bayesian_predictive_methods_for_model_selection.pdf:application/pdf}
}

@article{vehtari_practical_2017,
	title = {Practical Bayesian model evaluation using leave-one-out cross-validation and {WAIC}},
	volume = {27},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-016-9696-4},
	doi = {10.1007/s11222-016-9696-4},
	abstract = {Leave-one-out cross-validation ({LOO}) and the widely applicable information criterion ({WAIC}) are methods for estimating pointwise out-of-sample prediction accuracy from a ﬁtted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. {LOO} and {WAIC} have various advantages over simpler estimates of predictive error such as {AIC} and {DIC} but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for {LOO} and {WAIC} that can be performed using existing simulation draws. We introduce an efﬁcient computation of {LOO} using Pareto-smoothed importance sampling ({PSIS}), a new procedure for regularizing importance weights. Although {WAIC} is asymptotically equal to {LOO}, we demonstrate that {PSIS}-{LOO} is more robust in the ﬁnite case with weak priors or inﬂuential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models ﬁt with the Bayesian inference package Stan.},
	pages = {1413--1432},
	number = {5},
	journaltitle = {Stat Comput},
	author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
	urldate = {2019-06-25},
	date = {2017-09},
	langid = {english},
	file = {vehtari_et_al_2017_practical_bayesian_model_evaluation_using_leave-one-out_cross-validation_and.pdf:/home/nathan/Dropbox/njames/zotero_sync/vehtari_et_al_2017_practical_bayesian_model_evaluation_using_leave-one-out_cross-validation_and.pdf:application/pdf}
}

@article{carpenter_simulation-based_nodate,
	title = {Simulation-Based Calibration with Stan and {RStan}},
	pages = {17},
	author = {Carpenter, Bob},
	langid = {english},
	file = {carpenter_simulation-based_calibration_with_stan_and_rstan.pdf:/home/nathan/Dropbox/njames/zotero_sync/carpenter_simulation-based_calibration_with_stan_and_rstan.pdf:application/pdf}
}

@article{lee_dependence_2019,
	title = {Dependence modeling for multi-type recurrent events via copulas},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.8283},
	doi = {10.1002/sim.8283},
	shorttitle = {Dependence modeling for multi-type recurrent events via copulas},
	journaltitle = {Statistics in Medicine},
	author = {Lee, Jooyoung and Cook, Richard J.},
	urldate = {2019-06-26},
	date = {2019-06-24},
	langid = {english},
	file = {lee_cook_2019_dependence_modeling_for_multi-type_recurrent_events_via_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/lee_cook_2019_dependence_modeling_for_multi-type_recurrent_events_via_copulas.pdf:application/pdf}
}

@article{tang_nonparametric_2018,
	title = {A nonparametric Bayesian continual reassessment method in single-agent dose-finding studies},
	volume = {18},
	issn = {1471-2288},
	url = {https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-018-0604-9},
	doi = {10.1186/s12874-018-0604-9},
	abstract = {Background: The main purpose of dose-finding studies in Phase I trial is to estimate maximum tolerated dose ({MTD}), which is the maximum test dose that can be assigned with an acceptable level of toxicity. Existing methods developed for single-agent dose-finding assume that the dose-toxicity relationship follows a specific parametric potency curve. This assumption may lead to bias and unsafe dose escalations due to the misspecification of parametric curve.
Methods: This paper relaxes the parametric assumption of dose-toxicity relationship by imposing a Dirichlet process prior on unknown dose-toxicity curve. A hybrid algorithm combining the Gibbs sampler and adaptive rejection Metropolis sampling ({ARMS}) algorithm is developed to estimate the dose-toxicity curve, and a two-stage Bayesian nonparametric adaptive design is presented to estimate {MTD}.
Results: For comparison, we consider two classical continual reassessment methods ({CRMs}) (i.e., logistic and power models). Numerical results show the flexibility of the proposed method for single-agent dose-finding trials, and the proposed method behaves better than two classical {CRMs} under our considered scenarios.
Conclusions: The proposed dose-finding procedure is model-free and robust, and behaves satisfactorily even in small sample cases.},
	pages = {172},
	number = {1},
	journaltitle = {{BMC} Med Res Methodol},
	author = {Tang, Niansheng and Wang, Songjian and Ye, Gen},
	urldate = {2019-07-02},
	date = {2018-12},
	langid = {english},
	file = {tang_et_al_2018_a_nonparametric_bayesian_continual_reassessment_method_in_single-agent.pdf:/home/nathan/Dropbox/njames/zotero_sync/tang_et_al_2018_a_nonparametric_bayesian_continual_reassessment_method_in_single-agent.pdf:application/pdf}
}

@article{chapple_regression_2019,
	title = {A regression based phase I clinical trial for late-onset toxicities without clinician elicitation},
	volume = {14},
	issn = {24518654},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2451865418301509},
	doi = {10.1016/j.conctc.2019.100327},
	abstract = {An extension of the isotonic regression based phase I clinical trial design is presented that incorporates partial follow-up times into estimation of the raw toxicity probabilities. This phase I clinical trial design, called the {TITE}-{IR} design, drastically decreases average trial duration by allowing patients to be treated immediately after being enrolled in a phase I clinical trial. The {TITE}-{IR} design does not require specification of a prior skeleton of toxicity probabilities like the continual reassessment method, has an additional trial parameter for controlling aggressiveness of dose escalation, and has an easily understood formula for estimating toxicity probabilities. An R statistical software package is described in detail in the appendix for simulating and implementing the design. A simulation study shows that the {TITE}-{IR} design outperforms the 3 + 3 design in terms of selecting the true maximum tolerated dose and results in shorter trial times, without a large loss in efficiency, compared to the isotonic regression design and Storer's up-and-down design D. These properties make the {TITE}-{IR} design a more appealing option to clinicians than the two most commonly used 3 + 3 designs and the isotonic regression design with larger follow-up windows for toxicity.},
	pages = {100327},
	journaltitle = {Contemporary Clinical Trials Communications},
	author = {Chapple, Andrew G. and Wojcik, Janusz J. and {McDaniel}, Lee S.},
	urldate = {2019-07-02},
	date = {2019-06},
	langid = {english},
	file = {chapple_et_al_2019_a_regression_based_phase_i_clinical_trial_for_late-onset_toxicities_without.pdf:/home/nathan/Dropbox/njames/zotero_sync/chapple_et_al_2019_a_regression_based_phase_i_clinical_trial_for_late-onset_toxicities_without.pdf:application/pdf}
}

@article{sabanes_bove_model-based_2019,
	title = {Model-Based Dose Escalation Designs in \textit{R} with \textbf{{crmPack}}},
	volume = {89},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v89/i10/},
	doi = {10.18637/jss.v089.i10},
	abstract = {Model-based dose escalation designs have gained increasing interest due to the need for more eﬃcient and informative Phase I trials. The wide-spread implementation of such designs has been hindered by the need for either licensing specialized commercial software or programming the design and simulations from scratch for each project. The R-package {crmPack} provides a simple and uniﬁed object-oriented framework for model-based dose escalation designs. This enables the standard use of such designs, while being able to ﬂexibly adapt and extend them. The framework comprises classes and methods for the data structure including the dose grid, statistical models including prior speciﬁcation, rules for maximum increments, next best dose, and adaptive stopping and cohort sizes. In addition to multiple modiﬁed classic continual reassessment method and escalation with overdose control designs with possibly advanced prior speciﬁcations (e.g., minimal informative and mixture priors), {crmPack} currently features dual-endpoint (safety and biomarker) designs and two-part designs. Optional assignment of a small number of patients in each cohort to placebo instead of treatment enables the use in trials outside Oncology.},
	number = {10},
	journaltitle = {J. Stat. Soft.},
	author = {Sabanés Bové, Daniel and Yeung, Wai Yin and Palermo, Giuseppe and Jaki, Thomas},
	urldate = {2019-07-02},
	date = {2019},
	langid = {english},
	file = {sabanés_bové_et_al_2019_model-based_dose_escalation_designs_in_ir-i_with_bcrmpack-b.pdf:/home/nathan/Dropbox/njames/zotero_sync/sabanés_bové_et_al_2019_model-based_dose_escalation_designs_in_ir-i_with_bcrmpack-b.pdf:application/pdf}
}

@article{zhao_efficient_2019,
	title = {Efficient augmentation and relaxation learning for individualized treatment rules using observational data},
	url = {http://arxiv.org/abs/1901.00663},
	abstract = {Individualized treatment rules aim to identify if, when, which, and to whom treatment should be applied. A globally aging population, rising healthcare costs, and increased access to patient-level data have created an urgent need for high-quality estimators of individualized treatment rules that can be applied to observational data. A recent and promising line of research for estimating individualized treatment rules recasts the problem of estimating an optimal treatment rule as a weighted classification problem. We consider a class of estimators for optimal treatment rules that are analogous to convex large-margin classifiers. The proposed class applies to observational data and is doubly-robust in the sense that correct specification of either a propensity or outcome model leads to consistent estimation of the optimal individualized treatment rule. Using techniques from semiparametric efficiency theory, we derive rates of convergence for the proposed estimators and use these rates to characterize the bias-variance trade-off for estimating individualized treatment rules with classification-based methods. Simulation experiments informed by these results demonstrate that it is possible to construct new estimators within the proposed framework that significantly outperform existing ones. We illustrate the proposed methods using data from a labor training program and a study of inflammatory bowel syndrome.},
	journaltitle = {{arXiv}:1901.00663 [stat]},
	author = {Zhao, Ying-Qi and Laber, Eric B. and Ning, Yang and Saha, Sumona and Sands, Bruce},
	urldate = {2019-07-02},
	date = {2019-01-03},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1901.00663},
	keywords = {Statistics - Methodology},
	file = {zhao_et_al_2019_efficient_augmentation_and_relaxation_learning_for_individualized_treatment.pdf:/home/nathan/Dropbox/njames/zotero_sync/zhao_et_al_2019_efficient_augmentation_and_relaxation_learning_for_individualized_treatment.pdf:application/pdf}
}

@article{liu_i3+3_nodate,
	title = {The i3+3 Design for Phase I Clinical Trials},
	abstract = {Purpose The 3+3 design has been shown to be less likely to achieve the objectives of phase I dose-finding trials when compared with more advanced model-based designs. One major criticism of the 3+3 design is that it is based on simple rules, does not depend on statistical models for inference, and leads to unsafe and unreliable operating characteristics. On the other hand, being rule-based allows 3+3 to be easily understood and implemented in practice, making it the first choice among clinicians. Is it possible to have a rule-based design with great performance?
Methods We propose a new rule-based design called i3+3, where the letter “i” represents the word “interval”. The i3+3 design is based on simple but more advanced rules that account for the variabilities in the observed data. We compare the operating characteristics for the proposed i3+3 design with other popular phase I designs by simulation.
Results The i3+3 design is far superior than the 3+3 design in trial safety and the ability to identify the true {MTD}. Compared with model-based phase I designs, i3+3 also demonstrates comparable performances. In other words, the i3+3 design possesses both the simplicity and transparency of the rule-based approaches, and the superior operating characteristics seen in model-based approaches. An online R Shiny tool (https://i3design.shinyapps.io/i3plus3/) is provided to illustrate the i3+3 design, although in practice it requires no software to design or conduct a dose-finding trial.
Conclusion The i3+3 design could be a practice-altering method for the clinical community. 1 {INTRODUCTION} 1.1. Background Phase I dose-finding trials represent the first stage of testing a new drug or new therapy in humans and are crucial in clinical drug development as they provide dose recommendation for later phase clinical trials. The primary goal of phase I trials is to assess dose limiting toxicities ({DLT}) and find the maximum tolerated dose ({MTD}) while maintaining patient safety. Statistical designs for phase I dose-finding trials can be generally divided into two classes: rule-based methods and model-based methods. The most widely used 3+3 design (1) is an example of rulebased methods, in which dose escalation and de-escalation decisions are based on a set of prespecified rules. It is by far the most popular method in practice due to its simplicity.},
	pages = {39},
	author = {Liu, Meizi and Wang, Sue-Jane and Ji, Yuan},
	langid = {english},
	file = {liu_et_al_the_i3+3_design_for_phase_i_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/liu_et_al_the_i3+3_design_for_phase_i_clinical_trials.pdf:application/pdf}
}

@article{domenicano_bayesian_2019,
	title = {Bayesian uncertainty‐directed dose finding designs},
	issn = {0035-9254, 1467-9876},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/rssc.12355},
	doi = {10.1111/rssc.12355},
	abstract = {We introduce Bayesian uncertainty-directed ({BUD}) designs for phase I–{II} dose ﬁnding trials. This class of designs assigns patients to candidate dose levels with the aim of maximizing explicit information metrics at completion of the trial, while avoiding the treatment of patients with toxic or ineffective dose levels during the trial. Explicit information metrics provide, at completion of the clinical study, accuracy measures of the ﬁnal selection of optimal or nearly optimal dose levels. The {BUD} approach utilizes the decision theoretic framework and builds on utility functions that rank candidate dose levels.The utility of a dose combines the probabilities of toxicity events and the probability of a positive response to treatment. We discuss the application of {BUD} designs in two distinct settings; dose ﬁnding studies for single agents and precision medicine studies with biomarker measurements that allow dose optimization at the individual level. The approach proposed and the simulation scenarios used in the evaluation of {BUD} designs are motivated by a stereotactic body radiation therapy study in lung cancer at our institution.},
	pages = {rssc.12355},
	journaltitle = {J. R. Stat. Soc. C},
	author = {Domenicano, I. and Ventz, S. and Cellamare, M. and Mak, R. H. and Trippa, L.},
	urldate = {2019-07-02},
	date = {2019-05-24},
	langid = {english},
	file = {domenicano_et_al_2019_bayesian_uncertainty‐directed_dose_finding_designs.pdf:/home/nathan/Dropbox/njames/zotero_sync/domenicano_et_al_2019_bayesian_uncertainty‐directed_dose_finding_designs.pdf:application/pdf}
}

@article{sparapani_nonparametric_2019,
	title = {Nonparametric competing risks analysis using Bayesian Additive Regression Trees},
	issn = {0962-2802, 1477-0334},
	url = {http://journals.sagepub.com/doi/10.1177/0962280218822140},
	doi = {10.1177/0962280218822140},
	abstract = {Many time-to-event studies are complicated by the presence of competing risks. Such data are often analyzed using Cox models for the cause-specific hazard function or Fine and Gray models for the subdistribution hazard. In practice, regression relationships in competing risks data are often complex and may include nonlinear functions of covariates, interactions, high-dimensional parameter spaces and nonproportional cause-specific, or subdistribution, hazards. Model misspecification can lead to poor predictive performance. To address these issues, we propose a novel approach: flexible prediction modeling of competing risks data using Bayesian Additive Regression Trees ({BART}). We study the simulation performance in two-sample scenarios as well as a complex regression setting, and benchmark its performance against standard regression techniques as well as random survival forests. We illustrate the use of the proposed method on a recently published study of patients undergoing hematopoietic stem cell transplantation.},
	pages = {096228021882214},
	journaltitle = {Stat Methods Med Res},
	author = {Sparapani, Rodney and Logan, Brent R and {McCulloch}, Robert E and Laud, Purushottam W},
	urldate = {2019-07-03},
	date = {2019-01-07},
	langid = {english},
	file = {sparapani_et_al_2019_nonparametric_competing_risks_analysis_using_bayesian_additive_regression_trees.pdf:/home/nathan/Dropbox/njames/zotero_sync/sparapani_et_al_2019_nonparametric_competing_risks_analysis_using_bayesian_additive_regression_trees.pdf:application/pdf}
}

@article{wasserstein_moving_2019,
	title = {Moving to a World Beyond “p {\textless} 0.05”},
	volume = {73},
	issn = {0003-1305, 1537-2731},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2019.1583913},
	doi = {10.1080/00031305.2019.1583913},
	pages = {1--19},
	issue = {sup1},
	journaltitle = {The American Statistician},
	author = {Wasserstein, Ronald L. and Schirm, Allen L. and Lazar, Nicole A.},
	urldate = {2019-07-03},
	date = {2019-03-29},
	langid = {english},
	file = {wasserstein_et_al_2019_moving_to_a_world_beyond_“p_0.pdf:/home/nathan/Dropbox/njames/zotero_sync/wasserstein_et_al_2019_moving_to_a_world_beyond_“p_0.pdf:application/pdf}
}

@article{amrhein_inferential_nodate,
	title = {Inferential Statistics as Descriptive Statistics: There Is No Replication Crisis if We Don’t Expect Replication},
	abstract = {Statistical inference often fails to replicate. One reason is that many results may be selected for drawing inference because some threshold of a statistic like the P-value was crossed, leading to biased reported effect sizes. Nonetheless, considerable non-replication is to be expected even without selective reporting, and generalizations from single studies are rarely if ever warranted. Honestly reported results must vary from replication to replication because of varying assumption violations and random variation; excessive agreement itself would suggest deeper problems, such as failure to publish results in conflict with group expectations or desires. A general perception of a “replication crisis” may thus reflect failure to recognize that statistical tests not only test hypotheses, but countless assumptions and the entire environment in which research takes place. Because of all the uncertain and unknown assumptions that underpin statistical inferences, we should treat inferential statistics as highly unstable local descriptions of relations between assumptions and data, rather than as providing generalizable inferences about hypotheses or models. And that means we should treat statistical results as being much more incomplete and uncertain than is currently the norm. Acknowledging this uncertainty could help reduce the allure of selective reporting: Since a small P-value could be large in a replication study, and a large P-value could be small, there is simply no need to selectively report studies based on statistical results. Rather than focusing our study reports on uncertain conclusions, we should thus focus on describing accurately how the study was conducted, what problems occurred, what data were obtained, what analysis methods were used and why, and what output those methods produced.},
	pages = {10},
	journaltitle = {{THE} {AMERICAN} {STATISTICIAN}},
	author = {Amrhein, Valentin and Trafimow, David and Greenland, Sander},
	langid = {english},
	file = {amrhein_et_al_inferential_statistics_as_descriptive_statistics.pdf:/home/nathan/Dropbox/njames/zotero_sync/amrhein_et_al_inferential_statistics_as_descriptive_statistics.pdf:application/pdf}
}

@article{wason_latent_2019,
	title = {A latent variable model for improving inference in trials assessing the effect of dose on toxicity and composite efficacy endpoints},
	issn = {0962-2802, 1477-0334},
	url = {http://journals.sagepub.com/doi/10.1177/0962280219831038},
	doi = {10.1177/0962280219831038},
	abstract = {It is often of interest to explore how dose affects the toxicity and efficacy properties of a novel treatment. In oncology, efficacy is often assessed through response, which is defined by a patient having no new tumour lesions and their tumour size shrinking by 30\%. Usually response and toxicity are analysed as binary outcomes in early phase trials. Methods have been proposed to improve the efficiency of analysing response by utilising the continuous tumour size information instead of dichotomising it. However, these methods do not allow for toxicity or for different doses. Motivated by a phase {II} trial testing multiple doses of a treatment against placebo, we propose a latent variable model that can estimate the probability of response and no toxicity (or other related outcomes) for different doses. We assess the confidence interval coverage and efficiency properties of the method, compared to methods that do not use the continuous tumour size, in a simulation study and the real study. The coverage is close to nominal when model assumptions are met, although can be below nominal when the model is misspecified. Compared to methods that treat response as binary, the method has confidence intervals with 30–50\% narrower widths. The method adds considerable efficiency but care must be taken that the model assumptions are reasonable.},
	pages = {096228021983103},
	journaltitle = {Stat Methods Med Res},
	author = {Wason, James {MS} and Seaman, Shaun R},
	urldate = {2019-07-03},
	date = {2019-02-25},
	langid = {english},
	file = {wason_seaman_2019_a_latent_variable_model_for_improving_inference_in_trials_assessing_the_effect.pdf:/home/nathan/Dropbox/njames/zotero_sync/wason_seaman_2019_a_latent_variable_model_for_improving_inference_in_trials_assessing_the_effect.pdf:application/pdf}
}

@article{li_copula-based_2019,
	title = {Copula-based semiparametric analysis for time series data with detection limits: {COPULA}-{BASED} {SEMIPARAMETRIC} {ANALYSIS}},
	issn = {03195724},
	url = {http://doi.wiley.com/10.1002/cjs.11503},
	doi = {10.1002/cjs.11503},
	shorttitle = {Copula-based semiparametric analysis for time series data with detection limits},
	journaltitle = {Can J Statistics},
	author = {Li, Fuyuan and Tang, Yanlin and Wang, Huixia Judy},
	urldate = {2019-07-16},
	date = {2019-06-18},
	langid = {english},
	file = {li_et_al_2019_copula-based_semiparametric_analysis_for_time_series_data_with_detection_limits.pdf:/home/nathan/Dropbox/njames/zotero_sync/li_et_al_2019_copula-based_semiparametric_analysis_for_time_series_data_with_detection_limits.pdf:application/pdf}
}

@report{jihan_streaming_2019-1,
	title = {Streaming stochastic variational Bayes; An improved approach for Bayesian inference with data streams},
	url = {https://peerj.com/preprints/27790},
	abstract = {Online learning is an essential tool for predictive analysis based on continuous, endless data streams. Adopting Bayesian inference for online settings allows hierarchical modeling while representing the uncertainty of model parameters. Existing online inference techniques are motivated by either the traditional Bayesian updating or the stochastic optimizations. However, traditional Bayesian updating suffers from overconfidence posteriors, where posterior variance becomes too inadequate to adapt to new changes to the posterior. On the other hand, stochastic optimization of variational objective demands exhausting additional analysis to optimize a hyperparameter that controls the posterior variance. In this paper, we present ''Streaming Stochastic Variational Bayes" ({SSVB})—a novel online approximation inference framework for data streaming to address the aforementioned shortcomings of the current state-of-the-art. {SSVB} adjusts its posterior variance duly without any user-specified hyperparameters while efficiently accommodating the drifting patterns to the posteriors. Moreover, {SSVB} can be easily adopted by practitioners for a wide range of models (i.e. simple regression models to complex hierarchical models) with little additional analysis. We appraised the performance of {SSVB} against Population Variational Inference ({PVI}), Stochastic Variational Inference ({SVI}) and Black-box Streaming Variational Bayes ({BB}-{SVB}) using two non-conjugate probabilistic models; multinomial logistic regression and linear mixed effect model. Furthermore, we also discuss the significant accuracy gain with {SSVB} based inference against conventional online learning models for each task.},
	institution = {{PeerJ} Preprints},
	type = {preprint},
	author = {Jihan, Nadheesh and Jayasinghe, Malith and Perera, Srinath},
	urldate = {2019-07-16},
	date = {2019-06-10},
	langid = {english},
	doi = {10.7287/peerj.preprints.27790v1},
	file = {Jihan et al. - 2019 - Streaming stochastic variational Bayes\; An improve.pdf:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/DWDQI9PS/Jihan et al. - 2019 - Streaming stochastic variational Bayes\; An improve.pdf:application/pdf}
}

@article{zhang_copula-based_2019,
	title = {A Copula-Based {GLMM} Model for Multivariate Longitudinal Data with Mixed-Types of Responses},
	issn = {0976-8386, 0976-8394},
	url = {http://link.springer.com/10.1007/s13571-019-00197-8},
	doi = {10.1007/s13571-019-00197-8},
	abstract = {We propose a copula-based generalized linear mixed model ({GLMM}) to jointly analyze multivariate longitudinal data with mixed types, including continuous, count and binary responses. The association of repeated measurements is modelled through the {GLMM} model, meanwhile a pair-copula construction (D-vine) is adopted to measure the dependency structure between diﬀerent responses. By combining mixed models and D-vine copulas, our proposed approach could not only deal with unbalanced data with arbitrary margins but also handle moderate dimensional problems due to the eﬃciency and ﬂexibility of D-vines. Based on D-vine copulas, algorithms for sampling mixed data and computing likelihood are also developed. Leaving the random eﬀects distribution unspeciﬁed, we use nonparametric maximum likelihood for model ﬁtting. Then an E-M algorithm is used to obtain the maximum likelihood estimates of parameters. Both simulations and real data analysis show that the nonparametric models are more eﬃcient and ﬂexible than the parametric models.},
	journaltitle = {Sankhya B},
	author = {Zhang, Weiping and Zhang, {MengMeng} and Chen, Yu},
	urldate = {2019-07-16},
	date = {2019-06-11},
	langid = {english},
	file = {zhang_et_al_2019_a_copula-based_glmm_model_for_multivariate_longitudinal_data_with_mixed-types.pdf:/home/nathan/Dropbox/njames/zotero_sync/zhang_et_al_2019_a_copula-based_glmm_model_for_multivariate_longitudinal_data_with_mixed-types.pdf:application/pdf}
}

@article{greenland_valid_2019,
	title = {Valid P-Values Behave Exactly as They Should: Some Misleading Criticisms of P-Values and Their Resolution With S-Values},
	volume = {73},
	issn = {0003-1305, 1537-2731},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1529625},
	doi = {10.1080/00031305.2018.1529625},
	shorttitle = {Valid \textit{P} -Values Behave Exactly as They Should},
	pages = {106--114},
	issue = {sup1},
	journaltitle = {The American Statistician},
	author = {Greenland, Sander},
	urldate = {2019-07-16},
	date = {2019-03-29},
	langid = {english},
	file = {greenland_2019_valid_p-values_behave_exactly_as_they_should.pdf:/home/nathan/Dropbox/njames/zotero_sync/greenland_2019_valid_p-values_behave_exactly_as_they_should.pdf:application/pdf}
}

@article{ghanbari_wavelet_2019,
	title = {Wavelet estimation of copula function based on cencored data},
	volume = {2019},
	issn = {1029-242X},
	url = {https://journalofinequalitiesandapplications.springeropen.com/articles/10.1186/s13660-019-2140-5},
	doi = {10.1186/s13660-019-2140-5},
	abstract = {In this paper, we consider wavelet analysis to obtain an estimator of a copula function based on censored data. We show that optimal convergence rates for the mean integrated squared error ({MISE}) of linear wavelet-based function estimators are exact under right censoring model. Moreover, we derive asymptotic formulae for {MISE}. Finally, the simulation results and the analysis of real data validate the proposed procedure.},
	pages = {188},
	number = {1},
	journaltitle = {J Inequal Appl},
	author = {Ghanbari, Bahareh and Yarmohammadi, Masoud and Hosseinioun, Narges and Shirazi, Esmaeil},
	urldate = {2019-07-16},
	date = {2019-12},
	langid = {english},
	file = {ghanbari_et_al_2019_wavelet_estimation_of_copula_function_based_on_cencored_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/ghanbari_et_al_2019_wavelet_estimation_of_copula_function_based_on_cencored_data.pdf:application/pdf}
}

@article{brock_trialr:_2019,
	title = {trialr: Bayesian Clinical Trial Designs in R and Stan},
	url = {http://arxiv.org/abs/1907.00161},
	shorttitle = {trialr},
	abstract = {This manuscript introduces an R package called trialr that implements a collection of clinical trial methods in Stan and R. In this article, we explore three methods in detail. The ﬁrst is the continual reassessment method for conducting phase I dose-ﬁnding trials that seek a maximum tolerable dose. The second is {EﬀTox}, a dose-ﬁnding design that scrutinises doses by joint eﬃcacy and toxicity outcomes. The third is the augmented binary method for modelling the probability of treatment success in phase {II} oncology trials with reference to repeated measures of continuous tumour size and binary indicators of treatment failure. We emphasise in this article the beneﬁts that stem from having access to posterior samples, including ﬂexible inference and powerful visualisation. We hope that this package encourages the use of Bayesian methods in clinical trials.},
	journaltitle = {{arXiv}:1907.00161 [stat]},
	author = {Brock, Kristian},
	urldate = {2019-07-16},
	date = {2019-06-29},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1907.00161},
	keywords = {Statistics - Methodology, Statistics - Applications, Statistics - Computation, 97K80},
	file = {brock_2019_trialr.pdf:/home/nathan/Dropbox/njames/zotero_sync/brock_2019_trialr.pdf:application/pdf}
}

@article{gabry_visualization_2019,
	title = {Visualization in Bayesian workflow},
	volume = {182},
	issn = {09641998},
	url = {http://doi.wiley.com/10.1111/rssa.12378},
	doi = {10.1111/rssa.12378},
	abstract = {Bayesian data analysis is about more than just computing a posterior distribution, and Bayesian visualization is about more than trace plots of Markov chains. Practical Bayesian data analysis, like all data analysis, is an iterative process of model building, inference, model checking and evaluation, and model expansion. Visualization is helpful in each of these stages of the Bayesian workﬂow and it is indispensable when drawing inferences from the types of modern, high dimensional models that are used by applied researchers.},
	pages = {389--402},
	number = {2},
	journaltitle = {J. R. Stat. Soc. A},
	author = {Gabry, Jonah and Simpson, Daniel and Vehtari, Aki and Betancourt, Michael and Gelman, Andrew},
	urldate = {2019-07-11},
	date = {2019-02},
	langid = {english},
	file = {gabry_et_al_2019_visualization_in_bayesian_workflow.pdf:/home/nathan/Dropbox/njames/zotero_sync/gabry_et_al_2019_visualization_in_bayesian_workflow.pdf:application/pdf}
}

@article{hill_bayesian_2011,
	title = {Bayesian Nonparametric Modeling for Causal Inference},
	volume = {20},
	issn = {1061-8600, 1537-2715},
	url = {http://www.tandfonline.com/doi/abs/10.1198/jcgs.2010.08162},
	doi = {10.1198/jcgs.2010.08162},
	pages = {217--240},
	number = {1},
	journaltitle = {Journal of Computational and Graphical Statistics},
	author = {Hill, Jennifer L.},
	urldate = {2019-07-11},
	date = {2011-01},
	langid = {english},
	file = {hill_2011_bayesian_nonparametric_modeling_for_causal_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/hill_2011_bayesian_nonparametric_modeling_for_causal_inference.pdf:application/pdf}
}

@article{sauerbrei_state---art_nodate,
	title = {State-of-the-art in selection of variables and functional forms in multivariable analysis – outstanding issues},
	abstract = {How to select variables and identify functional forms for continuous variables is a key concern when creating a multivariable model. Ad hoc ‘traditional’ approaches to variable selection have been in use for at least 50 years. Similarly, methods for determining functional forms for continuous variables were first suggested many years ago. More recently, many alternative approaches to address these two challenges have been proposed, but knowledge of their properties and meaningful comparisons between them are scarce. To define a state-of-the-art and to provide evidence-supported guidance to researchers who have only a basic level of statistical knowledge many outstanding issues in multivariable modelling remain. Our main aims are to identify and illustrate such gaps in the literature and present them at a moderate technical level to the wide community of practitioners, researchers and students of statistics.},
	pages = {68},
	author = {Sauerbrei, Willi and Perperoglou, Aris and Schmid, Matthias and Abrahamowicz, Michal and Becher, Heiko and Binder, Harald and Dunkler, Daniela and Jr, Frank E Harrell and Royston, Patrick and Heinze, Georg},
	langid = {english},
	file = {sauerbrei_et_al_state-of-the-art_in_selection_of_variables_and_functional_forms_in.pdf:/home/nathan/Dropbox/njames/zotero_sync/sauerbrei_et_al_state-of-the-art_in_selection_of_variables_and_functional_forms_in.pdf:application/pdf}
}

@article{kennedy_know_2019,
	title = {Know your population and know your model: Using model-based regression and poststratification to generalize findings beyond the observed sample},
	url = {http://arxiv.org/abs/1906.11323},
	shorttitle = {Know your population and know your model},
	abstract = {Psychology is all about interactions, and this has deep implications for inference from non-representative samples. For the goal of estimating average treatment eﬀects, we propose to ﬁt a model allowing treatment to interact with background variables and then average over the distribution of these variables in the population. This can be seen as an extension of multilevel regression and poststratiﬁcation ({MRP}), a method used in political science and other areas of survey research, where researchers wish to generalize from a sparse and possibly non-representative sample to the general population. In this paper, we discuss areas where this method can be used in the psychological sciences. We use our method to estimate the norming distribution for the Big Five Personality Scale using open source data. We argue that large open data sources like this and other collaborative data sources can be combined with {MRP} to help resolve current challenges of generalizability and replication in psychology.},
	journaltitle = {{arXiv}:1906.11323 [stat]},
	author = {Kennedy, Lauren and Gelman, Andrew},
	urldate = {2019-07-11},
	date = {2019-06-26},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1906.11323},
	keywords = {Statistics - Applications},
	file = {kennedy_gelman_2019_know_your_population_and_know_your_model.pdf:/home/nathan/Dropbox/njames/zotero_sync/kennedy_gelman_2019_know_your_population_and_know_your_model.pdf:application/pdf}
}

@article{natanegara_current_2014,
	title = {The current state of Bayesian methods in medical product development: survey results and recommendations from the {DIA} Bayesian Scientific Working Group},
	volume = {13},
	issn = {15391604},
	url = {http://doi.wiley.com/10.1002/pst.1595},
	doi = {10.1002/pst.1595},
	shorttitle = {The current state of Bayesian methods in medical product development},
	pages = {3--12},
	number = {1},
	journaltitle = {Pharmaceut. Statist.},
	author = {Natanegara, Fanni and Neuenschwander, Beat and Seaman, John W. and Kinnersley, Nelson and Heilmann, Cory R. and Ohlssen, David and Rochester, George},
	urldate = {2019-07-11},
	date = {2014-01},
	langid = {english},
	file = {natanegara_et_al_2014_the_current_state_of_bayesian_methods_in_medical_product_development.pdf:/home/nathan/Dropbox/njames/zotero_sync/natanegara_et_al_2014_the_current_state_of_bayesian_methods_in_medical_product_development.pdf:application/pdf}
}

@article{yao_quality_2019,
	title = {Quality of Uncertainty Quantification for Bayesian Neural Network Inference},
	url = {http://arxiv.org/abs/1906.09686},
	abstract = {Bayesian Neural Networks ({BNNs}) place priors over the parameters in a neural network. Inference in {BNNs}, however, is difﬁcult; all inference methods for {BNNs} are approximate. In this work, we empirically compare the quality of predictive uncertainty estimates for 10 common inference methods on both regression and classiﬁcation tasks. Our experiments demonstrate that commonly used metrics (e.g. test log-likelihood) can be misleading. Our experiments also indicate that inference innovations designed to capture structure in the posterior do not necessarily produce high quality posterior approximations.},
	journaltitle = {{arXiv}:1906.09686 [cs, stat]},
	author = {Yao, Jiayu and Pan, Weiwei and Ghosh, Soumya and Doshi-Velez, Finale},
	urldate = {2019-07-16},
	date = {2019-06-23},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1906.09686},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {yao_et_al_2019_quality_of_uncertainty_quantification_for_bayesian_neural_network_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/yao_et_al_2019_quality_of_uncertainty_quantification_for_bayesian_neural_network_inference.pdf:application/pdf}
}

@report{ghosh_statistical_2019,
	title = {Statistical Modeling of Insurance Data via Vine Copula},
	url = {http://www.preprints.org/manuscript/201906.0235/v1},
	abstract = {Copulas are useful tools for modeling the dependence structure between two or more variables. Copulas are becoming a quite flexible tool in modeling dependence among the components of a multivariate vector, in particular to predict losses in insurance and finance. In this article, we study the dependence structure of some well-known real life insurance data (with two components mainly) and subsequently identify the best bivariate copula to model such a scenario via {VineCopula} package in R. Associated structural properties of these bivariate copulas are also discussed.},
	institution = {{MATHEMATICS} \& {COMPUTER} {SCIENCE}},
	type = {preprint},
	author = {Ghosh, Indranil and Watts, Dalton},
	urldate = {2019-07-16},
	date = {2019-06-24},
	langid = {english},
	doi = {10.20944/preprints201906.0235.v1},
	file = {ghosh_watts_2019_statistical_modeling_of_insurance_data_via_vine_copula.pdf:/home/nathan/Dropbox/njames/zotero_sync/ghosh_watts_2019_statistical_modeling_of_insurance_data_via_vine_copula.pdf:application/pdf}
}

@article{yang_nonparametric_2019,
	title = {Nonparametric Estimation of Copula Regression Models With Discrete Outcomes},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2018.1546586},
	doi = {10.1080/01621459.2018.1546586},
	abstract = {Multivariate discrete outcomes are common in a wide range of areas including insurance, finance, and biology. When the interplay between outcomes is significant, quantifying dependencies among interrelated variables is of great importance. Due to their ability to accommodate dependence flexibly, copulas are being applied increasingly. Yet, the application of copulas on discrete data is still in its infancy; one of the biggest barriers is the nonuniqueness of copulas, calling into question model interpretations and predictions. In this article, we study copula estimation with discrete outcomes in a regression context. As the marginal distributions vary with covariates, inclusion of continuous regressors expands the region of support for consistent estimation of copulas. Because some properties of continuous outcomes do not carry over to discrete outcomes, specification of a copula model has been a problem. We propose a nonparametric estimator of copulas to identify the “hidden” dependence structure for discrete outcomes and develop its asymptotic properties. The proposed nonparametric estimator can also serve as a diagnostic tool for selecting a parametric form for copulas. In the simulation study, we explore the performance of the proposed estimator under different scenarios and provide guidance on when the choice of copulas is important. The performance of the estimator improves as discreteness diminishes. A practical bandwidth selector is also proposed. An empirical analysis examines a dataset from the Local Government Property Insurance Fund ({LGPIF}) in the state of Wisconsin. We apply the nonparametric estimator to model the dependence among claim frequencies from different types of insurance coverage. Supplementary materials for this article are available online.},
	pages = {1--25},
	journaltitle = {Journal of the American Statistical Association},
	author = {Yang, Lu and Frees, Edward W. and Zhang, Zhengjun},
	urldate = {2019-07-19},
	date = {2019-01-15},
	langid = {english},
	file = {yang_et_al_2019_nonparametric_estimation_of_copula_regression_models_with_discrete_outcomes.pdf:/home/nathan/Dropbox/njames/zotero_sync/yang_et_al_2019_nonparametric_estimation_of_copula_regression_models_with_discrete_outcomes.pdf:application/pdf}
}

@article{fuentes_nonparametric_2013,
	title = {Nonparametric spatial models for extremes: application to extreme temperature data},
	volume = {16},
	issn = {1386-1999, 1572-915X},
	url = {http://link.springer.com/10.1007/s10687-012-0154-1},
	doi = {10.1007/s10687-012-0154-1},
	shorttitle = {Nonparametric spatial models for extremes},
	abstract = {Estimating the probability of extreme temperature events is diﬃcult because of limited records across time and the need to extrapolate the distributions of these events, as opposed to just the mean, to locations where observations are not available. Another related issue is the need to characterize the uncertainty in the estimated probability of extreme events at diﬀerent locations. Although the tools for statistical modeling of univariate extremes are well-developed, extending these tools to model spatial extreme data is an active area of research. In this paper, in order to make inference about spatial extreme events, we introduce a new nonparametric model for extremes. We present a Dirichlet-based copula model that is a ﬂexible alternative to parametric copula models such as the normal and t-copula. This presents the most ﬂexible multivariate copula approach in the literature. The proposed modelling approach is ﬁtted using a Bayesian framework that allow us to take into account diﬀerent sources of uncertainty in the data and models. To characterize the complex dependence structure in the extreme events we use nonstationary (space-dependent) extremalcoeﬃcient functions, and threshold-speciﬁc extremal functions. We apply our methods to annual maximum temperature values in the east-south-central United States.},
	pages = {75--101},
	number = {1},
	journaltitle = {Extremes},
	author = {Fuentes, Montserrat and Henry, John and Reich, Brian},
	urldate = {2019-07-19},
	date = {2013-03},
	langid = {english},
	file = {fuentes_et_al_2013_nonparametric_spatial_models_for_extremes.pdf:/home/nathan/Dropbox/njames/zotero_sync/fuentes_et_al_2013_nonparametric_spatial_models_for_extremes.pdf:application/pdf}
}

@article{elfadaly_eliciting_2017,
	title = {Eliciting Dirichlet and Gaussian copula prior distributions for multinomial models},
	volume = {27},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-016-9632-7},
	doi = {10.1007/s11222-016-9632-7},
	abstract = {In this paper, we propose novel methods of quantifying expert opinion about prior distributions for multinomial models. Two different multivariate priors are elicited using median and quartile assessments of the multinomial probabilities. First, we start by eliciting a univariate beta distribution for the probability of each category. Then we elicit the hyperparameters of the Dirichlet distribution, as a tractable conjugate prior, from those of the univariate betas through various forms of reconciliation using least-squares techniques. However, a multivariate copula function will give a more ﬂexible correlation structure between multinomial parameters if it is used as their multivariate prior distribution. So, second, we use beta marginal distributions to construct a Gaussian copula as a multivariate normal distribution function that binds these marginals and expresses the dependence structure between them. The proposed method elicits a positive-deﬁnite correlation matrix of this Gaussian copula. The two proposed methods are designed to be used through interactive graphical software written in Java.},
	pages = {449--467},
	number = {2},
	journaltitle = {Stat Comput},
	author = {Elfadaly, Fadlalla G. and Garthwaite, Paul H.},
	urldate = {2019-07-19},
	date = {2017-03},
	langid = {english},
	file = {elfadaly_garthwaite_2017_eliciting_dirichlet_and_gaussian_copula_prior_distributions_for_multinomial.pdf:/home/nathan/Dropbox/njames/zotero_sync/elfadaly_garthwaite_2017_eliciting_dirichlet_and_gaussian_copula_prior_distributions_for_multinomial.pdf:application/pdf}
}

@article{leisen_vector_2013,
	title = {A vector of Dirichlet processes},
	volume = {7},
	issn = {1935-7524},
	url = {http://projecteuclid.org/euclid.ejs/1357913282},
	doi = {10.1214/12-EJS764},
	abstract = {Random probability vectors are of great interest especially in view of their application to statistical inference. Indeed, they can be used for identifying the de Finetti mixing measure in the representation of the law of a partially exchangeable array of random elements taking values in a separable and complete metric space. In this paper we describe the construction of a vector of Dirichlet processes based on the normalization of an exchangeable vector of completely random measures that are jointly inﬁnitely divisible. After deducing the form of the multivariate Laplace exponent associated to the vector of the gamma completely random measures, we analyze some of their distributional properties. Our attention particularly focuses on the dependence structure and the speciﬁc partition probability function induced by the proposed vector.},
	pages = {62--90},
	number = {0},
	journaltitle = {Electron. J. Statist.},
	author = {Leisen, Fabrizio and Lijoi, Antonio and Spanó, Dario},
	urldate = {2019-07-19},
	date = {2013},
	langid = {english},
	file = {leisen_et_al_2013_a_vector_of_dirichlet_processes.pdf:/home/nathan/Dropbox/njames/zotero_sync/leisen_et_al_2013_a_vector_of_dirichlet_processes.pdf:application/pdf}
}

@article{silva_mcmc_nodate,
	title = {{MCMC} Methods for Bayesian Mixtures of Copulas},
	abstract = {Applications of copula models have been increasing in number in recent years. This class of models provides a modular parameterization of joint distributions: the speciﬁcation of the marginal distributions is parameterized separately from the dependence structure of the joint, a convenient way of encoding a model for domains such as ﬁnance. Some recent advances on how to specify copulas for arbitrary dimensions have been proposed, by means of mixtures of decomposable graphical models. This paper introduces a Bayesian approach for dealing with mixtures of copulas which, due to the lack of prior conjugacy, raise computational challenges. We motivate and present families of Markov chain Monte Carlo ({MCMC}) proposals that exploit the particular structure of mixtures of copulas. Diﬀerent algorithms are evaluated according to their mixing properties, and an application in ﬁnancial forecasting with missing data illustrates the usefulness of the methodology.},
	pages = {8},
	author = {Silva, Ricardo and Gramacy, Robert B},
	langid = {english},
	file = {silva_gramacy_mcmc_methods_for_bayesian_mixtures_of_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/silva_gramacy_mcmc_methods_for_bayesian_mixtures_of_copulas.pdf:application/pdf}
}

@article{levi_assessing_nodate,
	title = {Assessing Data Support for the Simplifying Assumption in Bivariate Conditional Copulas},
	abstract = {The paper considers the problem of establishing data support for the simplifying assumption ({SA}) in a bivariate conditional copula model. It is known that {SA} greatly simpliﬁes the inference for a conditional copula model, but standard tools and methods for testing {SA} in a Bayesian setting tend to not provide reliable results. After splitting the observed data into training and test sets, the method proposed will use a ﬂexible Bayesian model ﬁt to the training data to deﬁne tests based on randomization and standard asymptotic theory. Its performance is studied using simulated data. The paper’s supplementary material also discusses theoretical justiﬁcation for the method and implementations in alternative models of interest, e.g. Gaussian, Logistic and Quantile regressions.},
	pages = {13},
	author = {Levi, Evgeny and Craiu, Radu V},
	langid = {english},
	file = {levi_craiu_assessing_data_support_for_the_simplifying_assumption_in_bivariate_conditional.pdf:/home/nathan/Dropbox/njames/zotero_sync/levi_craiu_assessing_data_support_for_the_simplifying_assumption_in_bivariate_conditional.pdf:application/pdf}
}

@article{harrington_new_2019,
	title = {New Guidelines for Statistical Reporting in the \textit{Journal}},
	volume = {381},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/10.1056/NEJMe1906559},
	doi = {10.1056/NEJMe1906559},
	pages = {285--286},
	number = {3},
	journaltitle = {N Engl J Med},
	author = {Harrington, David and D’Agostino, Ralph B. and Gatsonis, Constantine and Hogan, Joseph W. and Hunter, David J. and Normand, Sharon-Lise T. and Drazen, Jeffrey M. and Hamel, Mary Beth},
	urldate = {2019-07-23},
	date = {2019-07-18},
	langid = {english},
	file = {harrington_et_al_2019_new_guidelines_for_statistical_reporting_in_the_ijournal-i.pdf:/home/nathan/Dropbox/njames/zotero_sync/harrington_et_al_2019_new_guidelines_for_statistical_reporting_in_the_ijournal-i.pdf:application/pdf}
}

@article{follmann_analysis_nodate,
	title = {Analysis of Ordered Composite Endpoints},
	abstract = {Composite endpoints are frequently used in clinical trials, but simple approaches, such as the time to ﬁrst event, do not reﬂect any ordering among the endpoints. But some endpoints, such as mortality, are worse than others. A variety of procedures have been proposed to reﬂect the severity of the individual endpoints such as pairwise ranking approaches, the win ratio, and the Desirability of Outcome Ranking ({DOOR}). When patients have different lengths of follow-up, however, ranking can be difﬁcult and proposed methods do not naturally lead to regression approaches and require specialized software. This paper deﬁnes an ordering score O to operationalize the patient ranking implied by hierarchical endpoints. We show how differential censoring of followup corresponds to multiple interval censoring of the ordering score allowing standard software for survival models to be used to calculate the nonparametric mles of different measures. Additionally, if one assumes that the ordering score is transformable to an exponential random variable, a semi-parametric regression obtains which is equivalent to the proportional hazards model subject to multiple interval censoring. Standard software can be used for estimation. We show that the {NPMLE} can be poorly behaved compared to the simple estimators in staggered entry trials. We also show that the semi-parametric estimator can be more efﬁcient than simple estimators and explore how standard Cox regression maneuvers can be used to assess model ﬁt, allow for ﬂexible generalizations, and assess interactions of covariates with treatment. We analyze a trial of short versus long-term anti-platlet therapy using our methods. Copyright c 0000 John Wiley \& Sons, Ltd.},
	pages = {16},
	author = {Follmann, Dean and Fay, Michael and Hamasaki, Toshimitsu and Evans, Scott},
	langid = {english},
	file = {follmann_et_al_analysis_of_ordered_composite_endpoints.pdf:/home/nathan/Dropbox/njames/zotero_sync/follmann_et_al_analysis_of_ordered_composite_endpoints.pdf:application/pdf}
}

@article{neuenschwander_predictively_2019,
	title = {Predictively Consistent Prior Effective Sample Sizes},
	url = {http://arxiv.org/abs/1907.04185},
	abstract = {Determining the sample size of an experiment can be challenging, even more so when incorporating external information via a prior distribution. Such information is increasingly used to reduce the size of the control group in randomized clinical trials. Knowing the amount of prior information, expressed as an equivalent prior eﬀective sample size ({ESS}), clearly facilitates trial designs. Various methods to obtain a prior’s {ESS} have been proposed recently. They have been justiﬁed by the fact that they give the standard {ESS} for one-parameter exponential families. However, despite being based on similar information-based metrics, they may lead to surprisingly diﬀerent {ESS} for non-conjugate settings, which complicates many designs with prior information. We show that current methods fail a basic predictive consistency criterion, which requires the expected posterior–predictive {ESS} for a sample of size N to be the sum of the prior {ESS} and N . The expected local-information-ratio {ESS} is introduced and shown to be predictively consistent. It corrects the {ESS} of current methods, as shown for normally distributed data with a heavy-tailed Student-t prior and exponential data with a generalized Gamma prior. Finally, two applications are discussed: the prior {ESS} for the control group derived from historical data, and the posterior {ESS} for hierarchical subgroup analyses.},
	journaltitle = {{arXiv}:1907.04185 [stat]},
	author = {Neuenschwander, Beat and Weber, Sebastian and Schmidli, Heinz and O'Hagan, Anthony},
	urldate = {2019-07-30},
	date = {2019-07-09},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1907.04185},
	keywords = {Statistics - Applications, G.3},
	file = {neuenschwander_et_al_2019_predictively_consistent_prior_effective_sample_sizes.pdf:/home/nathan/Dropbox/njames/zotero_sync/neuenschwander_et_al_2019_predictively_consistent_prior_effective_sample_sizes.pdf:application/pdf}
}

@article{alexopoulos_bayesian_2019,
	title = {Bayesian Variable Selection for Gaussian copula regression models},
	url = {http://arxiv.org/abs/1907.08245},
	abstract = {We develop a novel Bayesian method to select important predictors in regression models with multiple responses of diverse types. In particular, a sparse Gaussian copula regression model is used to account for the multivariate dependencies between any combination of discrete and continuous responses and their association with a set of predictors. We utilize the parameter expansion for data augmentation strategy to construct a Markov chain Monte Carlo algorithm for the estimation of the parameters and the latent variables of the model. Based on a centered parametrization of the Gaussian latent variables, we design an eﬃcient proposal distribution to update jointly the latent binary vectors of important predictors and the corresponding nonzero regression coeﬃcients. The proposed strategy is tested on simulated data and applied to two real data sets in which the responses consist of low-intensity counts, binary, ordinal and continuous variables.},
	journaltitle = {{arXiv}:1907.08245 [stat]},
	author = {Alexopoulos, Angelos and Bottolo, Leonardo},
	urldate = {2019-07-30},
	date = {2019-07-18},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1907.08245},
	keywords = {Statistics - Methodology, Statistics - Applications, Statistics - Computation, 62J12, 62P10},
	file = {alexopoulos_bottolo_2019_bayesian_variable_selection_for_gaussian_copula_regression_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/alexopoulos_bottolo_2019_bayesian_variable_selection_for_gaussian_copula_regression_models.pdf:application/pdf}
}

@article{ghahroodi_gaussian_2019,
	title = {Gaussian Copula–based Regression Models for the Analysis of Mixed Outcomes: An Application on Household's Utilization of Health Services Data},
	issn = {2214-1766},
	url = {https://www.atlantis-press.com/article/125912322},
	doi = {10.2991/jsta.d.190306.009},
	shorttitle = {Gaussian Copula–based Regression Models for the Analysis of Mixed Outcomes},
	abstract = {In analyzing most correlated outcomes, the popular multivariate Gaussian distribution is very restrictive and therefore dependence modeling using copulas is nowadays very common to take into account the association among mixed outcomes. In this paper, we use Gaussian copula to construct a joint distribution for three mixed discrete and continuous responses. Our approach entails specifying marginal regression models for the outcomes, and combining them via a copula to form a joint model. Closed form for likelihood function is obtained by considering sampling weights. We also obtain the likelihood function for mixed responses where one of the responses, time to event outcome, may have censored values. Some simulation studies are performed to illustrate the performance of the model. Finally, the model is applied on data involving trivariate mixed outcomes on hospitalization of individuals, based on the survey of household’s utilization of health services.},
	journaltitle = {{JSTA}},
	author = {Ghahroodi, Z. Rezaei and Saba, R. Aliakbari and Baghfalaki, T.},
	urldate = {2019-08-12},
	date = {2019},
	langid = {english},
	file = {ghahroodi_et_al_2019_gaussian_copula–based_regression_models_for_the_analysis_of_mixed_outcomes.pdf:/home/nathan/Dropbox/njames/zotero_sync/ghahroodi_et_al_2019_gaussian_copula–based_regression_models_for_the_analysis_of_mixed_outcomes.pdf:application/pdf}
}

@report{fourment_evaluating_2019,
	title = {Evaluating probabilistic programming and fast variational Bayesian inference in phylogenetics},
	url = {http://biorxiv.org/lookup/doi/10.1101/702944},
	abstract = {Recent advances in statistical machine learning techniques have led to the creation of probabilistic programming frameworks. These frameworks enable probabilistic models to be rapidly prototyped and ﬁt to data using scalable approximation methods such as variational inference. In this work, we explore the use of the Stan language for probabilistic programming in application to phylogenetic models. We show that many commonly used phylogenetic models including the general time reversible ({GTR}) substitution model, rate heterogeneity among sites, and a range of coalescent models can be implemented using a probabilistic programming language. The posterior probability distributions obtained via the black box variational inference engine in Stan were compared to those obtained with reference implementations of Markov chain Monte Carlo ({MCMC}) for phylogenetic inference. We ﬁnd that black box variational inference in Stan is less accurate than {MCMC} methods for phylogenetic models, but requires far less compute time. Finally, we evaluate a custom implementation of mean-ﬁeld variational inference on the Jukes-Cantor substitution model and show that a specialized implementation of variational inference can be two orders of magnitude faster and more accurate than a general purpose probabilistic implementation.},
	institution = {Bioinformatics},
	type = {preprint},
	author = {Fourment, Mathieu and Darling, Aaron E.},
	urldate = {2019-08-12},
	date = {2019-07-15},
	langid = {english},
	doi = {10.1101/702944},
	file = {fourment_darling_2019_evaluating_probabilistic_programming_and_fast_variational_bayesian_inference_in.pdf:/home/nathan/Dropbox/njames/zotero_sync/fourment_darling_2019_evaluating_probabilistic_programming_and_fast_variational_bayesian_inference_in.pdf:application/pdf}
}

@article{kadhem_factor_2019,
	title = {Factor copula models for mixed data},
	url = {http://arxiv.org/abs/1907.07395},
	abstract = {We develop factor copula models for analysing the dependence among mixed continuous and discrete responses. Factor copula models are canonical vine copulas that involve both observed and latent variables, hence they allow tail, asymmetric and non-linear dependence. They can be explained as conditional independence models with latent variables that don’t necessarily have an additive latent structure. We focus on important issues that would interest the social data analyst, such as model selection and goodness-of-ﬁt. Our general methodology is demonstrated with an extensive simulation study and illustrated by re-analysing three mixed response datasets. Our study suggests that there can be a substantial improvement over the standard factor model for mixed data and makes the argument for moving to factor copula models.},
	journaltitle = {{arXiv}:1907.07395 [stat]},
	author = {Kadhem, Sayed H. and Nikoloulopoulos, Aristidis K.},
	urldate = {2019-08-12},
	date = {2019-07-17},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1907.07395},
	keywords = {Statistics - Methodology},
	file = {kadhem_nikoloulopoulos_2019_factor_copula_models_for_mixed_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/kadhem_nikoloulopoulos_2019_factor_copula_models_for_mixed_data.pdf:application/pdf}
}

@article{smith_bayesian_2019,
	title = {Bayesian Inference for Regression Copulas},
	url = {http://arxiv.org/abs/1907.04529},
	abstract = {We propose a new semi-parametric distributional regression smoother for continuous data, which is based on a copula decomposition of the joint distribution of the vector of response values. The copula is high-dimensional and constructed by inversion of a pseudo regression, where the conditional mean and variance are non-parametric functions of the covariates modeled using Bayesian splines. By integrating out the spline coeﬃcients, we derive an implicit copula that captures dependence as a smooth non-parametric function of the covariates, which we call a regression copula. We derive some of its properties, and show that the entire distribution—including the mean and variance—of the response from the copula model are also smooth nonparametric functions of the covariates. Even though the implicit copula cannot be expressed in closed form, we estimate it eﬃciently using both Hamiltonian Monte Carlo and variational Bayes methods. Using four real data examples, we illustrate the eﬃcacy of these estimators, and show the properties and advantages of the copula model, for implicit copulas of dimension up to 40,981. The approach produces predictive densities of the response that are locally adaptive with respect to the covariates, and are more accurate than those from benchmark methods in every case.},
	journaltitle = {{arXiv}:1907.04529 [stat]},
	author = {Smith, Michael Stanley and Klein, Nadja},
	urldate = {2019-08-12},
	date = {2019-07-10},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1907.04529},
	keywords = {Statistics - Methodology},
	file = {smith_klein_2019_bayesian_inference_for_regression_copulas.pdf:/home/nathan/Dropbox/njames/zotero_sync/smith_klein_2019_bayesian_inference_for_regression_copulas.pdf:application/pdf}
}

@article{klein_bayesian_2019,
	title = {Bayesian Variable Selection for Non-Gaussian Responses: A Marginally Calibrated Copula Approach},
	url = {http://arxiv.org/abs/1907.04530},
	shorttitle = {Bayesian Variable Selection for Non-Gaussian Responses},
	abstract = {We propose a new highly ﬂexible and tractable Bayesian approach to undertake variable selection in non-Gaussian regression models. It uses a copula decomposition for the vector of observations on the dependent variable. This allows the marginal distribution of the dependent variable to be calibrated accurately using a nonparametric or other estimator. The family of copulas employed are ‘implicit copulas’ that are constructed from existing hierarchical Bayesian models used for variable selection, and we establish some of their properties. Even though the copulas are high-dimensional, they can be estimated eﬃciently and quickly using Monte Carlo methods. A simulation study shows that when the responses are {nonGaussian} the approach selects variables more accurately than contemporary benchmarks. A marketing example illustrates that accounting for even mild deviations from normality can lead to a substantial improvement. To illustrate the full potential of our approach we extend it to spatial variable selection for {fMRI} data. It allows for voxel-speciﬁc marginal calibration of the magnetic resonance signal at over 6,000 voxels, leading to a considerable increase in the quality of the activation maps.},
	journaltitle = {{arXiv}:1907.04530 [stat]},
	author = {Klein, Nadja and Smith, Michael Stanley},
	urldate = {2019-08-12},
	date = {2019-07-10},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1907.04530},
	keywords = {Statistics - Methodology},
	file = {klein_smith_2019_bayesian_variable_selection_for_non-gaussian_responses.pdf:/home/nathan/Dropbox/njames/zotero_sync/klein_smith_2019_bayesian_variable_selection_for_non-gaussian_responses.pdf:application/pdf}
}

@article{wang_comment:_2019,
	title = {Comment: Variational Autoencoders as Empirical Bayes},
	volume = {34},
	issn = {0883-4237},
	url = {https://projecteuclid.org/euclid.ss/1563501638},
	doi = {10.1214/19-STS710},
	shorttitle = {Comment},
	pages = {229--233},
	number = {2},
	journaltitle = {Statist. Sci.},
	author = {Wang, Yixin and Miller, Andrew C. and Blei, David M.},
	urldate = {2019-08-12},
	date = {2019-05},
	langid = {english},
	file = {wang_et_al_2019_comment.pdf:/home/nathan/Dropbox/njames/zotero_sync/wang_et_al_2019_comment.pdf:application/pdf}
}

@article{gneiting_probabilistic_2007,
	title = {Probabilistic forecasts, calibration and sharpness},
	volume = {69},
	issn = {1369-7412, 1467-9868},
	url = {http://doi.wiley.com/10.1111/j.1467-9868.2007.00587.x},
	doi = {10.1111/j.1467-9868.2007.00587.x},
	abstract = {Probabilistic forecasts of continuous variables take the form of predictive densities or predictive cumulative distribution functions. We propose a diagnostic approach to the evaluation of predictive performance that is based on the paradigm of maximizing the sharpness of the predictive distributions subject to calibration. Calibration refers to the statistical consistency between the distributional forecasts and the observations and is a joint property of the predictions and the events that materialize. Sharpness refers to the concentration of the predictive distributions and is a property of the forecasts only. A simple theoretical framework allows us to distinguish between probabilistic calibration, exceedance calibration and marginal calibration. We propose and study tools for checking calibration and sharpness, among them the probability integral transform histogram, marginal calibration plots, the sharpness diagram and proper scoring rules. The diagnostic approach is illustrated by an assessment and ranking of probabilistic forecasts of wind speed at the Stateline wind energy centre in the {US} Paciﬁc Northwest. In combination with cross-validation or in the time series context, our proposal provides very general, nonparametric alternatives to the use of information criteria for model diagnostics and model selection.},
	pages = {243--268},
	number = {2},
	journaltitle = {J Royal Statistical Soc B},
	author = {Gneiting, Tilmann and Balabdaoui, Fadoua and Raftery, Adrian E.},
	urldate = {2019-08-12},
	date = {2007-04},
	langid = {english},
	file = {gneiting_et_al_2007_probabilistic_forecasts,_calibration_and_sharpness.pdf:/home/nathan/Dropbox/njames/zotero_sync/gneiting_et_al_2007_probabilistic_forecasts,_calibration_and_sharpness.pdf:application/pdf}
}

@article{stephens_met_nodate,
	title = {The Met Ofﬁce Weather Game: investigating how different methods for presenting probabilistic weather forecasts inﬂuence decision-making},
	abstract = {To inform the way probabilistic forecasts would be displayed on their website, the {UK} Met Ofﬁce ran an online game as a mass participation experiment to highlight the best methods of communicating uncertainty in rainfall and temperature forecasts, and to widen public engagement in uncertainty in weather forecasting. The game used a hypothetical “ice-cream seller” scenario and a randomized structure to test decision-making ability using different methods of representing uncertainty and to enable participants to experience being “lucky” or “unlucky” when the most likely forecast scenario did not occur.},
	pages = {18},
	author = {Stephens, Elisabeth M and Spiegelhalter, David J and Mylne, Ken and Harrison, Mark},
	langid = {english},
	file = {stephens_et_al_the_met_ofﬁce_weather_game.pdf:/home/nathan/Dropbox/njames/zotero_sync/stephens_et_al_the_met_ofﬁce_weather_game.pdf:application/pdf}
}

@article{kleinman_semi-parametric_1998,
	title = {A semi-parametric Bayesian approach to generalized linear mixed models},
	abstract = {The linear mixed eﬀects model with normal errors is a popular model for the analysis of repeated measures and longitudinal data. The generalized linear model is useful for data that have non-normal errors but where the errors are uncorrelated. A descendant of these two models generates a model for correlated data with non-normal errors, called the generalized linear mixed model ({GLMM}). Frequentist attempts to ﬁt these models generally rely on approximate results and inference relies on asymptotic assumptions. Recent advances in computing technology have made Bayesian approaches to this class of models computationally feasible. Markov chain Monte Carlo methods can be used to obtain ‘exact’ inference for these models, as demonstrated by Zeger and Karim.  In the linear or generalized linear mixed model, the random eﬀects are typically taken to have a fully parametric distribution, such as the normal distribution. In this paper, we extend the {GLMM} by allowing the random eﬀects to have a non-parametric prior distribution. We do this using a Dirichlet process prior for the general distribution of the random eﬀects. The approach easily extends to more general population models. We perform computations for the models using the Gibbs sampler. 1998 John Wiley \& Sons, Ltd.},
	pages = {18},
	author = {Kleinman, Ken P and Ibrahim, Joseph G},
	date = {1998},
	langid = {english},
	file = {kleinman_ibrahim_1998_a_semi-parametric_bayesian_approach_to_generalized_linear_mixed_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/kleinman_ibrahim_1998_a_semi-parametric_bayesian_approach_to_generalized_linear_mixed_models.pdf:application/pdf}
}

@article{gelman_physiological_1996,
	title = {Physiological Pharmacokinetic Analysis Using Population Modeling and Informative Prior Distributions},
	volume = {91},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1996.10476708},
	doi = {10.1080/01621459.1996.10476708},
	pages = {1400--1412},
	number = {436},
	journaltitle = {Journal of the American Statistical Association},
	author = {Gelman, Andrew and Bois, Frederic and Jiang, Jiming},
	urldate = {2019-08-16},
	date = {1996-12},
	langid = {english},
	file = {gelman_et_al_1996_physiological_pharmacokinetic_analysis_using_population_modeling_and.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_et_al_1996_physiological_pharmacokinetic_analysis_using_population_modeling_and.pdf:application/pdf}
}

@article{abuhelwa_advan-style_2015,
	title = {{ADVAN}-style analytical solutions for common pharmacokinetic models},
	volume = {73},
	issn = {10568719},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1056871915000362},
	doi = {10.1016/j.vascn.2015.03.004},
	abstract = {Introduction: The analytical solutions to compartmental pharmacokinetic models are well known, but have not been presented in a form that easily allows for complex dosing regimen and changes in covariate/parameter values that may occur at discrete times within and/or between dosing intervals.},
	pages = {42--48},
	journaltitle = {Journal of Pharmacological and Toxicological Methods},
	author = {Abuhelwa, Ahmad Y. and Foster, David J.R. and Upton, Richard N.},
	urldate = {2019-08-16},
	date = {2015-05},
	langid = {english},
	file = {abuhelwa_et_al_2015_advan-style_analytical_solutions_for_common_pharmacokinetic_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/abuhelwa_et_al_2015_advan-style_analytical_solutions_for_common_pharmacokinetic_models.pdf:application/pdf}
}

@article{noauthor_bayesian_nodate,
	title = {The Bayesian Analysis of Population Pharmacokinetic Models},
	pages = {15},
	langid = {english},
	file = {The Bayesian Analysis of Population Pharmacokineti.pdf:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/ZYZX6G4S/The Bayesian Analysis of Population Pharmacokineti.pdf:application/pdf}
}

@article{wakefield_bayesian_1996,
	title = {The Bayesian Analysis of Population Pharmacokinetic Models},
	volume = {91},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1996.10476664},
	doi = {10.1080/01621459.1996.10476664},
	pages = {62--75},
	number = {433},
	journaltitle = {Journal of the American Statistical Association},
	author = {Wakefield, Jon},
	urldate = {2019-08-16},
	date = {1996-03},
	langid = {english},
	file = {wakefield_1996_the_bayesian_analysis_of_population_pharmacokinetic_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/wakefield_1996_the_bayesian_analysis_of_population_pharmacokinetic_models.pdf:application/pdf}
}

@article{tuntland_implementation_2014,
	title = {Implementation of pharmacokinetic and pharmacodynamic strategies in early research phases of drug discovery and development at Novartis Institute of Biomedical Research},
	volume = {5},
	issn = {1663-9812},
	url = {http://journal.frontiersin.org/article/10.3389/fphar.2014.00174/abstract},
	doi = {10.3389/fphar.2014.00174},
	abstract = {Characterizing the relationship between the pharmacokinetics ({PK}, concentration vs. time) and pharmacodynamics ({PD}, effect vs. time) is an important tool in the discovery and development of new drugs in the pharmaceutical industry. The purpose of this publication is to serve as a guide for drug discovery scientists toward optimal design and conduct of {PK}/{PD} studies in the research phase. This review is a result of the collaborative efforts of {DMPK} scientists from various Metabolism and Pharmacokinetic ({MAP}) departments of the global organization Novartis Institute of Biomedical Research ({NIBR}). We recommend that {PK}/{PD} strategies be implemented in early research phases of drug discovery projects to enable successful transition to drug development. Effective {PK}/{PD} study design, analysis, and interpretation can help scientists elucidate the relationship between {PK} and {PD}, understand the mechanism of drug action, and identify {PK} properties for further improvement and optimal compound design. Additionally, {PK}/{PD} modeling can help increase the translation of in vitro compound potency to the in vivo setting, reduce the number of in vivo animal studies, and improve translation of ﬁndings from preclinical species into the clinical setting. This review focuses on three important elements of successful {PK}/{PD} studies, namely partnership among key scientists involved in the study execution; parameters that inﬂuence study designs; and data analysis and interpretation. Speciﬁc examples and case studies are highlighted to help demonstrate key points for consideration. The intent is to provide a broad {PK}/{PD} foundation for colleagues in the pharmaceutical industry and serve as a tool to promote appropriate discussions on early research project teams with key scientists involved in {PK}/{PD} studies.},
	journaltitle = {Front. Pharmacol.},
	author = {Tuntland, Tove and Ethell, Brian and Kosaka, Takatoshi and Blasco, Francesca and Zang, Richard Xu and Jain, Monish and Gould, Ty and Hoffmaster, Keith},
	urldate = {2019-08-16},
	date = {2014-07-28},
	langid = {english},
	file = {tuntland_et_al_2014_implementation_of_pharmacokinetic_and_pharmacodynamic_strategies_in_early.pdf:/home/nathan/Dropbox/njames/zotero_sync/tuntland_et_al_2014_implementation_of_pharmacokinetic_and_pharmacodynamic_strategies_in_early.pdf:application/pdf}
}

@article{mould_basic_2013,
	title = {Basic Concepts in Population Modeling, Simulation, and Model-Based Drug Development—Part 2: Introduction to Pharmacokinetic Modeling Methods},
	volume = {2},
	issn = {2163-8306},
	url = {http://doi.wiley.com/10.1038/psp.2013.14},
	doi = {10.1038/psp.2013.14},
	shorttitle = {Basic Concepts in Population Modeling, Simulation, and Model-Based Drug Development—Part 2},
	pages = {e38},
	number = {4},
	journaltitle = {{CPT}: pharmacomet. syst. pharmacol.},
	author = {Mould, D R and Upton, R N},
	urldate = {2019-08-16},
	date = {2013-04},
	langid = {english},
	file = {mould_upton_2013_basic_concepts_in_population_modeling,_simulation,_and_model-based_drug.pdf:/home/nathan/Dropbox/njames/zotero_sync/mould_upton_2013_basic_concepts_in_population_modeling,_simulation,_and_model-based_drug.pdf:application/pdf}
}

@article{hedeker_application_1997,
	title = {Application of random-effects pattern-mixture models for missing data in longitudinal studies.},
	volume = {2},
	issn = {1939-1463, 1082-989X},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/1082-989X.2.1.64},
	doi = {10.1037/1082-989X.2.1.64},
	pages = {64--78},
	number = {1},
	journaltitle = {Psychological Methods},
	author = {Hedeker, Donald and Gibbons, Robert D.},
	urldate = {2019-08-20},
	date = {1997},
	langid = {english},
	file = {hedeker_gibbons_1997_application_of_random-effects_pattern-mixture_models_for_missing_data_in.pdf:/home/nathan/Dropbox/njames/zotero_sync/hedeker_gibbons_1997_application_of_random-effects_pattern-mixture_models_for_missing_data_in.pdf:application/pdf}
}

@article{michiels_selection_1999,
	title = {Selection Models and Pattern-Mixture Models for Incomplete Data with Covariates},
	volume = {55},
	issn = {0006341X},
	url = {http://doi.wiley.com/10.1111/j.0006-341X.1999.00978.x},
	doi = {10.1111/j.0006-341X.1999.00978.x},
	abstract = {M. ost models for incomplete data are formulated within the selection model framework. This paper studies similarities and differences of modeling incomplete data within both selection and patternmixture settings. The focus is on missing at random mechanisms and on categorical data. Point and interval estimation is discussed. A comparison of both approaches is done on side effects in a psychiatric study.},
	pages = {978--983},
	number = {3},
	journaltitle = {Biometrics},
	author = {Michiels, Bart and Molenberghs, Geert and Lipsitz, Stuart R.},
	urldate = {2019-08-20},
	date = {1999-09},
	langid = {english},
	file = {michiels_et_al_1999_selection_models_and_pattern-mixture_models_for_incomplete_data_with_covariates.pdf:/home/nathan/Dropbox/njames/zotero_sync/michiels_et_al_1999_selection_models_and_pattern-mixture_models_for_incomplete_data_with_covariates.pdf:application/pdf}
}

@article{ibrahim_missing_2009,
	title = {Missing data methods in longitudinal studies: a review},
	volume = {18},
	issn = {1133-0686, 1863-8260},
	url = {http://link.springer.com/10.1007/s11749-009-0138-x},
	doi = {10.1007/s11749-009-0138-x},
	shorttitle = {Missing data methods in longitudinal studies},
	abstract = {Incomplete data are quite common in biomedical and other types of research, especially in longitudinal studies. During the last three decades, a vast amount of work has been done in the area. This has led, on the one hand, to a rich taxonomy of missing-data concepts, issues, and methods and, on the other hand, to a variety of data-analytic tools. Elements of taxonomy include: missing data patterns, mechanisms, and modeling frameworks; inferential paradigms; and sensitivity analysis frameworks. These are described in detail. A variety of concrete modeling devices is presented. To make matters concrete, two case studies are considered. The ﬁrst one concerns quality of life among breast cancer patients, while the second one examines data from the Muscatine children’s obesity study.},
	pages = {1--43},
	number = {1},
	journaltitle = {{TEST}},
	author = {Ibrahim, Joseph G. and Molenberghs, Geert},
	urldate = {2019-08-20},
	date = {2009-05},
	langid = {english},
	file = {ibrahim_molenberghs_2009_missing_data_methods_in_longitudinal_studies.pdf:/home/nathan/Dropbox/njames/zotero_sync/ibrahim_molenberghs_2009_missing_data_methods_in_longitudinal_studies.pdf:application/pdf}
}

@article{hogan_model-based_1997,
	title = {Model-Based Approaches to Analysing Incomplete Longitudinal and Failure Time Data},
	volume = {16},
	abstract = {Since Wu and Carroll (Biometrics 44, 175—188) proposed a model for longitudinal progression in the presence of informative dropout, several researchers have developed and studied models for situations where both a vector of repeated outcomes and an event time is available for each subject. These models have been developed for either longitudinal studies with dropout or for survival studies in which a random, timevarying covariate is measured repeatedly across time. When inference about the longitudinal variable is of interest, event times are treated as covariates and are often incomplete due to censoring. If survival or event time is the primary endpoint, repeated outcomes observed prior to the event are viewed as covariates; this covariate process is often incomplete, measured with error, or observed at unscheduled times during the study. We review several models which are used to handle incomplete response and covariate data in both survival and longitudinal studies.},
	pages = {14},
	journaltitle = {Stat Med},
	author = {Hogan, Joseph W},
	date = {1997},
	langid = {english},
	file = {hogan_1997_model-based_approaches_to_analysing_incomplete_longitudinal_and_failure_time.pdf:/home/nathan/Dropbox/njames/zotero_sync/hogan_1997_model-based_approaches_to_analysing_incomplete_longitudinal_and_failure_time.pdf:application/pdf}
}

@article{molenberghs_analysis_1997,
	title = {The analysis of longitudinal ordinal data with nonrandom drop-out},
	volume = {84},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/84.1.33},
	doi = {10.1093/biomet/84.1.33},
	abstract = {A model is proposed for longitudinal ordinal data with nonrandom drop-out, which combines the multivariate Dale model for longitudinal ordinal data with a logistic regression model for drop-out. Since response and drop-out are modelled as conditionally independent given complete data, the resulting likelihood can be maximised relatively simply, using the {EM} algorithm, which with acceleration is acceptably fast and, with appropriate additions, can produce estimates of precision. The approach is illustrated with an example. Such modelling of nonrandom drop-out requires caution because the interpretation of the fitted models depends on assumptions that are unexaminable in a fundamental sense, and the conclusions cannot be regarded as necessarily robust. The main role of such modelling may be as a component of a sensitivity analysis.},
	pages = {33--44},
	number = {1},
	journaltitle = {Biometrika},
	author = {Molenberghs, G},
	urldate = {2019-08-20},
	date = {1997-03-01},
	langid = {english},
	file = {molenberghs_1997_the_analysis_of_longitudinal_ordinal_data_with_nonrandom_drop-out.pdf:/home/nathan/Dropbox/njames/zotero_sync/molenberghs_1997_the_analysis_of_longitudinal_ordinal_data_with_nonrandom_drop-out.pdf:application/pdf}
}

@article{noauthor_modeling_nodate,
	title = {Modeling the Drop-Out Mechanism in Repeated-Measures Studies},
	pages = {11},
	langid = {english},
	file = {modeling_the_drop-out_mechanism_in_repeated-measures_studies.pdf:/home/nathan/Dropbox/njames/zotero_sync/modeling_the_drop-out_mechanism_in_repeated-measures_studies.pdf:application/pdf}
}

@article{little_pattern-mixture_1996,
	title = {Pattern-Mixture Models for Multivariate Incomplete Data with Covariates},
	volume = {52},
	issn = {0006341X},
	url = {https://www.jstor.org/stable/2533148?origin=crossref},
	doi = {10.2307/2533148},
	abstract = {Pattern-mixture models stratify incomplete data by the pattern of missing values and formulate distinct models within each stratum. Pattern-mixture models are developed for analyzing a random sample on continuous variables Y(i), Y(2) when values of Y(2) are nonrandomly missing. Methods for scalar Y(i) and Y(2) are here generalized to vector Y(i) and Y(2) with additional fixed covariates x. Parameters in these models are identified by alternative assumptions about the missing-data mechanism. Models may be underidentified (in which case additional assumptions are needed), just-identified, or overidentified. Maximum likelihood and Bayesian methods are developed for the latter two situations, using the {EM} and {SEM} algorithms, direct and iterative simulation methods. The methods are illustrated on a data set involving alternative dosage regimens for the treatment of schizophrenia using haloperidol and on a regression example. Sensitivity to alternative assumptions about the missing-data mechanism is assessed, and the new methods are compared with completecase analysis and maximum likelihood for a probit selection model.},
	pages = {98},
	number = {1},
	journaltitle = {Biometrics},
	author = {Little, Roderick J. A. and Wang, Yongxiao},
	urldate = {2019-08-20},
	date = {1996-03},
	langid = {english},
	file = {little_wang_1996_pattern-mixture_models_for_multivariate_incomplete_data_with_covariates.pdf:/home/nathan/Dropbox/njames/zotero_sync/little_wang_1996_pattern-mixture_models_for_multivariate_incomplete_data_with_covariates.pdf:application/pdf}
}

@article{muth_user-friendly_2018,
	title = {User-friendly Bayesian regression modeling: A tutorial with rstanarm and shinystan},
	volume = {14},
	issn = {2292-1354},
	url = {http://www.tqmp.org/RegularArticles/vol14-2/p099},
	doi = {10.20982/tqmp.14.2.p099},
	shorttitle = {User-friendly Bayesian regression modeling},
	abstract = {This tutorial provides a pragmatic introduction to specifying, estimating and interpreting single-level and hierarchical linear regression models in the Bayesian framework. We start by summarizing why one should consider the Bayesian approach to the most common forms of regression. Next we introduce the R package rstanarm for Bayesian applied regression modeling. An overview of rstanarm fundamentals accompanies step-by-step guidance for ﬁtting a single-level regression model with the stan\_glm function, and ﬁtting hierarchical regression models with the stan\_lmer function, illustrated with data from an experience sampling study on changes in affective states. Exploration of the results is facilitated by the intuitive and user-friendly shinystan package. Data and scripts are available on the Open Science Framework page of the project. For readers unfamiliar with R, this tutorial is self-contained to enable all researchers who apply regression techniques to try these methods with their own data. Regression modeling with the functions in the rstanarm package will be a straightforward transition for researchers familiar with their frequentist counterparts, lm (or glm) and lmer.},
	pages = {99--119},
	number = {2},
	journaltitle = {{TQMP}},
	author = {Muth, Chelsea and Oravecz, Zita and Gabry, Jonah},
	urldate = {2019-08-21},
	date = {2018-04-01},
	langid = {english},
	file = {muth_et_al_2018_user-friendly_bayesian_regression_modeling.pdf:/home/nathan/Dropbox/njames/zotero_sync/muth_et_al_2018_user-friendly_bayesian_regression_modeling.pdf:application/pdf}
}

@article{guo_optimal_2019,
	title = {An optimal Bayesian predictive probability design for phase {II} clinical trials with simple and complicated endpoints},
	issn = {0323-3847, 1521-4036},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201900022},
	doi = {10.1002/bimj.201900022},
	abstract = {Most existing phase {II} clinical trial designs focus on conventional chemotherapy with binary tumor response as the endpoint. The advent of novel therapies, such as molecularly targeted agents and immunotherapy, has made the endpoint of phase {II} trials more complicated, often involving ordinal, nested, and coprimary endpoints. We propose a simple and flexible Bayesian optimal phase {II} predictive probability ({OPP}) design that handles binary and complex endpoints in a unified way. The Dirichletmultinomial model is employed to accommodate different types of endpoints. At each interim, given the observed interim data, we calculate the Bayesian predictive probability of success, should the trial continue to the maximum planned sample size, and use it to make the go/no-go decision. The {OPP} design controls the type I error rate, maximizes power or minimizes the expected sample size, and is easy to implement, because the go/no-go decision boundaries can be enumerated and included in the protocol before the onset of the trial. Simulation studies show that the {OPP} design has satisfactory operating characteristics.},
	pages = {bimj.201900022},
	journaltitle = {Biometrical Journal},
	author = {Guo, Beibei and Liu, Suyu},
	urldate = {2019-08-21},
	date = {2019-08-12},
	langid = {english},
	file = {guo_liu_2019_an_optimal_bayesian_predictive_probability_design_for_phase_ii_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/guo_liu_2019_an_optimal_bayesian_predictive_probability_design_for_phase_ii_clinical_trials.pdf:application/pdf}
}

@article{albert_sequential_2001,
	title = {Sequential Ordinal Modeling with Applications to Survival Data},
	volume = {57},
	issn = {1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.0006-341X.2001.00829.x},
	doi = {10.1111/j.0006-341X.2001.00829.x},
	abstract = {Summary. This paper considers the class of sequential ordinal models in relation to other models for ordinal response data. Markov chain Monte Carlo ({MCMC}) algorithms, based on the approach of Albert and Chib (1993, Journal of the American Statistical Association88, 669–679), are developed for the fitting of these models. The ideas and methods are illustrated in detail with a real data example on the length of hospital stay for patients undergoing heart surgery. A notable aspect of this analysis is the comparison, based on marginal likelihoods and training sample priors, of several nonnested models, such as the sequential model, the cumulative ordinal model, and Weibull and log-logistic models.},
	pages = {829--836},
	number = {3},
	journaltitle = {Biometrics},
	author = {Albert, James H. and Chib, Siddhartha},
	urldate = {2019-09-07},
	date = {2001},
	langid = {english},
	keywords = {Gibbs sampling, Bayes factor, Cumulative ordinal probit and logit model, Discrete hazard function, Marginal likelihood, Metropolis-Hastings algorithm, Model comparison, Nonnested models, Sequential ordinal probit and logit, Training sample prior.},
	file = {albert_chib_2001_sequential_ordinal_modeling_with_applications_to_survival_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/albert_chib_2001_sequential_ordinal_modeling_with_applications_to_survival_data.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/P9E84TSQ/j.0006-341X.2001.00829.html:text/html}
}

@article{higgs_clipped_2010,
	title = {A clipped latent variable model for spatially correlated ordered categorical data},
	volume = {54},
	issn = {01679473},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167947310000897},
	doi = {10.1016/j.csda.2010.02.024},
	abstract = {We propose a model for a point-referenced spatially correlated ordered categorical response and methodology for inference. Models and methods for spatially correlated continuous response data are widespread, but models for spatially correlated categorical data, and especially ordered multi-category data, are less developed. Bayesian models and methodology have been proposed for the analysis of independent and clustered ordered categorical data, and also for binary and count point-referenced spatial data. We combine and extend these methods to describe a Bayesian model for point-referenced (as opposed to lattice) spatially correlated ordered categorical data. We include simulation results and show that our model offers superior predictive performance as compared to a non-spatial cumulative probit model and a more standard Bayesian generalized linear spatial model. We demonstrate the usefulness of our model in a real-world example to predict ordered categories describing stream health within the state of Maryland.},
	pages = {1999--2011},
	number = {8},
	journaltitle = {Computational Statistics \& Data Analysis},
	author = {Higgs, Megan Dailey and Hoeting, Jennifer A.},
	urldate = {2019-09-07},
	date = {2010-08},
	langid = {english},
	file = {higgs_hoeting_2010_a_clipped_latent_variable_model_for_spatially_correlated_ordered_categorical.pdf:/home/nathan/Dropbox/njames/zotero_sync/higgs_hoeting_2010_a_clipped_latent_variable_model_for_spatially_correlated_ordered_categorical.pdf:application/pdf}
}

@article{liddell_analyzing_2018-1,
	title = {Analyzing ordinal data with metric models: What could possibly go wrong?},
	volume = {79},
	issn = {00221031},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022103117307746},
	doi = {10.1016/j.jesp.2018.08.009},
	shorttitle = {Analyzing ordinal data with metric models},
	abstract = {We surveyed all articles in the Journal of Personality and Social Psychology ({JPSP}), Psychological Science ({PS}), and the Journal of Experimental Psychology: General ({JEP}:G) that mentioned the term “Likert,” and found that 100\% of the articles that analyzed ordinal data did so using a metric model. We present novel evidence that analyzing ordinal data as if they were metric can systematically lead to errors. We demonstrate false alarms (i.e., detecting an eﬀect where none exists, Type I errors) and failures to detect eﬀects (i.e., loss of power, Type {II} errors). We demonstrate systematic inversions of eﬀects, for which treating ordinal data as metric indicates the opposite ordering of means than the true ordering of means. We show the same problems — false alarms, misses, and inversions — for interactions in factorial designs and for trend analyses in regression. We demonstrate that averaging across multiple ordinal measurements does not solve or even ameliorate these problems. A central contribution is a graphical explanation of how and when the misrepresentations occur. Moreover, we point out that there is no sure-ﬁre way to detect these problems by treating the ordinal values as metric, and instead we advocate use of ordered-probit models (or similar) because they will better describe the data. Finally, although frequentist approaches to some ordered-probit models are available, we use Bayesian methods because of their ﬂexibility in specifying models and their richness and accuracy in providing parameter estimates. An R script is provided for running an analysis that compares ordered-probit and metric models.},
	pages = {328--348},
	journaltitle = {Journal of Experimental Social Psychology},
	author = {Liddell, Torrin M. and Kruschke, John K.},
	urldate = {2019-09-07},
	date = {2018-11},
	langid = {english},
	file = {liddell_kruschke_2018_analyzing_ordinal_data_with_metric_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/liddell_kruschke_2018_analyzing_ordinal_data_with_metric_models2.pdf:application/pdf}
}

@article{gelman_when_2019,
	title = {When we make recommendations for scientific practice, we are (at best) acting as social scientists},
	issn = {0014-2972, 1365-2362},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/eci.13165},
	doi = {10.1111/eci.13165},
	journaltitle = {Eur J Clin Invest},
	author = {Gelman, Andrew},
	urldate = {2019-09-09},
	date = {2019-08-17},
	langid = {english},
	file = {gelman_2019_when_we_make_recommendations_for_scientific_practice,_we_are_(at_best)_acting.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_2019_when_we_make_recommendations_for_scientific_practice,_we_are_(at_best)_acting.pdf:application/pdf}
}

@article{ursino_random-effects_2019,
	title = {Random-effects meta-analysis of phase I dose-finding studies using stochastic process priors},
	url = {http://arxiv.org/abs/1908.06733},
	abstract = {Phase I dose-ﬁnding studies aim at identifying the maximal tolerated dose ({MTD}). It is not uncommon that several dose-ﬁnding studies are conducted, although often with some variation in the administration mode or dose panel. For instance, sorafenib ({BAY} 43-900) was used as monotherapy in at least 29 phase I trials according to a recent search in clinicaltrials.gov. Since the toxicity may not be directly related to the speciﬁc indication, synthesizing the information from several studies might be worthwhile. However, this is rarely done in practice and only a ﬁxed-eﬀect meta-analysis framework was proposed to date. We developed a Bayesian random-eﬀects meta-analysis methodology to pool several phase I trials and suggest the {MTD}. A curve free hierarchical model on the logistic scale with random eﬀects, accounting for between-trial heterogeneity, is used to model the probability of toxicity across the investigated doses. An Ornstein-Uhlenbeck Gaussian process is adopted for the random eﬀects structure. Prior distributions for the curve free model are based on a latent Gamma process. An extensive simulation study showed good performance of the proposed method also under model deviations. Sharing information between phase I studies can improve the precision of {MTD} selection, at least when the number of trials is reasonably large.},
	journaltitle = {{arXiv}:1908.06733 [q-bio, stat]},
	author = {Ursino, Moreno and Röver, Christian and Zohar, Sarah and Friede, Tim},
	urldate = {2019-09-09},
	date = {2019-08-01},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1908.06733},
	keywords = {Statistics - Methodology, Quantitative Biology - Quantitative Methods},
	file = {ursino_et_al_2019_random-effects_meta-analysis_of_phase_i_dose-finding_studies_using_stochastic.pdf:/home/nathan/Dropbox/njames/zotero_sync/ursino_et_al_2019_random-effects_meta-analysis_of_phase_i_dose-finding_studies_using_stochastic.pdf:application/pdf}
}

@article{the_adaptive_platform_trials_coalition_adaptive_2019,
	title = {Adaptive platform trials: definition, design, conduct and reporting considerations},
	issn = {1474-1776, 1474-1784},
	url = {http://www.nature.com/articles/s41573-019-0034-3},
	doi = {10.1038/s41573-019-0034-3},
	shorttitle = {Adaptive platform trials},
	abstract = {Researchers, clinicians, policymakers and patients are increasingly interested in questions about therapeutic interventions that are difficult or costly to answer with traditional, free-standing, parallel-group randomized controlled trials ({RCTs}). Examples include scenarios in which there is a desire to compare multiple interventions, to generate separate effect estimates across subgroups of patients with distinct but related conditions or clinical features, or to minimize downtime between trials. In response, researchers have proposed new {RCT} designs such as adaptive platform trials ({APTs}), which are able to study multiple interventions in a disease or condition in a perpetual manner, with interventions entering and leaving the platform on the basis of a predefined decision algorithm. {APTs} offer innovations that could reshape clinical trials, and several {APTs} are now funded in various disease areas. With the aim of facilitating the use of {APTs}, here we review common features and issues that arise with such trials, and offer recommendations to promote best practices in their design, conduct, oversight and reporting.},
	journaltitle = {Nat Rev Drug Discov},
	author = {{The Adaptive Platform Trials Coalition}},
	urldate = {2019-09-09},
	date = {2019-08-28},
	langid = {english},
	file = {the_adaptive_platform_trials_coalition_2019_adaptive_platform_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/the_adaptive_platform_trials_coalition_2019_adaptive_platform_trials.pdf:application/pdf}
}

@article{klein_marginally-calibrated_2019,
	title = {Marginally-calibrated deep distributional regression},
	url = {http://arxiv.org/abs/1908.09482},
	abstract = {Deep neural network ({DNN}) regression models are widely used in applications requiring state-of-the-art predictive accuracy. However, until recently there has been little work on accurate uncertainty quantiﬁcation for predictions from such models. We add to this literature by outlining an approach to constructing predictive distributions that are ‘marginally calibrated’. This is where the long run average of the predictive distributions of the response variable matches the observed empirical margin. Our approach considers a {DNN} regression with a conditionally Gaussian prior for the ﬁnal layer weights, from which an implicit copula process on the feature space is extracted. This copula process is combined with a nonparametrically estimated marginal distribution for the response. The end result is a scalable distributional {DNN} regression method with marginally calibrated predictions, and our work complements existing methods for probability calibration. The approach is ﬁrst illustrated using two applications of dense layer feed-forward neural networks. However, our main motivating applications are in likelihood-free inference, where distributional deep regression is used to estimate marginal posterior distributions. In two complex ecological time series examples we employ the implicit copulas of convolutional networks, and show that marginal calibration results in improved uncertainty quantiﬁcation. Our approach also avoids the need for manual speciﬁcation of summary statistics, a requirement that is burdensome for users and typical of competing likelihood-free inference methods.},
	journaltitle = {{arXiv}:1908.09482 [stat]},
	author = {Klein, Nadja and Nott, David J. and Smith, Michael Stanley},
	urldate = {2019-09-09},
	date = {2019-08-26},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1908.09482},
	keywords = {Statistics - Methodology, Statistics - Computation, Statistics - Machine Learning},
	file = {klein_et_al_2019_marginally-calibrated_deep_distributional_regression.pdf:/home/nathan/Dropbox/njames/zotero_sync/klein_et_al_2019_marginally-calibrated_deep_distributional_regression.pdf:application/pdf}
}

@article{masegosa_probabilistic_2019,
	title = {Probabilistic Models with Deep Neural Networks},
	url = {http://arxiv.org/abs/1908.03442},
	abstract = {Recent advances in statistical inference have signiﬁcantly expanded the toolbox of probabilistic modeling. Historically, probabilistic modeling has been constrained to (i) very restricted model classes where exact or approximate probabilistic inference were feasible, and (ii) small or medium-sized data sets which ﬁt within the main memory of the computer. However, developments in variational inference, a general form of approximate probabilistic inference originated in statistical physics, are allowing probabilistic modeling to overcome these restrictions: (i) Approximate probabilistic inference is now possible over a broad class of probabilistic models containing a large number of parameters, and (ii) scalable inference methods based on stochastic gradient descent and distributed computation engines allow to apply probabilistic modeling over massive data sets. One important practical consequence of these advances is the possibility to include deep neural networks within a probabilistic model to capture complex non-linear stochastic relationships between random variables. These advances in conjunction with the release of novel probabilistic modeling toolboxes have greatly expanded the scope of application of probabilistic models, and allow these models to take advantage of the recent strides made by the deep learning community. In this paper we review the main concepts, methods and tools needed to use deep neural networks within a probabilistic modeling framework.},
	journaltitle = {{arXiv}:1908.03442 [cs, math, stat]},
	author = {Masegosa, Andrés R. and Cabañas, Rafael and Langseth, Helge and Nielsen, Thomas D. and Salmerón, Antonio},
	urldate = {2019-09-09},
	date = {2019-08-09},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1908.03442},
	keywords = {Mathematics - Statistics Theory, Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {masegosa_et_al_2019_probabilistic_models_with_deep_neural_networks.pdf:/home/nathan/Dropbox/njames/zotero_sync/masegosa_et_al_2019_probabilistic_models_with_deep_neural_networks.pdf:application/pdf}
}

@article{tidwell_bayesian_2019,
	title = {Bayesian clinical trials at The University of Texas {MD} Anderson Cancer Center: An update},
	issn = {1740-7745, 1740-7753},
	url = {http://journals.sagepub.com/doi/10.1177/1740774519871471},
	doi = {10.1177/1740774519871471},
	shorttitle = {Bayesian clinical trials at The University of Texas {MD} Anderson Cancer Center},
	abstract = {Background/aims: In our 2009 article, we showed that Bayesian methods had established a foothold in developing therapies in our institutional oncology trials. In this article, we will document what has happened since that time. In addition, we will describe barriers to implementing Bayesian clinical trials, as well as our experience overcoming them.
Methods: We reviewed {MD} Anderson Cancer Center clinical trials submitted to the institutional protocol office for scientific and ethical review between January 2009 and December 2013, the same length time period as the previous article. We tabulated Bayesian methods implemented for design or analyses for each trial and then compared these to our previous findings.
Results: Overall, we identified 1020 trials and found that 283 (28\%) had Bayesian components so we designated them as Bayesian trials. Among {MD} Anderson–only and multicenter trials, 56\% and 14\%, respectively, were Bayesian, higher rates than our previous study. Bayesian trials were more common in phase I/{II} trials (34\%) than in phase {III}/{IV} (6\%) trials. Among Bayesian trials, the most commonly used features were for toxicity monitoring (65\%), efficacy monitoring (36\%), and dose finding (22\%). The majority (86\%) of Bayesian trials used non-informative priors. A total of 75 (27\%) trials applied Bayesian methods for trial design and primary endpoint analysis. Among this latter group, the most commonly used methods were the Bayesian logistic regression model (N = 22), the continual reassessment method (N = 20), and adaptive randomization (N = 16). Median institutional review board approval time from protocol submission was the same 1.4 months for Bayesian and non-Bayesian trials. Since the previous publication, the Biomarker-Integrated Approaches of Targeted Therapy for Lung Cancer Elimination ({BATTLE}) trial was the first large-scale decision trial combining multiple treatments in a single trial. Since then, two regimens in breast cancer therapy have been identified and published from the cooperative Investigation of Serial Studies to Predict Your Therapeutic Response with Imaging and Molecular Analysis (I-{SPY} 2), enhancing cooperation among investigators and drug developers across the nation, as well as advancing information needed for personalized medicine. Many software programs and Shiny applications for Bayesian trial design and calculations are available from our website which has had more than 21,000 downloads worldwide since 2004.
Conclusion: Bayesian trials have the increased flexibility in trial design needed for personalized medicine, resulting in more cooperation among researchers working to fight against cancer. Some disadvantages of Bayesian trials remain, but new methods and software are available to improve their function and incorporation into cancer clinical research.},
	pages = {174077451987147},
	journaltitle = {Clinical Trials},
	author = {Tidwell, Rebecca S Slack and Peng, S Andrew and Chen, Minxing and Liu, Diane D and Yuan, Ying and Lee, J Jack},
	urldate = {2019-09-10},
	date = {2019-08-26},
	langid = {english},
	file = {tidwell_et_al_2019_bayesian_clinical_trials_at_the_university_of_texas_md_anderson_cancer_center.pdf:/home/nathan/Dropbox/njames/zotero_sync/tidwell_et_al_2019_bayesian_clinical_trials_at_the_university_of_texas_md_anderson_cancer_center.pdf:application/pdf}
}

@article{sheiner_estimation_1977,
	title = {Estimation of population characteristics of pharmacokinetic parameters from routine clinical data},
	volume = {5},
	issn = {0090-466X},
	url = {http://link.springer.com/10.1007/BF01061728},
	doi = {10.1007/BF01061728},
	pages = {445--479},
	number = {5},
	journaltitle = {Journal of Pharmacokinetics and Biopharmaceutics},
	author = {Sheiner, Lewis B. and Rosenberg, Barr and Marathe, Vinay V.},
	urldate = {2019-09-10},
	date = {1977-10},
	langid = {english},
	file = {sheiner_et_al_1977_estimation_of_population_characteristics_of_pharmacokinetic_parameters_from.pdf:/home/nathan/Dropbox/njames/zotero_sync/sheiner_et_al_1977_estimation_of_population_characteristics_of_pharmacokinetic_parameters_from.pdf:application/pdf}
}

@article{bonate_recommended_2005,
	title = {Recommended reading in population pharmacokinetic pharmacodynamics},
	volume = {7},
	issn = {1550-7416},
	url = {http://link.springer.com/10.1208/aapsj070237},
	doi = {10.1208/aapsj070237},
	abstract = {Developing the skills or expertise to create useful population pharmacokinetic-pharmacodynamic models can be a daunting task-the level of mathematical and statistical complexity is such that newcomers to the field are frequently overwhelmed. A good place to start in learning the field is to read articles in the literature. However, the number of articles dealing with population pharmacokinetic pharmacodynamics is exponentially increasing on a yearly basis, so choosing which articles to read can be difficult. The purpose of this review is to provide a recommended reading list for newcomers to the field. The list was chosen based on perceived impact of the article in the field, the quality of the article, or to highlight some important detail contained within the article. After reading the articles in the list, it is believed that the reader will have a broad overview of the field and have a sound foundation for moredetailed reading of the literature.},
	pages = {E363--E373},
	number = {2},
	journaltitle = {{AAPS} J},
	author = {Bonate, Peter L.},
	urldate = {2019-09-10},
	date = {2005-06},
	langid = {english},
	file = {bonate_2005_recommended_reading_in_population_pharmacokinetic_pharmacodynamics.pdf:/home/nathan/Dropbox/njames/zotero_sync/bonate_2005_recommended_reading_in_population_pharmacokinetic_pharmacodynamics.pdf:application/pdf}
}

@article{derendorf_modeling_1999,
	title = {Modeling of pharmacokinetic/pharmacodynamic ({PK}/{PD}) relationships: Concepts and perspectives},
	volume = {16},
	issn = {07248741},
	url = {http://link.springer.com/10.1023/A:1011907920641},
	doi = {10.1023/A:1011907920641},
	pages = {176--185},
	number = {2},
	journaltitle = {Pharmaceutical Research},
	author = {Derendorf, Hartmut and Meibohm, Bernd},
	urldate = {2019-09-10},
	date = {1999},
	file = {derendorf_meibohm_1999_modeling_of_pharmacokinetic-pharmacodynamic_(pk-pd)_relationships.pdf:/home/nathan/Dropbox/njames/zotero_sync/derendorf_meibohm_1999_modeling_of_pharmacokinetic-pharmacodynamic_(pk-pd)_relationships.pdf:application/pdf}
}

@article{hahn_two-stage_2011,
	title = {Two-stage vs mixed-effect approach to pharmacodynamic modeling of propofol in children using state entropy: Propofol pharmacodynamics in children},
	volume = {21},
	issn = {11555645},
	url = {http://doi.wiley.com/10.1111/j.1460-9592.2011.03584.x},
	doi = {10.1111/j.1460-9592.2011.03584.x},
	shorttitle = {Two-stage vs mixed-effect approach to pharmacodynamic modeling of propofol in children using state entropy},
	abstract = {Objectives: To compare the population pharmacodynamic ({PD}) models of propofol in children derived using two-stage and mixed-effect modeling approaches.
Methods: Fifty-two {ASA} 1 and 2 children aged 6–15 years presenting for gastrointestinal endoscopy were administered a loading dose of 4 {mgÆkg})1 of propofol intravenously at an infusion rate determined by a randomization schedule. Using the plasma concentration predicted by the Paedfusor pharmacokinetic ({PK}) model, the propofol effect on state entropy ({SE}) was modeled using the two-stage and the mixed-effect modeling approaches, and the ﬁnal population {PD} models were compared with each other in terms of their prediction performance, using median percentage and absolute percentage errors as well as mean absolute weighted error as metrics. The effects of age and body weight as prospective covariates were examined.
Results: The ﬁnal population models were comparable with each other; the two-stage and the mixed-effect approaches resulted in a ke0 of 2.38 and 2.66 min)1, c of 5.29 and 5.68, and {EC}50 of 4.73 and 4.84 {lgÆml})1, respectively. The bootstrap estimates of the {PD} parameters were mean ({SD}) ke0 = 2.38 (0.10), c = 5.30 (0.30), and {EC}50 = 4.73 (0.14). The {PD} parameters did not exhibit dependence on age and body weight. The parameters reported in this study in children were different from their adult counterparts reported in previous studies.
Conclusions: Models derived using different mathematical approaches produced consistent model parameters. By virtue of its relative computational efﬁciency, the two-stage approach can serve as an attractive alternative to the mixed-effect approach in situations where data are not sparse.},
	pages = {691--698},
	number = {6},
	journaltitle = {Pediatric Anesthesia},
	author = {Hahn, Jin-Oh and Khosravi, Sara and Dumont, Guy A. and Ansermino, John Mark},
	urldate = {2019-09-10},
	date = {2011-06},
	langid = {english},
	file = {hahn_et_al_2011_two-stage_vs_mixed-effect_approach_to_pharmacodynamic_modeling_of_propofol_in.pdf:/home/nathan/Dropbox/njames/zotero_sync/hahn_et_al_2011_two-stage_vs_mixed-effect_approach_to_pharmacodynamic_modeling_of_propofol_in.pdf:application/pdf}
}

@article{dayneka_comparison_1993,
	title = {Comparison of four basic models of indirect pharmacodynamic responses},
	volume = {21},
	issn = {0090-466X},
	url = {http://link.springer.com/10.1007/BF01061691},
	doi = {10.1007/BF01061691},
	pages = {457--478},
	number = {4},
	journaltitle = {Journal of Pharmacokinetics and Biopharmaceutics},
	author = {Dayneka, Natalie L. and Garg, Varun and Jusko, William J.},
	urldate = {2019-09-10},
	date = {1993-08},
	langid = {english},
	file = {dayneka_et_al_1993_comparison_of_four_basic_models_of_indirect_pharmacodynamic_responses.pdf:/home/nathan/Dropbox/njames/zotero_sync/dayneka_et_al_1993_comparison_of_four_basic_models_of_indirect_pharmacodynamic_responses.pdf:application/pdf}
}

@misc{noauthor_guidance_nodate,
	title = {Guidance for Industry: Exposure-Response Relationships - Study Design, Data Analysis, and Regulatory Applications},
	publisher = {{US} {FDA}; {CDER}; {CBER}},
	file = {guidance_for_industry.pdf:/home/nathan/Dropbox/njames/zotero_sync/guidance_for_industry.pdf:application/pdf}
}

@article{purdie_guidance_nodate,
	title = {Guidance for Industry: Population Pharmacokinetics},
	pages = {26},
	author = {Purdie, Florine P},
	langid = {english},
	file = {purdie_guidance_for_industry.pdf:/home/nathan/Dropbox/njames/zotero_sync/purdie_guidance_for_industry.pdf:application/pdf}
}

@incollection{spruill_introduction_2014,
	title = {Introduction to Pharmacokinetics and Pharmacodynamics},
	isbn = {978-1-58528-387-3},
	booktitle = {Concepts in Clinical Pharmacokinetics},
	author = {Spruill, William and Wade, William and {DiPiro}, Joseph and Blouin, Robert and Pruemer, Jane},
	date = {2014},
	file = {spruill_introduction_to_pharmacokinetics_and_pharmacodynamics.pdf:/home/nathan/Dropbox/njames/zotero_sync/spruill_introduction_to_pharmacokinetics_and_pharmacodynamics.pdf:application/pdf}
}

@article{xu_validating_2014,
	title = {Validating drug repurposing signals using electronic health records: a case study of metformin associated with reduced cancer mortality},
	issn = {1067-5027, 1527-974X},
	url = {https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2014-002649},
	doi = {10.1136/amiajnl-2014-002649},
	shorttitle = {Validating drug repurposing signals using electronic health records},
	abstract = {Objectives Drug repurposing, which finds new indications for existing drugs, has received great attention recently. The goal of our work is to assess the feasibility of using electronic health records ({EHRs}) and automated informatics methods to efficiently validate a recent drug repurposing association of metformin with reduced cancer mortality.
Methods By linking two large {EHRs} from Vanderbilt University Medical Center and Mayo Clinic to their tumor registries, we constructed a cohort including 32 415 adults with a cancer diagnosis at Vanderbilt and 79 258 cancer patients at Mayo from 1995 to 2010. Using automated informatics methods, we further identified type 2 diabetes patients within the cancer cohort and determined their drug exposure information, as well as other covariates such as smoking status. We then estimated {HRs} for all-cause mortality and their associated 95\% {CIs} using stratified Cox proportional hazard models. {HRs} were estimated according to metformin exposure, adjusted for age at diagnosis, sex, race, body mass index, tobacco use, insulin use, cancer type, and non-cancer Charlson comorbidity index.
Results Among all Vanderbilt cancer patients, metformin was associated with a 22\% decrease in overall mortality compared to other oral hypoglycemic medications ({HR} 0.78; 95\% {CI} 0.69 to 0.88) and with a 39\% decrease compared to type 2 diabetes patients on insulin only ({HR} 0.61; 95\% {CI} 0.50 to 0.73). Diabetic patients on metformin also had a 23\% improved survival compared with non-diabetic patients ({HR} 0.77; 95\% {CI} 0.71 to 0.85). These associations were replicated using the Mayo Clinic {EHR} data. Many site-specific cancers including breast, colorectal, lung, and prostate demonstrated reduced mortality with metformin use in at least one {EHR}.
Conclusions {EHR} data suggested that the use of metformin was associated with decreased mortality after a cancer diagnosis compared with diabetic and non-diabetic cancer patients not on metformin, indicating its potential as a chemotherapeutic regimen. This study serves as a model for robust and inexpensive validation studies for drug repurposing signals using {EHR} data.},
	pages = {amiajnl--2014--002649},
	journaltitle = {Journal of the American Medical Informatics Association},
	author = {Xu, H. and Aldrich, M. C. and Chen, Q. and Liu, H. and Peterson, N. B. and Dai, Q. and Levy, M. and Shah, A. and Han, X. and Ruan, X. and Jiang, M. and Li, Y. and Julien, J. S. and Warner, J. and Friedman, C. and Roden, D. M. and Denny, J. C.},
	urldate = {2019-09-10},
	date = {2014-07-22},
	langid = {english},
	file = {xu_et_al_2014_validating_drug_repurposing_signals_using_electronic_health_records.pdf:/home/nathan/Dropbox/njames/zotero_sync/xu_et_al_2014_validating_drug_repurposing_signals_using_electronic_health_records.pdf:application/pdf}
}

@article{walker_population_1998,
	title = {Population Models with a Nonparametric Random Coefficient Distribution},
	volume = {60},
	series = {B},
	abstract = {Population data fit very naturally into a hierarchical framework. At the first stage of this hierarchy the data of a particular individual are modelled, typically by a nonlinear regression model, with the same regression model assumed for each individual. Inter-individual variability is accommodated at the second stage by assuming that the parameters of each indi vidual are independently and identically distributed from a population distribution F. Often, interest is in learning about F so that predictions can be made for future individuals from the population. Previous Bayesian work has largely concentrated on F being assigned a specific parametric form, typically the normal. In this paper we propose a Bayesian nonparametric approach using the Dirichlet process (Ferguson, 1973; Antoniak, 1974) as a class of prior dis tributions for F. We consider the important case where covariate relationships are modelled at the second stage, and allow for errors-in-variables in the measured covariates. Relevant pos terior distributions are summarised using Markov chain Monte Carlo methods. A challenging population pharmacokinetic dataset, involving a nonlinear concentration/time relationship and individual-specific covariates, is analysed and the results are compared with those of previous non-Bayesian parametric and non-parametric analyses.},
	pages = {196--214},
	journaltitle = {Sankhya : The Indian Journal of Statistics},
	author = {Walker, Stephen and Wakefield, Jon},
	date = {1998},
	langid = {english},
	file = {walker_wakefield_1998_population_models_with_a_nonparametric_random_coefficient_distribution.pdf:/home/nathan/Dropbox/njames/zotero_sync/walker_wakefield_1998_population_models_with_a_nonparametric_random_coefficient_distribution.pdf:application/pdf}
}

@article{wakefield_bayesian_1997,
	title = {Bayesian Nonparametric Population Models: Formulation and Comparison with Likelihood Approaches},
	volume = {25},
	issn = {0090466X},
	url = {http://link.springer.com/10.1023/A:1025736230707},
	doi = {10.1023/A:1025736230707},
	pages = {235--253},
	number = {2},
	journaltitle = {Journal of Pharmacokinetics and Biopharmaceutics},
	author = {Wakefield, Jon and Walker, Stephen},
	urldate = {2019-09-16},
	date = {1997},
	langid = {english},
	file = {wakefield_walker_1997_bayesian_nonparametric_population_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/wakefield_walker_1997_bayesian_nonparametric_population_models.pdf:application/pdf}
}

@article{rosner_bayesian_1997,
	title = {Bayesian Population Pharmacokinetic and Pharmacodynamic Analyses Using Mixture Models},
	volume = {25},
	pages = {25},
	number = {2},
	journaltitle = {Journal of Pharmacokinetics and Biopharmaceutics},
	author = {Rosner, Gary L and Muller, Peter},
	date = {1997},
	langid = {english},
	file = {rosner_muller_bayesian_population_pharmacokinetic_and_pharmacodynamic_analyses_using_mixture.pdf:/home/nathan/Dropbox/njames/zotero_sync/rosner_muller_bayesian_population_pharmacokinetic_and_pharmacodynamic_analyses_using_mixture.pdf:application/pdf}
}

@article{kleinman_semiparametric_1998,
	title = {A Semiparametric Bayesian Approach to the Random Effects Model},
	volume = {54},
	issn = {0006341X},
	url = {https://www.jstor.org/stable/2533846?origin=crossref},
	doi = {10.2307/2533846},
	abstract = {In longitudinal random effects models, the random effects are typically assumed to have a normal distribution in both Bayesian and classical models. We provide a Bayesian model that allows the random effects to have a nonparametric prior distribution. We propose a Dirichlet process prior for the distribution of the random effects; computation is made possible by the Gibbs sampler. An example using marker data from an {AIDS} study is given to illustrate the methodology.},
	pages = {921},
	number = {3},
	journaltitle = {Biometrics},
	author = {Kleinman, Ken P. and Ibrahim, Joseph G.},
	urldate = {2019-09-16},
	date = {1998-09},
	langid = {english},
	file = {kleinman_ibrahim_1998_a_semiparametric_bayesian_approach_to_the_random_effects_model.pdf:/home/nathan/Dropbox/njames/zotero_sync/kleinman_ibrahim_1998_a_semiparametric_bayesian_approach_to_the_random_effects_model.pdf:application/pdf}
}

@article{mallet_nonparametric_1988,
	title = {Nonparametric maximum likelihood estimation for population pharmacokinetics, with application to cyclosporine},
	volume = {16},
	issn = {0090-466X},
	url = {http://link.springer.com/10.1007/BF01062140},
	doi = {10.1007/BF01062140},
	pages = {311--327},
	number = {3},
	journaltitle = {Journal of Pharmacokinetics and Biopharmaceutics},
	author = {Mallet, Alain and Mentré, France and Steimer, Jean -Louis and Lokiec, François},
	urldate = {2019-09-16},
	date = {1988-06},
	langid = {english},
	file = {mallet_et_al_1988_nonparametric_maximum_likelihood_estimation_for_population_pharmacokinetics,.pdf:/home/nathan/Dropbox/njames/zotero_sync/mallet_et_al_1988_nonparametric_maximum_likelihood_estimation_for_population_pharmacokinetics,.pdf:application/pdf}
}

@article{nedelman_disadvantages_2005,
	title = {On Some "Disadvantages" of the Population Approach},
	volume = {7},
	abstract = {In a seminal article on population pharmacokinetic modeling, researchers demonstrated how means and variances of pharmacokinetic parameters for a patient population could be inferred from sparse data collected under conditions of routine patient care. But they also identified 4 potential concerns about their methodology: unobserved confounding variables may bias the inferences; conditions under which data are collected may lead to inaccuracies of reporting or recording; correlations among important predictor variables may reduce statistical efficiency; and costs cannot be controlled by principles of study design. Experiences are reviewed that relate to these potential disadvantages. A method is presented for diagnosing the possible presence of confounding. A model is constructed and applied that captures the influences of data inaccuracies. An example of selecting from among correlated covariates is summarized. Finally, a methodology for optimal study design is reviewed and applied to an example.},
	pages = {E374--E382},
	number = {2},
	journaltitle = {The {AAPS} Journal},
	author = {Nedelman, Jerry R},
	date = {2005},
	langid = {english},
	file = {nedelman_on_some_disadvantages_of_the_population_approach.pdf:/home/nathan/Dropbox/njames/zotero_sync/nedelman_on_some_disadvantages_of_the_population_approach.pdf:application/pdf}
}

@article{grazian_review_2019,
	title = {A review of Approximate Bayesian Computation methods via density estimation: inference for simulator-models},
	url = {http://arxiv.org/abs/1909.02736},
	shorttitle = {A review of Approximate Bayesian Computation methods via density estimation},
	abstract = {This paper provides a review of Approximate Bayesian Computation ({ABC}) methods for carrying out Bayesian posterior inference, through the lens of density estimation. We describe several recent algorithms and make connection with traditional approaches. We show advantages and limitations of models based on parametric approaches and we then draw attention to developments in machine learning, which we believe have the potential to make {ABC} scalable to higher dimensions and may be the future direction for research in this area.},
	journaltitle = {{arXiv}:1909.02736 [stat]},
	author = {Grazian, Clara and Fan, Yanan},
	urldate = {2019-09-30},
	date = {2019-09-06},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1909.02736},
	keywords = {Statistics - Methodology, Statistics - Computation},
	file = {grazian_fan_2019_a_review_of_approximate_bayesian_computation_methods_via_density_estimation.pdf:/home/nathan/Dropbox/njames/zotero_sync/grazian_fan_2019_a_review_of_approximate_bayesian_computation_methods_via_density_estimation.pdf:application/pdf}
}

@article{alvares_semicomprisks:_nodate,
	title = {{SemiCompRisks}: An R Package for the Analysis of Independent and Cluster-correlated Semi-competing Risks Data},
	abstract = {Semi-competing risks refer to the setting where primary scientiﬁc interest lies in estimation and inference with respect to a non-terminal event, the occurrence of which is subject to a terminal event. In this paper, we present the R package {SemiCompRisks} that provides functions to perform the analysis of independent/clustered semi-competing risks data under the illness-death multi-state model. The package allows the user to choose the speciﬁcation for model components from a range of options giving users substantial ﬂexibility, including: accelerated failure time or proportional hazards regression models; parametric or non-parametric speciﬁcations for baseline survival functions; parametric or non-parametric speciﬁcations for random effects distributions when the data are clustercorrelated; and, a Markov or semi-Markov speciﬁcation for terminal event following non-terminal event. While estimation is mainly performed within the Bayesian paradigm, the package also provides the maximum likelihood estimation for select parametric models. The package also includes functions for univariate survival analysis as complementary analysis tools.},
	pages = {24},
	author = {Alvares, Danilo and Haneuse, Sebastien and Lee, Catherine and Lee, Kyu Ha},
	langid = {english},
	file = {alvares_et_al_semicomprisks.pdf:/home/nathan/Dropbox/njames/zotero_sync/alvares_et_al_semicomprisks.pdf:application/pdf}
}

@article{cote_rank-based_2019,
	title = {Rank-based inference tools for copula regression, with property and casualty insurance applications},
	volume = {89},
	issn = {01676687},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167668718301744},
	doi = {10.1016/j.insmatheco.2019.08.001},
	abstract = {Rank-based procedures are commonly used for inference in copula models for continuous responses whose behavior does not depend on covariates. This paper describes how these procedures can be adapted to the broader framework in which (possibly non-linear) regression models for the marginal responses are linked by a copula that does not depend on covariates. The validity of many of these techniques can be derived from the asymptotic equivalence between the classical empirical copula process and its analog based on suitable residuals from the marginal models. Moment-based parameter estimation and copula goodness-of-fit tests are shown to remain valid under weak conditions on the marginal error term distributions, even when the residual-based empirical copula process fails to converge weakly. The performance of these procedures is evaluated through simulation in the context of two general insurance applications: micro-level multivariate insurance claims, and dependent loss triangles.},
	pages = {1--15},
	journaltitle = {Insurance: Mathematics and Economics},
	author = {Côté, Marie-Pier and Genest, Christian and Omelka, Marek},
	urldate = {2019-09-30},
	date = {2019-11},
	langid = {english},
	file = {côté_et_al_2019_rank-based_inference_tools_for_copula_regression,_with_property_and_casualty.pdf:/home/nathan/Dropbox/njames/zotero_sync/côté_et_al_2019_rank-based_inference_tools_for_copula_regression,_with_property_and_casualty.pdf:application/pdf}
}

@book{johnson_ordinal_1999,
	location = {New York},
	title = {Ordinal data modeling},
	isbn = {978-0-387-98718-7},
	series = {Statistics for social science and public policy},
	pagetotal = {258},
	publisher = {Springer},
	author = {Johnson, Valen E. and Albert, Jim},
	date = {1999},
	keywords = {Statistical methods, Numbers, Ordinal, Policy sciences, Social sciences}
}

@article{bellanti_integration_2015,
	title = {Integration of {PKPD} relationships into benefit–risk analysis},
	volume = {80},
	issn = {0306-5251},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4631171/},
	doi = {10.1111/bcp.12674},
	abstract = {Aim
Despite the continuous endeavour to achieve high standards in medical care through effectiveness measures, a quantitative framework for the assessment of the benefit–risk balance of new medicines is lacking prior to regulatory approval. The aim of this short review is to summarise the approaches currently available for benefit–risk assessment. In addition, we propose the use of pharmacokinetic–pharmacodynamic ({PKPD}) modelling as the pharmacological basis for evidence synthesis and evaluation of novel therapeutic agents.

Methods
A comprehensive literature search has been performed using {MESH} terms in {PubMed}, in which articles describing benefit–risk assessment and modelling and simulation were identified. In parallel, a critical review of multi-criteria decision analysis ({MCDA}) is presented as a tool for characterising a drug's safety and efficacy profile.

Results
A definition of benefits and risks has been proposed by the European Medicines Agency ({EMA}), in which qualitative and quantitative elements are included. However, in spite of the value of {MCDA} as a quantitative method, decisions about benefit–risk balance continue to rely on subjective expert opinion. By contrast, a model-informed approach offers the opportunity for a more comprehensive evaluation of benefit–risk balance before extensive evidence is generated in clinical practice.

Conclusions
Benefit–risk balance should be an integral part of the risk management plan and as such considered before marketing authorisation. Modelling and simulation can be incorporated into {MCDA} to support the evidence synthesis as well evidence generation taking into account the underlying correlations between favourable and unfavourable effects. In addition, it represents a valuable tool for the optimization of protocol design in effectiveness trials.},
	pages = {979--991},
	number = {5},
	journaltitle = {Br J Clin Pharmacol},
	author = {Bellanti, Francesco and van Wijk, Rob C and Danhof, Meindert and Della Pasqua, Oscar},
	urldate = {2019-10-02},
	date = {2015-11},
	pmid = {25940398},
	pmcid = {PMC4631171},
	file = {bellanti_et_al_2015_integration_of_pkpd_relationships_into_benefit–risk_analysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/bellanti_et_al_2015_integration_of_pkpd_relationships_into_benefit–risk_analysis.pdf:application/pdf}
}

@article{sorensen_bayesian_2016,
	title = {Bayesian linear mixed models using Stan: A tutorial for psychologists, linguists, and cognitive scientists},
	volume = {12},
	issn = {2292-1354},
	url = {http://www.tqmp.org/RegularArticles/vol12-3/p175},
	doi = {10.20982/tqmp.12.3.p175},
	shorttitle = {Bayesian linear mixed models using Stan},
	abstract = {With the arrival of the R packages nlme and lme4, linear mixed models ({LMMs}) have come to be widely used in experimentally-driven areas like psychology, linguistics, and cognitive science. This tutorial provides a practical introduction to ﬁtting {LMMs} in a Bayesian framework using the probabilistic programming language Stan. We choose Stan (rather than {WinBUGS} or {JAGS}) because it provides an elegant and scalable framework for ﬁtting models in most of the standard applications of {LMMs}. We ease the reader into ﬁtting increasingly complex {LMMs}, using a twocondition repeated measures self-paced reading study.},
	pages = {175--200},
	number = {3},
	journaltitle = {{TQMP}},
	author = {Sorensen, Tanner and Hohenstein, Sven and Vasishth, Shravan},
	urldate = {2019-10-02},
	date = {2016-10-01},
	langid = {english},
	file = {sorensen_et_al_2016_bayesian_linear_mixed_models_using_stan.pdf:/home/nathan/Dropbox/njames/zotero_sync/sorensen_et_al_2016_bayesian_linear_mixed_models_using_stan.pdf:application/pdf}
}

@article{kusmierczyk_correcting_2019,
	title = {Correcting Predictions for Approximate Bayesian Inference},
	url = {http://arxiv.org/abs/1909.04919},
	abstract = {Bayesian models quantify uncertainty and facilitate optimal decision-making in downstream applications. For most models, however, practitioners are forced to use approximate inference techniques that lead to sub-optimal decisions due to incorrect posterior predictive distributions. We present a novel approach that corrects for inaccuracies in posterior inference by altering the decision-making process. We train a separate model to make optimal decisions under the approximate posterior, combining interpretable Bayesian modeling with optimization of direct predictive accuracy in a principled fashion. The solution is generally applicable as a plug-in module for predictive decision-making for arbitrary probabilistic programs, irrespective of the posterior inference strategy. We demonstrate the approach empirically in several problems, conﬁrming its potential.},
	journaltitle = {{arXiv}:1909.04919 [cs, stat]},
	author = {Kuśmierczyk, Tomasz and Sakaya, Joseph and Klami, Arto},
	urldate = {2019-10-03},
	date = {2019-09-11},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1909.04919},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {kuśmierczyk_et_al_2019_correcting_predictions_for_approximate_bayesian_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/kuśmierczyk_et_al_2019_correcting_predictions_for_approximate_bayesian_inference.pdf:application/pdf}
}

@article{ruberg_inference_2019,
	title = {Inference and Decision Making for 21st-Century Drug Development and Approval},
	volume = {73},
	issn = {0003-1305, 1537-2731},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2019.1566091},
	doi = {10.1080/00031305.2019.1566091},
	abstract = {The cost and time of pharmaceutical drug development continue to grow at rates that many say are unsustainable. These trends have enormous impact on what treatments get to patients, when they get them and how they are used. The statistical framework for supporting decisions in regulated clinical development of new medicines has followed a traditional path of frequentist methodology. Trials using hypothesis tests of “no treatment effect” are done routinely, and the p-value {\textless} 0.05 is often the determinant of what constitutes a “successful”trial. Many drugs fail in clinical development, adding to the cost of new medicines, and some evidence points blame at the deficiencies of the frequentist paradigm. An unknown number effective medicines may have been abandoned because trials were declared “unsuccessful” due to a pvalue exceeding 0.05. Recently, the Bayesian paradigm has shown utility in the clinical drug development process for its probability-based inference. We argue for a Bayesian approach that employs data from other trials as a “prior” for Phase 3 trials so that synthesized evidence across trials can be utilized to compute probability statements that are valuable for understanding the magnitude of treatment effect. Such a Bayesian paradigm provides a promising framework for improving statistical inference and regulatory decision making.},
	pages = {319--327},
	issue = {sup1},
	journaltitle = {The American Statistician},
	author = {Ruberg, Stephen J. and Harrell, Frank E. and Gamalo-Siebers, Margaret and {LaVange}, Lisa and Jack Lee, J. and Price, Karen and Peck, Carl},
	urldate = {2019-10-03},
	date = {2019-03-29},
	langid = {english},
	file = {ruberg_et_al_2019_inference_and_decision_making_for_21st-century_drug_development_and_approval.pdf:/home/nathan/Dropbox/njames/zotero_sync/ruberg_et_al_2019_inference_and_decision_making_for_21st-century_drug_development_and_approval.pdf:application/pdf}
}

@article{greco_bayesian_2016,
	title = {A Bayesian network meta-analysis for binary outcome: how to do it},
	volume = {25},
	issn = {0962-2802, 1477-0334},
	url = {http://journals.sagepub.com/doi/10.1177/0962280213500185},
	doi = {10.1177/0962280213500185},
	shorttitle = {A Bayesian network meta-analysis for binary outcome},
	abstract = {This study presents an overview of conceptual and practical issues of a network meta-analysis ({NMA}), particularly focusing on its application to randomised controlled trials with a binary outcome of interest. We start from general considerations on {NMA} to specifically appraise how to collect study data, structure the analytical network and specify the requirements for different models and parameter interpretations, with the ultimate goal of providing physicians and clinician-investigators a practical tool to understand pros and cons of {NMA}. Specifically, we outline the key steps, from the literature search to sensitivity analysis, necessary to perform a valid {NMA} of binomial data, exploiting Markov Chain Monte Carlo approaches. We also apply this analytical approach to a case study on the beneficial effects of volatile agents compared to total intravenous anaesthetics for surgery to further clarify the statistical details of the models, diagnostics and computations. Finally, datasets and models for the freeware {WinBUGS} package are presented for the anaesthetic agent example.},
	pages = {1757--1773},
	number = {5},
	journaltitle = {Stat Methods Med Res},
	author = {Greco, Teresa and Landoni, Giovanni and Biondi-Zoccai, Giuseppe and D'Ascenzo, Fabrizio and Zangrillo, Alberto},
	urldate = {2019-10-07},
	date = {2016-10},
	langid = {english},
	file = {greco_et_al_2016_a_bayesian_network_meta-analysis_for_binary_outcome.pdf:/home/nathan/Dropbox/njames/zotero_sync/greco_et_al_2016_a_bayesian_network_meta-analysis_for_binary_outcome.pdf:application/pdf}
}

@article{umlauf_bamlss:_2019,
	title = {bamlss: A Lego Toolbox for Flexible Bayesian Regression (and Beyond)},
	url = {http://arxiv.org/abs/1909.11784},
	shorttitle = {bamlss},
	abstract = {Over the last decades, the challenges in applied regression and in predictive modeling have been changing considerably: (1) More ﬂexible model speciﬁcations are needed as big(ger) data become available, facilitated by more powerful computing infrastructure. (2) Full probabilistic modeling rather than predicting just means or expectations is crucial in many applications. (3) Interest in Bayesian inference has been increasing both as an appealing framework for regularizing or penalizing model estimation as well as a natural alternative to classical frequentist inference. However, while there has been a lot of research in all three areas, also leading to associated software packages, a modular software implementation that allows to easily combine all three aspects has not yet been available. For ﬁlling this gap, the R package bamlss is introduced for Bayesian additive models for location, scale, and shape (and beyond). At the core of the package are algorithms for highly-eﬃcient Bayesian estimation and inference that can be applied to generalized additive models ({GAMs}) or generalized additive models for location, scale, and shape ({GAMLSS}), also known as distributional regression. However, its building blocks are designed as “Lego bricks” encompassing various distributions (exponential family, Cox, joint models, . . . ), regression terms (linear, splines, random eﬀects, tensor products, spatial ﬁelds, . . . ), and estimators ({MCMC}, backﬁtting, gradient boosting, lasso, . . . ). It is demonstrated how these can be easily recombined to make classical models more ﬂexible or create new custom models for speciﬁc modeling challenges.},
	journaltitle = {{arXiv}:1909.11784 [cs, stat]},
	author = {Umlauf, Nikolaus and Klein, Nadja and Simon, Thorsten and Zeileis, Achim},
	urldate = {2019-10-21},
	date = {2019-09-25},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1909.11784},
	keywords = {Statistics - Methodology, Statistics - Computation, Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {umlauf_et_al_2019_bamlss.pdf:/home/nathan/Dropbox/njames/zotero_sync/umlauf_et_al_2019_bamlss.pdf:application/pdf}
}

@article{shahbaba_deep_2019,
	title = {Deep Markov Chain Monte Carlo},
	url = {http://arxiv.org/abs/1910.05692},
	abstract = {We propose a new computationally efﬁcient sampling scheme for Bayesian inference involving high dimensional probability distributions. Our method maps the original parameter space into a low-dimensional latent space, explores the latent space to generate samples, and maps these samples back to the original space for inference. While our method can be used in conjunction with any dimension reduction technique to obtain the latent space, and any standard sampling algorithm to explore the low-dimensional space, here we speciﬁcally use a combination of auto-encoders (for dimensionality reduction) and Hamiltonian Monte Carlo ({HMC}, for sampling). To this end, we ﬁrst run an {HMC} to generate some initial samples from the original parameter space, and then use these samples to train an auto-encoder. Next, starting with an initial state, we use the encoding part of the autoencoder to map the initial state to a point in the low-dimensional latent space. Using another {HMC}, this point is then treated as an initial state in the latent space to generate a new state, which is then mapped to the original space using the decoding part of the auto-encoder. The resulting point can be treated as a Metropolis-Hasting ({MH}) proposal, which is either accepted or rejected. While the induced dynamics in the parameter space is no longer Hamiltonian, it remains time reversible, and the Markov chain could still converge to the canonical distribution using a volume correction term. Dropping the volume correction step results in convergence to an approximate but reasonably accurate distribution. The empirical results based on several high-dimensional problems show that our method could substantially reduce the computational cost of Bayesian inference.},
	journaltitle = {{arXiv}:1910.05692 [stat]},
	author = {Shahbaba, Babak and Lomeli, Luis Martinez and Chen, Tian and Lan, Shiwei},
	urldate = {2019-10-21},
	date = {2019-10-13},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1910.05692},
	keywords = {Statistics - Computation},
	file = {shahbaba_et_al_2019_deep_markov_chain_monte_carlo.pdf:/home/nathan/Dropbox/njames/zotero_sync/shahbaba_et_al_2019_deep_markov_chain_monte_carlo.pdf:application/pdf}
}

@article{huggins_practical_2019,
	title = {Practical Posterior Error Bounds from Variational Objectives},
	url = {http://arxiv.org/abs/1910.04102},
	abstract = {Variational inference has become an increasingly attractive fast alternative to Markov chain Monte Carlo methods for approximate Bayesian inference. However, a major obstacle to the widespread use of variational methods is the lack of post-hoc accuracy measures that are both theoretically justiﬁed and computationally efﬁcient. In this paper, we provide rigorous bounds on the error of posterior mean and uncertainty estimates that arise from full-distribution approximations, as in variational inference. Our bounds are widely applicable as they require only that the approximating and exact posteriors have polynomial moments. Our bounds are computationally efﬁcient for variational inference in that they require only standard values from variational objectives, straightforward analytic calculations, and simple Monte Carlo estimates. We show that our analysis naturally leads to a new and improved workﬂow for variational inference. Finally, we demonstrate the utility of our proposed workﬂow and error bounds on a real-data example with a widely used multilevel hierarchical model.},
	journaltitle = {{arXiv}:1910.04102 [cs, math, stat]},
	author = {Huggins, Jonathan H. and Kasprzak, Mikołaj and Campbell, Trevor and Broderick, Tamara},
	urldate = {2019-10-21},
	date = {2019-10-09},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1910.04102},
	keywords = {Statistics - Methodology, Mathematics - Statistics Theory, Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {huggins_et_al_2019_practical_posterior_error_bounds_from_variational_objectives.pdf:/home/nathan/Dropbox/njames/zotero_sync/huggins_et_al_2019_practical_posterior_error_bounds_from_variational_objectives.pdf:application/pdf}
}

@article{conover_rank_nodate,
	title = {Rank Transformations as a Bridge Between Parametric   and Nonparametric Statistics},
	pages = {10},
	author = {Conover, W J and Iman, Ronald L},
	langid = {english},
	file = {conover_iman_rank_transformations_as_a_bridge_between_parametric_and_nonparametric.pdf:/home/nathan/Dropbox/njames/zotero_sync/conover_iman_rank_transformations_as_a_bridge_between_parametric_and_nonparametric.pdf:application/pdf}
}

@article{yu_bayesian_2001,
	title = {Bayesian quantile regression},
	pages = {11},
	author = {Yu, Keming and Moyeed, Rana A},
	date = {2001},
	langid = {english},
	file = {yu_moyeed_2001_bayesian_quantile_regression.pdf:/home/nathan/Dropbox/njames/zotero_sync/yu_moyeed_2001_bayesian_quantile_regression.pdf:application/pdf}
}

@article{gelfand_sampling-based_1990,
	title = {Sampling-Based Approaches to Calculating Marginal Densities},
	volume = {85},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1990.10476213},
	doi = {10.1080/01621459.1990.10476213},
	pages = {398--409},
	number = {410},
	journaltitle = {Journal of the American Statistical Association},
	author = {Gelfand, Alan E. and Smith, Adrian F. M.},
	urldate = {2019-10-31},
	date = {1990-06},
	langid = {english},
	file = {gelfand_smith_1990_sampling-based_approaches_to_calculating_marginal_densities.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelfand_smith_1990_sampling-based_approaches_to_calculating_marginal_densities.pdf:application/pdf}
}

@article{johnson_gibbs_2010,
	title = {Gibbs sampling for a Bayesian hierarchical general linear model},
	volume = {4},
	issn = {1935-7524},
	url = {http://projecteuclid.org/euclid.ejs/1268655652},
	doi = {10.1214/09-EJS515},
	abstract = {We consider a Bayesian hierarchical version of the normal theory general linear model which is practically relevant in the sense that it is general enough to have many applications and it is not straightforward to sample directly from the corresponding posterior distribution. Thus we study a block Gibbs sampler that has the posterior as its invariant distribution. In particular, we establish that the Gibbs sampler converges at a geometric rate. This allows us to establish conditions for a central limit theorem for the ergodic averages used to estimate features of the posterior. Geometric ergodicity is also a key requirement for using batch means methods to consistently estimate the variance of the asymptotic normal distribution. Together, our results give practitioners the tools to be as conﬁdent in inferences based on the observations from the Gibbs sampler as they would be with inferences based on random samples from the posterior. Our theoretical results are illustrated with an application to data on the cost of health plans issued by health maintenance organizations.},
	pages = {313--333},
	number = {0},
	journaltitle = {Electron. J. Statist.},
	author = {Johnson, Alicia A. and Jones, Galin L.},
	urldate = {2019-10-31},
	date = {2010},
	langid = {english},
	file = {johnson_jones_2010_gibbs_sampling_for_a_bayesian_hierarchical_general_linear_model.pdf:/home/nathan/Dropbox/njames/zotero_sync/johnson_jones_2010_gibbs_sampling_for_a_bayesian_hierarchical_general_linear_model.pdf:application/pdf}
}

@article{chib_mcmc_nodate,
	title = {On {MCMC} sampling in hierarchical longitudinal models},
	abstract = {Markov chain Monte Carlo ({MCMC}) algorithms have revolutionized Bayesian practice. In their simplest form (i.e., when parameters are updated one at a time) they are, however, often slow to converge when applied to high-dimensional statistical models. A remedy for this problem is to block the parameters into groups, which are then updated simultaneously using either a Gibbs or Metropolis-Hastings step. In this paper we construct several (partially and fully blocked) {MCMC} algorithms for minimizing the autocorrelation in {MCMC} samples arising from important classes of longitudinal data models. We exploit an identity used by Chib (1995) in the context of Bayes factor computation to show how the parameters in a general linear mixed model may be updated in a single block, improving convergence and producing essentially independent draws from the posterior of the parameters of interest. We also investigate the value of blocking in non-Gaussian mixed models, as well as in a class of binary response data longitudinal models. We illustrate the approaches in detail with three real-data examples.},
	pages = {10},
	author = {Chib, Siddhartha and Carlin, Bradley P},
	langid = {english},
	file = {chib_carlin_on_mcmc_sampling_in_hierarchical_longitudinal_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/chib_carlin_on_mcmc_sampling_in_hierarchical_longitudinal_models.pdf:application/pdf}
}

@article{gilks_random-effects_1993,
	title = {Random-Effects Models for Longitudinal Data Using Gibbs Sampling},
	volume = {49},
	issn = {0006341X},
	url = {https://www.jstor.org/stable/2532557?origin=crossref},
	doi = {10.2307/2532557},
	abstract = {Analysis of longitudinal studies is often complicated through differences amongst individuals in the number and spacing of observations. Laird and Ware (1982, Biometrics 38, 963-974) proposed a linear random-effects model to deal with this problem. We propose a generalisation of this model to accommodate multiple random effects, and show how Gibbs sampling can be used to estimate it. We illustrate the methodology with an analysis of long-term response to hepatitis B vaccination, and demonstrate that the methodology can be easily and effectively extended to deal with censoring in the dependent variable.},
	pages = {441},
	number = {2},
	journaltitle = {Biometrics},
	author = {Gilks, W. R. and Wang, C. C. and Yvonnet, B. and Coursaget, P.},
	urldate = {2019-10-31},
	date = {1993-06},
	langid = {english},
	file = {gilks_et_al_1993_random-effects_models_for_longitudinal_data_using_gibbs_sampling.pdf:/home/nathan/Dropbox/njames/zotero_sync/gilks_et_al_1993_random-effects_models_for_longitudinal_data_using_gibbs_sampling.pdf:application/pdf}
}

@article{lange_hierarchical_nodate,
	title = {Hierarchical Bayes Models for the Progression of {HIV} Infection Using Longitudinal {CD}4+ Counts.},
	abstract = {Taking the absolute number of {CD}4+ cells (also known as T helper cells, T4 cells, and {CD}4 cells) as a marker of disease progression for persons infected with the human immunodeficiency virus ({HIV}) we model longitudinal series of such counts for a sample of 331 subjects in the San Francisco Men's Health Study. We conduct a careful and fully Bayesian analysis of these data. We are able to employ individual level nonlinear models incorporating critical features such as incomplete and unbalanced data, population covariates, unobserved random change points, heterogeneous variances, and errors-in-variables. Using results of previously published work from several different sources we construct rather precise prior distributions. Our analysis provides marginal posterior distributions for all population parameters in our model for this cohort. Using an inverse prediction approach we also develop the posterior distributions of time for {CD}4+ count to reach a specified level.},
	pages = {35},
	author = {Lange, Nicholas and Carlin, Bradley P and Gelfand, Alan E},
	langid = {english},
	file = {lange_et_al_hierarchical_bayes_models_for_the_progression_of_hiv_infection_using.pdf:/home/nathan/Dropbox/njames/zotero_sync/lange_et_al_hierarchical_bayes_models_for_the_progression_of_hiv_infection_using.pdf:application/pdf}
}

@article{babic_comparison_2019,
	title = {Comparison and Classification of Flexible Distributions for Multivariate Skew and Heavy-Tailed Data},
	volume = {11},
	issn = {2073-8994},
	url = {https://www.mdpi.com/2073-8994/11/10/1216},
	doi = {10.3390/sym11101216},
	abstract = {We present, compare and classify popular families of ﬂexible multivariate distributions. Our classiﬁcation is based on the type of symmetry (spherical, elliptical, central symmetry or asymmetry) and the tail behaviour (a single tail weight parameter or multiple tail weight parameters). We compare the families both theoretically (relevant properties and distinctive features) and with a Monte Carlo study (comparing the ﬁtting abilities in ﬁnite samples).},
	pages = {1216},
	number = {10},
	journaltitle = {Symmetry},
	author = {Babić, Slađana and Ley, Christophe and Veredas, David},
	urldate = {2019-10-31},
	date = {2019-09-30},
	langid = {english},
	file = {babić_et_al_2019_comparison_and_classification_of_flexible_distributions_for_multivariate_skew.pdf:/home/nathan/Dropbox/njames/zotero_sync/babić_et_al_2019_comparison_and_classification_of_flexible_distributions_for_multivariate_skew.pdf:application/pdf}
}

@article{guha_predicting_2019,
	title = {Predicting Phenotypes from Brain Connection Structure},
	url = {http://arxiv.org/abs/1910.02506},
	abstract = {This article focuses on the problem of predicting a response variable based on a network-valued predictor. Our particular motivation is developing interpretable and accurate predictive models for cognitive traits and neuro-psychiatric disorders based on an individual's brain connection network (connectome). Current methods focus on reducing the complex and high-dimensional brain network into a low-dimensional set of pre-specified features prior to applying standard predictive algorithms. Such methods are sensitive to feature choice and inevitably discard information. We instead propose a nonparametric Bayes class of models that utilize information from the entire adjacency matrix defining connections among brain regions in adaptively defining flexible predictive algorithms, while maintaining interpretability. The proposed Bayesian Connectomics ({BaCon}) model class utilizes Poisson-Dirichlet processes to detect a lower-dimensional, bidirectional (covariate, subject) pattern in the adjacency matrix. The small n, large p problem is transformed into a "small n, small q" problem, facilitating an effective stochastic search of the predictors. A spike-and-slab prior for the cluster predictors strikes a balance between regression model parsimony and flexibility, resulting in improved inferences and test case predictions. We describe basic properties of the {BaCon} model class and develop efficient algorithms for posterior computation. The resulting methods are shown to outperform existing approaches in simulations and applied to a creative reasoning data set.},
	journaltitle = {{arXiv}:1910.02506 [stat]},
	author = {Guha, Subharup and Jung, Rex and Dunson, David},
	urldate = {2019-10-31},
	date = {2019-10-06},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1910.02506},
	keywords = {Statistics - Methodology, Statistics - Applications, Statistics - Computation},
	file = {guha_et_al_2019_predicting_phenotypes_from_brain_connection_structure.pdf:/home/nathan/Dropbox/njames/zotero_sync/guha_et_al_2019_predicting_phenotypes_from_brain_connection_structure.pdf:application/pdf}
}

@article{mckinley_bayesian_2015,
	title = {Bayesian Model Choice in Cumulative Link Ordinal Regression Models},
	volume = {10},
	issn = {1936-0975},
	url = {http://arxiv.org/abs/1503.07642},
	doi = {10.1214/14-BA884},
	abstract = {The use of the proportional odds ({PO}) model for ordinal regression is ubiquitous in the literature. If the assumption of parallel lines does not hold for the data, then an alternative is to specify a non-proportional odds ({NPO}) model, where the regression parameters are allowed to vary depending on the level of the response. However, it is often diﬃcult to ﬁt these models, and challenges regarding model choice and ﬁtting are further compounded if there are a large number of explanatory variables. We make two contributions towards tackling these issues: ﬁrstly, we develop a Bayesian method for ﬁtting these models, that ensures the stochastic ordering conditions hold for an arbitrary ﬁnite range of the explanatory variables, allowing {NPO} models to be ﬁtted to any observed data set. Secondly, we use reversible-jump Markov chain Monte Carlo to allow the model to choose between {PO} and {NPO} structures for each explanatory variable, and show how variable selection can be incorporated. These methods can be adapted for any monotonic increasing link functions. We illustrate the utility of these approaches on novel data from a longitudinal study of individual-level risk factors aﬀecting body condition score in a dog population in Zenzele, South Africa.},
	pages = {1--30},
	number = {1},
	journaltitle = {Bayesian Anal.},
	author = {{McKinley}, Trevelyan J. and Morters, Michelle and Wood, James L. N.},
	urldate = {2019-11-02},
	date = {2015-03},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1503.07642},
	keywords = {Statistics - Methodology, Mathematics - Statistics Theory},
	file = {arXiv.org Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/RH7Q2YT9/1503.html:text/html;mckinley_et_al_2015_bayesian_model_choice_in_cumulative_link_ordinal_regression_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/mckinley_et_al_2015_bayesian_model_choice_in_cumulative_link_ordinal_regression_models2.pdf:application/pdf}
}

@article{leon-novelo_assessing_2010,
	title = {Assessing Toxicities in a Clinical Trial: Bayesian Inference for Ordinal Data Nested within Categories},
	volume = {66},
	issn = {0006341X},
	url = {http://doi.wiley.com/10.1111/j.1541-0420.2009.01359.x},
	doi = {10.1111/j.1541-0420.2009.01359.x},
	shorttitle = {Assessing Toxicities in a Clinical Trial},
	abstract = {This article addresses modeling and inference for ordinal outcomes nested within categorical responses. We propose a mixture of normal distributions for latent variables associated with the ordinal data. This mixture model allows us to ﬁx without loss of generality the cutpoint parameters that link the latent variable with the observed ordinal outcome. Moreover, the mixture model is shown to be more ﬂexible in estimating cell probabilities when compared to the traditional Bayesian ordinal probit regression model with random cutpoint parameters. We extend our model to take into account possible dependence among the outcomes in diﬀerent categories. We apply the model to a randomized phase {III} study to compare treatments on the basis of toxicities recorded by type of toxicity and grade within type. The data include the diﬀerent (categorical) toxicity types exhibited in each patient. Each type of toxicity has an (ordinal) grade associated to it. The dependence among the diﬀerent types of toxicity exhibited by the same patient is modeled by introducing patient-speciﬁc random eﬀects.},
	pages = {966--974},
	number = {3},
	journaltitle = {Biometrics},
	author = {Leon-Novelo, L.G. and Zhou, X. and Bekele, B. Nebiyou and Müller, P.},
	urldate = {2019-11-02},
	date = {2010-09},
	langid = {english},
	file = {leon-novelo_et_al_2010_assessing_toxicities_in_a_clinical_trial.pdf:/home/nathan/Dropbox/njames/zotero_sync/leon-novelo_et_al_2010_assessing_toxicities_in_a_clinical_trial.pdf:application/pdf}
}

@article{lunn_bayesian_2002,
	title = {Bayesian Analysis of Population {PK}/{PD} Models: General Concepts and Software},
	volume = {29},
	pages = {37},
	number = {3},
	journaltitle = {Journal of Pharmacokinetics and Pharmacodynamics},
	author = {Lunn, David J and Best, Nicky and Thomas, Andrew and Wakeﬁeld, Jon and Spiegelhalter, David},
	date = {2002-06},
	langid = {english},
	file = {lunn_et_al_bayesian_analysis_of_population_pk-pd_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/lunn_et_al_bayesian_analysis_of_population_pk-pd_models.pdf:application/pdf}
}

@article{razaee_nonparametric_2019,
	title = {A Nonparametric Bayesian Design for Drug Combination Cancer Trials},
	url = {http://arxiv.org/abs/1910.09163},
	abstract = {We propose an adaptive design for early phase drug combination cancer trials with the goal of estimating the maximum tolerated dose ({MTD}). A nonparametric Bayesian model, using beta priors truncated to the set of partially ordered dose combinations, is used to describe the probability of dose limiting toxicity ({DLT}). Dose allocation between successive cohorts of patients is estimated using a modiﬁed Continual Reassessment scheme. The updated probabilities of {DLT} are calculated with a Gibbs sampler that employs a weighting mechanism to calibrate the inﬂuence of data versus the prior. At the end of the trial, we recommend one or more dose combinations as the {MTD} based on our proposed algorithm. The design operating characteristics indicate that our method is comparable with existing methods. As an illustration, we apply our method to a phase I clinical trial of {CB}-839 and Gemcitabine.},
	journaltitle = {{arXiv}:1910.09163 [stat]},
	author = {Razaee, Zahra S. and Wien-Cook, Galen and Tighiouart, Mourad},
	urldate = {2019-11-21},
	date = {2019-10-21},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1910.09163},
	keywords = {Statistics - Applications},
	file = {razaee_et_al_2019_a_nonparametric_bayesian_design_for_drug_combination_cancer_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/razaee_et_al_2019_a_nonparametric_bayesian_design_for_drug_combination_cancer_trials.pdf:application/pdf}
}

@article{dette_equivalence_2019,
	title = {Equivalence tests for binary efficacy-toxicity responses},
	url = {http://arxiv.org/abs/1910.08769},
	abstract = {Clinical trials often aim to compare a new drug with a reference treatment in terms of eﬃcacy and/or toxicity depending on covariates such as, for example, the dose level of the drug. Equivalence of these treatments can be claimed if the diﬀerence in average outcome is below a certain threshold over the covariate range. In this paper we assume that the eﬃcacy and toxicity of the treatments are measured as binary outcome variables and we address two problems. First, we develop a new test procedure for the assessment of equivalence of two treatments over the entire covariate range for a single binary endpoint. Our approach is based on a parametric bootstrap, which generates data under the constraint that the distance between the curves is equal to the pre-speciﬁed equivalence threshold. Second, we address equivalence for bivariate binary (correlated) outcomes by extending the previous approach for a univariate response. For this purpose we use a 2-dimensional Gumbel model for binary eﬃcacy-toxicity responses. We investigate the operating characteristics of the proposed approaches by means of a simulation study and present a case study as an illustration.},
	journaltitle = {{arXiv}:1910.08769 [stat]},
	author = {Dette, Holger and Möllenhoff, Kathrin and Bretz, Frank},
	urldate = {2019-11-21},
	date = {2019-10-19},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1910.08769},
	keywords = {Statistics - Methodology},
	file = {dette_et_al_2019_equivalence_tests_for_binary_efficacy-toxicity_responses.pdf:/home/nathan/Dropbox/njames/zotero_sync/dette_et_al_2019_equivalence_tests_for_binary_efficacy-toxicity_responses.pdf:application/pdf}
}

@article{mcgregor_stabilising_2019,
	title = {Stabilising priors for robust Bayesian deep learning},
	url = {http://arxiv.org/abs/1910.10386},
	abstract = {Bayesian neural networks ({BNNs}) have developed into useful tools for probabilistic modelling due to recent advances in variational inference enabling large scale {BNNs}. However, {BNNs} remain brittle and hard to train, especially: (1) when using deep architectures consisting of many hidden layers and (2) in situations with large weight variances. We use signal propagation theory to quantify these challenges and propose self-stabilising priors. This is achieved by a reformulation of the {ELBO} to allow the prior to inﬂuence network signal propagation. Then, we develop a stabilising prior, where the distributional parameters of the prior are adjusted before each forward pass to ensure stability of the propagating signal. This stabilised signal propagation leads to improved convergence and robustness making it possible to train deeper networks and in more noisy settings.},
	journaltitle = {{arXiv}:1910.10386 [cs, stat]},
	author = {{McGregor}, Felix and Pretorius, Arnu and Preez, Johan du and Kroon, Steve},
	urldate = {2019-11-21},
	date = {2019-10-23},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1910.10386},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {mcgregor_et_al_2019_stabilising_priors_for_robust_bayesian_deep_learning.pdf:/home/nathan/Dropbox/njames/zotero_sync/mcgregor_et_al_2019_stabilising_priors_for_robust_bayesian_deep_learning.pdf:application/pdf}
}

@article{morita_semi-parametric_2019,
	title = {A Semi-parametric Bayesian Approach to Population Finding with Time-to-Event and Toxicity Data in a Randomized Clinical Trial},
	url = {http://arxiv.org/abs/1910.12174},
	abstract = {A utility-based Bayesian population ﬁnding ({BaPoFi}) method was proposed by Morita and Mu¨ller (2017, Biometrics, 1355-1365) to analyze data from a randomized clinical trial with the aim of identifying good predictive baseline covariates for optimizing the target population for a future study. The approach casts the population ﬁnding process as a formal decision problem together with a ﬂexible probability model using a random forest to deﬁne a regression mean function. {BaPoFi} is constructed to handle a single continuous or binary outcome variable. In this paper, we develop {BaPoFi}-{TTE} as an extension of the earlier approach for clinically important cases of time-to-event ({TTE}) data with censoring, and also accounting for a toxicity outcome. We model the association of {TTE} data with baseline covariates using a semi-parametric failure time model with a P´olya tree prior for an unknown error term and a random forest for a ﬂexible regression mean function. We deﬁne a utility function that addresses a trade-oﬀ between eﬃcacy and toxicity as one of the important clinical considerations for population ﬁnding. We examine the operating characteristics of the proposed method in extensive simulation studies. For illustration, we apply the proposed method to data from a randomized oncology clinical trial. Concerns in a preliminary analysis of the same data based on a parametric model motivated the proposed more general approach.},
	journaltitle = {{arXiv}:1910.12174 [stat]},
	author = {Morita, Satoshi and Müller, Peter and Abe, Hiroyasu},
	urldate = {2019-11-21},
	date = {2019-10-26},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1910.12174},
	keywords = {Statistics - Applications},
	file = {morita_et_al_2019_a_semi-parametric_bayesian_approach_to_population_finding_with_time-to-event.pdf:/home/nathan/Dropbox/njames/zotero_sync/morita_et_al_2019_a_semi-parametric_bayesian_approach_to_population_finding_with_time-to-event.pdf:application/pdf}
}

@article{chen_joint_2019,
	title = {Joint Quantile Regression for Spatial Data},
	url = {http://arxiv.org/abs/1910.13119},
	abstract = {Linear quantile regression is a powerful tool to investigate how predictors may aﬀect a response heterogeneously across diﬀerent quantile levels. Unfortunately, existing approaches ﬁnd it extremely diﬃcult to adjust for any dependency between observation units, largely because such methods are not based upon a fully generative model of the data. For analyzing spatially indexed data, we address this diﬃculty by generalizing the joint quantile regression model of Yang and Tokdar (2017) and characterizing spatial dependence via a Gaussian or t copula process on the underlying quantile levels of the observation units. A Bayesian semiparametric approach is introduced to perform inference of model parameters and carry out spatial quantile smoothing. An eﬀective model comparison criteria is provided, particularly for selecting between diﬀerent model speciﬁcations of tail heaviness and tail dependence. Extensive simulation studies and an application to particulate matter concentration in northeast {US} are presented to illustrate substantial gains in inference quality, accuracy and uncertainty quantiﬁcation over existing alternatives.},
	journaltitle = {{arXiv}:1910.13119 [stat]},
	author = {Chen, Xu and Tokdar, Surya T.},
	urldate = {2019-11-21},
	date = {2019-10-29},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1910.13119},
	keywords = {Statistics - Methodology},
	file = {chen_tokdar_2019_joint_quantile_regression_for_spatial_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/chen_tokdar_2019_joint_quantile_regression_for_spatial_data.pdf:application/pdf}
}

@article{wei_practical_2019,
	title = {Practical considerations for the implementation of adaptive designs for oncology Phase I dose-finding trials},
	volume = {1},
	issn = {2631-3316},
	url = {https://www.future-science.com/doi/10.4155/fdd-2019-0021},
	doi = {10.4155/fdd-2019-0021},
	abstract = {The traditional 3 + 3 design continues to be commonly used for Phase I dose-finding oncology trials, despite increasing criticisms and development of innovative methods. Unfortunately, it is a challenge to convince principal investigators to use novel designs. The goal of this paper is to persuade researchers to break away from 3 + 3 design and provide potential solutions to better designs and implementation strategy. We reviewed the statistical methods for adaptive Phase I designs. The barriers among all the major components of the implementation team have been emphasized and potential solutions have been discussed. Institutional support to the principal investigators and statistician, as well as to other team members is essential to design and implement adaptive trials in academic medical institutions.},
	pages = {FDD18},
	number = {2},
	journaltitle = {Future Drug Discovery},
	author = {Wei, Lai and Pan, Xueliang and Fernandez, Soledad},
	urldate = {2019-11-21},
	date = {2019-10-01},
	langid = {english},
	file = {wei_et_al_2019_practical_considerations_for_the_implementation_of_adaptive_designs_for.pdf:/home/nathan/Dropbox/njames/zotero_sync/wei_et_al_2019_practical_considerations_for_the_implementation_of_adaptive_designs_for.pdf:application/pdf}
}

@article{kreuzer_bayesian_2019,
	title = {Bayesian Multivariate Nonlinear State Space Copula Models},
	url = {http://arxiv.org/abs/1911.00448},
	abstract = {In this paper we propose a ﬂexible class of multivariate nonlinear non-Gaussian state space models, based on copulas. More precisely, we assume that the observation equation and the state equation are deﬁned by copula families that are not necessarily equal. For each time point, the resulting model can be described by a C-vine copula truncated after the ﬁrst tree, where the root node is represented by the latent state. Inference is performed within the Bayesian framework, using the Hamiltonian Monte Carlo method, where a further D-vine truncated after the ﬁrst tree is used as prior distribution to capture the temporal dependence in the latent states. Simulation studies show that the proposed copula-based approach is extremely ﬂexible, since it is able to describe a wide range of dependence structures and, at the same time, allows us to deal with missing data. The application to atmospheric pollutant measurement data shows that our approach is suitable for accurate modeling and prediction of data dynamics in the presence of missing values. Comparison to a Gaussian linear state space model and to Bayesian additive regression trees shows the superior performance of the proposed model with respect to predictive accuracy.},
	journaltitle = {{arXiv}:1911.00448 [stat]},
	author = {Kreuzer, Alexander and Valle, Luciana Dalla and Czado, Claudia},
	urldate = {2019-11-21},
	date = {2019-11-01},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1911.00448},
	keywords = {Statistics - Methodology},
	file = {kreuzer_et_al_2019_bayesian_multivariate_nonlinear_state_space_copula_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/kreuzer_et_al_2019_bayesian_multivariate_nonlinear_state_space_copula_models.pdf:application/pdf}
}

@article{kreuzer_bayesian_2019-1,
	title = {Bayesian inference for dynamic vine copulas in higher dimensions},
	url = {http://arxiv.org/abs/1911.00702},
	abstract = {We propose a class of dynamic vine copula models. This is an extension of static vine copulas and a generalization of dynamic C-vine and D-vine copulas studied by Almeida et al (2016) and Goel and Mehra (2019). Within this class, we allow for time-varying dependence by driving the vine copula parameters with latent {AR}(1) processes. This modeling approach is very ﬂexible but estimation is not straightforward due to the highdimensional parameter space. We propose a Bayesian estimation approach, which relies on a novel approximation of the posterior distribution. This approximation allows to use Markov Chain Monte Carlo methods, such as elliptical slice sampling, in a sequential way. In contrast to other Bayesian sequential estimation procedures for vine copula models as proposed by Gruber and Czado (2015), there is no need to collapse copula parameters to point estimates before proceeding to the next tree. Thus more information and uncertainty is propagated from lower to higher trees. A simulation study shows satisfactory performance of the Bayesian procedure. This dynamic modeling and inference approach can be applied in various ﬁelds, where static vine copulas have already proven to be successful, including environmental sciences, medicine and ﬁnance. Here we study the dependence among 21 exchange rates. For comparison we also estimate a static vine copula model and dynamic C-vine and D-vine copula models. This comparison shows superior performance of the proposed dynamic vine copula model with respect to one day ahead forecasting accuracy.},
	journaltitle = {{arXiv}:1911.00702 [stat]},
	author = {Kreuzer, Alexander and Czado, Claudia},
	urldate = {2019-11-21},
	date = {2019-11-02},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1911.00702},
	keywords = {Statistics - Methodology},
	file = {kreuzer_czado_2019_bayesian_inference_for_dynamic_vine_copulas_in_higher_dimensions.pdf:/home/nathan/Dropbox/njames/zotero_sync/kreuzer_czado_2019_bayesian_inference_for_dynamic_vine_copulas_in_higher_dimensions.pdf:application/pdf}
}

@article{fidler_nonlinear_2019,
	title = {Nonlinear Mixed-Effects Model Development and Simulation Using nlmixr and Related R Open-Source Packages},
	volume = {8},
	issn = {2163-8306},
	url = {https://ascpt.onlinelibrary.wiley.com/doi/abs/10.1002/psp4.12445},
	doi = {10.1002/psp4.12445},
	abstract = {nlmixr is a free and open-source R package for fitting nonlinear pharmacokinetic ({PK}), pharmacodynamic ({PD}), joint {PK}-{PD}, and quantitative systems pharmacology mixed-effects models. Currently, nlmixr is capable of fitting both traditional compartmental {PK} models as well as more complex models implemented using ordinary differential equations. We believe that, over time, it will become a capable, credible alternative to commercial software tools, such as {NONMEM}, Monolix, and Phoenix {NLME}.},
	pages = {621--633},
	number = {9},
	journaltitle = {{CPT}: Pharmacometrics \& Systems Pharmacology},
	author = {Fidler, Matthew and Wilkins, Justin J. and Hooijmaijers, Richard and Post, Teun M. and Schoemaker, Rik and Trame, Mirjam N. and Xiong, Yuan and Wang, Wenping},
	urldate = {2019-11-25},
	date = {2019},
	langid = {english},
	file = {fidler_et_al_2019_nonlinear_mixed-effects_model_development_and_simulation_using_nlmixr_and.pdf:/home/nathan/Dropbox/njames/zotero_sync/fidler_et_al_2019_nonlinear_mixed-effects_model_development_and_simulation_using_nlmixr_and.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/Z9C9TYZ5/psp4.html:text/html}
}

@article{bauer_nonmem_2019,
	title = {{NONMEM} Tutorial Part I: Description of Commands and Options, With Simple Examples of Population Analysis},
	issn = {2163-8306, 2163-8306},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/psp4.12404},
	doi = {10.1002/psp4.12404},
	shorttitle = {{NONMEM} Tutorial Part I},
	pages = {psp4.12404},
	journaltitle = {{CPT} Pharmacometrics Syst. Pharmacol.},
	author = {Bauer, Robert J.},
	urldate = {2019-11-25},
	date = {2019-06-13},
	langid = {english},
	file = {bauer_2019_nonmem_tutorial_part_i.pdf:/home/nathan/Dropbox/njames/zotero_sync/bauer_2019_nonmem_tutorial_part_i.pdf:application/pdf}
}

@article{bauer_nonmem_2019-1,
	title = {{NONMEM} Tutorial Part {II}: Estimation Methods and Advanced Examples},
	issn = {2163-8306, 2163-8306},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/psp4.12422},
	doi = {10.1002/psp4.12422},
	shorttitle = {{\textless}span style="font-variant},
	pages = {psp4.12422},
	journaltitle = {{CPT} Pharmacometrics Syst. Pharmacol.},
	author = {Bauer, Robert J.},
	urldate = {2019-11-25},
	date = {2019-05},
	langid = {english},
	file = {bauer_2019_nonmem_tutorial_part_ii.pdf:/home/nathan/Dropbox/njames/zotero_sync/bauer_2019_nonmem_tutorial_part_ii.pdf:application/pdf}
}

@misc{noauthor_torsten:_2019,
	title = {Torsten: A Pharmacokinetic/Pharmacodynamic Model Library for Stan User Manual},
	url = {https://github.com/metrumresearchgroup/Torsten/blob/master/docs/torsten_manual.pdf},
	publisher = {Metrum Research Group},
	urldate = {2019-12-01},
	date = {2019-11-27},
	file = {2019_torsten.pdf:/home/nathan/Dropbox/njames/zotero_sync/2019_torsten.pdf:application/pdf}
}

@article{kaur_current_2011,
	title = {Current role of dexmedetomidine in clinical anesthesia and intensive care},
	volume = {5},
	issn = {0259-1162},
	url = {http://www.aeronline.org/text.asp?2011/5/2/128/94750},
	doi = {10.4103/0259-1162.94750},
	pages = {128},
	number = {2},
	journaltitle = {Anesth Essays Res},
	author = {Kaur, Manpreet and Singh, Pm},
	urldate = {2019-12-02},
	date = {2011},
	langid = {english},
	file = {kaur_singh_2011_current_role_of_dexmedetomidine_in_clinical_anesthesia_and_intensive_care.pdf:/home/nathan/Dropbox/njames/zotero_sync/kaur_singh_2011_current_role_of_dexmedetomidine_in_clinical_anesthesia_and_intensive_care.pdf:application/pdf}
}

@article{gertler_dexmedetomidine:_2001,
	title = {Dexmedetomidine: A Novel Sedative-Analgesic Agent},
	volume = {14},
	issn = {0899-8280, 1525-3252},
	url = {https://www.tandfonline.com/doi/full/10.1080/08998280.2001.11927725},
	doi = {10.1080/08998280.2001.11927725},
	shorttitle = {Dexmedetomidine},
	pages = {13--21},
	number = {1},
	journaltitle = {Baylor University Medical Center Proceedings},
	author = {Gertler, Ralph and Brown, H. Cleighton and Mitchell, Donald H. and Silvius, Erin N.},
	urldate = {2019-12-02},
	date = {2001-01},
	langid = {english},
	file = {gertler_et_al_2001_dexmedetomidine.pdf:/home/nathan/Dropbox/njames/zotero_sync/gertler_et_al_2001_dexmedetomidine.pdf:application/pdf}
}

@article{naaz_dexmedetomidine_2014,
	title = {Dexmedetomidine in Current Anaesthesia Practice- A Review},
	volume = {8},
	issn = {2249782X},
	url = {http://jcdr.net/article_fulltext.asp?issn=0973-709x&year=2014&volume=8&issue=10&page=GE01&issn=0973-709x&id=4946},
	doi = {10.7860/JCDR/2014/9624.4946},
	abstract = {Dexmedetomidine is an alpha 2 adrenergic receptor agonist, even ten times more selective than clonidine. It is a very versatile drug in anaesthesia practice, finding place in increasing number of clinical scenarios and is no more limited to intensive care unit ({ICU}) sedation. It is analgesic, has anaesthetic sparing effect, sympatholytic property, useful in other procedural sedation and also has cardiovascular stabilizing property. It reduces delirium and preserves respiratory function which adds benefits to its uses. The aim of this review is to make awareness of its role in present anaesthesia and discuss its limitations at the same time.},
	number = {10},
	journaltitle = {{JCDR}},
	author = {Naaz, Shagufta and Ozair, Erum},
	urldate = {2019-12-02},
	date = {2014-10},
	langid = {english},
	file = {naaz_ozair_2014_dexmedetomidine_in_current_anaesthesia_practice-_a_review.pdf:/home/nathan/Dropbox/njames/zotero_sync/naaz_ozair_2014_dexmedetomidine_in_current_anaesthesia_practice-_a_review.pdf:application/pdf}
}

@article{plambech_dexmedetomidine_2015,
	title = {Dexmedetomidine in the pediatric population: a review},
	volume = {81},
	pages = {13},
	number = {3},
	journaltitle = {{MINERVA} {ANESTESIOLOGICA}},
	author = {Plambech, M Z and Afshari, A},
	date = {2015},
	langid = {english},
	file = {plambech_afshari_2015_dexmedetomidine_in_the_pediatric_population.pdf:/home/nathan/Dropbox/njames/zotero_sync/plambech_afshari_2015_dexmedetomidine_in_the_pediatric_population.pdf:application/pdf}
}

@article{weerink_clinical_2017,
	title = {Clinical Pharmacokinetics and Pharmacodynamics of Dexmedetomidine},
	volume = {56},
	issn = {0312-5963, 1179-1926},
	url = {http://link.springer.com/10.1007/s40262-017-0507-7},
	doi = {10.1007/s40262-017-0507-7},
	pages = {893--913},
	number = {8},
	journaltitle = {Clin Pharmacokinet},
	author = {Weerink, Maud A. S. and Struys, Michel M. R. F. and Hannivoort, Laura N. and Barends, Clemens R. M. and Absalom, Anthony R. and Colin, Pieter},
	urldate = {2019-12-05},
	date = {2017-08},
	langid = {english},
	file = {weerink_et_al_2017_clinical_pharmacokinetics_and_pharmacodynamics_of_dexmedetomidine.pdf:/home/nathan/Dropbox/njames/zotero_sync/weerink_et_al_2017_clinical_pharmacokinetics_and_pharmacodynamics_of_dexmedetomidine.pdf:application/pdf}
}

@article{wiczling_pharmacokinetics_2016,
	title = {The pharmacokinetics of dexmedetomidine during long-term infusion in critically ill pediatric patients. A Bayesian approach with informative priors},
	volume = {43},
	issn = {1567-567X, 1573-8744},
	url = {http://link.springer.com/10.1007/s10928-016-9474-0},
	doi = {10.1007/s10928-016-9474-0},
	pages = {315--324},
	number = {3},
	journaltitle = {J Pharmacokinet Pharmacodyn},
	author = {Wiczling, Paweł and Bartkowska-Śniatkowska, Alicja and Szerkus, Oliwia and Siluk, Danuta and Rosada-Kurasińska, Jowita and Warzybok, Justyna and Borsuk, Agnieszka and Kaliszan, Roman and Grześkowiak, Edmund and Bienert, Agnieszka},
	urldate = {2019-12-05},
	date = {2016-06},
	langid = {english},
	file = {wiczling_et_al_2016_the_pharmacokinetics_of_dexmedetomidine_during_long-term_infusion_in_critically.pdf:/home/nathan/Dropbox/njames/zotero_sync/wiczling_et_al_2016_the_pharmacokinetics_of_dexmedetomidine_during_long-term_infusion_in_critically.pdf:application/pdf}
}

@article{smuszkiewicz_pharmacokinetics_2018,
	title = {Pharmacokinetics of dexmedetomidine during analgosedation in {ICU} patients},
	volume = {45},
	issn = {1567-567X, 1573-8744},
	url = {http://link.springer.com/10.1007/s10928-017-9564-7},
	doi = {10.1007/s10928-017-9564-7},
	abstract = {Dexmedetomidine ({DEX}) is a fairly new alfa2-agonist which has been increasingly used in recent years for analgosedation, mostly because it offers a unique ability of providing both moderate level of sedation and analgesia without respiratory depression. Despite of many papers published, there are still only a few concerning the {PK} of the drug given as long-term infusion in {ICU} patients. The aim of this work was to characterize the population pharmacokinetics of dexmedetomidine and to investigate the potential beneﬁts of individualization of drug dosing based on patient characteristics in the heterogeneous group of medical and surgical patients staying in intensive care unit. This study was performed in the group of 17 males and 10 females patients with a median age of 59.5 years and median body weight of 75 kg. Blood samples for dexmedetomidine assay were collected from arterial catheter, during and after discontinuation of a standard infusion, that ranged from 24 to 102 h. The following covariates were examined to inﬂuence dexmedetomidine {PK}: age, sex, body weight, patients’ health status described by Sequential Organ Failure Assessment Score ({SOFA}), inotropes usage, and infusion duration. The dexmedetomidine {PK} was best described by a two-compartment model. The typical values of {PK} parameters were estimated as 27 L for the volume of the central compartment, 87.6 L for the volume of the peripheral compartment, 38.5 L/h (9.2 {mL}/min/kg for a 70 kg patient) for systemic clearance and 46.4 L/h for the distribution clearance. Those values are consistent with literature ﬁndings. We were unable to show any signiﬁcant relationship between collected covariates and dexmedetomidine {PK}. This study does not provide sufﬁcient evidence to support the individualization of dexmedetomidine dosing based on age, sex, body weight, {SOFA}, and infusion duration.},
	pages = {277--284},
	number = {2},
	journaltitle = {J Pharmacokinet Pharmacodyn},
	author = {Smuszkiewicz, Piotr and Wiczling, Paweł and Ber, Justyna and Warzybok, Justyna and Małkiewicz, Tomasz and Matysiak, Jan and Klupczyńska, Agnieszka and Trojanowska, Iwona and Kokot, Zenon and Grześkowiak, Edmund and Krzyzanski, Wojciech and Bienert, Agnieszka},
	urldate = {2019-12-05},
	date = {2018-04},
	langid = {english},
	file = {smuszkiewicz_et_al_2018_pharmacokinetics_of_dexmedetomidine_during_analgosedation_in_icu_patients.pdf:/home/nathan/Dropbox/njames/zotero_sync/smuszkiewicz_et_al_2018_pharmacokinetics_of_dexmedetomidine_during_analgosedation_in_icu_patients.pdf:application/pdf}
}

@misc{teh_dirichlet_2010,
	title = {Dirichlet Process},
	publisher = {University College London},
	author = {Teh, Yee Whye},
	date = {2010},
	file = {teh_2010_dirichlet_process.pdf:/home/nathan/Dropbox/njames/zotero_sync/teh_2010_dirichlet_process.pdf:application/pdf}
}

@article{camerlenghi_latent_2019,
	title = {Latent Nested Nonparametric Priors},
	issn = {1936-0975},
	url = {https://projecteuclid.org/euclid.ba/1561601089},
	doi = {10.1214/19-BA1169},
	abstract = {Discrete random structures are important tools in Bayesian nonparametrics and the resulting models have proven eﬀective in density estimation, clustering, topic modeling and prediction, among others. In this paper, we consider nested processes and study the dependence structures they induce. Dependence ranges between homogeneity, corresponding to full exchangeability, and maximum heterogeneity, corresponding to (unconditional) independence across samples. The popular nested Dirichlet process is shown to degenerate to the fully exchangeable case when there are ties across samples at the observed or latent level. To overcome this drawback, inherent to nesting general discrete random measures, we introduce a novel class of latent nested processes. These are obtained by adding common and group-speciﬁc completely random measures and, then, normalizing to yield dependent random probability measures. We provide results on the partition distributions induced by latent nested processes, and develop a Markov Chain Monte Carlo sampler for Bayesian inferences. A test for distributional homogeneity across groups is obtained as a by-product. The results and their inferential implications are showcased on synthetic and real data.},
	journaltitle = {Bayesian Anal.},
	author = {Camerlenghi, Federico and Dunson, David B. and Lijoi, Antonio and Prünster, Igor and Rodríguez, Abel},
	urldate = {2019-12-13},
	date = {2019-06},
	langid = {english},
	file = {camerlenghi_et_al_2019_latent_nested_nonparametric_priors.pdf:/home/nathan/Dropbox/njames/zotero_sync/camerlenghi_et_al_2019_latent_nested_nonparametric_priors.pdf:application/pdf}
}

@article{davidian_smooth_1992,
	title = {Smooth nonparametric maximum likelihood estimation for population pharmacokinetics, with application to quinidine},
	volume = {20},
	issn = {0090-466X},
	url = {http://link.springer.com/10.1007/BF01061470},
	doi = {10.1007/BF01061470},
	pages = {529--556},
	number = {5},
	journaltitle = {Journal of Pharmacokinetics and Biopharmaceutics},
	author = {Davidian, Marie and Gallant, A. Ronald},
	urldate = {2019-12-13},
	date = {1992-10},
	langid = {english},
	file = {davidian_gallant_1992_smooth_nonparametric_maximum_likelihood_estimation_for_population.pdf:/home/nathan/Dropbox/njames/zotero_sync/davidian_gallant_1992_smooth_nonparametric_maximum_likelihood_estimation_for_population.pdf:application/pdf}
}

@article{beesley_emerging_2019,
	title = {The emerging landscape of health research based on biobanks linked to electronic health records: Existing resources, statistical challenges, and potential opportunities},
	issn = {0277-6715, 1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8445},
	doi = {10.1002/sim.8445},
	shorttitle = {The emerging landscape of health research based on biobanks linked to electronic health records},
	pages = {sim.8445},
	journaltitle = {Statistics in Medicine},
	author = {Beesley, Lauren J. and Salvatore, Maxwell and Fritsche, Lars G. and Pandit, Anita and Rao, Arvind and Brummett, Chad and Willer, Cristen J. and Lisabeth, Lynda D. and Mukherjee, Bhramar},
	urldate = {2019-12-20},
	date = {2019-12-20},
	langid = {english},
	file = {beesley_et_al_2019_the_emerging_landscape_of_health_research_based_on_biobanks_linked_to.pdf:/home/nathan/Dropbox/njames/zotero_sync/beesley_et_al_2019_the_emerging_landscape_of_health_research_based_on_biobanks_linked_to.pdf:application/pdf}
}

@article{holland_statistics_1986,
	title = {Statistics and Causal Inference},
	volume = {81},
	abstract = {Problems involving causal inference have dogged at the heels of statistics since its earliest days. Correlation does not imply causation, and yet causal conclusions drawn from a carefully designed experiment are often valid. What can a statistical model say about causation? This question is ad- dressed by using a particular model for causal inference (Holland and Rubin 1983; Rubin 1974) to critique the discussions of other writers on causation and causal inference. These include selected philosophers, med- ical researchers, statisticians, econometricians, and proponents of causal modeling.},
	pages = {945--960},
	number = {396},
	journaltitle = {Journal of the American Statistical Association},
	author = {Holland, Paul W},
	date = {1986-12},
	langid = {english},
	file = {holland_1986_statistics_and_causal_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/holland_1986_statistics_and_causal_inference.pdf:application/pdf}
}

@article{stewart_second-generation_2019,
	title = {Second-Generation P-Values, Shrinkage, and Regularized Models},
	volume = {7},
	issn = {2296-701X},
	url = {https://www.frontiersin.org/article/10.3389/fevo.2019.00486/full},
	doi = {10.3389/fevo.2019.00486},
	pages = {486},
	journaltitle = {Front. Ecol. Evol.},
	author = {Stewart, Thomas G. and Blume, Jeffrey D.},
	urldate = {2020-01-09},
	date = {2019-12-17},
	langid = {english},
	file = {stewart_blume_2019_second-generation_p-values,_shrinkage,_and_regularized_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/stewart_blume_2019_second-generation_p-values,_shrinkage,_and_regularized_models.pdf:application/pdf}
}

@article{mukhopadhyay_nonparametric_2019,
	title = {Nonparametric Universal Copula Modeling},
	url = {http://arxiv.org/abs/1912.05503},
	abstract = {To handle the ubiquitous problem of “dependence learning,” copulas are quickly becoming a pervasive tool across a wide range of data-driven disciplines encompassing neuroscience, ﬁnance, econometrics, genomics, social science, machine learning, healthcare and many more. At the same time, despite their practical value, the empirical methods of ‘learning copula from data’ have been unsystematic with full of case-speciﬁc recipes. Taking inspiration from modern {LP}-nonparametrics (Parzen and Mukhopadhyay, 2013a,b, Mukhopadhyay and Parzen, 2014, 2018, Mukhopadhyay, 2017, 2016), this paper presents a modest contribution to the need for a more uniﬁed and structured approach of copula modeling that is simultaneously valid for arbitrary combinations of continuous and discrete variables.},
	journaltitle = {{arXiv}:1912.05503 [stat]},
	author = {Mukhopadhyay, Subhadeep and Parzen, Emanuel},
	urldate = {2020-01-09},
	date = {2019-12-11},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1912.05503},
	keywords = {Statistics - Methodology, Statistics - Applications, Statistics - Computation},
	file = {mukhopadhyay_parzen_2019_nonparametric_universal_copula_modeling.pdf:/home/nathan/Dropbox/njames/zotero_sync/mukhopadhyay_parzen_2019_nonparametric_universal_copula_modeling.pdf:application/pdf}
}

@article{takeda_titeboinet_2019,
	title = {{TITE}‐{BOIN}‐{ET}: Time‐to‐event Bayesian optimal interval design to accelerate dose‐finding based on both efficacy and toxicity outcomes},
	issn = {1539-1604, 1539-1612},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1995},
	doi = {10.1002/pst.1995},
	shorttitle = {{TITE}‐{BOIN}‐{ET}},
	abstract = {One of the primary purposes of an oncology dose-finding trial is to identify an optimal dose ({OD}) that is both tolerable and has an indication of therapeutic benefit for subjects in subsequent clinical trials. In addition, it is quite important to accelerate early stage trials to shorten the entire period of drug development. However, it is often challenging to make adaptive decisions of dose escalation and de-escalation in a timely manner because of the fast accrual rate, the difference of outcome evaluation periods for efficacy and toxicity and the late-onset outcomes. To solve these issues, we propose the time-to-event Bayesian optimal interval design to accelerate dose-finding based on cumulative and pending data of both efficacy and toxicity. The new design, named “{TITE}-{BOIN}-{ET}” design, is nonparametric and a model-assisted design. Thus, it is robust, much simpler, and easier to implement in actual oncology dosefinding trials compared with the model-based approaches. These characteristics are quite useful from a practical point of view. A simulation study shows that the {TITE}-{BOIN}-{ET} design has advantages compared with the modelbased approaches in both the percentage of correct {OD} selection and the average number of patients allocated to the {ODs} across a variety of realistic settings. In addition, the {TITE}-{BOIN}-{ET} design significantly shortens the trial duration compared with the designs without sequential enrollment and therefore has the potential to accelerate early stage dose-finding trials.},
	pages = {pst.1995},
	journaltitle = {Pharmaceutical Statistics},
	author = {Takeda, Kentaro and Morita, Satoshi and Taguri, Masataka},
	urldate = {2020-01-09},
	date = {2019-12-12},
	langid = {english},
	file = {takeda_et_al_2019_tite‐boin‐et.pdf:/home/nathan/Dropbox/njames/zotero_sync/takeda_et_al_2019_tite‐boin‐et.pdf:application/pdf}
}

@article{greenland_causal_1999,
	title = {Causal Diagrams for Epidemiologic Research:},
	volume = {10},
	issn = {1044-3983},
	url = {https://insights.ovid.com/crossref?an=00001648-199901000-00008},
	doi = {10.1097/00001648-199901000-00008},
	shorttitle = {Causal Diagrams for Epidemiologic Research},
	pages = {37--48},
	number = {1},
	journaltitle = {Epidemiology},
	author = {Greenland, Sander and Pearl, Judea and Robins, James M.},
	urldate = {2020-01-13},
	date = {1999-01},
	langid = {english},
	file = {greenland_et_al_1999_causal_diagrams_for_epidemiologic_research.pdf:/home/nathan/Dropbox/njames/zotero_sync/greenland_et_al_1999_causal_diagrams_for_epidemiologic_research2.pdf:application/pdf}
}

@article{hernan_structural_2004,
	title = {A Structural Approach to Selection Bias:},
	volume = {15},
	issn = {1044-3983},
	url = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00001648-200409000-00020},
	doi = {10.1097/01.ede.0000135174.63482.43},
	shorttitle = {A Structural Approach to Selection Bias},
	abstract = {The term “selection bias” encompasses various biases in epidemiology. We describe examples of selection bias in casecontrol studies (eg, inappropriate selection of controls) and cohort studies (eg, informative censoring). We argue that the causal structure underlying the bias in each example is essentially the same: conditioning on a common effect of 2 variables, one of which is either exposure or a cause of exposure and the other is either the outcome or a cause of the outcome. This structure is shared by other biases (eg, adjustment for variables affected by prior exposure). A structural classiﬁcation of bias distinguishes between biases resulting from conditioning on common effects (“selection bias”) and those resulting from the existence of common causes of exposure and outcome (“confounding”). This classiﬁcation also leads to a uniﬁed approach to adjust for selection bias.},
	pages = {615--625},
	number = {5},
	journaltitle = {Epidemiology},
	author = {Hernán, Miguel A. and Hernández-Díaz, Sonia and Robins, James M.},
	urldate = {2020-01-13},
	date = {2004-09},
	langid = {english},
	file = {hernán_et_al_2004_a_structural_approach_to_selection_bias.pdf:/home/nathan/Dropbox/njames/zotero_sync/hernán_et_al_2004_a_structural_approach_to_selection_bias.pdf:application/pdf}
}

@article{pearl_causal_nodate,
	title = {Causal diagrams for empirical research},
	abstract = {The primary aim of this paper is to show how graphical models can be used as a mathematical language for integrating statistical and subject-matter information. In particular, the paper develops a principled, nonparametric framework for causal inference, in which diagrams are queried to determine if the assumptions available are sufficient for identifying causal effects from nonexperimental data. If so the diagrams can be queried to produce mathematical expressions for causal effects in terms of observed distributions; otherwise, the diagrams can be queried to suggest additional observations or auxiliary experiments from which the desired inferences can be obtained.},
	pages = {20},
	author = {Pearl, Judea},
	langid = {english},
	file = {pearl_causal_diagrams_for_empirical_research.pdf:/home/nathan/Dropbox/njames/zotero_sync/pearl_causal_diagrams_for_empirical_research.pdf:application/pdf}
}

@article{akacha_estimands_2017,
	title = {Estimands and Their Role in Clinical Trials},
	volume = {9},
	issn = {1946-6315},
	url = {https://www.tandfonline.com/doi/full/10.1080/19466315.2017.1302358},
	doi = {10.1080/19466315.2017.1302358},
	pages = {268--271},
	number = {3},
	journaltitle = {Statistics in Biopharmaceutical Research},
	author = {Akacha, Mouna and Bretz, Frank and Ohlssen, David and Rosenkranz, Gerd and Schmidli, Heinz},
	urldate = {2020-01-15},
	date = {2017-07-03},
	langid = {english},
	file = {akacha_et_al_2017_estimands_and_their_role_in_clinical_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/akacha_et_al_2017_estimands_and_their_role_in_clinical_trials.pdf:application/pdf}
}

@article{akacha_estimands_2017-1,
	title = {Estimands in clinical trials - broadening the perspective: Estimands in clinical trials - broadening the perspective},
	volume = {36},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.7033},
	doi = {10.1002/sim.7033},
	shorttitle = {Estimands in clinical trials - broadening the perspective},
	pages = {5--19},
	number = {1},
	journaltitle = {Statist. Med.},
	author = {Akacha, Mouna and Bretz, Frank and Ruberg, Stephen},
	urldate = {2020-01-15},
	date = {2017-01-15},
	langid = {english},
	file = {akacha_et_al_2017_estimands_in_clinical_trials_-_broadening_the_perspective.pdf:/home/nathan/Dropbox/njames/zotero_sync/akacha_et_al_2017_estimands_in_clinical_trials_-_broadening_the_perspective.pdf:application/pdf}
}

@article{richardson_single_nodate,
	title = {Single World Intervention Graphs: A Primer},
	abstract = {We present a simple graphical theory unifying causal directed acyclic graphs ({DAGs}) and potential (aka counterfactual) outcomes via a node-splitting transformation. We introduce a new graph, the Single-World Intervention Graph ({SWIG}). The {SWIG} encodes the counterfactual independences associated with a speciﬁc hypothetical intervention on the set of treatment variables. The nodes on the {SWIG} are the corresponding counterfactual random variables. We illustrate the theory with a number of examples. Our graphical theory of {SWIGs} may be used to infer the counterfactual independence relations that hold among the {SWIG} variables under the {FFRCISTG} model of Robins (1986) and the {NPSEM} model with Independent Errors of Pearl (2000, 2009). Furthermore, in the absence of hidden variables, the joint distribution of the counterfactuals is identiﬁed; the identifying formula is the extended g-computation formula introduced in (Robins et al., 2004). As an illustration of the beneﬁt of reasoning with {SWIGs}, we use {SWIGs} to correct an error regarding Example 11.3.3 presented in (Pearl, 2009).},
	pages = {11},
	author = {Richardson, Thomas S and Robins, James M},
	langid = {english},
	file = {richardson_robins_single_world_intervention_graphs.pdf:/home/nathan/Dropbox/njames/zotero_sync/richardson_robins_single_world_intervention_graphs.pdf:application/pdf}
}

@article{joffe_invited_1999,
	title = {Invited Commentary: Propensity Scores},
	volume = {150},
	issn = {0002-9262, 1476-6256},
	url = {https://academic.oup.com/aje/article-lookup/doi/10.1093/oxfordjournals.aje.a010011},
	doi = {10.1093/oxfordjournals.aje.a010011},
	shorttitle = {Invited Commentary},
	pages = {327--333},
	number = {4},
	journaltitle = {American Journal of Epidemiology},
	author = {Joffe, M. M. and Rosenbaum, P. R.},
	urldate = {2020-01-21},
	date = {1999-08-15},
	langid = {english},
	file = {joffe_rosenbaum_1999_invited_commentary.pdf:/home/nathan/Dropbox/njames/zotero_sync/joffe_rosenbaum_1999_invited_commentary.pdf:application/pdf}
}

@article{rosenbaum_central_nodate,
	title = {The central role of the propensity score in observational studies for causal effects},
	abstract = {The propensity score is the conditional probability of assignment to a particular treatment given a vector of observed covariates. Both large and small sample theory show that adjustment for the scalar propensity score is sufficient to remove bias due to all observed covariates. Applications include: (i) matched sampling on the univariate propensity score, which is a generalization of discriminant matching, (ii) multivariate adjustment by subclassification on the propensity score where the same subclasses are used to estimate treatment effects for all outcome variables and in all subpopulations, and (iii) visual representation of multivariate covariance adjustment by a twodimensional plot.},
	pages = {15},
	author = {Rosenbaum, Paul R and Rubin, Donald B},
	langid = {english},
	file = {rosenbaum_rubin_the_central_role_of_the_propensity_score_in_observational_studies_for_causal.pdf:/home/nathan/Dropbox/njames/zotero_sync/rosenbaum_rubin_the_central_role_of_the_propensity_score_in_observational_studies_for_causal.pdf:application/pdf}
}

@article{mckinney_international_2020,
	title = {International evaluation of an {AI} system for breast cancer screening},
	volume = {577},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/s41586-019-1799-6},
	doi = {10.1038/s41586-019-1799-6},
	pages = {89--94},
	number = {7788},
	journaltitle = {Nature},
	author = {{McKinney}, Scott Mayer and Sieniek, Marcin and Godbole, Varun and Godwin, Jonathan and Antropova, Natasha and Ashrafian, Hutan and Back, Trevor and Chesus, Mary and Corrado, Greg C. and Darzi, Ara and Etemadi, Mozziyar and Garcia-Vicente, Florencia and Gilbert, Fiona J. and Halling-Brown, Mark and Hassabis, Demis and Jansen, Sunny and Karthikesalingam, Alan and Kelly, Christopher J. and King, Dominic and Ledsam, Joseph R. and Melnick, David and Mostofi, Hormuz and Peng, Lily and Reicher, Joshua Jay and Romera-Paredes, Bernardino and Sidebottom, Richard and Suleyman, Mustafa and Tse, Daniel and Young, Kenneth C. and De Fauw, Jeffrey and Shetty, Shravya},
	urldate = {2020-01-22},
	date = {2020-01},
	langid = {english},
	file = {mckinney_et_al_2020_international_evaluation_of_an_ai_system_for_breast_cancer_screening.pdf:/home/nathan/Dropbox/njames/zotero_sync/mckinney_et_al_2020_international_evaluation_of_an_ai_system_for_breast_cancer_screening.pdf:application/pdf}
}

@article{kurth_results_2006,
	title = {Results of Multivariable Logistic Regression, Propensity Matching, Propensity Adjustment, and Propensity-based Weighting under Conditions of Nonuniform Effect},
	volume = {163},
	issn = {1476-6256, 0002-9262},
	url = {http://academic.oup.com/aje/article/163/3/262/59818/Results-of-Multivariable-Logistic-Regression},
	doi = {10.1093/aje/kwj047},
	pages = {262--270},
	number = {3},
	journaltitle = {American Journal of Epidemiology},
	author = {Kurth, Tobias and Walker, Alexander M. and Glynn, Robert J. and Chan, K. Arnold and Gaziano, J. Michael and Berger, Klaus and Robins, James M.},
	urldate = {2020-01-23},
	date = {2006-02-01},
	langid = {english},
	file = {kurth_et_al_2006_results_of_multivariable_logistic_regression,_propensity_matching,_propensity.pdf:/home/nathan/Dropbox/njames/zotero_sync/kurth_et_al_2006_results_of_multivariable_logistic_regression,_propensity_matching,_propensity.pdf:application/pdf}
}

@article{franklin_comparing_2017,
	title = {Comparing the performance of propensity score methods in healthcare database studies with rare outcomes},
	volume = {36},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7250},
	doi = {10.1002/sim.7250},
	abstract = {Nonrandomized studies of treatments from electronic healthcare databases are critical for producing the evidence necessary to making informed treatment decisions, but often rely on comparing rates of events observed in a small number of patients. In addition, studies constructed from electronic healthcare databases, for example, administrative claims data, often adjust for many, possibly hundreds, of potential confounders. Despite the importance of maximizing efficiency when there are many confounders and few observed outcome events, there has been relatively little research on the relative performance of different propensity score methods in this context. In this paper, we compare a wide variety of propensity-based estimators of the marginal relative risk. In contrast to prior research that has focused on specific statistical methods in isolation of other analytic choices, we instead consider a method to be defined by the complete multistep process from propensity score modeling to final treatment effect estimation. Propensity score model estimation methods considered include ordinary logistic regression, Bayesian logistic regression, lasso, and boosted regression trees. Methods for utilizing the propensity score include pair matching, full matching, decile strata, fine strata, regression adjustment using one or two nonlinear splines, inverse propensity weighting, and matching weights. We evaluate methods via a ‘plasmode’ simulation study, which creates simulated datasets on the basis of a real cohort study of two treatments constructed from administrative claims data. Our results suggest that regression adjustment and matching weights, regardless of the propensity score model estimation method, provide lower bias and mean squared error in the context of rare binary outcomes. Copyright © 2017 John Wiley \& Sons, Ltd.},
	pages = {1946--1963},
	number = {12},
	journaltitle = {Statistics in Medicine},
	author = {Franklin, Jessica M. and Eddings, Wesley and Austin, Peter C. and Stuart, Elizabeth A. and Schneeweiss, Sebastian},
	urldate = {2020-01-23},
	date = {2017},
	langid = {english},
	keywords = {epidemiology, healthcare databases, propensity score, risk ratio, simulation},
	file = {franklin_et_al_2017_comparing_the_performance_of_propensity_score_methods_in_healthcare_database.pdf:/home/nathan/Dropbox/njames/zotero_sync/franklin_et_al_2017_comparing_the_performance_of_propensity_score_methods_in_healthcare_database.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/ICJF65SN/sim.html:text/html}
}

@article{austin_moving_2015,
	title = {Moving towards best practice when using inverse probability of treatment weighting ({IPTW}) using the propensity score to estimate causal treatment effects in observational studies},
	volume = {34},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6607},
	doi = {10.1002/sim.6607},
	abstract = {The propensity score is defined as a subject's probability of treatment selection, conditional on observed baseline covariates. Weighting subjects by the inverse probability of treatment received creates a synthetic sample in which treatment assignment is independent of measured baseline covariates. Inverse probability of treatment weighting ({IPTW}) using the propensity score allows one to obtain unbiased estimates of average treatment effects. However, these estimates are only valid if there are no residual systematic differences in observed baseline characteristics between treated and control subjects in the sample weighted by the estimated inverse probability of treatment. We report on a systematic literature review, in which we found that the use of {IPTW} has increased rapidly in recent years, but that in the most recent year, a majority of studies did not formally examine whether weighting balanced measured covariates between treatment groups. We then proceed to describe a suite of quantitative and qualitative methods that allow one to assess whether measured baseline covariates are balanced between treatment groups in the weighted sample. The quantitative methods use the weighted standardized difference to compare means, prevalences, higher-order moments, and interactions. The qualitative methods employ graphical methods to compare the distribution of continuous baseline covariates between treated and control subjects in the weighted sample. Finally, we illustrate the application of these methods in an empirical case study. We propose a formal set of balance diagnostics that contribute towards an evolving concept of ‘best practice’ when using {IPTW} to estimate causal treatment effects using observational data. © 2015 The Authors. Statistics in Medicine Published by John Wiley \& Sons Ltd.},
	pages = {3661--3679},
	number = {28},
	journaltitle = {Statistics in Medicine},
	author = {Austin, Peter C. and Stuart, Elizabeth A.},
	urldate = {2020-01-23},
	date = {2015},
	langid = {english},
	keywords = {causal inference, observational study, propensity score, inverse probability of treatment weighting, {IPTW}},
	file = {austin_stuart_2015_moving_towards_best_practice_when_using_inverse_probability_of_treatment.pdf:/home/nathan/Dropbox/njames/zotero_sync/austin_stuart_2015_moving_towards_best_practice_when_using_inverse_probability_of_treatment.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/YQ8V9LSI/sim.html:text/html}
}

@article{zigler_central_2016,
	title = {The Central Role of Bayes’ Theorem for Joint Estimation of Causal Effects and Propensity Scores},
	volume = {70},
	issn = {0003-1305, 1537-2731},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2015.1111260},
	doi = {10.1080/00031305.2015.1111260},
	pages = {47--54},
	number = {1},
	journaltitle = {The American Statistician},
	author = {Zigler, Corwin Matthew},
	urldate = {2020-01-23},
	date = {2016-01-02},
	langid = {english},
	file = {zigler_2016_the_central_role_of_bayes’_theorem_for_joint_estimation_of_causal_effects_and.pdf:/home/nathan/Dropbox/njames/zotero_sync/zigler_2016_the_central_role_of_bayes’_theorem_for_joint_estimation_of_causal_effects_and.pdf:application/pdf}
}

@article{van_driest_pragmatic_2016,
	title = {Pragmatic pharmacology: population pharmacokinetic analysis of fentanyl using remnant samples from children after cardiac surgery},
	volume = {81},
	issn = {1365-2125},
	url = {https://bpspubs.onlinelibrary.wiley.com/doi/abs/10.1111/bcp.12903},
	doi = {10.1111/bcp.12903},
	shorttitle = {Pragmatic pharmacology},
	abstract = {Aims One barrier contributing to the lack of pharmacokinetic ({PK}) data in paediatric populations is the need for serial sampling. Analysis of clinically obtained specimens and data may overcome this barrier. To add evidence for the feasibility of this approach, we sought to determine {PK} parameters for fentanyl in children after cardiac surgery using specimens and data generated in the course of clinical care, without collecting additional blood samples. Methods We measured fentanyl concentrations in plasma from leftover clinically-obtained specimens in 130 paediatric cardiac surgery patients and successfully generated a {PK} dataset using drug dosing data extracted from electronic medical records. Using a population {PK} approach, we estimated {PK} parameters for this population, assessed model goodness-of-fit and internal model validation, and performed subset data analyses. Through simulation studies, we compared predicted fentanyl concentrations using model-driven weight-adjusted per kg vs. fixed per kg fentanyl dosing. Results Fentanyl clearance for a 6.4 kg child, the median weight in our cohort, is 5.7 l h–1 (2.2–9.2 l h–1), similar to values found in prior formal {PK} studies. Model assessment and subset analyses indicated the model adequately fit the data. Of the covariates studied, only weight significantly impacted fentanyl kinetics, but substantial inter-individual variability remained. In simulation studies, model-driven weight-adjusted per kg fentanyl dosing led to more consistent therapeutic fentanyl concentrations than fixed per kg dosing. Conclusions We show here that population {PK} modelling using sparse remnant samples and electronic medical records data provides a powerful tool for assessment of drug kinetics and generation of individualized dosing regimens.},
	pages = {1165--1174},
	number = {6},
	journaltitle = {British Journal of Clinical Pharmacology},
	author = {Van Driest, Sara L. and Marshall, Matthew D. and Hachey, Brian and Beck, Cole and Crum, Kim and Owen, Jill and Smith, Andrew H. and Kannankeril, Prince J. and Woodworth, Alison and Caprioli, Richard M. and Choi, Leena},
	urldate = {2020-01-30},
	date = {2016},
	langid = {english},
	keywords = {analgesia, opportunistic research, paediatrics, population pharmacokinetics, post-operative pain, pragmatic research},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/57BCJ7DI/bcp.html:text/html;van_driest_et_al_2016_pragmatic_pharmacology.pdf:/home/nathan/Dropbox/njames/zotero_sync/van_driest_et_al_2016_pragmatic_pharmacology.pdf:application/pdf}
}

@article{bang_doubly_2005,
	title = {Doubly Robust Estimation in Missing Data and Causal Inference Models},
	volume = {61},
	issn = {1541-0420},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2005.00377.x},
	doi = {10.1111/j.1541-0420.2005.00377.x},
	abstract = {The goal of this article is to construct doubly robust ({DR}) estimators in ignorable missing data and causal inference models. In a missing data model, an estimator is {DR} if it remains consistent when either (but not necessarily both) a model for the missingness mechanism or a model for the distribution of the complete data is correctly specified. Because with observational data one can never be sure that either a missingness model or a complete data model is correct, perhaps the best that can be hoped for is to find a {DR} estimator. {DR} estimators, in contrast to standard likelihood-based or (nonaugmented) inverse probability-weighted estimators, give the analyst two chances, instead of only one, to make a valid inference. In a causal inference model, an estimator is {DR} if it remains consistent when either a model for the treatment assignment mechanism or a model for the distribution of the counterfactual data is correctly specified. Because with observational data one can never be sure that a model for the treatment assignment mechanism or a model for the counterfactual data is correct, inference based on {DR} estimators should improve upon previous approaches. Indeed, we present the results of simulation studies which demonstrate that the finite sample performance of {DR} estimators is as impressive as theory would predict. The proposed method is applied to a cardiovascular clinical trial.},
	pages = {962--973},
	number = {4},
	journaltitle = {Biometrics},
	author = {Bang, Heejung and Robins, James M.},
	urldate = {2020-02-02},
	date = {2005},
	langid = {english},
	keywords = {Longitudinal data, Causal inference, Doubly robust estimation, Marginal structural model, Missing data, Semiparametrics},
	file = {bang_robins_2005_doubly_robust_estimation_in_missing_data_and_causal_inference_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/bang_robins_2005_doubly_robust_estimation_in_missing_data_and_causal_inference_models.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/5XWII2TU/j.1541-0420.2005.00377.html:text/html}
}

@article{ding_sensitivity_2016,
	title = {Sensitivity Analysis Without Assumptions},
	volume = {27},
	issn = {1044-3983},
	url = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00001648-201605000-00011},
	doi = {10.1097/EDE.0000000000000457},
	shorttitle = {Sensitivity Analysis Without Assumptions},
	abstract = {Unmeasured confounding may undermine the validity of causal inference with observational studies. Sensitivity analysis provides an attractive way to partially circumvent this issue by assessing the potential influence of unmeasured confounding on causal conclusions. However, previous sensitivity analysis approaches often make strong and untestable assumptions such as having an unmeasured confounder that is binary, or having no interaction between the effects of the exposure and the confounder on the outcome, or having only one unmeasured confounder. Without imposing any assumptions on the unmeasured confounder or confounders, we derive a bounding factor and a sharp inequality such that the sensitivity analysis parameters must satisfy the inequality if an unmeasured confounder is to explain away the observed effect estimate or reduce it to a particular level. Our approach is easy to implement and involves only two sensitivity parameters. Surprisingly, our bounding factor, which makes no simplifying assumptions, is no more conservative than a number of previous sensitivity analysis techniques that do make assumptions. Our new bounding factor implies not only the traditional Cornfield conditions that both the relative risk of the exposure on the confounder and that of the confounder on the outcome must satisfy but also a high threshold that the maximum of these relative risks must satisfy. Furthermore, this new bounding factor can be viewed as a measure of the strength of confounding between the exposure and the outcome induced by a confounder.},
	pages = {368--377},
	number = {3},
	journaltitle = {Epidemiology},
	author = {Ding, Peng and {VanderWeele}, Tyler J.},
	urldate = {2020-02-02},
	date = {2016-05},
	langid = {english},
	file = {ding_vanderweele_2016_sensitivity_analysis_without_assumptions.pdf:/home/nathan/Dropbox/njames/zotero_sync/ding_vanderweele_2016_sensitivity_analysis_without_assumptions.pdf:application/pdf}
}

@article{kang_demystifying_2007,
	title = {Demystifying Double Robustness: A Comparison of Alternative Strategies for Estimating a Population Mean from Incomplete Data},
	volume = {22},
	issn = {0883-4237},
	url = {http://projecteuclid.org/euclid.ss/1207580167},
	doi = {10.1214/07-STS227},
	shorttitle = {Demystifying Double Robustness},
	abstract = {When outcomes are missing for reasons beyond an investigator’s control, there are two different ways to adjust a parameter estimate for covariates that may be related both to the outcome and to missingness. One approach is to model the relationships between the covariates and the outcome and use those relationships to predict the missing values. Another is to model the probabilities of missingness given the covariates and incorporate them into a weighted or stratiﬁed estimate. Doubly robust ({DR}) procedures apply both types of model simultaneously and produce a consistent estimate of the parameter if either of the two models has been correctly speciﬁed. In this article, we show that {DR} estimates can be constructed in many ways. We compare the performance of various {DR} and non-{DR} estimates of a population mean in a simulated example where both models are incorrect but neither is grossly misspeciﬁed. Methods that use inverse-probabilities as weights, whether they are {DR} or not, are sensitive to misspeciﬁcation of the propensity model when some estimated propensities are small. Many {DR} methods perform better than simple inverse-probability weighting. None of the {DR} methods we tried, however, improved upon the performance of simple regression-based prediction of the missing values. This study does not represent every missing-data problem that will arise in practice. But it does demonstrate that, in at least some settings, two wrong models are not better than one.},
	pages = {523--539},
	number = {4},
	journaltitle = {Statist. Sci.},
	author = {Kang, Joseph D. Y. and Schafer, Joseph L.},
	urldate = {2020-02-02},
	date = {2007-11},
	langid = {english},
	file = {kang_schafer_2007_demystifying_double_robustness.pdf:/home/nathan/Dropbox/njames/zotero_sync/kang_schafer_2007_demystifying_double_robustness.pdf:application/pdf}
}

@article{vanderweele_sensitivity_2017,
	title = {Sensitivity Analysis in Observational Research: Introducing the E-Value},
	volume = {167},
	issn = {0003-4819},
	url = {http://annals.org/article.aspx?doi=10.7326/M16-2607},
	doi = {10.7326/M16-2607},
	shorttitle = {Sensitivity Analysis in Observational Research},
	pages = {268},
	number = {4},
	journaltitle = {Ann Intern Med},
	author = {{VanderWeele}, Tyler J. and Ding, Peng},
	urldate = {2020-02-02},
	date = {2017-08-15},
	langid = {english},
	file = {vanderweele_ding_2017_sensitivity_analysis_in_observational_research.pdf:/home/nathan/Dropbox/njames/zotero_sync/vanderweele_ding_2017_sensitivity_analysis_in_observational_research.pdf:application/pdf}
}

@article{ahmed_raza_robust_2016,
	title = {Robust normalization protocols for multiplexed fluorescence bioimage analysis},
	volume = {9},
	issn = {1756-0381},
	url = {http://www.biodatamining.org/content/9/1/11},
	doi = {10.1186/s13040-016-0088-2},
	abstract = {The study of mapping and interaction of co-localized proteins at a sub-cellular level is important for understanding complex biological phenomena. One of the recent techniques to map co-localized proteins is to use the standard immuno-fluorescence microscopy in a cyclic manner (Nat Biotechnol 24:1270–8, 2006; Proc Natl Acad Sci 110:11982–7, 2013). Unfortunately, these techniques suffer from variability in intensity and positioning of signals from protein markers within a run and across different runs. Therefore, it is necessary to standardize protocols for preprocessing of the multiplexed bioimaging ({MBI}) data from multiple runs to a comparable scale before any further analysis can be performed on the data. In this paper, we compare various normalization protocols and propose on the basis of the obtained results, a robust normalization technique that produces consistent results on the {MBI} data collected from different runs using the Toponome Imaging System ({TIS}). Normalization results produced by the proposed method on a sample {TIS} data set for colorectal cancer patients were ranked favorably by two pathologists and two biologists. We show that the proposed method produces higher between class Kullback-Leibler ({KL}) divergence and lower within class {KL} divergence on a distribution of cell phenotypes from colorectal cancer and histologically normal samples.},
	pages = {11},
	number = {1},
	journaltitle = {{BioData} Mining},
	author = {Ahmed Raza, Shan E and Langenkämper, Daniel and Sirinukunwattana, Korsuk and Epstein, David and Nattkemper, Tim W. and Rajpoot, Nasir M.},
	urldate = {2020-02-07},
	date = {2016-12},
	langid = {english},
	file = {ahmed_raza_et_al_2016_robust_normalization_protocols_for_multiplexed_fluorescence_bioimage_analysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/ahmed_raza_et_al_2016_robust_normalization_protocols_for_multiplexed_fluorescence_bioimage_analysis.pdf:application/pdf}
}

@article{tian_empirical_2019,
	title = {An empirical comparison of two novel transformation models},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8425},
	doi = {10.1002/sim.8425},
	abstract = {Continuous response variables are often transformed to meet modeling assumptions, but the choice of the transformation can be challenging. Two transformation models have recently been proposed: semiparametric cumulative probability models ({CPMs}) and parametric most likely transformation models ({MLTs}). Both approaches model the cumulative distribution function and require specifying a link function, which implicitly assumes that the responses follow a known distribution after some monotonic transformation. However, the two approaches estimate the transformation differently. With {CPMs}, an ordinal regression model is fit, which essentially treats each continuous response as a unique category and therefore nonparametrically estimates the transformation; {CPMs} are semiparametric linear transformation models. In contrast, with {MLTs}, the transformation is parameterized using flexible basis functions. Conditional expectations and quantiles are readily derived from both methods on the response variable's original scale. We compare the two methods with extensive simulations. We find that both methods generally have good performance with moderate and large sample sizes. {MLTs} slightly outperformed {CPMs} in small sample sizes under correct models. {CPMs} tended to be somewhat more robust to model misspecification and outcome rounding. Except in the simplest situations, both methods outperform basic transformation approaches commonly used in practice. We apply both methods to an {HIV} biomarker study.},
	journaltitle = {Statistics in Medicine},
	author = {Tian, Yuqi and Hothorn, Torsten and Li, Chun and Harrell, Frank E. and Shepherd, Bryan E.},
	urldate = {2020-02-07},
	date = {2019-12},
	langid = {english},
	keywords = {nonparametric maximum likelihood estimation, ordinal regression model, {HIV}, transformation model},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/L7RCBZEU/sim.html:text/html;tian_et_al_2019_an_empirical_comparison_of_two_novel_transformation_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/tian_et_al_2019_an_empirical_comparison_of_two_novel_transformation_models.pdf:application/pdf}
}

@book{harrell_regression_2015,
	location = {Cham Heidelberg New York},
	edition = {Second edition},
	title = {Regression modeling strategies: with applications to linear models, logistic and ordinal regression, and survival analysis},
	isbn = {978-3-319-19424-0 978-3-319-33039-6 978-3-319-19425-7},
	series = {Springer series in statistics},
	shorttitle = {Regression modeling strategies},
	pagetotal = {582},
	publisher = {Springer},
	author = {Harrell, Frank E.},
	date = {2015},
	note = {{OCLC}: 922304565},
	file = {harrell_2015_regression_modeling_strategies.pdf:/home/nathan/Dropbox/njames/zotero_sync/harrell_2015_regression_modeling_strategies.pdf:application/pdf}
}

@book{congdon_bayesian_2005,
	location = {Chichester ; New York},
	title = {Bayesian models for categorical data},
	isbn = {978-0-470-09237-8},
	series = {Wiley series in probability and statistics},
	pagetotal = {425},
	publisher = {Wiley},
	author = {Congdon, P.},
	date = {2005},
	keywords = {Bayesian statistical decision theory, Markov processes, Monte Carlo method, Multivariate analysis}
}

@article{payandeh_glm-based_nodate,
	title = {A {GLM}-Based Method to Estimate a Copula's Parameter(s)},
	abstract = {This study introduces a new approach to problem of estimating parameter(s) of a given copula. More precisely, using the concept of the generalized linear models ({GLM}) accompanied with least square method, we introduce an estimation method, say {GLM}-method. A simulation study has been conducted to provide a comparison among the inversion of Kendal’s tau, the inversion of Spearman’s rho, the {PML}, the Copula-quantile regression with (q = 0.25, 0.50, 0.75), and the {GLMmethod}. Such simulation study shows that the {GLM}-method is an appropriate method whenever the data distributed according to an elliptical distribution.},
	pages = {14},
	author = {Payandeh, Amir and Farid-Rohani, Mohammad R and Qazvini, Marjan},
	langid = {english},
	file = {payandeh_et_al_a_glm-based_method_to_estimate_a_copula's_parameter(s).pdf:/home/nathan/Dropbox/njames/zotero_sync/payandeh_et_al_a_glm-based_method_to_estimate_a_copula's_parameter(s).pdf:application/pdf}
}

@article{angrist_identification_1996,
	title = {Identification of Causal Effects Using Instrumental Variables},
	volume = {91},
	doi = {10.2307/2291629},
	pages = {444--455},
	number = {434},
	journaltitle = {{JASA}},
	author = {Angrist, Joshua D and Imbens, Guido W and Rubin, Donald B},
	date = {1996-06},
	langid = {english},
	file = {angrist_et_al_1996_identification_of_causal_effects_using_instrumental_variables.pdf:/home/nathan/Dropbox/njames/zotero_sync/angrist_et_al_1996_identification_of_causal_effects_using_instrumental_variables.pdf:application/pdf}
}

@article{baiocchi_instrumental_2014,
	title = {Instrumental variable methods for causal inference},
	volume = {33},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6128},
	doi = {10.1002/sim.6128},
	abstract = {{AbstractA} goal of many health studies is to determine the causal effect of a treatment or intervention on health outcomes. Often, it is not ethically or practically possible to conduct a perfectly randomized experiment, and instead, an observational study must be used. A major challenge to the validity of observational studies is the possibility of unmeasured confounding (i.e., unmeasured ways in which the treatment and control groups differ before treatment administration, which also affect the outcome). Instrumental variables analysis is a method for controlling for unmeasured confounding. This type of analysis requires the measurement of a valid instrumental variable, which is a variable that (i) is independent of the unmeasured confounding; (ii) affects the treatment; and (iii) affects the outcome only indirectly through its effect on the treatment. This tutorial discusses the types of causal effects that can be estimated by instrumental variables analysis; the assumptions needed for instrumental variables analysis to provide valid estimates of causal effects and sensitivity analysis for those assumptions; methods of estimation of causal effects using instrumental variables; and sources of instrumental variables in health studies. Copyright © 2014 John Wiley \& Sons, Ltd.},
	pages = {2297--2340},
	number = {13},
	journaltitle = {Statistics in Medicine},
	author = {Baiocchi, Michael and Cheng, Jing and Small, Dylan S.},
	urldate = {2020-02-17},
	date = {2014},
	langid = {english},
	keywords = {observational study, confounding, comparative effectiveness, instrumental variables},
	file = {baiocchi_et_al_2014_instrumental_variable_methods_for_causal_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/baiocchi_et_al_2014_instrumental_variable_methods_for_causal_inference.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/KKCT3D6B/sim.html:text/html}
}

@article{papageorgiou_bayesian_2019-1,
	title = {Bayesian density regression for discrete outcomes},
	volume = {61},
	issn = {1467-842X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/anzs.12273},
	doi = {10.1111/anzs.12273},
	abstract = {We develop Bayesian models for density regression with emphasis on discrete outcomes. The problem of density regression is approached by considering methods for multivariate density estimation of mixed scale variables, and obtaining conditional densities from the multivariate ones. The approach to multivariate mixed scale outcome density estimation that we describe represents discrete variables, either responses or covariates, as discretised versions of continuous latent variables. We present and compare several models for obtaining these thresholds in the challenging context of count data analysis where the response may be over- and/or under-dispersed in some of the regions of the covariate space. We utilise a nonparametric mixture of multivariate Gaussians to model the directly observed and the latent continuous variables. The paper presents a Markov chain Monte Carlo algorithm for posterior sampling, sufficient conditions for weak consistency, and illustrations on density, mean and quantile regression utilising simulated and real datasets.},
	pages = {336--359},
	number = {3},
	journaltitle = {Australian \& New Zealand Journal of Statistics},
	author = {Papageorgiou, Georgios},
	urldate = {2020-02-21},
	date = {2019},
	langid = {english},
	keywords = {Dirichlet process mixtures, joint models, Kullback–Leibler property, latent variables, over-dispersion, under-dispersion},
	file = {papageorgiou_2019_bayesian_density_regression_for_discrete_outcomes.pdf:/home/nathan/Dropbox/njames/zotero_sync/papageorgiou_2019_bayesian_density_regression_for_discrete_outcomes.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/IDH3L3KP/anzs.html:text/html}
}

@article{frangakis_principal_2002,
	title = {Principal Stratification in Causal Inference},
	volume = {58},
	issn = {1541-0420},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/j.0006-341X.2002.00021.x},
	doi = {10.1111/j.0006-341X.2002.00021.x},
	abstract = {Summary. Many scientific problems require that treatment comparisons be adjusted for posttreatment variables, but the estimands underlying standard methods are not causal effects. To address this deficiency, we propose a general framework for comparing treatments adjusting for posttreatment variables that yields principal effects based on principal stratification. Principal stratification with respect to a posttreatment variable is a cross-classification of subjects defined by the joint potential values of that posttreatment variable under each of the treatments being compared. Principal effects are causal effects within a principal stratum. The key property of principal strata is that they are not affected by treatment assignment and therefore can be used just as any pretreatment covariate, such as age category. As a result, the central property of our principal effects is that they are always causal effects and do not suffer from the complications of standard posttreatment-adjusted estimands. We discuss briefly that such principal causal effects are the link between three recent applications with adjustment for posttreatment variables: (i) treatment noncompliance, (ii) missing outcomes (dropout) following treatment noncompliance, and (iii) censoring by death. We then attack the problem of surrogate or biomarker endpoints, where we show, using principal causal effects, that all current definitions of surrogacy, even when perfectly true, do not generally have the desired interpretation as causal effects of treatment on outcome. We go on to formulate estimands based on principal stratification and principal causal effects and show their superiority.},
	pages = {21--29},
	number = {1},
	journaltitle = {Biometrics},
	author = {Frangakis, Constantine E. and Rubin, Donald B.},
	urldate = {2020-02-24},
	date = {2002},
	langid = {english},
	keywords = {Causal inference, Principal stratification, Missing data, Biomarker, Censoring by death, Posttreatment variable, Quality of life, Rubin causal model, Surrogate},
	file = {frangakis_rubin_2002_principal_stratification_in_causal_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/frangakis_rubin_2002_principal_stratification_in_causal_inference.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/48KHEM8M/j.0006-341X.2002.00021.html:text/html}
}

@article{gilbert_sensitivity_2003,
	title = {Sensitivity Analysis for the Assessment of Causal Vaccine Effects on Viral Load in {HIV} Vaccine Trials},
	volume = {59},
	issn = {1541-0420},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/1541-0420.00063},
	doi = {10.1111/1541-0420.00063},
	abstract = {Summary. Vaccines with limited ability to prevent {HIV} infection may positively impact the {HIV}/{AIDS} pandemic by preventing secondary transmission and disease in vaccine recipients who become infected. To evaluate the impact of vaccination on secondary transmission and disease, efficacy trials assess vaccine effects on {HIV} viral load and other surrogate endpoints measured after infection. A standard test that compares the distribution of viral load between the infected subgroups of vaccine and placebo recipients does not assess a causal effect of vaccine, because the comparison groups are selected after randomization. To address this problem, we formulate clinically relevant causal estimands using the principal stratification framework developed by Frangakis and Rubin (2002, Biometrics58, 21–29), and propose a class of logistic selection bias models whose members identify the estimands. Given a selection model in the class, procedures are developed for testing and estimation of the causal effect of vaccination on viral load in the principal stratum of subjects who would be infected regardless of randomization assignment. We show how the procedures can be used for a sensitivity analysis that quantifies how the causal effect of vaccination varies with the presumed magnitude of selection bias.},
	pages = {531--541},
	number = {3},
	journaltitle = {Biometrics},
	author = {Gilbert, Peter B. and Bosch, Ronald J. and Hudgens, Michael G.},
	urldate = {2020-02-24},
	date = {2003},
	langid = {english},
	keywords = {Causal inference, Principal stratification, Posttreatment selection bias},
	file = {gilbert_et_al_2003_sensitivity_analysis_for_the_assessment_of_causal_vaccine_effects_on_viral_load.pdf:/home/nathan/Dropbox/njames/zotero_sync/gilbert_et_al_2003_sensitivity_analysis_for_the_assessment_of_causal_vaccine_effects_on_viral_load.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/39PXGELX/1541-0420.html:text/html}
}

@article{shepherd_eliciting_2007,
	title = {Eliciting a Counterfactual Sensitivity Parameter},
	volume = {61},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1198/000313007X163213},
	doi = {10.1198/000313007X163213},
	pages = {56--63},
	number = {1},
	journaltitle = {The American Statistician},
	author = {Shepherd, Bryan E and Gilbert, Peter B and Mehrotra, Devan V},
	urldate = {2020-02-24},
	date = {2007-02},
	langid = {english},
	file = {shepherd_et_al_2007_eliciting_a_counterfactual_sensitivity_parameter.pdf:/home/nathan/Dropbox/njames/zotero_sync/shepherd_et_al_2007_eliciting_a_counterfactual_sensitivity_parameter.pdf:application/pdf}
}

@article{gelman_holes_2020,
	title = {Holes in Bayesian Statistics},
	url = {http://arxiv.org/abs/2002.06467},
	abstract = {Every philosophy has holes, and it is the responsibility of proponents of a philosophy to point out these problems. Here are a few holes in Bayesian data analysis: (1) the usual rules of conditional probability fail in the quantum realm, (2) ﬂat or weak priors lead to terrible inferences about things we care about, (3) subjective priors are incoherent, (4) Bayes factors fail in the presence of ﬂat or weak priors, (5) for Cantorian reasons we need to check our models, but this destroys the coherence of Bayesian inference.},
	journaltitle = {{arXiv}:2002.06467 [math, stat]},
	author = {Gelman, Andrew and Yao, Yuling},
	urldate = {2020-02-24},
	date = {2020-02-15},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2002.06467},
	keywords = {Statistics - Methodology, Mathematics - Statistics Theory},
	file = {gelman_yao_2020_holes_in_bayesian_statistics.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_yao_2020_holes_in_bayesian_statistics.pdf:application/pdf}
}

@article{valle_ordinal_2019,
	title = {Ordinal regression models for zero-inflated and/or over-dispersed count data},
	volume = {9},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/s41598-019-39377-x},
	doi = {10.1038/s41598-019-39377-x},
	pages = {3046},
	number = {1},
	journaltitle = {Sci Rep},
	author = {Valle, Denis and Ben Toh, Kok and Laporta, Gabriel Zorello and Zhao, Qing},
	urldate = {2020-02-26},
	date = {2019-12},
	langid = {english},
	file = {valle_et_al_2019_ordinal_regression_models_for_zero-inflated_and-or_over-dispersed_count_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/valle_et_al_2019_ordinal_regression_models_for_zero-inflated_and-or_over-dispersed_count_data.pdf:application/pdf}
}

@book{fahrmeir_multivariate_1994,
	location = {New York},
	title = {Multivariate statistical modelling based on generalized linear models},
	isbn = {978-0-387-94233-9},
	series = {Springer series in statistics},
	pagetotal = {425},
	publisher = {Springer-Verlag},
	author = {Fahrmeir, L. and Tutz, Gerhard},
	date = {1994},
	keywords = {Multivariate analysis, Linear models (Statistics)}
}

@article{sjolander_reaction_2011,
	title = {Reaction to Pearl's Critique of Principal Stratification},
	volume = {7},
	issn = {1557-4679},
	url = {https://www.degruyter.com/view/j/ijb.2011.7.issue-1/ijb.2011.7.1.1324/ijb.2011.7.1.1324.xml},
	doi = {10.2202/1557-4679.1324},
	abstract = {This Reader’s Reaction contains some brief remarks regarding Pearl’s concerns regarding the value of principal stratification.},
	pages = {1--5},
	number = {1},
	journaltitle = {The International Journal of Biostatistics},
	author = {Sjolander, Arvid},
	urldate = {2020-02-27},
	date = {2011-01-13},
	langid = {english},
	file = {sjolander_2011_reaction_to_pearl's_critique_of_principal_stratification.pdf:/home/nathan/Dropbox/njames/zotero_sync/sjolander_2011_reaction_to_pearl's_critique_of_principal_stratification.pdf:application/pdf}
}

@article{joffe_principal_2011,
	title = {Principal Stratification and Attribution Prohibition: Good Ideas Taken Too Far},
	volume = {7},
	issn = {1557-4679},
	url = {https://www.degruyter.com/view/j/ijb.2011.7.issue-1/1557-4679.1367/1557-4679.1367.xml},
	doi = {10.2202/1557-4679.1367},
	shorttitle = {Principal Stratification and Attribution Prohibition},
	abstract = {Pearl’s article provides a useful springboard for discussing further the benefits and drawbacks of principal stratification and the associated discomfort with attributing effects to post-treatment variables. The basic insights of the approach are important: pay close attention to modification of treatment effects by variables not observable before treatment decisions are made, and be careful in attributing effects to variables when counterfactuals are ill-defined. These insights have often been taken too far in many areas of application of the approach, including instrumental variables, censoring by death, and surrogate outcomes. A novel finding is that the usual principal stratification estimand in the setting of censoring by death is by itself of little practical value in estimating intervention effects.},
	pages = {1--22},
	number = {1},
	journaltitle = {The International Journal of Biostatistics},
	author = {Joffe, Marshall},
	urldate = {2020-02-27},
	date = {2011-01-14},
	langid = {english},
	file = {joffe_2011_principal_stratification_and_attribution_prohibition.pdf:/home/nathan/Dropbox/njames/zotero_sync/joffe_2011_principal_stratification_and_attribution_prohibition.pdf:application/pdf}
}

@article{vanderweele_principal_2011,
	title = {Principal Stratification -- Uses and Limitations},
	volume = {7},
	issn = {1557-4679},
	url = {https://www.degruyter.com/view/j/ijb.2011.7.issue-1/ijb.2011.7.1.1329/ijb.2011.7.1.1329.xml},
	doi = {10.2202/1557-4679.1329},
	abstract = {Pearl (2011) asked for the causal inference community to clarify the role of the principal stratification framework in the analysis of causal effects. Here, I argue that the notion of principal stratification has shed light on problems of non-compliance, censoring-by-death, and the analysis of post-infection outcomes; that it may be of use in considering problems of surrogacy but further development is needed; that it is of some use in assessing “direct effects”; but that it is not the appropriate tool for assessing “mediation.” There is nothing within the principal stratification framework that corresponds to a measure of an “indirect” or “mediated” effect.},
	pages = {1--14},
	number = {1},
	journaltitle = {The International Journal of Biostatistics},
	author = {{VanderWeele}, Tyler J},
	urldate = {2020-02-27},
	date = {2011-01-11},
	langid = {english},
	file = {vanderweele_2011_principal_stratification_--_uses_and_limitations.pdf:/home/nathan/Dropbox/njames/zotero_sync/vanderweele_2011_principal_stratification_--_uses_and_limitations.pdf:application/pdf}
}

@article{pearl_principal_2011,
	title = {Principal Stratification -- a Goal or a Tool?},
	volume = {7},
	issn = {1557-4679},
	url = {https://www.degruyter.com/view/j/ijb.2011.7.issue-1/ijb.2011.7.1.1322/ijb.2011.7.1.1322.xml},
	doi = {10.2202/1557-4679.1322},
	abstract = {Principal stratification has recently become a popular tool to address certain causal inference questions, particularly in dealing with post-randomization factors in randomized trials. Here, we analyze the conceptual basis for this framework and invite response to clarify the value of principal stratification in estimating causal effects of interest.},
	pages = {1--13},
	number = {1},
	journaltitle = {The International Journal of Biostatistics},
	author = {Pearl, Judea},
	urldate = {2020-02-27},
	date = {2011-01-30},
	langid = {english},
	file = {pearl_2011_principal_stratification_--_a_goal_or_a_tool.pdf:/home/nathan/Dropbox/njames/zotero_sync/pearl_2011_principal_stratification_--_a_goal_or_a_tool.pdf:application/pdf}
}

@article{bauer_survey_2007,
	title = {A survey of population analysis methods and software for complex pharmacokinetic and pharmacodynamic models with examples},
	volume = {9},
	issn = {1550-7416},
	url = {http://link.springer.com/10.1208/aapsj0901007},
	doi = {10.1208/aapsj0901007},
	abstract = {An overview is provided of the present population analysis methods and an assessment of which software packages are most appropriate for various {PK}/{PD} modeling problems. Four {PK}/{PD} example problems were solved using the programs {NONMEM} {VI} beta version, {PDx}-{MCPEM}, S-{ADAPT}, {MONOLIX}, and {WinBUGS}, informally assessed for reasonable accuracy and stability in analyzing these problems. Also, for each program we describe their general interface, ease of use, and abilities. We conclude with discussing which algorithms and software are most suitable for which types of {PK}/ {PD} problems. {NONMEM} {FO} method is accurate and fast with 2-compartment models, if intra-individual and interindividual variances are small. The {NONMEM} {FOCE} method is slower than {FO}, but gives accurate population values regardless of size of intra- and interindividual errors. However, if data are very sparse, the {NONMEM} {FOCE} method can lead to inaccurate values, while the Laplace method can provide more accurate results. The exact {EM} methods (performed using S-{ADAPT}, {PDx}-{MCPEM}, and {MONOLIX}) have greater stability in analyzing complex {PK}/{PD} models, and can provide accurate results with sparse or rich data. {MCPEM} methods perform more slowly than {NONMEM} {FOCE} for simple models, but perform more quickly and stably than {NONMEM} {FOCE} for complex models. {WinBUGS} provides accurate assessments of the population parameters, standard errors and 95\% conﬁdence intervals for all examples. Like the {MCPEM} methods, {WinBUGS}’s efﬁciency increases relative to {NONMEM} when solving the complex {PK}/{PD} models.},
	pages = {E60--E83},
	number = {1},
	journaltitle = {{AAPS} J},
	author = {Bauer, Robert J. and Guzy, Serge and Ng, Chee},
	urldate = {2020-03-04},
	date = {2007-03},
	langid = {english},
	file = {bauer_et_al_2007_a_survey_of_population_analysis_methods_and_software_for_complex.pdf:/home/nathan/Dropbox/njames/zotero_sync/bauer_et_al_2007_a_survey_of_population_analysis_methods_and_software_for_complex.pdf:application/pdf}
}

@article{kuhn_coupling_2004,
	title = {Coupling a stochastic approximation version of {EM} with an {MCMC} procedure},
	volume = {8},
	issn = {1292-8100, 1262-3318},
	url = {http://www.esaim-ps.org/10.1051/ps:2004007},
	doi = {10.1051/ps:2004007},
	abstract = {The stochastic approximation version of {EM} ({SAEM}) proposed by Delyon et al. (1999) is a powerful alternative to {EM} when the E-step is intractable. Convergence of {SAEM} toward a maximum of the observed likelihood is established when the unobserved data are simulated at each iteration under the conditional distribution. We show that this very restrictive assumption can be weakened. Indeed, the results of Benveniste et al. for stochastic approximation with Markovian perturbations are used to establish the convergence of {SAEM} when it is coupled with a Markov chain Monte-Carlo procedure. This result is very useful for many practical applications. Applications to the convolution model and the change-points model are presented to illustrate the proposed method.},
	pages = {115--131},
	journaltitle = {{ESAIM}: {PS}},
	author = {Kuhn, Estelle and Lavielle, Marc},
	urldate = {2020-03-04},
	date = {2004-08},
	langid = {english},
	file = {kuhn_lavielle_2004_coupling_a_stochastic_approximation_version_of_em_with_an_mcmc_procedure.pdf:/home/nathan/Dropbox/njames/zotero_sync/kuhn_lavielle_2004_coupling_a_stochastic_approximation_version_of_em_with_an_mcmc_procedure.pdf:application/pdf}
}

@article{delyon_convergence_nodate,
	title = {Convergence of a Stochastic Approximation Version of the {EM} Algorithm},
	pages = {36},
	author = {Delyon, Bernard and Lavielle, Marc and Mo, Eric},
	langid = {english},
	file = {delyon_et_al_convergence_of_a_stochastic_approximation_version_of_the_em_algorithm.pdf:/home/nathan/Dropbox/njames/zotero_sync/delyon_et_al_convergence_of_a_stochastic_approximation_version_of_the_em_algorithm.pdf:application/pdf}
}

@article{li_balancing_2018,
	title = {Balancing Covariates via Propensity Score Weighting},
	volume = {113},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2016.1260466},
	doi = {10.1080/01621459.2016.1260466},
	abstract = {Covariate balance is crucial for unconfounded descriptive or causal comparisons. However, lack of balance is common in observational studies. This article considers weighting strategies for balancing covariates. We define a general class of weights—the balancing weights—that balance the weighted distributions of the covariates between treatment groups. These weights incorporate the propensity score to weight each group to an analyst-selected target population. This class unifies existing weighting methods, including commonly used weights such as inverse-probability weights as special cases. General large-sample results on nonparametric estimation based on these weights are derived. We further propose a new weighting scheme, the overlap weights, in which each unit’s weight is proportional to the probability of that unit being assigned to the opposite group. The overlap weights are bounded, and minimize the asymptotic variance of the weighted average treatment effect among the class of balancing weights. The overlap weights also possess a desirable small-sample exact balance property, based on which we propose a new method that achieves exact balance for means of any selected set of covariates. Two applications illustrate these methods and compare them with other approaches.},
	pages = {390--400},
	number = {521},
	journaltitle = {Journal of the American Statistical Association},
	author = {Li, Fan and Morgan, Kari Lock and Zaslavsky, Alan M.},
	urldate = {2020-03-04},
	date = {2018-01-02},
	langid = {english},
	file = {li_et_al_2018_balancing_covariates_via_propensity_score_weighting.pdf:/home/nathan/Dropbox/njames/zotero_sync/li_et_al_2018_balancing_covariates_via_propensity_score_weighting.pdf:application/pdf}
}

@article{li_weighting_2013,
	title = {A Weighting Analogue to Pair Matching in Propensity Score Analysis},
	volume = {9},
	issn = {1557-4679, 2194-573X},
	url = {https://www.degruyter.com/view/j/ijb.2013.9.issue-2/ijb-2012-0030/ijb-2012-0030.xml},
	doi = {10.1515/ijb-2012-0030},
	abstract = {Propensity score ({PS}) matching is widely used for studying treatment effects in observational studies. This article proposes the method of matching weights ({MWs}) as an analog to one-to-one pair matching without replacement on the {PS} with a caliper. Compared with pair matching, the proposed method offers more efficient estimation, more accurate variance calculation, better balance, and simpler asymptotic analysis. A statistical test for the misspecification of the {PS} model is proposed for balance checking purposes. An augmented version of the {MW} estimator is developed that has the double robust property, that is, the estimator is consistent, if either the outcome model or the {PS} model is correct. The proposed method is studied in simulations and illustrated through a real data example.},
	number = {2},
	journaltitle = {The International Journal of Biostatistics},
	author = {Li, Liang and Greene, Tom},
	urldate = {2020-03-04},
	date = {2013-01-01},
	langid = {english},
	file = {li_greene_2013_a_weighting_analogue_to_pair_matching_in_propensity_score_analysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/li_greene_2013_a_weighting_analogue_to_pair_matching_in_propensity_score_analysis.pdf:application/pdf}
}

@article{moscoe_regression_2015,
	title = {Regression discontinuity designs are underutilized in medicine, epidemiology, and public health: a review of current and best practice},
	volume = {68},
	issn = {08954356},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0895435614003990},
	doi = {10.1016/j.jclinepi.2014.06.021},
	shorttitle = {Regression discontinuity designs are underutilized in medicine, epidemiology, and public health},
	abstract = {Objectives: Regression discontinuity ({RD}) designs allow for rigorous causal inference when patients receive a treatment based on scoring above or below a cutoff point on a continuously measured variable. We provide an introduction to the theory of {RD} and a systematic review and assessment of the {RD} literature in medicine, epidemiology, and public health. Study Design and Setting: We review the necessary conditions for valid {RD} results, provide a practical guide to {RD} implementation, compare {RD} to other methodologies, and conduct a systematic review of the {RD} literature in {PubMed}.
Results: We describe ﬁve key elements of analysis all {RD} studies should report, including tests of validity conditions and robustness checks. Thirty two empirical {RD} studies in {PubMed} met our selection criteria. Most of the 32 {RD} articles analyzed the effectiveness of social policies or mental health interventions, with only two evaluating clinical interventions to improve physical health. Seven out of the 32 studies reported on all the ﬁve key elements.
Conclusion: Increased use of {RD} provides an exciting opportunity for obtaining unbiased causal effect estimates when experiments are not feasible or when we want to evaluate programs under ‘‘real-life’’ conditions. Although treatment eligibility in medicine, epidemiology, and public health is commonly determined by threshold rules, use of {RD} in these ﬁelds has been very limited until now. Ó 2015 The Authors. Published by Elsevier Inc. This is an open access article under the {CC} {BY}-{NC}-{ND} license (http://creativecommons.org/ licenses/by-nc-nd/3.0/).},
	pages = {132--143},
	number = {2},
	journaltitle = {Journal of Clinical Epidemiology},
	author = {Moscoe, Ellen and Bor, Jacob and Bärnighausen, Till},
	urldate = {2020-03-04},
	date = {2015-02},
	langid = {english},
	file = {moscoe_et_al_2015_regression_discontinuity_designs_are_underutilized_in_medicine,_epidemiology,.pdf:/home/nathan/Dropbox/njames/zotero_sync/moscoe_et_al_2015_regression_discontinuity_designs_are_underutilized_in_medicine,_epidemiology,.pdf:application/pdf}
}

@article{heckman_econometric_2008,
	title = {Econometric Causality},
	volume = {76},
	issn = {1751-5823},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1751-5823.2007.00024.x},
	doi = {10.1111/j.1751-5823.2007.00024.x},
	abstract = {This paper presents the econometric approach to causal modelling. It is motivated by policy problems. New causal parameters are defined and identified to address specific policy problems. Economists embrace a scientific approach to causality and model the preferences and choices of agents to infer subjective (agent) evaluations as well as objective outcomes. Anticipated and realized subjective and objective outcomes are distinguished. Models for simultaneous causality are developed. The paper contrasts the Neyman–Rubin model of causality with the econometric approach.},
	pages = {1--27},
	number = {1},
	journaltitle = {International Statistical Review},
	author = {Heckman, James J.},
	urldate = {2020-03-04},
	date = {2008},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1751-5823.2007.00024.x},
	keywords = {anticipated vs. realized outcomes, Causality, counterfactuals, econometrics, Neyman–Rubin model, Roy model, subjective and objective evaluations, treatment effects},
	file = {heckman_2008_econometric_causality.pdf:/home/nathan/Dropbox/njames/zotero_sync/heckman_2008_econometric_causality.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/5NPI5USV/j.1751-5823.2007.00024.html:text/html}
}

@article{vehtari_survey_2012,
	title = {A survey of Bayesian predictive methods for model assessment, selection and comparison},
	volume = {6},
	issn = {1935-7516},
	url = {http://projecteuclid.org/euclid.ssu/1356628931},
	doi = {10.1214/12-SS102},
	abstract = {To date, several methods exist in the statistical literature for model assessment, which purport themselves speciﬁcally as Bayesian predictive methods. The decision theoretic assumptions on which these methods are based are not always clearly stated in the original articles, however. The aim of this survey is to provide a uniﬁed review of Bayesian predictive model assessment and selection methods, and of methods closely related to them. We review the various assumptions that are made in this context and discuss the connections between diﬀerent approaches, with an emphasis on how each method approximates the expected utility of using a Bayesian model for the purpose of predicting future data.},
	pages = {142--228},
	number = {0},
	journaltitle = {Statist. Surv.},
	author = {Vehtari, Aki and Ojanen, Janne},
	urldate = {2020-03-19},
	date = {2012},
	langid = {english},
	file = {vehtari_ojanen_2012_a_survey_of_bayesian_predictive_methods_for_model_assessment,_selection_and.pdf:/home/nathan/Dropbox/njames/zotero_sync/vehtari_ojanen_2012_a_survey_of_bayesian_predictive_methods_for_model_assessment,_selection_and.pdf:application/pdf}
}

@article{chang_bypassing_nodate,
	title = {Bypassing the Curse of Dimensionality: Feasible Multivariate Density Estimation},
	abstract = {Given vector-valued data — \{xt\}Tt=1 — the curse of dimensionality makes nonparametrically estimating the data’s density infeasible when the number of series, D, is large. Because estimators that always converge rapidly do not exist, we construct estimators that converge rapidly most of the time. We adapt ideas from the Bayesian compression literature to represent the density as a parsimonious mixture. For a finite number of periods, T , the number of mixture components is random. We bound this variable as a function of T with high probability. We adopt the nonparametric Bayesian framework, constructing a computationally efficient estimator using Dirichlet processes. The number of mixture co√mponents√governs our model’s complexity, and our e√stimator’s convergence rates — log(T )/ T in the unconditional case and log(T )/ T in the conditional case — depend on D only through the constant term. We show our procedure produces a well-calibrated joint predictive density for a monthly macroeconomic panel.},
	pages = {74},
	author = {Chang, Minsu and Sangrey, Paul},
	langid = {english},
	file = {chang_sangrey_bypassing_the_curse_of_dimensionality.pdf:/home/nathan/Dropbox/njames/zotero_sync/chang_sangrey_bypassing_the_curse_of_dimensionality.pdf:application/pdf}
}

@article{albert_bayesian_2020,
	title = {Bayesian Computing in the Statistics and Data Science Curriculum},
	url = {http://arxiv.org/abs/2002.09716},
	abstract = {Bayesian statistics has gained great momentum since the computational developments of the 1990s. Gradually, advances in Bayesian methodology and software have made Bayesian techniques much more accessible to applied statisticians and, in turn, have transformed Bayesian education at the undergraduate and graduate levels. In this article, we introduce the history behind Bayesian computing, discuss the important role of simulation, and lay out the foundation of Markov chain Monte Carlo. We further survey and weigh various options for implementing Bayesian computational methods in practice. We conclude with computing recommendations for diﬀerent models of the modern Bayesian classroom, from introductory applied courses to advanced courses with more emphasis on theory.},
	journaltitle = {{arXiv}:2002.09716 [stat]},
	author = {Albert, Jim and Hu, Jingchen},
	urldate = {2020-03-25},
	date = {2020-02-22},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2002.09716},
	keywords = {Statistics - Computation},
	file = {albert_hu_2020_bayesian_computing_in_the_statistics_and_data_science_curriculum.pdf:/home/nathan/Dropbox/njames/zotero_sync/albert_hu_2020_bayesian_computing_in_the_statistics_and_data_science_curriculum.pdf:application/pdf}
}

@article{daniel_methods_2013,
	title = {Methods for dealing with time-dependent confounding},
	volume = {32},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.5686},
	doi = {10.1002/sim.5686},
	pages = {1584--1618},
	number = {9},
	journaltitle = {Statist. Med.},
	author = {Daniel, R.M. and Cousens, S.N. and De Stavola, B.L. and Kenward, M. G. and Sterne, J. A. C.},
	urldate = {2020-03-31},
	date = {2013-04-30},
	langid = {english},
	file = {daniel_et_al_2013_methods_for_dealing_with_time-dependent_confounding.pdf:/home/nathan/Dropbox/njames/zotero_sync/daniel_et_al_2013_methods_for_dealing_with_time-dependent_confounding.pdf:application/pdf}
}

@article{vehtari_expectation_nodate,
	title = {Expectation Propagation as a Way of Life: A Framework for Bayesian Inference on Partitioned Data},
	abstract = {A common divide-and-conquer approach for Bayesian computation with big data is to partition the data, perform local inference for each piece separately, and combine the results to obtain a global posterior approximation. While being conceptually and computationally appealing, this method involves the problematic need to also split the prior for the local inferences; these weakened priors may not provide enough regularization for each separate computation, thus eliminating one of the key advantages of Bayesian methods. To resolve this dilemma while still retaining the generalizability of the underlying local inference method, we apply the idea of expectation propagation ({EP}) as a framework for distributed Bayesian inference. The central idea is to iteratively update approximations to the local likelihoods given the state of the other approximations and the prior.},
	pages = {54},
	author = {Vehtari, Aki and Gelman, Andrew and Sivula, Tuomas and Jylänki, Pasi and Tran, Dustin and Sahai, Swupnil and Blomstedt, Paul and Cunningham, John P and Schiminovich, David and Robert, Christian P},
	langid = {english},
	file = {vehtari_et_al_expectation_propagation_as_a_way_of_life.pdf:/home/nathan/Dropbox/njames/zotero_sync/vehtari_et_al_expectation_propagation_as_a_way_of_life.pdf:application/pdf}
}

@article{betancourt_bayesian_2010,
	title = {A Bayesian Approach To Histogram Comparison},
	url = {http://arxiv.org/abs/1009.5604},
	abstract = {Determining if two histograms are consistent, whether they have been drawn from the same underlying distribution or not, is a common problem in physics. Existing approaches are not only limited in power but also inapplicable to histograms ﬁlled with importance weights, a common feature of Monte Carlo simulations. From a Bayesian perspective, the comparison between a single underlying distribution and two underlying distributions is readily solved within the context of model comparison. I introduce an implementation of Bayesian model comparison to the problem, including the extension to importance sampling.},
	journaltitle = {{arXiv}:1009.5604 [physics]},
	author = {Betancourt, M. J.},
	urldate = {2020-03-31},
	date = {2010-09-28},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1009.5604},
	keywords = {Physics - Data Analysis, Statistics and Probability},
	file = {betancourt_2010_a_bayesian_approach_to_histogram_comparison.pdf:/home/nathan/Dropbox/njames/zotero_sync/betancourt_2010_a_bayesian_approach_to_histogram_comparison.pdf:application/pdf}
}

@article{betancourt_cruising_2012,
	title = {Cruising The Simplex: Hamiltonian Monte Carlo and the Dirichlet Distribution},
	url = {http://arxiv.org/abs/1010.3436},
	doi = {10.1063/1.3703631},
	shorttitle = {Cruising The Simplex},
	abstract = {Due to its constrained support, the Dirichlet distribution is uniquely suited to many applications. The constraints that make it powerful, however, can also hinder practical implementations, particularly those utilizing Markov Chain Monte Carlo ({MCMC}) techniques such as Hamiltonian Monte Carlo. I demonstrate a series of transformations that reshape the canonical Dirichlet distribution into a form much more amenable to {MCMC} algorithms.},
	pages = {157--164},
	journaltitle = {{arXiv}:1010.3436 [physics]},
	author = {Betancourt, M. J.},
	urldate = {2020-03-31},
	date = {2012},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1010.3436},
	keywords = {Physics - Data Analysis, Statistics and Probability},
	file = {betancourt_2012_cruising_the_simplex.pdf:/home/nathan/Dropbox/njames/zotero_sync/betancourt_2012_cruising_the_simplex.pdf:application/pdf}
}

@article{santanna_doubly_2018,
	title = {Doubly Robust Difference-in-Differences Estimators},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=3293315},
	doi = {10.2139/ssrn.3293315},
	abstract = {This article proposes doubly robust estimators for the average treatment eﬀect on the treated ({ATT}) in diﬀerence-in-diﬀerences ({DID}) research designs. In contrast to alternative {DID} estimators, the proposed estimators are consistent if either (but not necessarily both) a propensity score or outcome regression working models are correctly speciﬁed. We also derive the semiparametric eﬃciency bound for the {ATT} in {DID} designs when either panel or repeated cross-section data are available, and show that our proposed estimators attain the semiparametric eﬃciency bound when the working models are correctly speciﬁed. Furthermore, we quantify the potential eﬃciency gains of having access to panel data instead of repeated cross-section data. Finally, by paying particular attention to the estimation method used to estimate the nuisance parameters, we show that one can sometimes construct doubly robust {DID} estimators for the {ATT} that are also doubly robust for inference. Simulation studies and an empirical application illustrate the desirable ﬁnite-sample performance of the proposed estimators. Open-source software for implementing the proposed policy evaluation tools is available.},
	journaltitle = {{SSRN} Journal},
	author = {Sant'Anna, Pedro H. C. and Zhao, Jun B.},
	urldate = {2020-04-07},
	date = {2018},
	langid = {english},
	file = {sant'anna_zhao_2018_doubly_robust_difference-in-differences_estimators.pdf:/home/nathan/Dropbox/njames/zotero_sync/sant'anna_zhao_2018_doubly_robust_difference-in-differences_estimators.pdf:application/pdf}
}

@article{santanna_doubly_nodate,
	title = {Doubly Robust Diﬀerence-in-Diﬀerences Estimators: Supplemental Appendix},
	pages = {27},
	author = {Sant’Anna, Pedro H C and Zhao, Jun B},
	langid = {english},
	file = {sant’anna_zhao_doubly_robust_diﬀerence-in-diﬀerences_estimators.pdf:/home/nathan/Dropbox/njames/zotero_sync/sant’anna_zhao_doubly_robust_diﬀerence-in-diﬀerences_estimators.pdf:application/pdf}
}

@article{robins_marginal_2000,
	title = {Marginal Structural Models and Causal Inference in Epidemiology:},
	volume = {11},
	issn = {1044-3983},
	url = {http://journals.lww.com/00001648-200009000-00011},
	doi = {10.1097/00001648-200009000-00011},
	shorttitle = {Marginal Structural Models and Causal Inference in Epidemiology},
	pages = {550--560},
	number = {5},
	journaltitle = {Epidemiology},
	author = {Robins, James M. and Hernán, Miguel Ángel and Brumback, Babette},
	urldate = {2020-04-09},
	date = {2000-09},
	langid = {english},
	file = {robins_et_al_2000_marginal_structural_models_and_causal_inference_in_epidemiology.pdf:/home/nathan/Dropbox/njames/zotero_sync/robins_et_al_2000_marginal_structural_models_and_causal_inference_in_epidemiology.pdf:application/pdf}
}

@article{hernan_marginal_2000,
	title = {Marginal Structural Models to Estimate the Causal Effect of Zidovudine on the Survival of {HIV}-Positive Men:},
	volume = {11},
	issn = {1044-3983},
	url = {http://journals.lww.com/00001648-200009000-00012},
	doi = {10.1097/00001648-200009000-00012},
	shorttitle = {Marginal Structural Models to Estimate the Causal Effect of Zidovudine on the Survival of {HIV}-Positive Men},
	pages = {561--570},
	number = {5},
	journaltitle = {Epidemiology},
	author = {Hernán, Miguel Ángel and Brumback, Babette and Robins, James M.},
	urldate = {2020-04-09},
	date = {2000-09},
	langid = {english},
	file = {hernán_et_al_2000_marginal_structural_models_to_estimate_the_causal_effect_of_zidovudine_on_the.pdf:/home/nathan/Dropbox/njames/zotero_sync/hernán_et_al_2000_marginal_structural_models_to_estimate_the_causal_effect_of_zidovudine_on_the.pdf:application/pdf}
}

@article{hernan_comparison_2006,
	title = {Comparison of Dynamic Treatment Regimes via Inverse Probability Weighting},
	volume = {98},
	issn = {1742-7843},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/j.1742-7843.2006.pto_329.x},
	doi = {10.1111/j.1742-7843.2006.pto_329.x},
	abstract = {Abstract: Appropriate analysis of observational data is our best chance to obtain answers to many questions that involve dynamic treatment regimes. This paper describes a simple method to compare dynamic treatment regimes by artificially censoring subjects and then using inverse probability weighting ({IPW}) to adjust for any selection bias introduced by the artificial censoring. The basic strategy can be summarized in four steps: 1) define two regimes of interest, 2) artificially censor individuals when they stop following one of the regimes of interest, 3) estimate inverse probability weights to adjust for the potential selection bias introduced by censoring in the previous step, 4) compare the survival of the uncensored individuals under each regime of interest by fitting an inverse probability weighted Cox proportional hazards model with the dichotomous regime indicator and the baseline confounders as covariates. In the absence of model misspecification, the method is valid provided data are available on all time-varying and baseline joint predictors of survival and regime discontinuation. We present an application of the method to compare the {AIDS}-free survival under two dynamic treatment regimes in a large prospective study of {HIV}-infected patients. The paper concludes by discussing the relative advantages and disadvantages of censoring/{IPW} versus g-estimation of nested structural models to compare dynamic regimes.},
	pages = {237--242},
	number = {3},
	journaltitle = {Basic \& Clinical Pharmacology \& Toxicology},
	author = {Hernán, Miguel A. and Lanoy, Emilie and Costagliola, Dominique and Robins, James M.},
	urldate = {2020-04-13},
	date = {2006},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1742-7843.2006.pto\_329.x},
	file = {hernán_et_al_2006_comparison_of_dynamic_treatment_regimes_via_inverse_probability_weighting.pdf:/home/nathan/Dropbox/njames/zotero_sync/hernán_et_al_2006_comparison_of_dynamic_treatment_regimes_via_inverse_probability_weighting.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/5L38YGI2/j.1742-7843.2006.pto_329.html:text/html}
}

@article{cain_when_2010,
	title = {When to Start Treatment? A Systematic Approach to the Comparison of Dynamic Regimes Using Observational Data},
	volume = {6},
	issn = {1557-4679},
	url = {https://www.degruyter.com/view/j/ijb.2010.6.2/ijb.2010.6.2.1212/ijb.2010.6.2.1212.xml},
	doi = {10.2202/1557-4679.1212},
	shorttitle = {When to Start Treatment?},
	abstract = {Dynamic treatment regimes are the type of regime most commonly used in clinical practice. For example, physicians may initiate combined antiretroviral therapy the first time an individual's recorded {CD}4 cell count drops below either 500 cells/mm3 or 350 cells/mm3. This paper describes an approach for using observational data to emulate randomized clinical trials that compare dynamic regimes of the form “initiate treatment within a certain time period of some time-varying covariate first crossing a particular threshold." We applied this method to data from the French Hospital database on {HIV} ({FHDH}-{ANRS} {CO}4), an observational study of {HIV}-infected patients, in order to compare dynamic regimes of the form “initiate treatment within m months after the recorded {CD}4 cell count first drops below x cells/mm3" where x takes values from 200 to 500 in increments of 10 and m takes values 0 or 3. We describe the method in the context of this example and discuss some complications that arise in emulating a randomized experiment using observational data.},
	number = {2},
	journaltitle = {The International Journal of Biostatistics},
	author = {Cain, Lauren E. and Robins, James M. and Lanoy, Emilie and Logan, Roger and Costagliola, Dominique and Hernán, Miguel A.},
	urldate = {2020-04-13},
	date = {2010-01-13},
	langid = {english},
	file = {cain_et_al_2010_when_to_start_treatment.pdf:/home/nathan/Dropbox/njames/zotero_sync/cain_et_al_2010_when_to_start_treatment.pdf:application/pdf}
}

@article{shepherd_estimating_2010,
	title = {Estimating the Optimal {CD}4 Count for {HIV}-infected Persons to Start Antiretroviral Therapy:},
	volume = {21},
	issn = {1044-3983},
	url = {http://journals.lww.com/00001648-201009000-00024},
	doi = {10.1097/EDE.0b013e3181e97737},
	shorttitle = {Estimating the Optimal {CD}4 Count for {HIV}-infected Persons to Start Antiretroviral Therapy},
	abstract = {Background—Optimal timing of antiretroviral therapy in {HIV}-infected persons is unclear, although two recent large observational studies have improved our understanding of the best {CD}4 threshold for initiation. These studies compared the effect of starting {HAART} on mortality and mortality/{AIDS} between strata defined using broad ranges of {CD}4 counts. We sought to expand this understanding using a novel statistical approach proposed by Robins and colleagues.
Methods—Using observational data from 1034 antiretroviral-naïve {HIV}-infected patients from Nashville, Tennessee, we directly estimated the optimal {CD}4 count for initiation of {HAART} to maximize patient health 6, 12, 24, and 36 months after the first instance of {CD}4 falling below 750. We measured health using two outcome metrics, one based on {CD}4 counts at the end of follow-up and the other based on a published quality-of-life scale; both metrics incorporated death, {AIDSdefining} events, serious non-{AIDS} events, and {CD}4 at the end of follow-up if asymptomatic.
Results—The {CD}4-based metric estimated that to maximize health 6, 12, 24, and 36 months after study entry, {HAART} should be initiated within 3 months of {CD}4 first dropping below 495 (95\% confidence interval [{CI}] = 468 – 522), 554 (459 – 750), 489 (427 – 750), and 509 (460 –750), respectively. The quality-of-life-based metric produced {CD}4 initiation threshold estimates of 337 (95\% {CI} = 201–442), 354 (288 – 386), 358 (294 – 750), and 475 (287 – 750) for the same time points.
Conclusions—Our results support early initiation of antiretroviral therapy, although the criterion for starting therapy depends on the choice of health outcome.},
	pages = {698--705},
	number = {5},
	journaltitle = {Epidemiology},
	author = {Shepherd, Bryan E. and Jenkins, Cathy A. and Rebeiro, Peter F. and Stinnette, Samuel E. and Bebawy, Sally S. and {McGowan}, Catherine C. and Hulgan, Todd and Sterling, Timothy R.},
	urldate = {2020-04-13},
	date = {2010-09},
	langid = {english},
	file = {shepherd_et_al_2010_estimating_the_optimal_cd4_count_for_hiv-infected_persons_to_start.pdf:/home/nathan/Dropbox/njames/zotero_sync/shepherd_et_al_2010_estimating_the_optimal_cd4_count_for_hiv-infected_persons_to_start.pdf:application/pdf}
}

@article{shepherd_comparing_2016,
	title = {Comparing results from multiple imputation and dynamic marginal structural models for estimating when to start antiretroviral therapy},
	volume = {35},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7007},
	doi = {10.1002/sim.7007},
	abstract = {Optimal timing of initiating antiretroviral therapy has been a controversial topic in {HIV} research. Two highly publicized studies applied different analytical approaches, a dynamic marginal structural model and a multiple imputation method, to different observational databases and came up with different conclusions. Discrepancies between the two studies' results could be due to differences between patient populations, fundamental differences between statistical methods, or differences between implementation details. For example, the two studies adjusted for different covariates, compared different thresholds, and had different criteria for qualifying measurements. If both analytical approaches were applied to the same cohort holding technical details constant, would their results be similar? In this study, we applied both statistical approaches using observational data from 12,708 {HIV}-infected persons throughout the {USA}. We held technical details constant between the two methods and then repeated analyses varying technical details to understand what impact they had on findings. We also present results applying both approaches to simulated data. Results were similar, although not identical, when technical details were held constant between the two statistical methods. Confidence intervals for the dynamic marginal structural model tended to be wider than those from the imputation approach, although this may have been due in part to additional external data used in the imputation analysis. We also consider differences in the estimands, required data, and assumptions of the two statistical methods. Our study provides insights into assessing optimal dynamic treatment regimes in the context of starting antiretroviral therapy and in more general settings. Copyright © 2016 John Wiley \& Sons, Ltd.},
	pages = {4335--4351},
	number = {24},
	journaltitle = {Statistics in Medicine},
	author = {Shepherd, Bryan E. and Liu, Qi and Mercaldo, Nathaniel and Jenkins, Cathy A. and Lau, Bryan and Cole, Stephen R. and Saag, Michael S. and Sterling, Timothy R.},
	urldate = {2020-04-13},
	date = {2016},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.7007},
	keywords = {causal inference, dynamic marginal structural models, {HIV}/{AIDS}, multiple imputation, survival analysis},
	file = {shepherd_et_al_2016_comparing_results_from_multiple_imputation_and_dynamic_marginal_structural.pdf:/home/nathan/Dropbox/njames/zotero_sync/shepherd_et_al_2016_comparing_results_from_multiple_imputation_and_dynamic_marginal_structural.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/R3TPBFKN/sim.html:text/html}
}

@article{schuler_targeted_2017,
	title = {Targeted Maximum Likelihood Estimation for Causal Inference in Observational Studies},
	volume = {185},
	issn = {0002-9262, 1476-6256},
	url = {https://academic.oup.com/aje/article-lookup/doi/10.1093/aje/kww165},
	doi = {10.1093/aje/kww165},
	pages = {65--73},
	number = {1},
	journaltitle = {Am. J. Epidemiol.},
	author = {Schuler, Megan S. and Rose, Sherri},
	urldate = {2020-04-13},
	date = {2017-01-01},
	langid = {english},
	file = {schuler_rose_2017_targeted_maximum_likelihood_estimation_for_causal_inference_in_observational.pdf:/home/nathan/Dropbox/njames/zotero_sync/schuler_rose_2017_targeted_maximum_likelihood_estimation_for_causal_inference_in_observational.pdf:application/pdf}
}

@article{burridge_note_1981,
	title = {A Note on Maximum Likelihood Estimation for Regression Models Using Grouped Data},
	volume = {43},
	issn = {00359246},
	url = {http://doi.wiley.com/10.1111/j.2517-6161.1981.tb01146.x},
	doi = {10.1111/j.2517-6161.1981.tb01146.x},
	abstract = {The estimation of parameters for a class of regression models using grouped or censored data is considered. It is shown that with a simple reparameterization some commonly used distributions, such as the normal and extreme value, result in a log-likelihood which is concave with respect to the transformed parameters. Apart from its theoretical implications for the existence and uniqueness of maximum likelihood estimates, this result suggests minor changes to some commonly used algorithms for maximum likelihood estimation from grouped data. Two simple examples are given.},
	pages = {41--45},
	number = {1},
	journaltitle = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Burridge, J.},
	urldate = {2020-04-15},
	date = {1981-09},
	langid = {english},
	file = {burridge_1981_a_note_on_maximum_likelihood_estimation_for_regression_models_using_grouped_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/burridge_1981_a_note_on_maximum_likelihood_estimation_for_regression_models_using_grouped_data.pdf:application/pdf}
}

@article{noauthor_concavity_nodate,
	title = {Concavity of the Log Likelihood},
	pages = {5},
	langid = {english},
	file = {concavity_of_the_log_likelihood.pdf:/home/nathan/Dropbox/njames/zotero_sync/concavity_of_the_log_likelihood.pdf:application/pdf}
}

@article{dardanoni_unified_1998,
	title = {A Unified Approach to Likelihood Inference on Stochastic Orderings in a Nonparametric Context},
	volume = {93},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/full/10.1080/01621459.1998.10473772},
	doi = {10.1080/01621459.1998.10473772},
	pages = {1112--1123},
	number = {443},
	journaltitle = {Journal of the American Statistical Association},
	author = {Dardanoni, Valentino and Forcina, Antonio},
	urldate = {2020-04-15},
	date = {1998-09},
	langid = {english},
	file = {dardanoni_forcina_1998_a_unified_approach_to_likelihood_inference_on_stochastic_orderings_in_a.pdf:/home/nathan/Dropbox/njames/zotero_sync/dardanoni_forcina_1998_a_unified_approach_to_likelihood_inference_on_stochastic_orderings_in_a.pdf:application/pdf}
}

@article{dawid_causal_2000,
	title = {Causal Inference without Counterfactuals},
	volume = {95},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2000.10474210},
	doi = {10.1080/01621459.2000.10474210},
	pages = {407--424},
	number = {450},
	journaltitle = {Journal of the American Statistical Association},
	author = {Dawid, A. P.},
	urldate = {2020-04-21},
	date = {2000-06},
	langid = {english},
	file = {casella_schwartz_comment.pdf:/home/nathan/Dropbox/njames/zotero_sync/casella_schwartz_comment.pdf:application/pdf;cox_2000_comment.pdf:/home/nathan/Dropbox/njames/zotero_sync/cox_2000_comment.pdf:application/pdf;dawid_2000_causal_inference_without_counterfactuals.pdf:/home/nathan/Dropbox/njames/zotero_sync/dawid_2000_causal_inference_without_counterfactuals.pdf:application/pdf;dawid_2000_rejoinder.pdf:/home/nathan/Dropbox/njames/zotero_sync/dawid_2000_rejoinder.pdf:application/pdf;pearl_comment.pdf:/home/nathan/Dropbox/njames/zotero_sync/pearl_comment.pdf:application/pdf;robins_greenland_comment.pdf:/home/nathan/Dropbox/njames/zotero_sync/robins_greenland_comment.pdf:application/pdf;rubin_comment.pdf:/home/nathan/Dropbox/njames/zotero_sync/rubin_comment.pdf:application/pdf;shafer_comment.pdf:/home/nathan/Dropbox/njames/zotero_sync/shafer_comment.pdf:application/pdf;wasserman_2000_comment.pdf:/home/nathan/Dropbox/njames/zotero_sync/wasserman_2000_comment.pdf:application/pdf}
}

@article{cox_comment_2000,
	title = {Comment},
	volume = {95},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2000.10474211},
	doi = {10.1080/01621459.2000.10474211},
	pages = {424--425},
	number = {450},
	journaltitle = {Journal of the American Statistical Association},
	author = {Cox, D. R.},
	urldate = {2020-04-21},
	date = {2000-06},
	langid = {english}
}

@article{noauthor_casella_nodate,
	title = {Casella Schwartz comment},
	pages = {4},
	langid = {english}
}

@article{noauthor_pearl_nodate,
	title = {Pearl Comment},
	pages = {5},
	langid = {english}
}

@article{noauthor_robins_nodate,
	title = {Robins Greenland Comment},
	pages = {6},
	langid = {english}
}

@article{noauthor_rubin_nodate,
	title = {Rubin Comment},
	pages = {5},
	langid = {english}
}

@article{noauthor_shafer_nodate,
	title = {Shafer Comment},
	pages = {6},
	langid = {english}
}

@article{wasserman_comment_2000,
	title = {Comment},
	volume = {95},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2000.10474217},
	doi = {10.1080/01621459.2000.10474217},
	pages = {442--443},
	number = {450},
	journaltitle = {Journal of the American Statistical Association},
	author = {Wasserman, Larry},
	urldate = {2020-04-21},
	date = {2000-06},
	langid = {english}
}

@article{dawid_rejoinder_2000,
	title = {Rejoinder},
	volume = {95},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2000.10474218},
	doi = {10.1080/01621459.2000.10474218},
	pages = {444--448},
	number = {450},
	journaltitle = {Journal of the American Statistical Association},
	author = {Dawid, A. P.},
	urldate = {2020-04-21},
	date = {2000-06},
	langid = {english}
}

@article{hernan_c-word_2018,
	title = {The C-Word: Scientific Euphemisms Do Not Improve Causal Inference From Observational Data},
	volume = {108},
	issn = {0090-0036, 1541-0048},
	url = {http://ajph.aphapublications.org/doi/10.2105/AJPH.2018.304337},
	doi = {10.2105/AJPH.2018.304337},
	shorttitle = {The C-Word},
	pages = {616--619},
	number = {5},
	journaltitle = {Am J Public Health},
	author = {Hernán, Miguel A.},
	urldate = {2020-04-21},
	date = {2018-05},
	langid = {english},
	file = {hernán_2018_the_c-word.pdf:/home/nathan/Dropbox/njames/zotero_sync/hernán_2018_the_c-word.pdf:application/pdf}
}

@article{choi_development_2020,
	title = {Development of a System for Postmarketing Population Pharmacokinetic and Pharmacodynamic Studies Using Real‐World Data From Electronic Health Records},
	volume = {107},
	issn = {0009-9236, 1532-6535},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpt.1787},
	doi = {10.1002/cpt.1787},
	pages = {934--943},
	number = {4},
	journaltitle = {Clin. Pharmacol. Ther.},
	author = {Choi, Leena and Beck, Cole and {McNeer}, Elizabeth and Weeks, Hannah L. and Williams, Michael L. and James, Nathan T. and Niu, Xinnan and Abou‐Khalil, Bassel W. and Birdwell, Kelly A. and Roden, Dan M. and Stein, C. Michael and Bejan, Cosmin A. and Denny, Joshua C. and Van Driest, Sara L.},
	urldate = {2020-04-30},
	date = {2020-04},
	langid = {english},
	file = {choi_et_al_2020_development_of_a_system_for_postmarketing_population_pharmacokinetic_and.pdf:/home/nathan/Dropbox/njames/zotero_sync/choi_et_al_2020_development_of_a_system_for_postmarketing_population_pharmacokinetic_and.pdf:application/pdf}
}

@article{gelman_beyond_2017,
	title = {Beyond subjective and objective in statistics},
	volume = {180},
	issn = {09641998},
	url = {http://doi.wiley.com/10.1111/rssa.12276},
	doi = {10.1111/rssa.12276},
	abstract = {Decisions in statistical data analysis are often justiﬁed, criticized or avoided by using concepts of objectivity and subjectivity. We argue that the words ‘objective’ and ‘subjective’ in statistics discourse are used in a mostly unhelpful way, and we propose to replace each of them with broader collections of attributes, with objectivity replaced by transparency , consensus, impartiality and correspondence to observable reality , and subjectivity replaced by awareness of multiple perspectives and context dependence. Together with stability , these make up a collection of virtues that we think is helpful in discussions of statistical foundations and practice. The advantage of these reformulations is that the replacement terms do not oppose each other and that they give more speciﬁc guidance about what statistical science strives to achieve. Instead of debating over whether a given statistical method is subjective or objective (or normatively debating the relative merits of subjectivity and objectivity in statistical practice), we can recognize desirable attributes such as transparency and acknowledgement of multiple perspectives as complementary goals. We demonstrate the implications of our proposal with recent applied examples from pharmacology, election polling and socio-economic stratiﬁcation. The aim of the paper is to push users and developers of statistical methods towards more effective use of diverse sources of information and more open acknowledgement of assumptions and goals.},
	pages = {967--1033},
	number = {4},
	journaltitle = {J. R. Stat. Soc. A},
	author = {Gelman, Andrew and Hennig, Christian},
	urldate = {2020-05-01},
	date = {2017-10},
	langid = {english},
	file = {gelman_hennig_2017_beyond_subjective_and_objective_in_statistics.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_hennig_2017_beyond_subjective_and_objective_in_statistics.pdf:application/pdf}
}

@article{gershman_tutorial_2011,
	title = {A Tutorial on Bayesian Nonparametric Models},
	url = {http://arxiv.org/abs/1106.2697},
	abstract = {A key problem in statistical modeling is model selection, how to choose a model at an appropriate level of complexity. This problem appears in many settings, most prominently in choosing the number of clusters in mixture models or the number of factors in factor analysis. In this tutorial we describe Bayesian nonparametric methods, a class of methods that side-steps this issue by allowing the data to determine the complexity of the model. This tutorial is a high-level introduction to Bayesian nonparametric methods and contains several examples of their application.},
	journaltitle = {{arXiv}:1106.2697 [stat]},
	author = {Gershman, Samuel J. and Blei, David M.},
	urldate = {2020-05-01},
	date = {2011-08-04},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1106.2697},
	keywords = {Statistics - Methodology, Statistics - Machine Learning},
	file = {gershman_blei_2011_a_tutorial_on_bayesian_nonparametric_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/gershman_blei_2011_a_tutorial_on_bayesian_nonparametric_models.pdf:application/pdf}
}

@article{orbanz_bayesian_nodate,
	title = {Bayesian Nonparametric Models},
	pages = {14},
	author = {Orbanz, Peter and Teh, Yee Whye},
	langid = {english},
	file = {orbanz_teh_bayesian_nonparametric_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/orbanz_teh_bayesian_nonparametric_models.pdf:application/pdf}
}

@article{stolley_when_1991,
	title = {When Genius Errs: R. A. Fisher and the Lung Cancer Controversy},
	volume = {133},
	issn = {1476-6256, 0002-9262},
	url = {https://academic.oup.com/aje/article/60062/When},
	doi = {10.1093/oxfordjournals.aje.a115904},
	shorttitle = {When Genius Errs},
	pages = {416--425},
	number = {5},
	journaltitle = {American Journal of Epidemiology},
	author = {Stolley, Paul D.},
	urldate = {2020-06-07},
	date = {1991-03-01},
	langid = {english},
	file = {stolley_1991_when_genius_errs.pdf:/home/nathan/Dropbox/njames/zotero_sync/stolley_1991_when_genius_errs.pdf:application/pdf}
}

@article{wynder_re_1991,
	title = {{RE}: “{WHEN} {GENIUS} {ERRS}: R. A. {FISHER} {AND} {THE} {LUNG} {CANCER} {CONTROVERSY}”},
	volume = {134},
	issn = {1476-6256, 0002-9262},
	url = {https://academic.oup.com/aje/article/131022/RE:},
	doi = {10.1093/oxfordjournals.aje.a116055},
	shorttitle = {{RE}},
	pages = {1467--1469},
	number = {12},
	journaltitle = {American Journal of Epidemiology},
	author = {Wynder, Ernst L.},
	urldate = {2020-06-07},
	date = {1991-12-15},
	langid = {english},
	file = {wynder_1991_re.pdf:/home/nathan/Dropbox/njames/zotero_sync/wynder_1991_re.pdf:application/pdf}
}

@article{tuyl_note_2017,
	title = {A Note on Priors for the Multinomial Model},
	volume = {71},
	issn = {0003-1305, 1537-2731},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2016.1222309},
	doi = {10.1080/00031305.2016.1222309},
	abstract = {An “overall objective” prior proposed for the multinomial model is shown to be inadequate in the presence of zero counts. An earlier proposed reference prior for when interest is in a particular category suffers from similar problems. It is argued that there is no need to deviate from the uniform prior proposed by Jeffreys, for which links with a non-Bayesian approach, when prediction is of interest, are shown.},
	pages = {298--301},
	number = {4},
	journaltitle = {The American Statistician},
	author = {Tuyl, Frank},
	urldate = {2020-06-08},
	date = {2017-10-02},
	langid = {english},
	file = {tuyl_2017_a_note_on_priors_for_the_multinomial_model.pdf:/home/nathan/Dropbox/njames/zotero_sync/tuyl_2017_a_note_on_priors_for_the_multinomial_model.pdf:application/pdf}
}

@article{casey_rationale_2020,
	title = {Rationale and Design of {ORCHID}: A Randomized Placebo-Controlled Trial of Hydroxychloroquine for Adults Hospitalized with {COVID}-19},
	issn = {2329-6933, 2325-6621},
	url = {https://www.atsjournals.org/doi/10.1513/AnnalsATS.202005-478SD},
	doi = {10.1513/AnnalsATS.202005-478SD},
	shorttitle = {Rationale and Design of {ORCHID}},
	abstract = {The Outcomes Related to {COVID}-19 treated with Hydroxychloroquine among In-patients with symptomatic Disease ({ORCHID}) trial is a multicenter, blinded, randomized trial of hydroxychloroquine versus placebo for the treatment of adults hospitalized with {COVID}-19. This document provides the rationale and background for the trial and highlights key design features. We discuss five novel challenges to the design and conduct of a large, multi-center, randomized trial during a pandemic, including: 1) widespread, off-label use of the study drug before the availability of safety and efficacy data; 2) the need to adapt traditional procedures for documentation of informed consent during an infectious pandemic; 3) developing a flexible and robust Bayesian analysis incorporating significant uncertainty about the disease, outcomes, and treatment; 4) obtaining indistinguishable drug and placebo without delaying enrollment; and 5) rapidly obtaining administrative and regulatory approvals. Our goals in describing how the {ORCHID} trial progressed from study conception to enrollment of the first patient in 15 days are to inform the development of other high-quality, multi-center trials targeting {COVID}-19. We describe lessons learned to improve the efficiency of future clinical trials, particularly in the setting of pandemics. The {ORCHID} trial will provide high-quality, clinically relevant data on the safety and efficacy of hydroxychloroquine for the treatment of {COVID}-19 among hospitalized adults. This trial was registered with {ClinicalTrials}.gov ({NCT}04332991) prior to enrollment of the first patient on April 2, 2020.},
	pages = {AnnalsATS.202005--478SD},
	journaltitle = {Annals {ATS}},
	author = {Casey, Jonathan D and Johnson, Nicholas J and Semler, Matthew W and Collins, Sean P and Aggarwal, Neil R and Brower, Roy G and Chang, Steven Y and Eppensteiner, John and Filbin, Michael and Gibbs, Kevin W and Ginde, Adit A and Gong, Michelle N and Harrell, Frank and Hayden, Douglas L and Hough, Catherine L and Khan, Akram and Leither, Lindsay M and Moss, Marc and Oldmixon, Cathryn F. and Park, Pauline K and Reineck, Lora A. and Ringwood, Nancy J and Robinson, Bryce RH and Schoenfeld, David A and Shapiro, Nathan I and Steingrub, Jay S and Torr, Donna K and Weissman, Alexandra and Lindsell, Christopher J and Rice, Todd W and Thompson, B. Taylor and Brown, Samuel M and Self, Wesley H and {the ORCHID Protocol Committee and the National Heart, Lung and Blood Institute Prevention and Early Treatment of Acute Lung Injury (PETAL) Network Investigators}},
	urldate = {2020-06-29},
	date = {2020-06-03},
	langid = {english},
	file = {casey_et_al_2020_rationale_and_design_of_orchid.pdf:/home/nathan/Dropbox/njames/zotero_sync/casey_et_al_2020_rationale_and_design_of_orchid.pdf:application/pdf}
}

@article{loaiza-maya_fast_2020,
	title = {Fast and Accurate Variational Inference for Models with Many Latent Variables},
	url = {http://arxiv.org/abs/2005.07430},
	abstract = {Models with a large number of latent variables are often used to fully utilize the information in big or complex data. However, they can be diﬃcult to estimate using standard approaches, and variational inference methods are a popular alternative. Key to the success of these is the selection of an approximation to the target density that is accurate, tractable and fast to calibrate using optimization methods. Mean ﬁeld or structured Gaussian approximations are common, but these can be inaccurate and slow to calibrate when there are many latent variables. Instead, we propose a family of tractable variational approximations that are more accurate and faster to calibrate for this case. The approximation is a parsimonious copula model for the parameter posterior, combined with the exact conditional posterior of the latent variables. We derive a simpliﬁed expression for the re-parameterization gradient of the variational lower bound, which is the main ingredient of eﬃcient optimization algorithms used to implement variational estimation. We illustrate using two substantive econometric examples. The ﬁrst is a nonlinear state space model for U.S. inﬂation. The second is a random coeﬃcients tobit model applied to a rich marketing dataset with one million sales observations from a panel of 10,000 individuals. In both cases, we show that our approximating family is faster to calibrate than either mean ﬁeld or structured Gaussian approximations, and that the gains in posterior estimation accuracy are considerable.},
	journaltitle = {{arXiv}:2005.07430 [econ, stat]},
	author = {Loaiza-Maya, Rubén and Smith, Michael Stanley and Nott, David J. and Danaher, Peter J.},
	urldate = {2020-06-29},
	date = {2020-05-15},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2005.07430},
	keywords = {Statistics - Methodology, Economics - Econometrics, G.3, 62P20},
	file = {loaiza-maya_et_al_2020_fast_and_accurate_variational_inference_for_models_with_many_latent_variables.pdf:/home/nathan/Dropbox/njames/zotero_sync/loaiza-maya_et_al_2020_fast_and_accurate_variational_inference_for_models_with_many_latent_variables.pdf:application/pdf}
}

@article{austin_graphical_nodate,
	title = {Graphical calibration curves and the integrated calibration index ({ICI}) for survival models},
	volume = {n/a},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8570},
	doi = {10.1002/sim.8570},
	abstract = {In the context of survival analysis, calibration refers to the agreement between predicted probabilities and observed event rates or frequencies of the outcome within a given duration of time. We aimed to describe and evaluate methods for graphically assessing the calibration of survival models. We focus on hazard regression models and restricted cubic splines in conjunction with a Cox proportional hazards model. We also describe modifications of the Integrated Calibration Index, of E50 and of E90. In this context, this is the average (respectively, median or 90th percentile) absolute difference between predicted survival probabilities and smoothed survival frequencies. We conducted a series of Monte Carlo simulations to evaluate the performance of these calibration measures when the underlying model has been correctly specified and under different types of model mis-specification. We illustrate the utility of calibration curves and the three calibration metrics by using them to compare the calibration of a Cox proportional hazards regression model with that of a random survival forest for predicting mortality in patients hospitalized with heart failure. Under a correctly specified regression model, differences between the two methods for constructing calibration curves were minimal, although the performance of the method based on restricted cubic splines tended to be slightly better. In contrast, under a mis-specified model, the smoothed calibration curved constructed using hazard regression tended to be closer to the true calibration curve. The use of calibration curves and of these numeric calibration metrics permits for a comprehensive comparison of the calibration of competing survival models.},
	issue = {n/a},
	journaltitle = {Statistics in Medicine},
	author = {Austin, Peter C. and Harrell, Frank E. and Klaveren, David van},
	urldate = {2020-06-29},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8570},
	keywords = {survival analysis, calibration, model validation, random forests, time-to-event model},
	file = {austin_et_al_graphical_calibration_curves_and_the_integrated_calibration_index_(ici)_for.pdf:/home/nathan/Dropbox/njames/zotero_sync/austin_et_al_graphical_calibration_curves_and_the_integrated_calibration_index_(ici)_for.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/7B4NV244/sim.html:text/html}
}

@report{gelman_bayesian_2020,
	title = {Bayesian analysis of tests with unknown specificity and sensitivity},
	url = {http://medrxiv.org/lookup/doi/10.1101/2020.05.22.20108944},
	abstract = {When testing for a rare disease, prevalence estimates can be highly sensitive to uncertainty in the speciﬁcity and sensitivity of the test. Bayesian inference is a natural way to propagate these uncertainties, with hierarchical modeling capturing variation in these parameters across experiments. Another concern is the people in the sample not being representative of the general population. Statistical adjustment cannot without strong assumptions correct for selection bias in an opt-in sample, but multilevel regression and poststratiﬁcation can at least adjust for known diﬀerences between the sample and the population. We demonstrate these models with code in Stan and discuss their application to a controversial recent study of {COVID}-19 antibodies in a sample of people from the Stanford University area. Wide posterior intervals make it impossible to evaluate the quantitative claims of that study regarding the number of unreported infections. For future studies, the methods described here should facilitate more accurate estimates of disease prevalence from imperfect tests performed on non-representative samples.},
	institution = {Epidemiology},
	type = {preprint},
	author = {Gelman, Andrew and Carpenter, Bob},
	urldate = {2020-06-29},
	date = {2020-05-25},
	langid = {english},
	doi = {10.1101/2020.05.22.20108944},
	file = {gelman_carpenter_2020_bayesian_analysis_of_tests_with_unknown_specificity_and_sensitivity.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelman_carpenter_2020_bayesian_analysis_of_tests_with_unknown_specificity_and_sensitivity.pdf:application/pdf}
}

@article{yao_stacking_2020,
	title = {Stacking for Non-mixing Bayesian Computations: The Curse and Blessing of Multimodal Posteriors},
	url = {http://arxiv.org/abs/2006.12335},
	shorttitle = {Stacking for Non-mixing Bayesian Computations},
	abstract = {When working with multimodal Bayesian posterior distributions, Markov chain Monte Carlo ({MCMC}) algorithms can have diﬃculty moving between modes, and default variational or mode-based approximate inferences will understate posterior uncertainty. And, even if the most important modes can be found, it is diﬃcult to evaluate their relative weights in the posterior. Here we propose an alternative approach, using parallel runs of {MCMC}, variational, or mode-based inference to hit as many modes or separated regions as possible, and then combining these using importance sampling based Bayesian stacking, a scalable method for constructing a weighted average of distributions so as to maximize cross-validated prediction utility. The result from stacking is not necessarily equivalent, even asymptotically, to fully Bayesian inference, but it serves many of the same goals. Under misspeciﬁed models, stacking can give better predictive performance than full Bayesian inference, hence the multimodality can be considered a blessing rather than a curse.},
	journaltitle = {{arXiv}:2006.12335 [stat]},
	author = {Yao, Yuling and Vehtari, Aki and Gelman, Andrew},
	urldate = {2020-06-29},
	date = {2020-06-22},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2006.12335},
	keywords = {Statistics - Methodology, Statistics - Machine Learning},
	file = {yao_et_al_2020_stacking_for_non-mixing_bayesian_computations.pdf:/home/nathan/Dropbox/njames/zotero_sync/yao_et_al_2020_stacking_for_non-mixing_bayesian_computations.pdf:application/pdf}
}

@article{oh_improved_2020,
	title = {Improved Generalized Raking Estimators to Address Dependent Covariate and Failure-Time Outcome Error},
	url = {http://arxiv.org/abs/2006.07480},
	abstract = {Biomedical studies that use electronic health records ({EHR}) data for inference are often subject to bias due to measurement error. The measurement error present in {EHR} data is typically complex, consisting of errors of unknown functional form in covariates and the outcome, which can be dependent. To address the bias resulting from such errors, generalized raking has recently been proposed as a robust method that yields consistent estimates without the need to model the error structure. We provide rationale for why these previously proposed raking estimators can be expected to be inefﬁcient in failure-time outcome settings involving misclassiﬁcation of the event indicator. We propose raking estimators that utilize multiple imputation, to impute either the target variables or auxiliary variables, to improve the efﬁciency. We also consider outcome-dependent sampling designs and investigate their impact on the efﬁciency of the raking estimators, either with or without multiple imputation. We present an extensive numerical study to examine the performance of the proposed estimators across various measurement error settings. We then apply the proposed methods to our motivating setting, in which we seek to analyze {HIV} outcomes in an observational cohort with electronic health records data from the Vanderbilt Comprehensive Care Clinic.},
	journaltitle = {{arXiv}:2006.07480 [stat]},
	author = {Oh, Eric J. and Shepherd, Bryan E. and Lumley, Thomas and Shaw, Pamela A.},
	urldate = {2020-06-29},
	date = {2020-06-12},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2006.07480},
	keywords = {Statistics - Methodology},
	file = {oh_et_al_2020_improved_generalized_raking_estimators_to_address_dependent_covariate_and.pdf:/home/nathan/Dropbox/njames/zotero_sync/oh_et_al_2020_improved_generalized_raking_estimators_to_address_dependent_covariate_and.pdf:application/pdf}
}

@article{vandekar_robust_2020,
	title = {A Robust Effect Size Index},
	volume = {85},
	issn = {0033-3123, 1860-0980},
	url = {http://link.springer.com/10.1007/s11336-020-09698-2},
	doi = {10.1007/s11336-020-09698-2},
	pages = {232--246},
	number = {1},
	journaltitle = {Psychometrika},
	author = {Vandekar, Simon and Tao, Ran and Blume, Jeffrey},
	urldate = {2020-06-29},
	date = {2020-03},
	langid = {english},
	file = {vandekar_et_al_2020_a_robust_effect_size_index.pdf:/home/nathan/Dropbox/njames/zotero_sync/vandekar_et_al_2020_a_robust_effect_size_index.pdf:application/pdf}
}

@article{hanson_bayesian_2007,
	title = {Bayesian Semiparametric Proportional Odds Models},
	volume = {63},
	issn = {1541-0420},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2006.00671.x},
	doi = {10.1111/j.1541-0420.2006.00671.x},
	abstract = {Methodology for implementing the proportional odds regression model for survival data assuming a mixture of finite Polya trees ({MPT}) prior on baseline survival is presented. Extensions to frailties and generalized odds rates are discussed. Although all manner of censoring and truncation can be accommodated, we discuss model implementation, regression diagnostics, and model comparison for right-censored data. An advantage of the {MPT} model is the relative ease with which predictive densities, survival, and hazard curves are generated. Much discussion is devoted to practical implementation of the proposed models, and a novel {MCMC} algorithm based on an approximating parametric normal model is developed. A modest simulation study comparing the small sample behavior of the {MPT} model to a rank-based estimator and a real data example is presented.},
	pages = {88--95},
	number = {1},
	journaltitle = {Biometrics},
	author = {Hanson, Timothy and Yang, Mingan},
	urldate = {2020-06-30},
	date = {2007},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1541-0420.2006.00671.x},
	keywords = {Frailty, Generalized odds rate, Hazard curve, Mixture of Polya trees, Regression, Survival analysis, Transformation model},
	file = {hanson_yang_2007_bayesian_semiparametric_proportional_odds_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/hanson_yang_2007_bayesian_semiparametric_proportional_odds_models.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/QU8MMK96/j.1541-0420.2006.00671.html:text/html}
}

@article{mallick_bayesian_2003,
	title = {A Bayesian semiparametric transformation model incorporating frailties},
	volume = {112},
	issn = {03783758},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378375802003300},
	doi = {10.1016/S0378-3758(02)00330-0},
	abstract = {We describe a Bayesian semiparametric (failure time) transformation model for which an unknown monotone transformation of failure times is assumed linearly dependent on observed covariates with an unspeciÿed error distribution. The two unknowns: the monotone transformation and error distribution are assigned prior distributions with large supports. Our class of regression model includes the proportional hazards, accelerated failure time, and frailty models. Numerical examples are presented.},
	pages = {159--174},
	number = {1},
	journaltitle = {Journal of Statistical Planning and Inference},
	author = {Mallick, Bani K. and Walker, Stephen},
	urldate = {2020-06-30},
	date = {2003-03},
	langid = {english},
	file = {mallick_walker_2003_a_bayesian_semiparametric_transformation_model_incorporating_frailties.pdf:/home/nathan/Dropbox/njames/zotero_sync/mallick_walker_2003_a_bayesian_semiparametric_transformation_model_incorporating_frailties.pdf:application/pdf}
}

@article{tutz_non_2020,
	title = {Non Proportional Odds Models are Widely Dispensable -- Sparser Modeling based on Parametric and Additive Location-Shift Approaches},
	url = {http://arxiv.org/abs/2006.03914},
	abstract = {The potential of location-shift models to ﬁnd adequate models between the proportional odds model and the non-proportional odds model is investigated. It is demonstrated that these models are very useful in ordinal modeling. While proportional odds models are often too simple, non proportional odds models are typically unnecessary complicated and seem widely dispensable. The class of location-shift models is also extended to allow for smooth effects. The additive location-shift model contains two functions for each explanatory variable, one for the location and one for dispersion. It is much sparser than hard-to-handle additive models with category-speciﬁc covariate functions but more ﬂexible than common vector generalized additive models.},
	journaltitle = {{arXiv}:2006.03914 [stat]},
	author = {Tutz, Gerhard and Berger, Moritz},
	urldate = {2020-07-01},
	date = {2020-06-06},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2006.03914},
	keywords = {Statistics - Methodology},
	file = {tutz_berger_2020_non_proportional_odds_models_are_widely_dispensable_--_sparser_modeling_based.pdf:/home/nathan/Dropbox/njames/zotero_sync/tutz_berger_2020_non_proportional_odds_models_are_widely_dispensable_--_sparser_modeling_based.pdf:application/pdf}
}

@report{kazembe_bayesian_2016,
	title = {Bayesian multinomial ordered categorical response model for the analysis of length of hospital stay},
	url = {https://peerj.com/preprints/1663v1},
	abstract = {Length of hospital stay ({LOS}) is of primary importance in health services research because it is directly related to health care management and cost of health care. In some epidemiological settings the actual length of stay is not directly observed but it is known to have happened in a particular interval or for simple epidemiological interpretation time is categorized into ordered categorical responses. In this paper, we focus our attention on cumulative regression models for ordinal responses to analyze length of hospital stay for children admitted to a paediatric ward for malaria. Such models exploit the ordered scale of the outcomes. We approach our analysis using a Bayesian probit model. Our model incorporated random effects for hospital specific heterogeneity, while simultaneously investigating nonlinear effects in covariates within the general framework of semi-parametric regression models. Findings indicate children who died had relatively shorter {LOS}, which suggest worse prognosis at admission. Calendar time effects indicated changing seasonal effects with high peaks in wet season and low peak in dry season, largely explained by malaria transmission patterns. Age showed deviation from linearity, and early discharge was associated with much older children than infants.},
	institution = {{PeerJ} {PrePrints}},
	type = {preprint},
	author = {Kazembe, Lawrence N},
	urldate = {2020-07-02},
	date = {2016-01-21},
	langid = {english},
	doi = {10.7287/peerj.preprints.1663v1},
	file = {kazembe_2016_bayesian_multinomial_ordered_categorical_response_model_for_the_analysis_of.pdf:/home/nathan/Dropbox/njames/zotero_sync/kazembe_2016_bayesian_multinomial_ordered_categorical_response_model_for_the_analysis_of.pdf:application/pdf}
}

@article{tutz_ordinal_nodate,
	title = {Ordinal regression modelling between proportional odds and non-proportional odds},
	pages = {32},
	author = {Tutz, Scholz},
	file = {tutz_ordinal_regression_modelling_between_proportional_odds_and_non-proportional_odds.pdf:/home/nathan/Dropbox/njames/zotero_sync/tutz_ordinal_regression_modelling_between_proportional_odds_and_non-proportional_odds.pdf:application/pdf}
}

@article{christensen_parametric_2008,
	title = {Parametric Nonparametric Statistics: An Introduction to Mixtures of Finite Polya Trees},
	volume = {62},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1198/000313008X366983},
	doi = {10.1198/000313008X366983},
	shorttitle = {Parametric Nonparametric Statistics},
	pages = {296--306},
	number = {4},
	journaltitle = {The American Statistician},
	author = {Christensen, Ronald and Hanson, Timothy and Jara, Alejandro},
	urldate = {2020-07-02},
	date = {2008-11},
	langid = {english},
	file = {christensen_et_al_2008_parametric_nonparametric_statistics.pdf:/home/nathan/Dropbox/njames/zotero_sync/christensen_et_al_2008_parametric_nonparametric_statistics.pdf:application/pdf}
}

@article{schorgendorfer_regression_2013,
	title = {Regression analysis using dependent Polya trees},
	volume = {32},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.5898},
	doi = {10.1002/sim.5898},
	abstract = {Many commonly used models for linear regression analysis force overly simplistic shape and scale constraints on the residual structure of data. We propose a semiparametric Bayesian model for regression analysis that produces data-driven inference by using a new type of dependent Polya tree prior to model arbitrary residual distributions that are allowed to evolve across increasing levels of an ordinal covariate (e.g., time, in repeated measurement studies). By modeling residual distributions at consecutive covariate levels or time points using separate, but dependent Polya tree priors, distributional information is pooled while allowing for broad pliability to accommodate many types of changing residual distributions. We can use the proposed dependent residual structure in a wide range of regression settings, including fixed-effects and mixed-effects linear and nonlinear models for cross-sectional, prospective, and repeated measurement data. A simulation study illustrates the flexibility of our novel semiparametric regression model to accurately capture evolving residual distributions. In an application to immune development data on immunoglobulin G antibodies in children, our new model outperforms several contemporary semiparametric regression models based on a predictive model selection criterion. Copyright © 2013 John Wiley \& Sons, Ltd.},
	pages = {4679--4695},
	number = {27},
	journaltitle = {Statistics in Medicine},
	author = {Schörgendorfer, Angela and Branscum, Adam J.},
	urldate = {2020-07-02},
	date = {2013},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.5898},
	keywords = {Bayesian nonparametrics, mixtures of finite Polya trees, semiparametric regression},
	file = {schörgendorfer_branscum_2013_regression_analysis_using_dependent_polya_trees.pdf:/home/nathan/Dropbox/njames/zotero_sync/schörgendorfer_branscum_2013_regression_analysis_using_dependent_polya_trees.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/KCPKXGLZ/sim.html:text/html}
}

@article{song_semiparametric_2012,
	title = {Semiparametric transformation models with Bayesian P-splines},
	volume = {22},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-011-9280-x},
	doi = {10.1007/s11222-011-9280-x},
	abstract = {In this paper, we aim to develop a semiparametric transformation model. Nonparametric transformation functions are modeled with Bayesian P-splines. The transformed variables can be ﬁtted to a general nonlinear mixed model, including linear or nonlinear regression models, mixed effect models, factor analysis models, and other latent variable models as special cases. Markov chain Monte Carlo algorithms are implemented to estimate transformation functions and unknown quantities in the model. The performance of the developed methodology is demonstrated with a simulation study. Its application to a real study on polydrug use is presented.},
	pages = {1085--1098},
	number = {5},
	journaltitle = {Stat Comput},
	author = {Song, Xin-Yuan and Lu, Zhao-Hua},
	urldate = {2020-07-02},
	date = {2012-09},
	langid = {english},
	file = {song_lu_2012_semiparametric_transformation_models_with_bayesian_p-splines.pdf:/home/nathan/Dropbox/njames/zotero_sync/song_lu_2012_semiparametric_transformation_models_with_bayesian_p-splines.pdf:application/pdf}
}

@incollection{damien_surviving_2013,
	title = {Surviving fully Bayesian nonparametric regression models},
	isbn = {978-0-19-969560-7},
	url = {http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780199695607.001.0001/acprof-9780199695607-chapter-30},
	abstract = {We discussed, compared and illustrated ﬂexible nonparametric models that can be used to introduce categorical and continuous covariates in the context of time–to–event data. The models correspond to generalizations of accelerated failure time models, based on dependent extensions of Dirichlet processes and Polya tree priors. Important advantages of the induced survival regression models include ease of interpretability and computational tractability. Furthermore, an important property of the proposed models is that the complete distribution of survival times is allowed o change with values of the predictors instead of just one or two characteristics, as implied for many commonly used survival models. The two extensions are compared by means of real–life data analyses.},
	pages = {593--616},
	booktitle = {Bayesian Theory and Applications},
	publisher = {Oxford University Press},
	author = {Hanson, Timothy E. and Jara, Alejandro},
	editor = {Damien, Paul and Dellaportas, Petros and Polson, Nicholas G. and Stephens, David A.},
	urldate = {2020-07-02},
	date = {2013-01-24},
	langid = {english},
	doi = {10.1093/acprof:oso/9780199695607.003.0030},
	doi = {10.1093/acprof:oso/9780199695607.003.0030},
	file = {hanson_jara_2013_surviving_fully_bayesian_nonparametric_regression_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/hanson_jara_2013_surviving_fully_bayesian_nonparametric_regression_models.pdf:application/pdf}
}

@article{berger_overall_2015,
	title = {Overall Objective Priors},
	volume = {10},
	issn = {1936-0975},
	url = {http://projecteuclid.org/euclid.ba/1422556416},
	doi = {10.1214/14-BA915},
	abstract = {In multi-parameter models, reference priors typically depend on the parameter or quantity of interest, and it is well known that this is necessary to produce objective posterior distributions with optimal properties. There are, however, many situations where one is simultaneously interested in all the parameters of the model or, more realistically, in functions of them that include aspects such as prediction, and it would then be useful to have a single objective prior that could safely be used to produce reasonable posterior inferences for all the quantities of interest. In this paper, we consider three methods for selecting a single objective prior and study, in a variety of problems including the multinomial problem, whether or not the resulting prior is a reasonable overall prior.},
	pages = {189--221},
	number = {1},
	journaltitle = {Bayesian Anal.},
	author = {Berger, James O. and Bernardo, Jose M. and Sun, Dongchu},
	urldate = {2020-07-02},
	date = {2015-03},
	langid = {english},
	file = {berger_et_al_2015_overall_objective_priors.pdf:/home/nathan/Dropbox/njames/zotero_sync/berger_et_al_2015_overall_objective_priors.pdf:application/pdf}
}

@online{betancourt_ordinal_2019,
	title = {Ordinal Regression},
	url = {https://betanalpha.github.io/assets/case_studies/ordinal_regression.html},
	abstract = {Regression models quantify statistical correlations by allowing latent effects to moderate the distribution of an observed outcome. Linear regression, for example, models the influence of latent effects on a continuous outcome, and logistic regression models the influence of latent effects on a binary outcome. Ordinal regression models the influence of a latent effect on an ordinal outcome consisting of discrete but ordered categories.

Ordinal outcomes often arise when a continuous outcome is censored in the observational process. One of the most common examples is when individual judgements or preferences are solicited but their responses are limited to discrete categories such as “Disagree”, “Undecided”, and “Agree”. In this case the ordinal outcomes are typically known as Likert, pronounced “Lick-urt”, scales. To remain as general as possible, and distance the discussion from the heritage of twentieth century racial psychology to which Likert scales were first applied, I will maintain the ordinal terminology here.

Here I review the mathematical structure of ordinal regression models and their practical implementation in Stan. In the process I also derive a principled prior model that ensures robustness even when ordinal data are only weakly informative.},
	author = {Betancourt, Michael},
	urldate = {2020-07-03},
	date = {2019-05}
}

@article{walker_estimation_1967,
	title = {Estimation of the probability of an event as a function of several independent variables},
	volume = {54},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/54.1-2.167},
	doi = {10.1093/biomet/54.1-2.167},
	pages = {167--179},
	number = {1},
	journaltitle = {Biometrika},
	author = {Walker, Strother H. and Duncan, David B.},
	urldate = {2020-07-17},
	date = {1967},
	langid = {english},
	file = {walker_duncan_1967_estimation_of_the_probability_of_an_event_as_a_function_of_several_independent.pdf:/home/nathan/Dropbox/njames/zotero_sync/walker_duncan_1967_estimation_of_the_probability_of_an_event_as_a_function_of_several_independent.pdf:application/pdf}
}

@article{li_new_2012,
	title = {A new residual for ordinal outcomes},
	volume = {99},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/asr073},
	doi = {10.1093/biomet/asr073},
	abstract = {We propose a new residual for regression models of ordinal outcomes, defined as E\{sign(y, Y )\}, where y is the observed outcome and Y is a random variable from the fitted distribution. This new residual is a single value per subject irrespective of the number of categories of the ordinal outcome, contains directional information between the observed value and the fitted distribution, and does not require the assignment of arbitrary numbers to categories. We study its properties, describe its connections with other residuals, ranks and ridits, and demonstrate its use in model diagnostics.},
	pages = {473--480},
	number = {2},
	journaltitle = {Biometrika},
	author = {Li, C. and Shepherd, B. E.},
	urldate = {2020-07-18},
	date = {2012-06-01},
	langid = {english},
	file = {li_shepherd_2012_a_new_residual_for_ordinal_outcomes.pdf:/home/nathan/Dropbox/njames/zotero_sync/li_shepherd_2012_a_new_residual_for_ordinal_outcomes.pdf:application/pdf}
}

@article{peterson_partial_1990,
	title = {Partial Proportional Odds Models for Ordinal Response Variables},
	volume = {39},
	issn = {00359254},
	url = {https://www.jstor.org/stable/10.2307/2347760?origin=crossref},
	doi = {10.2307/2347760},
	abstract = {The ordinal logistic regression model that {McCullagh} calls the proportional odds model is extended to models that allow non-proportional odds for a subset of the explanatory variables. The maximum likelihood method is used for estimation of parameters of general and restricted partial proportional odds models as well as for the derivation of Wald, Rao score and likelihood ratio tests. These tests assess association without assuming proportional odds and test proportional odds against various alternatives. Simulation results compare the score test for proportional odds with tests suggested by Koch, Amara and Singer that are based on a series of binary logistic models.},
	pages = {205},
	number = {2},
	journaltitle = {Applied Statistics},
	author = {Peterson, Bercedis and Harrell, Frank E.},
	urldate = {2020-07-18},
	date = {1990},
	langid = {english},
	file = {peterson_harrell_1990_partial_proportional_odds_models_for_ordinal_response_variables.pdf:/home/nathan/Dropbox/njames/zotero_sync/peterson_harrell_1990_partial_proportional_odds_models_for_ordinal_response_variables.pdf:application/pdf}
}

@article{zhou_semiparametric_2020,
	title = {Semiparametric Bayesian Inference for the Transmission Dynamics of {COVID}-19 with a State-Space Model},
	url = {http://arxiv.org/abs/2006.05581},
	abstract = {The outbreak of Coronavirus Disease 2019 ({COVID}-19) is an ongoing pandemic aﬀecting over 200 countries and regions. Inference about the transmission dynamics of {COVID}-19 can provide important insights into the speed of disease spread and the eﬀects of mitigation policies. We develop a novel Bayesian approach to such inference based on a probabilistic compartmental model using data of daily conﬁrmed {COVID}-19 cases. In particular, we consider a probabilistic extension of the classical susceptible-infectious-recovered model, which takes into account undocumented infections and allows the epidemiological parameters to vary over time. We estimate the disease transmission rate via a Gaussian process prior, which captures nonlinear changes over time without the need of speciﬁc parametric assumptions. We utilize a parallel-tempering Markov chain Monte Carlo algorithm to eﬃciently sample from the highly correlated posterior space. Predictions for future observations are done by sampling from their posterior predictive distributions. Performance of the proposed approach is assessed using simulated datasets. Finally, our approach is applied to {COVID}-19 data from six states of the United States: Washington, New York, California, Florida, Texas, and Illinois. An R package {BaySIR} is made available at https://github.com/tianjianzhou/{BaySIR} for the public to conduct independent analysis or reproduce the results in this paper.},
	journaltitle = {{arXiv}:2006.05581 [q-bio, stat]},
	author = {Zhou, Tianjian and Ji, Yuan},
	urldate = {2020-07-19},
	date = {2020-07-02},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2006.05581},
	keywords = {Statistics - Methodology, Statistics - Applications, Quantitative Biology - Populations and Evolution},
	file = {zhou_ji_2020_semiparametric_bayesian_inference_for_the_transmission_dynamics_of_covid-19.pdf:/home/nathan/Dropbox/njames/zotero_sync/zhou_ji_2020_semiparametric_bayesian_inference_for_the_transmission_dynamics_of_covid-19.pdf:application/pdf}
}

@book{gelman_bayesian_2014,
	location = {Boca Raton},
	edition = {Third edition},
	title = {Bayesian Data Analysis},
	isbn = {978-1-4398-4095-5},
	series = {Chapman \& Hall/{CRC} texts in statistical science},
	abstract = {"Preface This book is intended to have three roles and to serve three associated audiences: an introductory text on Bayesian inference starting from first principles, a graduate text on effective current approaches to Bayesian modeling and computation in statistics and related fields, and a handbook of Bayesian methods in applied statistics for general users of and researchers in applied statistics. Although introductory in its early sections, the book is definitely not elementary in the sense of a first text in statistics. The mathematics used in our book is basic probability and statistics, elementary calculus, and linear algebra. A review of probability notation is given in Chapter 1 along with a more detailed list of topics assumed to have been studied. The practical orientation of the book means that the reader's previous experience in probability, statistics, and linear algebra should ideally have included strong computational components. To write an introductory text alone would leave many readers with only a taste of the conceptual elements but no guidance for venturing into genuine practical applications, beyond those where Bayesian methods agree essentially with standard non-Bayesian analyses. On the other hand, we feel it would be a mistake to present the advanced methods without first introducing the basic concepts from our data-analytic perspective. Furthermore, due to the nature of applied statistics, a text on current Bayesian methodology would be incomplete without a variety of worked examples drawn from real applications. To avoid cluttering the main narrative, there are bibliographic notes at the end of each chapter and references at the end of the book"},
	pagetotal = {661},
	publisher = {{CRC} Press},
	author = {Gelman, Andrew and Carlin, John and Stern, Hal and Dunson, David and Vehtari, Aki and Rubin, Donald},
	date = {2014},
	keywords = {Bayesian statistical decision theory, {MATHEMATICS} / Probability \& Statistics / General}
}

@incollection{gelfand_approaches_1999,
	title = {Approaches for Semiparametric Bayesian Regression},
	abstract = {Developing regression relationships is a primary inferential activity. We consider such relationships in the context of hierarchical models incorporating linear structure at each stage. Modern statistical work encourages less presumptive, i.e., nonparametric speci cations for at least a portion of the modeling. That is, we seek to enrich the class of standard parametric hierarchical models by wandering nonparametrically near (in some sense) the standard class but retaining the linear structure. This enterprise falls within what is referred to as semiparametric modeling.},
	pages = {615--638},
	booktitle = {Asymptotics, Nonparametrics, and Time Series},
	publisher = {{CRC} Press},
	author = {Gelfand, Alan E},
	editor = {Ghosh, Subir},
	date = {1999},
	langid = {english},
	file = {gelfand_1999_approaches_for_semiparametric_bayesian_regression.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelfand_1999_approaches_for_semiparametric_bayesian_regression.pdf:application/pdf}
}

@book{agresti_categorical_2002,
	location = {New York},
	edition = {2nd ed},
	title = {Categorical Data Analysis},
	isbn = {978-0-471-36093-3},
	series = {Wiley series in probability and statistics},
	pagetotal = {710},
	publisher = {Wiley-Interscience},
	author = {Agresti, Alan},
	date = {2002},
	keywords = {Multivariate analysis}
}

@article{singh_ordinal_2020,
	title = {Ordinal outcomes: A cumulative probability model with the log link and an assumption of proportionality},
	volume = {39},
	issn = {0277-6715, 1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8479},
	doi = {10.1002/sim.8479},
	shorttitle = {Ordinal outcomes},
	pages = {1343--1361},
	number = {9},
	journaltitle = {Statistics in Medicine},
	author = {Singh, Gurbakhshash and Hilton Fick, Gordon},
	urldate = {2020-07-27},
	date = {2020-04-30},
	langid = {english},
	file = {singh_hilton_fick_2020_ordinal_outcomes.pdf:/home/nathan/Dropbox/njames/zotero_sync/singh_hilton_fick_2020_ordinal_outcomes.pdf:application/pdf}
}

@report{cruz_equivolumetric_2020,
	title = {Equivolumetric protocol generates library sizes proportional to total microbial load in next-generation sequencing},
	url = {http://biorxiv.org/lookup/doi/10.1101/2020.02.03.932301},
	abstract = {Next-generation sequencing ({NGS}) has been extensively employed to perform microbiome characterization worldwide. As a culture-independent methodology, it has allowed high-level profiling of sample microbial composition. However, most studies are limited to information regarding relative bacterial abundances, ignoring scenarios in which sample microbe biomass can vary widely. Here, we develop an equivolumetric protocol for amplicon library preparation capable of generating {NGS} data responsive to input {DNA}, recovering proportionality between observed read counts and absolute bacterial abundances. Under specified conditions, we argue that the estimation of colony-forming units ({CFU}), the most common unit of bacterial abundance in classical microbiology, is challenged mostly by resolution and taxon-to-taxon variation. We propose Bayesian cumulative probability models to address such issues. Our results indicate that predictive errors vary consistently below one order of magnitude for observed bacteria. We also demonstrate our approach has the potential to generalize to previously unseen bacteria, but predictive performance is hampered by specific taxa of uncommon profile. Finally, it remains clear that {NGS} data are not inherently restricted to relative information only, and microbiome science can indeed meet the working scales of traditional microbiology.},
	institution = {Molecular Biology},
	type = {preprint},
	author = {Cruz, Giuliano Netto Flores and Christoff, Ana Paula and de Oliveira, Luiz Felipe Valter},
	urldate = {2020-07-27},
	date = {2020-02-03},
	langid = {english},
	doi = {10.1101/2020.02.03.932301},
	file = {cruz_et_al_2020_equivolumetric_protocol_generates_library_sizes_proportional_to_total_microbial.pdf:/home/nathan/Dropbox/njames/zotero_sync/cruz_et_al_2020_equivolumetric_protocol_generates_library_sizes_proportional_to_total_microbial.pdf:application/pdf}
}

@article{hu_modeling_2018,
	title = {Modeling near-continuous clinical endpoint as categorical: application to longitudinal exposure–response modeling of Mayo scores for golimumab in patients with ulcerative colitis},
	volume = {45},
	issn = {1567-567X, 1573-8744},
	url = {http://link.springer.com/10.1007/s10928-018-9610-0},
	doi = {10.1007/s10928-018-9610-0},
	shorttitle = {Modeling near-continuous clinical endpoint as categorical},
	abstract = {Accurate characterization of exposure–response relationship of clinical endpoints is important in drug development to identify optimal dose regimens. Endpoints with C 10 ordered categories are typically analyzed as continuous. This manuscript aims to show circumstances where it is advantageous to analyze such data as ordered categorical. The results of continuous and categorical analyses are compared in a latent-variable based Indirect Response modeling framework for the longitudinal modeling of Mayo scores, ranging from 0 to 12, which is commonly used as a composite endpoint to measure the severity of ulcerative colitis ({UC}). Exposure response modeling of Mayo scores is complicated by the fact that studies typically include induction and maintenance phases with re-randomizations and other response-driven dose adjustments. The challenges are illustrated in this work by analyzing data collected from 3 phase {II}/{III} trials of golimumab in patients with moderate-to-severe {UC}. Visual predictive check was used for model evaluations. The ordered categorical approach is shown to be accurate and robust compared to the continuous approach. In addition, a disease progression model with an empirical bi-phasic rate of onset was found to be superior to the commonly used placebo model with one onset rate. An application of this modeling approach in guiding potential dose-adjustment was illustrated.},
	pages = {803--816},
	number = {6},
	journaltitle = {J Pharmacokinet Pharmacodyn},
	author = {Hu, Chuanpu and Adedokun, Omoniyi J. and Zhang, Liping and Sharma, Amarnath and Zhou, Honghui},
	urldate = {2020-07-27},
	date = {2018-12},
	langid = {english},
	file = {hu_et_al_2018_modeling_near-continuous_clinical_endpoint_as_categorical.pdf:/home/nathan/Dropbox/njames/zotero_sync/hu_et_al_2018_modeling_near-continuous_clinical_endpoint_as_categorical.pdf:application/pdf}
}

@article{assel_guidelines_2019,
	title = {Guidelines for reporting of statistics for clinical research in urology},
	volume = {123},
	issn = {14644096},
	url = {http://doi.wiley.com/10.1111/bju.14640},
	doi = {10.1111/bju.14640},
	pages = {401--410},
	number = {3},
	journaltitle = {{BJU} Int},
	author = {Assel, Melissa and Sjoberg, Daniel and Elders, Andrew and Wang, Xuemei and Huo, Dezheng and Botchway, Albert and Delfino, Kristin and Fan, Yunhua and Zhao, Zhiguo and Koyama, Tatsuki and Hollenbeck, Brent and Qin, Rui and Zahnd, Whitney and Zabor, Emily C. and Kattan, Michael W. and Vickers, Andrew J.},
	urldate = {2020-07-28},
	date = {2019-03},
	langid = {english},
	file = {assel_et_al_2019_guidelines_for_reporting_of_statistics_for_clinical_research_in_urology.pdf:/home/nathan/Dropbox/njames/zotero_sync/assel_et_al_2019_guidelines_for_reporting_of_statistics_for_clinical_research_in_urology.pdf:application/pdf}
}

@article{vickers_guidelines_2020,
	title = {Guidelines for Reporting of Figures and Tables for Clinical Research in Urology},
	volume = {78},
	issn = {03022838},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S030228382030316X},
	doi = {10.1016/j.eururo.2020.04.048},
	abstract = {In an effort to improve the presentation of and information within tables and ﬁgures in clinical urology research, we propose a set of appropriate guidelines. We introduce six principles: (1) include graphs only if they improve the reader’s ability to understand the study ﬁndings; (2) think through how a graph might best convey information, do not just select a graph from preselected options on statistical software; (3) do not use graphs to replace reporting key numbers in the text of a paper; (4) graphs should give an immediate visual impression of the data; (5) make it beautiful; and (6) make the labels and legend clear and complete. We present a list of quick “dos and don’ts” for both tables and ﬁgures. Investigators should feel free to break any of the guidelines if it would result in a beautiful ﬁgure or a clear table that communicates data effectively. That said, we believe that the quality of tables and ﬁgures in the medical literature would improve if these guidelines were to be followed.},
	pages = {97--109},
	number = {1},
	journaltitle = {European Urology},
	author = {Vickers, Andrew J. and Assel, Melissa J. and Sjoberg, Daniel D. and Qin, Rui and Zhao, Zhiguo and Koyama, Tatsuki and Botchway, Albert and Wang, Xuemei and Huo, Dezheng and Kattan, Michael and Zabor, Emily C. and Harrell, Frank},
	urldate = {2020-07-28},
	date = {2020-07},
	langid = {english},
	file = {vickers_et_al_2020_guidelines_for_reporting_of_figures_and_tables_for_clinical_research_in_urology.pdf:/home/nathan/Dropbox/njames/zotero_sync/vickers_et_al_2020_guidelines_for_reporting_of_figures_and_tables_for_clinical_research_in_urology.pdf:application/pdf}
}

@article{kottas_bayesian_2001,
	title = {Bayesian Semiparametric Median Regression Modeling},
	volume = {96},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1198/016214501753382363},
	doi = {10.1198/016214501753382363},
	pages = {1458--1468},
	number = {456},
	journaltitle = {Journal of the American Statistical Association},
	author = {Kottas, Athanasios and Gelfand, Alan E},
	urldate = {2020-07-28},
	date = {2001-12},
	langid = {english},
	file = {kottas_gelfand_2001_bayesian_semiparametric_median_regression_modeling.pdf:/home/nathan/Dropbox/njames/zotero_sync/kottas_gelfand_2001_bayesian_semiparametric_median_regression_modeling.pdf:application/pdf}
}

@article{iglesias_nonparametric_2009,
	title = {Nonparametric Bayesian modelling using skewed Dirichlet processes},
	volume = {139},
	issn = {03783758},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378375808003029},
	doi = {10.1016/j.jspi.2008.07.009},
	abstract = {We introduce a new class of discrete random probability measures that extend the definition of Dirichlet process ({DP}) by explicitly incorporating skewness. The asymmetry is controlled by a single parameter in such a way that symmetric {DPs} are obtained as a special case of the general construction. We review the main properties of skewed {DPs} and develop appropriate Polya urn schemes. We illustrate the modelling in the context of linear regression models of the capital asset pricing model ({CAPM}) type, where assessing symmetry for the error distribution is important to check validity of the model.},
	pages = {1203--1214},
	number = {3},
	journaltitle = {Journal of Statistical Planning and Inference},
	author = {Iglesias, Pilar L. and Orellana, Yasna and Quintana, Fernando A.},
	urldate = {2020-07-28},
	date = {2009-03},
	langid = {english},
	file = {iglesias_et_al_2009_nonparametric_bayesian_modelling_using_skewed_dirichlet_processes.pdf:/home/nathan/Dropbox/njames/zotero_sync/iglesias_et_al_2009_nonparametric_bayesian_modelling_using_skewed_dirichlet_processes.pdf:application/pdf}
}

@article{gelfand_computational_2002,
	title = {A Computational Approach for Full Nonparametric Bayesian Inference Under Dirichlet Process Mixture Models},
	volume = {11},
	issn = {1061-8600, 1537-2715},
	url = {http://www.tandfonline.com/doi/abs/10.1198/106186002760180518},
	doi = {10.1198/106186002760180518},
	pages = {289--305},
	number = {2},
	journaltitle = {Journal of Computational and Graphical Statistics},
	author = {Gelfand, Alan E and Kottas, Athanasios},
	urldate = {2020-07-28},
	date = {2002-06},
	langid = {english},
	file = {gelfand_kottas_2002_a_computational_approach_for_full_nonparametric_bayesian_inference_under.pdf:/home/nathan/Dropbox/njames/zotero_sync/gelfand_kottas_2002_a_computational_approach_for_full_nonparametric_bayesian_inference_under.pdf:application/pdf}
}

@article{gustafson_flexible_nodate,
	title = {Flexible Bayesian Modelling for Survival Data},
	abstract = {The analysis of failure time data often involves two strong assumptions. The proportional hazards assumption postulates that hazard rates corresponding to different levels of explanatory variables are proportional. The additive effects assumption speciﬁes that the effect associated with a particular explanatory variable does not depend on the levels of other explanatory variables. A hierarchical Bayes model is presented, under which both assumptions are relaxed. In particular, time-dependent covariate effects are explicitly modelled, and the additivity of effects is relaxed through the use of a modiﬁed neural network structure. The hierarchical nature of the model is useful in that it parsimoniously penalizes violations of the two assumptions, with the strength of the penalty being determined by the data.},
	pages = {19},
	author = {Gustafson, Paul},
	langid = {english},
	file = {gustafson_flexible_bayesian_modelling_for_survival_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/gustafson_flexible_bayesian_modelling_for_survival_data.pdf:application/pdf}
}

@thesis{jara_bayesian_2008,
	location = {Leuven, Belgium},
	title = {Bayesian Semiparametric Methods for the Analysis of Complex Data},
	pagetotal = {259},
	institution = {Katholieke Universiteit Leuven},
	type = {Doctoral Dissertation},
	author = {Jara, Alejandro},
	date = {2008-03},
	file = {jara_2008_bayesian_semiparametric_methods_for_the_analysis_of_complex_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/jara_2008_bayesian_semiparametric_methods_for_the_analysis_of_complex_data.pdf:application/pdf}
}

@article{banerjee_bayesian_2007,
	title = {Bayesian analysis of generalized odds-rate hazards models for survival data},
	volume = {13},
	issn = {1380-7870, 1572-9249},
	url = {http://link.springer.com/10.1007/s10985-007-9035-3},
	doi = {10.1007/s10985-007-9035-3},
	abstract = {In the analysis of censored survival data Cox proportional hazards model (1972) is extremely popular among the practitioners. However, in many real-life situations the proportionality of the hazard ratios does not seem to be an appropriate assumption. To overcome such a problem, we consider a class of nonproportional hazards models known as generalized odds-rate class of regression models. The class is general enough to include several commonly used models, such as proportional hazards model, proportional odds model, and accelerated life time model. The theoretical and computational properties of these models have been re-examined. The propriety of the posterior has been established under some mild conditions. A simulation study is conducted and a detailed analysis of the data from a prostate cancer study is presented to further illustrate the proposed methodology.},
	pages = {241--260},
	number = {2},
	journaltitle = {Lifetime Data Anal},
	author = {Banerjee, Tathagata and Chen, Ming-Hui and Dey, Dipak K. and Kim, Sungduk},
	urldate = {2020-07-29},
	date = {2007-04-20},
	langid = {english},
	file = {banerjee_et_al_2007_bayesian_analysis_of_generalized_odds-rate_hazards_models_for_survival_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/banerjee_et_al_2007_bayesian_analysis_of_generalized_odds-rate_hazards_models_for_survival_data.pdf:application/pdf}
}

@article{cox_locationscale_1995,
	title = {Location—scale cumulative odds models for ordinal data: A generalized non-linear model approach},
	volume = {14},
	issn = {02776715, 10970258},
	url = {http://doi.wiley.com/10.1002/sim.4780141105},
	doi = {10.1002/sim.4780141105},
	shorttitle = {Location—scale cumulative odds models for ordinal data},
	abstract = {Proportional odds regression models for multinomial probabilities based on ordered categories have been generalized in two somewhat different directions. Models having scale as well as location parameters for adjustment of boundaries (on an unobservable, underlying continuum) between categories have been employed in the context of {ROC} analysis. Partial proportional odds models, having different regression adjustments for different multinomial categories, have also been proposed. This paper considers a synthesis and further generalization of these two families. With use of a number of examples, I discuss and illustrate properties of this extended family of models. Emphasis is on the computation of maximum likelihood estimates of parameters, asymptotic standard deviations, and goodness-of-fit statistics with use of non-linear regression programs in standard statistical software such as {SAS}.},
	pages = {1191--1203},
	number = {11},
	journaltitle = {Statist. Med.},
	author = {Cox, Christopher},
	urldate = {2020-08-01},
	date = {1995-06-15},
	langid = {english},
	file = {cox_1995_location—scale_cumulative_odds_models_for_ordinal_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/cox_1995_location—scale_cumulative_odds_models_for_ordinal_data.pdf:application/pdf}
}

@article{peng_bayesian_1996,
	title = {Bayesian Analysis of {ROC} Curves Using Markov-chain Monte Carlo Methods},
	volume = {16},
	issn = {0272-989X, 1552-681X},
	url = {http://journals.sagepub.com/doi/10.1177/0272989X9601600411},
	doi = {10.1177/0272989X9601600411},
	pages = {404--411},
	number = {4},
	journaltitle = {Med Decis Making},
	author = {Peng, Fengchun and Hall, W. Jack},
	urldate = {2020-08-01},
	date = {1996-10},
	langid = {english},
	file = {peng_hall_1996_bayesian_analysis_of_roc_curves_using_markov-chain_monte_carlo_methods.pdf:/home/nathan/Dropbox/njames/zotero_sync/peng_hall_1996_bayesian_analysis_of_roc_curves_using_markov-chain_monte_carlo_methods.pdf:application/pdf}
}

@article{hellmich_bayesian_1998,
	title = {A Bayesian Approach to a General Regression Model for {ROC} Curves},
	volume = {18},
	issn = {0272-989X, 1552-681X},
	url = {http://journals.sagepub.com/doi/10.1177/0272989X9801800412},
	doi = {10.1177/0272989X9801800412},
	pages = {436--443},
	number = {4},
	journaltitle = {Med Decis Making},
	author = {Hellmich, Martin and Abrams, Keith R. and Jones, David R. and Lambert, Paul C.},
	urldate = {2020-08-01},
	date = {1998-10},
	langid = {english},
	file = {hellmich_et_al_1998_a_bayesian_approach_to_a_general_regression_model_for_roc_curves.pdf:/home/nathan/Dropbox/njames/zotero_sync/hellmich_et_al_1998_a_bayesian_approach_to_a_general_regression_model_for_roc_curves.pdf:application/pdf}
}

@article{ishwaran_general_2000,
	title = {A general class of hierarchical ordinal regression models with applications to correlated roc analysis},
	volume = {28},
	issn = {1708-945X},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.2307/3315913},
	doi = {10.2307/3315913},
	abstract = {The authors discuss a general class of hierarchical ordinal regression models that includes both location and scale parameters, allows link functions to be selected adaptively as finite mixtures of normal cumulative distribution functions, and incorporates flexible correlation structures for the latent scale variables. Exploiting the well-known correspondence between ordinal regression models and parametric {ROC} (Receiver Operating Characteristic) curves makes it possible to use a hierarchical {ROC} ({HROC}) analysis to study multilevel clustered data in diagnostic imaging studies. The authors present a Bayesian approach to model fitting using Markov chain Monte Carlo methods and discuss {HROC} applications to the analysis of data from two diagnostic radiology studies involving multiple interpreters.},
	pages = {731--750},
	number = {4},
	journaltitle = {Canadian Journal of Statistics},
	author = {Ishwaran, Hemant and Gatsonis, Constantine A.},
	urldate = {2020-08-01},
	date = {2000},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.2307/3315913},
	keywords = {Gibbs sampling, Bayesian hierarchical mode, {HROC} model, ordinal categorical data, ordinal regression, {ROC} curve},
	file = {ishwaran_gatsonis_2000_a_general_class_of_hierarchical_ordinal_regression_models_with_applications_to.pdf:/home/nathan/Dropbox/njames/zotero_sync/ishwaran_gatsonis_2000_a_general_class_of_hierarchical_ordinal_regression_models_with_applications_to.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/T4HDI7ER/3315913.html:text/html}
}

@article{tang_semiparametric_2018,
	title = {Semiparametric Bayesian analysis of transformation linear mixed models},
	volume = {166},
	issn = {0047259X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0047259X18300976},
	doi = {10.1016/j.jmva.2018.03.007},
	abstract = {In classical linear mixed models ({LMMs}), it is commonly assumed that the random effects and within-individual errors independently follow a Gaussian distribution. However, in some applications, this assumption may be inappropriate. To this end, this paper proposes a novel {LMM} by assuming that the random effects follow an unknown distribution, and the within-individual errors associated with the transformed responses are Gaussian. A semiparametric Bayesian approach is developed to make Bayesian inference on the novel {LMM} by using the truncated centered Dirichlet Process prior to approximate the unknown distribution of the random effects and using Bayesian P-splines to approximate the transformation function, and combining the Gibbs sampler and the Metropolis–Hastings algorithm. A Bayesian local influence analysis method is developed to assess the effect of minor perturbations. Simulation studies and an example are used to illustrate the proposed methodologies.},
	pages = {225--240},
	journaltitle = {Journal of Multivariate Analysis},
	author = {Tang, Niansheng and Wu, Ying and Chen, Dan},
	urldate = {2020-08-01},
	date = {2018-07},
	langid = {english},
	file = {tang_et_al_2018_semiparametric_bayesian_analysis_of_transformation_linear_mixed_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/tang_et_al_2018_semiparametric_bayesian_analysis_of_transformation_linear_mixed_models.pdf:application/pdf}
}

@incollection{deyoreo_bayesian_2020,
	title = {Bayesian nonparametric density regression for ordinal responses},
	pages = {65--89},
	booktitle = {Flexible Bayesian regression modelling},
	publisher = {Academic Press},
	author = {{DeYoreo}, Maria and Kottas, Athanasios},
	date = {2020},
	file = {deyoreo_kottas_2020_bayesian_nonparametric_density_regression_for_ordinal_responses.pdf:/home/nathan/Dropbox/njames/zotero_sync/deyoreo_kottas_2020_bayesian_nonparametric_density_regression_for_ordinal_responses.pdf:application/pdf}
}

@article{muller_bayesian_2013,
	title = {Bayesian Nonparametric Inference – Why and How},
	volume = {8},
	issn = {1936-0975},
	url = {http://projecteuclid.org/euclid.ba/1369407550},
	doi = {10.1214/13-BA811},
	abstract = {We review inference under models with nonparametric Bayesian ({BNP}) priors. The discussion follows a set of examples for some common inference problems. The examples are chosen to highlight problems that are challenging for standard parametric inference. We discuss inference for density estimation, clustering, regression and for mixed effects models with random effects distributions. While we focus on arguing for the need for the flexibility of {BNP} models, we also review some of the more commonly used {BNP} models, thus hopefully answering a bit of both questions, why and how to use {BNP}.},
	pages = {269--302},
	number = {2},
	journaltitle = {Bayesian Anal.},
	author = {Müller, Peter and Mitra, Riten},
	urldate = {2020-08-03},
	date = {2013-06},
	langid = {english},
	file = {müller_mitra_2013_bayesian_nonparametric_inference_–_why_and_how.pdf:/home/nathan/Dropbox/njames/zotero_sync/müller_mitra_2013_bayesian_nonparametric_inference_–_why_and_how.pdf:application/pdf}
}

@article{lin_semiparametric_2012,
	title = {Semiparametric Bayesian Survival Analysis using Models with Log-Linear Median},
	volume = {68},
	issn = {0006-341X},
	url = {https://www.jstor.org/stable/41806032},
	abstract = {We present a novel semiparametric survival model with a log-linear median regression function. As a useful alternative to existing semiparametric models, our large model class has many important practical advantages, including interpretation of the regression parameters via the median and the ability to address heteroscedasticity. We demonstrate that our modeling technique facilitates the ease of prior elicitation and computation for both parametric and semiparametric Bayesian analysis of survival data. We illustrate the advantages of our modeling, as well as model diagnostics, via a reanalysis of a small-cell lung cancer study. Results of our simulation study provide further support for our model in practice.},
	pages = {1136--1145},
	number = {4},
	journaltitle = {Biometrics},
	author = {Lin, Jianchang and Sinha, Debajyoti and Lipsitz, Stuart and Polpo, Adriano},
	urldate = {2020-08-04},
	date = {2012},
	note = {Publisher: International Biometric Society},
	file = {lin_et_al_2012_semiparametric_bayesian_survival_analysis_using_models_with_log-linear_median.pdf:/home/nathan/Dropbox/njames/zotero_sync/lin_et_al_2012_semiparametric_bayesian_survival_analysis_using_models_with_log-linear_median.pdf:application/pdf}
}

@article{zeng_maximum_2007,
	title = {Maximum likelihood estimation in semiparametric regression models with censored data},
	volume = {69},
	issn = {1467-9868},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1369-7412.2007.00606.x},
	doi = {10.1111/j.1369-7412.2007.00606.x},
	abstract = {Summary. Semiparametric regression models play a central role in formulating the effects of covariates on potentially censored failure times and in the joint modelling of incomplete repeated measures and failure times in longitudinal studies. The presence of infinite dimensional parameters poses considerable theoretical and computational challenges in the statistical analysis of such models. We present several classes of semiparametric regression models, which extend the existing models in important directions. We construct appropriate likelihood functions involving both finite dimensional and infinite dimensional parameters. The maximum likelihood estimators are consistent and asymptotically normal with efficient variances. We develop simple and stable numerical techniques to implement the corresponding inference procedures. Extensive simulation experiments demonstrate that the inferential and computational methods proposed perform well in practical settings. Applications to three medical studies yield important new insights. We conclude that there is no reason, theoretical or numerical, not to use maximum likelihood estimation for semiparametric regression models. We discuss several areas that need further research.},
	pages = {507--564},
	number = {4},
	journaltitle = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Zeng, D. and Lin, D. Y.},
	urldate = {2020-08-04},
	date = {2007},
	langid = {english},
	note = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1369-7412.2007.00606.x},
	keywords = {Counting process, {EM} algorithm, Generalized linear mixed models, Joint models, Multivariate failure times, Non-parametric likelihood, Profile likelihood, Proportional hazards, Random effects, Repeated measures, Semiparametric efficiency, Survival data, Transformation models},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/IR95F3W9/j.1369-7412.2007.00606.html:text/html;zeng_lin_2007_maximum_likelihood_estimation_in_semiparametric_regression_models_with_censored.pdf:/home/nathan/Dropbox/njames/zotero_sync/zeng_lin_2007_maximum_likelihood_estimation_in_semiparametric_regression_models_with_censored.pdf:application/pdf}
}

@incollection{hanson_bayesian_2005,
	title = {Bayesian Nonparametric Modeling and Data Analysis: An Introduction},
	volume = {25},
	isbn = {978-0-444-51539-1},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169716105250095},
	shorttitle = {Bayesian Nonparametric Modeling and Data Analysis},
	abstract = {Statistical models are developed for the purpose of addressing scientiﬁc questions. For each scientiﬁc question for which data are collected, the truth is sought by developing statistical models that are useful in this regard. Despite the fact that restrictive parametric models have been shown to be extraordinarily effective in many instances, there is and has been much scope for developing statistical inferences for models that allow for greater ﬂexibility. It would seem that just about any statistical modeling endeavor can be expanded and approached, at least conceptually, as a nonparametric problem. The purpose of this chapter is to give a brief discussion of, and introduction to, one of the two major approaches to the whole of statistics as it were, Bayesian nonparametrics.},
	pages = {245--278},
	booktitle = {Handbook of Statistics},
	publisher = {Elsevier},
	author = {Hanson, Timothy E. and Branscum, Adam J. and Johnson, Wesley O.},
	urldate = {2020-08-10},
	date = {2005},
	langid = {english},
	doi = {10.1016/S0169-7161(05)25009-5},
	file = {hanson_et_al_2005_bayesian_nonparametric_modeling_and_data_analysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/hanson_et_al_2005_bayesian_nonparametric_modeling_and_data_analysis.pdf:application/pdf}
}

@incollection{damien_bayesian_2005,
	title = {Some Bayesian Nonparametric Models},
	volume = {25},
	isbn = {978-0-444-51539-1},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169716105250101},
	pages = {279--314},
	booktitle = {Handbook of Statistics},
	publisher = {Elsevier},
	author = {Damien, Paul},
	urldate = {2020-08-10},
	date = {2005},
	langid = {english},
	doi = {10.1016/S0169-7161(05)25010-1},
	file = {damien_2005_some_bayesian_nonparametric_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/damien_2005_some_bayesian_nonparametric_models.pdf:application/pdf}
}

@incollection{walker_bayesian_2005,
	title = {Bayesian Nonparametric Inference},
	volume = {25},
	isbn = {978-0-444-51539-1},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169716105250125},
	pages = {339--371},
	booktitle = {Handbook of Statistics},
	publisher = {Elsevier},
	author = {Walker, Stephen},
	urldate = {2020-08-10},
	date = {2005},
	langid = {english},
	doi = {10.1016/S0169-7161(05)25012-5},
	file = {walker_2005_bayesian_nonparametric_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/walker_2005_bayesian_nonparametric_inference.pdf:application/pdf}
}

@incollection{chib_modeling_2005,
	title = {Modeling and Analysis for Categorical Response Data},
	volume = {25},
	isbn = {978-0-444-51539-1},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169716105250290},
	pages = {835--867},
	booktitle = {Handbook of Statistics},
	publisher = {Elsevier},
	author = {Chib, Siddhartha},
	urldate = {2020-08-10},
	date = {2005},
	langid = {english},
	doi = {10.1016/S0169-7161(05)25029-0},
	file = {chib_2005_modeling_and_analysis_for_categorical_response_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/chib_2005_modeling_and_analysis_for_categorical_response_data.pdf:application/pdf}
}

@incollection{stern_bayesian_2005,
	title = {Bayesian Model Checking and Model Diagnostics},
	volume = {25},
	isbn = {978-0-444-51539-1},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016971610525006X},
	pages = {171--192},
	booktitle = {Handbook of Statistics},
	publisher = {Elsevier},
	author = {Stern, Hal S. and Sinharay, Sandip},
	urldate = {2020-08-10},
	date = {2005},
	langid = {english},
	doi = {10.1016/S0169-7161(05)25006-X},
	file = {stern_sinharay_2005_bayesian_model_checking_and_model_diagnostics.pdf:/home/nathan/Dropbox/njames/zotero_sync/stern_sinharay_2005_bayesian_model_checking_and_model_diagnostics.pdf:application/pdf}
}

@article{carreno_pilot_2017,
	title = {Pilot Study of a Bayesian Approach To Estimate Vancomycin Exposure in Obese Patients with Limited Pharmacokinetic Sampling},
	volume = {61},
	issn = {0066-4804, 1098-6596},
	url = {https://AAC.asm.org/lookup/doi/10.1128/AAC.02478-16},
	doi = {10.1128/AAC.02478-16},
	abstract = {This study evaluated the predictive performance of a Bayesian {PK} estimation method ({ADAPT} V) to estimate the 24-h vancomycin area under the curve ({AUC}) with limited pharmacokinetic ({PK}) sampling in adult obese patients receiving vancomycin for suspected or conﬁrmed Gram-positive infections. This was an Albany Medical Center Institutional Review Board-approved prospective evaluation of 12 patients. Patients had a median (95\% conﬁdence interval) age of 61 years (39 to 71 years), a median creatinine clearance of 86 ml/min (75 to 120 ml/min), and a median body mass index of 45 kg/m2 (40 to 52 kg/m2). For each patient, ﬁve {PK} concentrations were measured, and four different vancomycin population {PK} models were used as Bayesian priors to estimate the vancomycin {AUC} ({AUCFULL}). Using each {PK} model as a prior, data-depleted {PK} subsets were used to estimate the 24-h {AUC} (i.e., peak and trough data [{AUCPT}], midpoint and trough data [{AUCMT}], and trough-only data [{AUCT}]). The 24-h {AUC} derived from the full data set ({AUCFULL}) was compared to the {AUC} derived from data-depleted subsets ({AUCPT}, {AUCMT}, and {AUCT}) for each model. For the four sets of analyses, {AUCFULL} estimates ranged from 437 to 489 mg·h/liter. The {AUCPT} provided the best approximation of the {AUCFULL}; {AUCMT} and {AUCT} tended to overestimate {AUCFULL}. Further prospective studies are needed to evaluate the impact of {AUC} monitoring in clinical practice, but the ﬁndings from this study suggest that the vancomycin {AUC} can be estimated with good precision and accuracy with limited {PK} sampling using Bayesian {PK} estimation software.},
	pages = {e02478--16, e02478--16},
	number = {5},
	journaltitle = {Antimicrob Agents Chemother},
	author = {Carreno, Joseph J. and Lomaestro, Ben and Tietjan, John and Lodise, Thomas P.},
	urldate = {2020-08-13},
	date = {2017-05},
	langid = {english},
	file = {carreno_et_al_2017_pilot_study_of_a_bayesian_approach_to_estimate_vancomycin_exposure_in_obese.pdf:/home/nathan/Dropbox/njames/zotero_sync/carreno_et_al_2017_pilot_study_of_a_bayesian_approach_to_estimate_vancomycin_exposure_in_obese.pdf:application/pdf}
}

@article{vinks_development_2020,
	title = {Development and Implementation of Electronic Health Record–Integrated Model-Informed Clinical Decision Support Tools for the Precision Dosing of Drugs},
	volume = {107},
	issn = {1532-6535},
	url = {http://ascpt.onlinelibrary.wiley.com/doi/abs/10.1002/cpt.1679},
	doi = {10.1002/cpt.1679},
	abstract = {Imagine it is 2030, and the drug label is in the cloud, is interactive, and can provide model-informed precision dosing support based on an individual's genomic and physiologic makeup that is uploaded via a user-friendly interface. Precision medicine has vastly improved our ability to provide tailored therapeutics, and groundbreaking advances in noninvasive systems have generated smart wearable devices that can follow our physiologic state and drug exposure in real time. One device consists of a microfluidic drug biosensor with a transmitter attached to the skin and a mobile app that displays concentration values and trends while issuing alerts and providing suggestions on dose changes when out of range. This sounds compelling, but why has model-informed precision dosing not yet become common clinical reality in 2020?},
	pages = {129--135},
	number = {1},
	journaltitle = {Clinical Pharmacology \& Therapeutics},
	author = {Vinks, Alexander A. and Peck, Richard W. and Neely, Michael and Mould, Diane R.},
	urldate = {2020-08-13},
	date = {2020},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpt.1679},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/9AC2M275/cpt.html:text/html;vinks_et_al_2020_development_and_implementation_of_electronic_health_record–integrated.pdf:/home/nathan/Dropbox/njames/zotero_sync/vinks_et_al_2020_development_and_implementation_of_electronic_health_record–integrated.pdf:application/pdf}
}

@article{vinks_electronic_2020,
	title = {Electronic Health Record–Embedded Decision Support Platform for Morphine Precision Dosing in Neonates},
	volume = {107},
	issn = {1532-6535},
	url = {http://ascpt.onlinelibrary.wiley.com/doi/abs/10.1002/cpt.1684},
	doi = {10.1002/cpt.1684},
	abstract = {Morphine is the opioid most commonly used for neonatal pain management. In intravenous form, it is administered as continuous infusions and intermittent injections, mostly based on empirically established protocols. Inadequate pain control in neonates can cause long-term adverse consequences; however, providing appropriate individualized morphine dosing is particularly challenging due to the interplay of rapid natural physiological changes and multiple life-sustaining procedures in patients who cannot describe their symptoms. At most institutions, morphine dosing in neonates is largely carried out as an iterative process using a wide range of starting doses and then titrating to effect based on clinical response and side effects using pain scores and levels of sedation. Our background data show that neonates exhibit large variability in morphine clearance resulting in a wide range of exposures, which are poorly predicted by dose alone. Here, we describe the development and implementation of an electronic health record–integrated, model-informed decision support platform for the precision dosing of morphine in the management of neonatal pain. The platform supports pharmacokinetic model-informed dosing guidance and has functionality to incorporate real-time drug concentration information. The feedback is inserted directly into prescribers' workflows so that they can make data-informed decisions. The expected outcomes are better clinical efficacy and safety with fewer side effects in the neonatal population.},
	pages = {186--194},
	number = {1},
	journaltitle = {Clinical Pharmacology \& Therapeutics},
	author = {Vinks, Alexander A. and Punt, Nieko C. and Menke, Frank and Kirkendall, Eric and Butler, Dawn and Duggan, Thomas J. and Cortezzo, {DonnaMaria} E. and Kiger, Sam and Dietrich, Tom and Spencer, Paul and Keefer, Rob and Setchell, Kenneth D. R. and Zhao, Junfang and Euteneuer, Joshua C. and Mizuno, Tomoyuki and Dufendach, Kevin R.},
	urldate = {2020-08-13},
	date = {2020},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpt.1684},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/BDAF7VYG/cpt.html:text/html;vinks_et_al_2020_electronic_health_record–embedded_decision_support_platform_for_morphine.pdf:/home/nathan/Dropbox/njames/zotero_sync/vinks_et_al_2020_electronic_health_record–embedded_decision_support_platform_for_morphine.pdf:application/pdf}
}

@article{wiczling_pharmacokinetics_2016-1,
	title = {The pharmacokinetics of dexmedetomidine during long-term infusion in critically ill pediatric patients. A Bayesian approach with informative priors},
	volume = {43},
	issn = {1567-567X, 1573-8744},
	url = {http://link.springer.com/10.1007/s10928-016-9474-0},
	doi = {10.1007/s10928-016-9474-0},
	pages = {315--324},
	number = {3},
	journaltitle = {J Pharmacokinet Pharmacodyn},
	author = {Wiczling, Paweł and Bartkowska-Śniatkowska, Alicja and Szerkus, Oliwia and Siluk, Danuta and Rosada-Kurasińska, Jowita and Warzybok, Justyna and Borsuk, Agnieszka and Kaliszan, Roman and Grześkowiak, Edmund and Bienert, Agnieszka},
	urldate = {2020-08-13},
	date = {2016-06},
	langid = {english},
	file = {wiczling_et_al_2016_the_pharmacokinetics_of_dexmedetomidine_during_long-term_infusion_in_critically.pdf:/home/nathan/Dropbox/njames/zotero_sync/wiczling_et_al_2016_the_pharmacokinetics_of_dexmedetomidine_during_long-term_infusion_in_critically2.pdf:application/pdf}
}

@article{larizza_complex_2018,
	title = {Complex Bayesian Modeling Workflows Encoding and Execution Made Easy With a Novel {WinBUGS} Plugin of the Drug Disease Model Resources Interoperability Framework},
	volume = {7},
	issn = {2163-8306},
	url = {http://ascpt.onlinelibrary.wiley.com/doi/abs/10.1002/psp4.12285%4010.1002/%28ISSN%292163-8306.MethodsandSoftware},
	doi = {10.1002/psp4.12285},
	abstract = {The Drug Disease Model Resources ({DDMoRe}) Interoperability Framework ({IOF}) enables pharmacometric model encoding and execution via Model Description Language ({MDL}) and R language, through the ddmore package. Through its components and converter plugins, the {IOF} can execute pharmacometric tasks using different target tools, starting from a single {MDL}-encoded model. In this article, we present the {WinBUGS} plugin and show how its integration in the {IOF} enables an easy implementation of complex Bayesian workflows. We selected a published diabetes-linked study as a real-world example, in which two inter-related models are used to estimate insulin secretion rate in response to a glucose stimulus from intravenous glucose tolerance test ({IVGTT}) data. This model was implemented following different approaches to propagate uncertainty, via diverse {IOF} target tools ({NONMEM}, {WinBUGS}, {PsN}, and Xpose). The developed software supports a plethora of pharmacokinetic/pharmacodynamic ({PK}/{PD}) modeling features. It provides solutions to reproducibility and interoperability issues in Bayesian modeling, and facilitates the difficult encoding of complex {PK}/{PD} models in {WinBUGS}.},
	pages = {298--308},
	number = {5},
	journaltitle = {{CPT}: Pharmacometrics \& Systems Pharmacology},
	author = {Larizza, Cristiana and Borella, Elisa and Pasotti, Lorenzo and Tartaglione, Palma and Smith, Mike and Moodie, Stuart and Magni, Paolo},
	urldate = {2020-08-13},
	date = {2018},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/psp4.12285},
	file = {larizza_et_al_2018_complex_bayesian_modeling_workflows_encoding_and_execution_made_easy_with_a.pdf:/home/nathan/Dropbox/njames/zotero_sync/larizza_et_al_2018_complex_bayesian_modeling_workflows_encoding_and_execution_made_easy_with_a.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/MME8YC88/(ISSN)2163-8306.html:text/html}
}

@article{liu_bayesian_2018,
	title = {Bayesian population pharmacokinetic modeling of florfenicol in pigs after intravenous and intramuscular administration},
	volume = {41},
	issn = {1365-2885},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/jvp.12677},
	doi = {10.1111/jvp.12677},
	abstract = {Bayesian population pharmacokinetic models of florfenicol in healthy pigs were developed based on retrospective data in pigs either via intravenous (i.v.) or intramuscular (i.m.) administration. Following i.v. administration, the disposition of florfenicol was best described by a two-compartment open model with the typical values of half-life at α phase (t1/2α), half-life at β phase (t1/2β), total body clearance (Cl), and volume of distribution (Vd) were 0.132 ± 0.0289, 2.78 ± 0.166 hr, 0.215 ± 0.0102, and 0.841 ± 0.0289 L kg−1, respectively. The disposition of florfenicol after i.m. administration was best described by a one-compartment open model. The typical values of maximum concentration of drug in serum (Cmax), elimination half-life (t1/2Kel), Cl, and Volume (V) were 5.52 ± 0.605 μg/ml, 9.96 ± 1.12 hr, 0.228 ± 0.0154 L hr−1 kg−1, and 3.28 ± 0.402 L/kg, respectively. The between-subject variabilities of all the parameters after i.m. administration were between 25.1\%–92.1\%. Florfenicol was well absorbed (94.1\%) after i.m. administration. According to Monte Carlo simulation, 8.5 and 6 mg/kg were adequate to exert 90\% bactericidal effect against Actinobacillus pleuropneumoniae after i.v. and i.m. administration.},
	pages = {719--725},
	number = {5},
	journaltitle = {Journal of Veterinary Pharmacology and Therapeutics},
	author = {Liu, Zhichang and Rong, Ting and Zeng, Dongping and Shen, Xiangguang and Ma, Xianyong and Zeng, Zhenling},
	urldate = {2020-08-13},
	date = {2018},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/jvp.12677},
	keywords = {Markov chain Monte Carlo, Bayesian, florfenicol, population pharmacokinetic, {WinBUGS}},
	file = {liu_et_al_2018_bayesian_population_pharmacokinetic_modeling_of_florfenicol_in_pigs_after.pdf:/home/nathan/Dropbox/njames/zotero_sync/liu_et_al_2018_bayesian_population_pharmacokinetic_modeling_of_florfenicol_in_pigs_after.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/SNVL57ZH/jvp.html:text/html}
}

@article{gamba_bayesian_2019,
	title = {Bayesian sequential integration within a preclinical pharmacokinetic and pharmacodynamic modeling framework: Lessons learned},
	volume = {18},
	issn = {1539-1612},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1941},
	doi = {10.1002/pst.1941},
	shorttitle = {Bayesian sequential integration within a preclinical pharmacokinetic and pharmacodynamic modeling framework},
	abstract = {The present manuscript aims to discuss the implications of sequential knowledge integration of small preclinical trials in a Bayesian pharmacokinetic and pharmacodynamic ({PK}-{PD}) framework. While, at first sight, a Bayesian {PK}-{PD} framework seems to be a natural framework to allow for sequential knowledge integration, the scope of this paper is to highlight some often-overlooked challenges while at the same time providing some guidances in the many and overwhelming choices that need to be made. Challenges as well as opportunities will be discussed that are related to the impact of (1) the prior specification, (2) the choice of random effects, (3) the type of sequential integration method. In addition, it will be shown how the success of a sequential integration strategy is highly dependent on a carefully chosen experimental design when small trials are analyzed.},
	pages = {486--506},
	number = {4},
	journaltitle = {Pharmaceutical Statistics},
	author = {Gamba, Fabiola La and Jacobs, Tom and Geys, Helena and Jaki, Thomas and Serroyen, Jan and Ursino, Moreno and Russu, Alberto and Faes, Christel},
	urldate = {2020-08-13},
	date = {2019},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.1941},
	keywords = {Bayesian inference, nonlinear hierarchical models, pharmacodynamics, pharmacokinetics, recursive, sequential},
	file = {gamba_et_al_2019_bayesian_sequential_integration_within_a_preclinical_pharmacokinetic_and.pdf:/home/nathan/Dropbox/njames/zotero_sync/gamba_et_al_2019_bayesian_sequential_integration_within_a_preclinical_pharmacokinetic_and.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/9DCVXKVU/pst.html:text/html}
}

@article{meng_bayesian_2019,
	title = {Bayesian estimation of time-varying parameters in ordinary differential equation models with noisy time-varying covariates},
	issn = {0361-0918, 1532-4141},
	url = {https://www.tandfonline.com/doi/full/10.1080/03610918.2019.1565584},
	doi = {10.1080/03610918.2019.1565584},
	abstract = {Ordinary differential equations ({ODEs}) are important mathematical models in applied sciences to describe dynamic processes. The parameters involved in the models usually have specific meanings, and hence need to be estimated from the observed data. In applications, the parameters may change with time, which are called timevarying parameters. In this paper, we propose a Bayesian penalized B-spline method to estimate the time-varying parameters and initial values in {ODEs}. Simulation studies show that this method is more efficient than the two-stage local polynomial method. Furthermore, we introduce the {DIC} model selection criterion to determine the number of knots of B-splines.},
	pages = {1--16},
	journaltitle = {Communications in Statistics - Simulation and Computation},
	author = {Meng, Lixin and Zhang, Jiwei and Zhang, Xue and Feng, Guozhong},
	urldate = {2020-08-13},
	date = {2019-02},
	langid = {english},
	file = {meng_et_al_2019_bayesian_estimation_of_time-varying_parameters_in_ordinary_differential.pdf:/home/nathan/Dropbox/njames/zotero_sync/meng_et_al_2019_bayesian_estimation_of_time-varying_parameters_in_ordinary_differential.pdf:application/pdf}
}

@article{duffull_analysis_2004,
	title = {{ANALYSIS} {OF} {POPULATION} {PHARMACOKINETIC} {DATA} {USING} {NONMEM} {AND} {WinBUGS}},
	volume = {15},
	issn = {1054-3406, 1520-5711},
	url = {https://www.tandfonline.com/doi/full/10.1081/BIP-200040824},
	doi = {10.1081/BIP-200040824},
	pages = {53--73},
	number = {1},
	journaltitle = {Journal of Biopharmaceutical Statistics},
	author = {Duffull, Stephen B. and Kirkpatrick, Carl M. J. and Green, Bruce and Holford, Nicholas H. G.},
	urldate = {2020-08-13},
	date = {2004-12-28},
	langid = {english},
	file = {duffull_et_al_2004_analysis_of_population_pharmacokinetic_data_using_nonmem_and_winbugs.pdf:/home/nathan/Dropbox/njames/zotero_sync/duffull_et_al_2004_analysis_of_population_pharmacokinetic_data_using_nonmem_and_winbugs.pdf:application/pdf}
}

@article{best_estimation_1995,
	title = {Estimation of population pharmacokinetics using the Gibbs sampler},
	volume = {23},
	issn = {0090-466X},
	url = {http://link.springer.com/10.1007/BF02353641},
	doi = {10.1007/BF02353641},
	pages = {407--435},
	number = {4},
	journaltitle = {Journal of Pharmacokinetics and Biopharmaceutics},
	author = {Best, Nicola G. and Tan, Keith K. C. and Gilks, Wally R. and Spiegelhalter, David J.},
	urldate = {2020-08-13},
	date = {1995-08},
	langid = {english},
	file = {best_et_al_1995_estimation_of_population_pharmacokinetics_using_the_gibbs_sampler.pdf:/home/nathan/Dropbox/njames/zotero_sync/best_et_al_1995_estimation_of_population_pharmacokinetics_using_the_gibbs_sampler.pdf:application/pdf}
}

@incollection{husmeier_bayesian_2005,
	location = {London},
	title = {Bayesian Analysis of Population Pharmacokinetic/Pharmacodynamic Models},
	isbn = {978-1-85233-778-0},
	url = {http://link.springer.com/10.1007/1-84628-119-9_11},
	abstract = {This chapter discusses Bayesian models of groups of individuals who may have taken several drug doses at various times throughout the course of a clinical trial. The Bayesian approach helps the derivation of predictive distributions that contribute to the optimisation of treatments for diﬀerent target populations.},
	pages = {351--370},
	booktitle = {Probabilistic Modeling in Bioinformatics and Medical Informatics},
	publisher = {Springer-Verlag},
	author = {Lunn, David J.},
	editor = {Husmeier, Dirk and Dybowski, Richard and Roberts, Stephen},
	urldate = {2020-08-13},
	date = {2005},
	langid = {english},
	doi = {10.1007/1-84628-119-9_11},
	note = {Series Title: Advanced Information and Knowledge Processing},
	file = {lunn_2005_bayesian_analysis_of_population_pharmacokinetic-pharmacodynamic_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/lunn_2005_bayesian_analysis_of_population_pharmacokinetic-pharmacodynamic_models.pdf:application/pdf}
}

@article{dokoumetzidis_propagation_2005,
	title = {Propagation of Population Pharmacokinetic Information Using a Bayesian Approach: Comparison with Meta-Analysis},
	volume = {32},
	issn = {1567-567X, 1573-8744},
	url = {http://link.springer.com/10.1007/s10928-005-0048-9},
	doi = {10.1007/s10928-005-0048-9},
	shorttitle = {Propagation of Population Pharmacokinetic Information Using a Bayesian Approach},
	pages = {401--418},
	number = {3},
	journaltitle = {J Pharmacokinet Pharmacodyn},
	author = {Dokoumetzidis, Aristides and Aarons, Leon},
	urldate = {2020-08-13},
	date = {2005-08},
	langid = {english},
	file = {dokoumetzidis_aarons_2005_propagation_of_population_pharmacokinetic_information_using_a_bayesian_approach.pdf:/home/nathan/Dropbox/njames/zotero_sync/dokoumetzidis_aarons_2005_propagation_of_population_pharmacokinetic_information_using_a_bayesian_approach.pdf:application/pdf}
}

@article{neve_nonparametric_2007,
	title = {Nonparametric identification of population models via Gaussian processes},
	volume = {43},
	issn = {00051098},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0005109807001057},
	doi = {10.1016/j.automatica.2006.12.024},
	abstract = {Population models are used to describe the dynamics of different subjects belonging to a population and play an important role in drug pharmacokinetics. A nonparametric identiﬁcation scheme is proposed in which both the average impulse response of the population and the individual ones are modelled as Gaussian stochastic processes. Assuming that the average curve is an integrated Wiener process, it is shown that its estimate is a cubic spline. An empirical Bayes algorithm for estimating both the average and the individual curves is worked out. The model is tested on simulated data sets as well as on xenobiotics pharmacokinetic data.},
	pages = {1134--1144},
	number = {7},
	journaltitle = {Automatica},
	author = {Neve, M. and De Nicolao, G. and Marchesi, L.},
	urldate = {2020-08-13},
	date = {2007-07},
	langid = {english},
	file = {neve_et_al_2007_nonparametric_identification_of_population_models_via_gaussian_processes.pdf:/home/nathan/Dropbox/njames/zotero_sync/neve_et_al_2007_nonparametric_identification_of_population_models_via_gaussian_processes.pdf:application/pdf}
}

@article{lunn_combining_2009,
	title = {Combining {MCMC} with ‘sequential’ {PKPD} modelling},
	volume = {36},
	issn = {1567-567X, 1573-8744},
	url = {http://link.springer.com/10.1007/s10928-008-9109-1},
	doi = {10.1007/s10928-008-9109-1},
	abstract = {We introduce a method for preventing unwanted feedback in Bayesian {PKPD} link models. We illustrate the approach using a simple example on a single individual, and subsequently demonstrate the ease with which it can be applied to more general settings. In particular, we look at the three ‘sequential’ population {PKPD} models examined by Zhang et al. (J Pharmacokinet Pharmacodyn 30:387–404, 2003; J Pharmacokinet Pharmacodyn 30:405–416, 2003), and provide graphical representations of these models to elucidate their structure. An important feature of our approach is that it allows uncertainty regarding the {PK} parameters to propagate through to inferences on the {PD} parameters. This is in contrast to standard two-stage approaches whereby ‘plug-in’ point estimates for either the population or the individual-speciﬁc {PK} parameters are required.},
	pages = {19--38},
	number = {1},
	journaltitle = {J Pharmacokinet Pharmacodyn},
	author = {Lunn, David and Best, Nicky and Spiegelhalter, David and Graham, Gordon and Neuenschwander, Beat},
	urldate = {2020-08-13},
	date = {2009-02},
	langid = {english},
	file = {lunn_et_al_2009_combining_mcmc_with_‘sequential’_pkpd_modelling.pdf:/home/nathan/Dropbox/njames/zotero_sync/lunn_et_al_2009_combining_mcmc_with_‘sequential’_pkpd_modelling.pdf:application/pdf}
}

@article{wang_derivation_2007,
	title = {Derivation of various {NONMEM} estimation methods},
	volume = {34},
	issn = {1567-567X, 1573-8744},
	url = {http://link.springer.com/10.1007/s10928-007-9060-6},
	doi = {10.1007/s10928-007-9060-6},
	abstract = {Various estimation methods and the lack of a systematic derivation of the core objective function implemented in {NONMEM} for nonlinear mixed effect modeling has caused consistent confusion and inquiry among scientists who routinely use {NONMEM} for data analysis. This paper provides a detailed derivation of the objective functions for the most commonly used estimation methods in {NONMEM}, such as the Laplacian method, the ﬁrst-order conditional estimation method ({FOCE}) with or without interaction, and the ﬁrst-order method ({FO}). In addition, models with homogenous or heterogeneous residual error were used to demonstrate the relationship between the objective functions derived from two different types of approximation, namely Laplacian approximation of log-likelihood and linearized model approximation. The relationship between these estimation methods and those implemented in {SAS} and Splus is discussed.},
	pages = {575--593},
	number = {5},
	journaltitle = {J Pharmacokinet Pharmacodyn},
	author = {Wang, Yaning},
	urldate = {2020-08-13},
	date = {2007-09-21},
	langid = {english},
	file = {wang_2007_derivation_of_various_nonmem_estimation_methods.pdf:/home/nathan/Dropbox/njames/zotero_sync/wang_2007_derivation_of_various_nonmem_estimation_methods.pdf:application/pdf}
}

@article{pillonetto_fast_2009,
	title = {Fast algorithms for nonparametric population modeling of large data sets},
	volume = {45},
	issn = {00051098},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0005109808003713},
	doi = {10.1016/j.automatica.2008.06.003},
	abstract = {Population models are widely applied in biomedical data analysis since they characterize both the average and individual responses of a population of subjects. In the absence of a reliable mechanistic model, one can resort to the Bayesian nonparametric approach that models the individual curves as Gaussian processes. This paper develops an efficient computational scheme for estimating the average and individual curves from large data sets collected in standardized experiments, i.e. with a fixed sampling schedule. It is shown that the overall scheme exhibits a ‘‘client–server’’ architecture. The server is in charge of handling and processing the collective data base of past experiments. The clients ask the server for the information needed to reconstruct the individual curve in a single new experiment. This architecture allows the clients to take advantage of the overall data set without violating possible privacy and confidentiality constraints and with negligible computational effort.},
	pages = {173--179},
	number = {1},
	journaltitle = {Automatica},
	author = {Pillonetto, Gianluigi and De Nicolao, Giuseppe and Chierici, Marco and Cobelli, Claudio},
	urldate = {2020-08-13},
	date = {2009-01},
	langid = {english},
	file = {pillonetto_et_al_2009_fast_algorithms_for_nonparametric_population_modeling_of_large_data_sets.pdf:/home/nathan/Dropbox/njames/zotero_sync/pillonetto_et_al_2009_fast_algorithms_for_nonparametric_population_modeling_of_large_data_sets.pdf:application/pdf}
}

@article{zhao_bayesian_2017,
	title = {Bayesian hierarchical model for analyzing multiresponse longitudinal pharmacokinetic data},
	volume = {36},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7505},
	doi = {10.1002/sim.7505},
	abstract = {Traditional Chinese medicine ({TCM}) is a very complex mixture containing many different ingredients. Thus, statistical analysis of traditional Chinese medicine data becomes challenging, as one needs to handle the association among the observed data across different time points and across different ingredients of the multivariate response. This paper builds a 3-stage Bayesian hierarchical model for analyzing multivariate response pharmacokinetic data. Usually, the dimensionality of the parameter space is very huge, which leads to the parameter-estimation difficulty. So we take the hybrid Markov chain Monte Carlo algorithms to obtain the posterior Bayesian estimation of corresponding parameters in our model. Both simulation study and real-data analysis show that our theoretical model and Markov chain Monte Carlo algorithms perform well, and especially the correlation among different ingredients can be calculated very accurately.},
	pages = {4816--4830},
	number = {30},
	journaltitle = {Statistics in Medicine},
	author = {Zhao, Liping and Xia, Zhiming},
	urldate = {2020-08-13},
	date = {2017},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.7505},
	keywords = {hierarchical model, {MCMC} algorithm, pharmacokinetic, traditional Chinese medicine},
	file = {Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/5QVLQ2IC/sim.html:text/html;zhao_xia_2017_bayesian_hierarchical_model_for_analyzing_multiresponse_longitudinal.pdf:/home/nathan/Dropbox/njames/zotero_sync/zhao_xia_2017_bayesian_hierarchical_model_for_analyzing_multiresponse_longitudinal.pdf:application/pdf}
}

@article{kathman_bayesian_2007,
	title = {A Bayesian Population {PK}–{PD} Model of Ispinesib-induced Myelosuppression},
	volume = {81},
	issn = {1532-6535},
	url = {http://ascpt.onlinelibrary.wiley.com/doi/abs/10.1038/sj.clpt.6100021},
	doi = {10.1038/sj.clpt.6100021},
	abstract = {The goal of the present analysis is to fit a Bayesian population pharmacokinetic pharmacodynomic ({PK}–{PD}) model to characterize the relationship between the concentration of ispinesib and changes in absolute neutrophil counts ({ANC}). Ispinesib, a kinesin spindle protein ({KSP}) inhibitor, blocks assembly of a functional mitotic spindle, leading to G2/M arrest. A first time in human, phase I open-label, non-randomized, dose-escalating study evaluated ispinesib at doses ranging from 1 to 21 mg/m2. {PK}–{PD} data were collected from 45 patients with solid tumors. The pharmacokinetics of ispinesib were well characterized by a two-compartment model. A semimechanistic model was fit to the {ANC}. The {PK} and {PD} data were successfully modelled simultaneously. This is the first presentation of simultaneously fitting a {PK}–{PD} model to {ANC} using Bayesian methods. Bayesian methods allow for the use of prior information for some system-related parameters. The model may be used to examine different schedules, doses, and infusion times. Clinical Pharmacology \& Therapeutics (2007) 81, 88–94. doi:10.1038/sj.clpt.6100021},
	pages = {88--94},
	number = {1},
	journaltitle = {Clinical Pharmacology \& Therapeutics},
	author = {Kathman, S. J. and Williams, D. H. and Hodge, J. P. and Dar, M.},
	urldate = {2020-08-13},
	date = {2007},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1038/sj.clpt.6100021},
	file = {kathman_et_al_2007_a_bayesian_population_pk–pd_model_of_ispinesib-induced_myelosuppression.pdf:/home/nathan/Dropbox/njames/zotero_sync/kathman_et_al_2007_a_bayesian_population_pk–pd_model_of_ispinesib-induced_myelosuppression.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/585Q9GE2/sj.clpt.html:text/html}
}

@article{jaeger_bayesian_2013,
	title = {Bayesian P-spline estimation in hierarchical models specified by systems of affine differential equations},
	volume = {13},
	issn = {1471-082X, 1477-0342},
	url = {http://journals.sagepub.com/doi/10.1177/1471082X12471371},
	doi = {10.1177/1471082X12471371},
	abstract = {Ordinary differential equations ({ODEs}) are widely used to model physical, chemical and biological processes. Current methods for parameter estimation can be computationally intensive and/or not suitable for inference and prediction. Frequentist approaches based on {ODE}-penalized smoothing techniques have recently solved part of these drawbacks. A full Bayesian approach based on {ODE}-penalized B-splines is proposed to jointly estimate {ODE} parameters and state functions from afﬁne systems of differential equations. Simulations inspired by pharmacokinetic studies show that the proposed method provides comparable results to methods based on explicit solution of the {ODEs} and outperforms the frequentist {ODE}-penalized smoothing approach. The basic model is extended to a hierarchical one in order to study cases where several subjects are involved. This Bayesian hierarchical approach is illustrated on real data for the study of perfusion ratio after a femoral artery occlusion. Model selection is feasible through the analysis of the posterior distributions of the {ODE} adhesion parameters and is illustrated on a real pharmacokinetic dataset.},
	pages = {3--40},
	number = {1},
	journaltitle = {Statistical Modelling},
	author = {Jaeger, Jonathan and Lambert, Philippe},
	urldate = {2020-08-13},
	date = {2013-02},
	langid = {english},
	file = {jaeger_lambert_2013_bayesian_p-spline_estimation_in_hierarchical_models_specified_by_systems_of.pdf:/home/nathan/Dropbox/njames/zotero_sync/jaeger_lambert_2013_bayesian_p-spline_estimation_in_hierarchical_models_specified_by_systems_of.pdf:application/pdf}
}

@article{neve_nonparametric_2008,
	title = {Nonparametric Identification of Population Models: An {MCMC} Approach},
	volume = {55},
	issn = {1558-2531},
	doi = {10.1109/TBME.2007.902240},
	shorttitle = {Nonparametric Identification of Population Models},
	abstract = {The paper deals with the nonparametric identification of population models, that is models that explain jointly the behavior of different subjects drawn from a population, e.g., responses of different patients to a drug. The average response of the population and the individual responses are modeled as continuous-time Gaussian processes with unknown hyperparameters. Within a Bayesian paradigm, the posterior expectation and variance of both the average and individual curves are computed by means of a Markov Chain Monte Carlo scheme. The model and the estimation procedure are tested on both simulated and experimental pharmacokinetic data.},
	pages = {41--50},
	number = {1},
	journaltitle = {{IEEE} Transactions on Biomedical Engineering},
	author = {Neve, Marta and De Nicolao, Giuseppe and Marchesi, Laura},
	date = {2008-01},
	note = {Conference Name: {IEEE} Transactions on Biomedical Engineering},
	keywords = {Drugs, Markov processes, Algorithms, Animals, Bayes methods, Bayesian estimation, Bayesian methods, Bayesian paradigm, biomedical data analysis, Computational modeling, Computer Simulation, continuous-time Gaussian processes, data analysis, Data analysis, Data Interpretation, Statistical, drug, drugs, expectation-maximisation algorithm, Gaussian processes, Humans, Markov Chain Monte Carlo, Markov Chain Monte Carlo scheme, Markov Chains, medical computing, Models, Biological, Models, Statistical, Monte Carlo Method, Monte Carlo methods, neural networks, Neural networks, nonparametric identification, nonparametric statistics, Parametric statistics, patient treatment, Performance analysis, pharmacokinetic data, Population Dynamics, population models, posterior expectation, regularization, splines, Testing},
	file = {IEEE Xplore Abstract Record:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/VGS4GM3G/4404094.html:text/html;neve_et_al_2008_nonparametric_identification_of_population_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/neve_et_al_2008_nonparametric_identification_of_population_models.pdf:application/pdf}
}

@article{wakefield_bayesian_1996-1,
	title = {The Bayesian Modeling of Covariates for Population Pharmacokinetic Models},
	volume = {91},
	pages = {917--927},
	number = {435},
	journaltitle = {Journal of the American Statistical Association},
	author = {Wakefield, Jon and Bennett, James},
	date = {1996-09},
	langid = {english},
	file = {wakefield_bennett_1996_the_bayesian_modeling_of_covariates_for_population_pharmacokinetic_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/wakefield_bennett_1996_the_bayesian_modeling_of_covariates_for_population_pharmacokinetic_models.pdf:application/pdf}
}

@book{ibrahim_bayesian_2010,
	location = {New York},
	edition = {Softcover repr. of the hardcover 1st edition 2001, corr. 2nd printing},
	title = {Bayesian survival analysis},
	isbn = {978-1-4419-2933-4},
	series = {Springer series in statistics},
	pagetotal = {479},
	publisher = {Springer},
	author = {Ibrahim, Joseph George and Chen, Ming-Hui and Sinha, Debajyoti},
	date = {2010}
}

@article{koethe_serum_2012,
	title = {Serum Leptin Level Mediates the Association of Body Composition and Serum C-Reactive Protein in {HIV}-Infected Persons on Antiretroviral Therapy},
	volume = {28},
	issn = {0889-2229, 1931-8405},
	url = {http://www.liebertpub.com/doi/10.1089/aid.2011.0232},
	doi = {10.1089/aid.2011.0232},
	pages = {552--557},
	number = {6},
	journaltitle = {{AIDS} Research and Human Retroviruses},
	author = {Koethe, John R. and Bian, Aihua and Shintani, Ayumi K. and Boger, M. Sean and Mitchell, Valerie J. and Erdem, Husamettin and Hulgan, Todd},
	urldate = {2020-08-13},
	date = {2012-06},
	langid = {english},
	file = {koethe_et_al_2012_serum_leptin_level_mediates_the_association_of_body_composition_and_serum.pdf:/home/nathan/Dropbox/njames/zotero_sync/koethe_et_al_2012_serum_leptin_level_mediates_the_association_of_body_composition_and_serum.pdf:application/pdf}
}

@article{koethe_metabolic_2015,
	title = {The metabolic and cardiovascular consequences of obesity in persons with {HIV} on long-term antiretroviral therapy:},
	issn = {0269-9370},
	url = {http://journals.lww.com/00002030-900000000-97959},
	doi = {10.1097/QAD.0000000000000893},
	shorttitle = {The metabolic and cardiovascular consequences of obesity in persons with {HIV} on long-term antiretroviral therapy},
	abstract = {Objective—This study assessed the effect of obesity on metabolic and cardiovascular disease risk factors in {HIV}-infected adults on antiretroviral therapy ({ART}) with sustained virologic suppression. Design—Observational, comparative cohort study with three group-matched arms: 35 non-obese and 35 obese {HIV}-infected persons on efavirenz, tenofovir, and emtricitabine with plasma {HIV}-1 {RNA} {\textless}50 copies/ml for {\textgreater}2 years, and 30 obese {HIV}-uninfected controls. Subjects did not have diabetes or known cardiovascular disease.
Methods—We compared glucose tolerance, serum lipids, brachial artery flow mediated dilation ({FMD}), carotid intima-media thickness ({cIMT}), and soluble inflammatory and vascular adhesion markers between non-obese and obese {HIV}-infected subjects, and between obese {HIV}-infected and {HIV}-uninfected subjects, using Wilcoxon rank sum tests and multivariate linear regression.
Results—The cohort was 52\% male and 48\% non-white. Non-obese and obese {HIV}-infected subjects did not differ by clinical or demographic characteristics. {HIV}-uninfected obese controls were younger than obese {HIV}-infected subjects and less likely to smoke (p≤0.03 for both). Among {HIV}-infected subjects, obesity was associated with greater insulin release, lower insulin sensitivity, and higher serum {hsCRP}, {IL}-6, and {TNF}-α receptor 1 levels (p{\textless}0.001), but similar lipid profiles, {sCD}14, {sCD}163, {ICAM}-1 and {VCAM}-1, and {cIMT} and {FMD}. In contrast, {HIVinfected} subjects had adverse lipid changes, and greater circulating {ICAM}-1, {VCAM}-1 and {sCD}14, compared to {HIV}-uninfected controls after adjusting for age and other factors.
Conclusions—Obesity impairs glucose metabolism and contributes to circulating {hsCRP}, {IL}-6, and {TNF}-α receptor 1 levels, but has few additive effects on dyslipidemia and endothelial activation, in {HIV}-infected adults on long-term {ART}.},
	pages = {1},
	journaltitle = {{AIDS}},
	author = {Koethe, John R. and Grome, Heather and Jenkins, Cathy A. and Kalams, Spyros A. and Sterling, Timothy R.},
	urldate = {2020-08-13},
	date = {2015-09},
	langid = {english},
	file = {koethe_et_al_2015_the_metabolic_and_cardiovascular_consequences_of_obesity_in_persons_with_hiv_on.pdf:/home/nathan/Dropbox/njames/zotero_sync/koethe_et_al_2015_the_metabolic_and_cardiovascular_consequences_of_obesity_in_persons_with_hiv_on.pdf:application/pdf}
}

@article{brunner_bayesian_1995,
	title = {Bayesian linear regression with error terms that have symmetric unimodal densities},
	volume = {4},
	issn = {1048-5252, 1029-0311},
	url = {http://www.tandfonline.com/doi/abs/10.1080/10485259508832625},
	doi = {10.1080/10485259508832625},
	abstract = {Bayes methods are provided for a multiple linear regression model in which the error terms have densities that are symmetric and unimodal at zero, but whose form is otherwise unknown. The posterior distribution of the vector of regression coefficientsis obtained, as well as the predictive distribution and a Bayes estimate of the error density. A new approximation method is described. A set of real data with outliers and a set of simulated data are used to compare this method to parametric methods and to an existing Monte Carlo approach.},
	pages = {335--348},
	number = {4},
	journaltitle = {Journal of Nonparametric Statistics},
	author = {Brunner, Lawrence J.},
	urldate = {2020-08-13},
	date = {1995-01},
	langid = {english},
	file = {Brunner - 1995 - Bayesian linear regression with error terms that h.pdf:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/VJ6MFK3X/Brunner - 1995 - Bayesian linear regression with error terms that h.pdf:application/pdf;brunner_1995_bayesian_linear_regression_with_error_terms_that_have_symmetric_unimodal.pdf:/home/nathan/Dropbox/njames/zotero_sync/brunner_1995_bayesian_linear_regression_with_error_terms_that_have_symmetric_unimodal.pdf:application/pdf}
}

@article{wakefield_bayesian_1994,
	title = {Bayesian Analysis of Linear and Non-Linear Population Models by Using the Gibbs Sampler},
	volume = {43},
	abstract = {A fully Bayesian analysis of linear and non-linear population models has previously been unavailable, as a consequence of the seeming impossibility of performing the necessary numerical integrations in the complex multiparameter structures that typically arise in such models. It is demonstrated that, for a variety of linear and non-linear population models, a fully Bayesian analysis can be implemented in a straightforward manner by using the Gibbs sampler. The approach is illustrated with examples involving challenging problems of outliers and meanvariance relationships in population modelling.},
	pages = {201--221},
	number = {1},
	journaltitle = {Applied Statistics},
	author = {Wakefield, J C and Smith, A F M and Racine-Poon, A and Gelfand, A E},
	date = {1994},
	langid = {english},
	file = {wakefield_et_al_1994_bayesian_analysis_of_linear_and_non-linear_population_models_by_using_the_gibbs.pdf:/home/nathan/Dropbox/njames/zotero_sync/wakefield_et_al_1994_bayesian_analysis_of_linear_and_non-linear_population_models_by_using_the_gibbs.pdf:application/pdf}
}

@incollection{bickel_bayesian_1999,
	location = {New York, {NY}},
	title = {The Bayesian approach to Population pharmacokinetic/pharmacodynamic modeling},
	volume = {140},
	isbn = {978-0-387-98640-1 978-1-4612-1502-8},
	url = {http://link.springer.com/10.1007/978-1-4612-1502-8_4},
	abstract = {It is one of the principal aims of drug development to discover, for a particular agent, the relationship between dose administered, drug concentrations in the body and efﬁcacy/toxicity. Understanding this relationship leads to the determination of doses which are both effective and safe. Population pharmacokinetic/pharmacodynamic models provide an important aid to this understanding.},
	pages = {205--265},
	booktitle = {Case Studies in Bayesian Statistics},
	publisher = {Springer New York},
	author = {Wakefield, Jon and Aarons, Leon and Racine-Poon, Amy},
	editor = {Gatsonis, Constantine and Kass, Robert E. and Carlin, Bradley and Carriquiry, Alicia and Gelman, Andrew and Verdinelli, Isabella and West, Mike},
	editorb = {Bickel, P. and Diggle, P. and Fienberg, S. and Krickeberg, K. and Olkin, I. and Wermuth, N. and Zeger, S.},
	editorbtype = {redactor},
	urldate = {2020-08-14},
	date = {1999},
	langid = {english},
	doi = {10.1007/978-1-4612-1502-8_4},
	note = {Series Title: Lecture Notes in Statistics},
	file = {wakefield_et_al_1999_the_bayesian_approach_to_population_pharmacokinetic-pharmacodynamic_modeling.pdf:/home/nathan/Dropbox/njames/zotero_sync/wakefield_et_al_1999_the_bayesian_approach_to_population_pharmacokinetic-pharmacodynamic_modeling.pdf:application/pdf}
}

@article{sheiner_evaluation_1980,
	title = {Evaluation of methods for estimating population pharmacokinetic parameters. I. Michaelis-menten model: Routine clinical pharmacokinetic data},
	volume = {8},
	issn = {0090-466X},
	url = {http://link.springer.com/10.1007/BF01060053},
	doi = {10.1007/BF01060053},
	shorttitle = {Evaluation of methods for estimating population pharmacokinetic parameters. I. Michaelis-menten model},
	pages = {553--571},
	number = {6},
	journaltitle = {Journal of Pharmacokinetics and Biopharmaceutics},
	author = {Sheiner, Lewis B. and Beal, Stuart L.},
	urldate = {2020-08-20},
	date = {1980-12},
	langid = {english},
	file = {sheiner_beal_1980_evaluation_of_methods_for_estimating_population_pharmacokinetic_parameters.pdf:/home/nathan/Dropbox/njames/zotero_sync/sheiner_beal_1980_evaluation_of_methods_for_estimating_population_pharmacokinetic_parameters.pdf:application/pdf}
}

@article{sheiner_evaluation_1983,
	title = {Evaluation of methods for estimating population pharmacokinetic parameters. {III}. Monoexponential model: Routine clinical pharmacokinetic data},
	volume = {11},
	issn = {0090-466X},
	url = {http://link.springer.com/10.1007/BF01061870},
	doi = {10.1007/BF01061870},
	shorttitle = {Evaluation of methods for estimating population pharmacokinetic parameters. {III}. Monoexponential model},
	pages = {303--319},
	number = {3},
	journaltitle = {Journal of Pharmacokinetics and Biopharmaceutics},
	author = {Sheiner, Lewis B. and Beal, Stuart L.},
	urldate = {2020-08-20},
	date = {1983-06},
	langid = {english},
	file = {sheiner_beal_1983_evaluation_of_methods_for_estimating_population_pharmacokinetic_parameters.pdf:/home/nathan/Dropbox/njames/zotero_sync/sheiner_beal_1983_evaluation_of_methods_for_estimating_population_pharmacokinetic_parameters.pdf:application/pdf}
}

@article{sheiner_evaluation_1981,
	title = {Evaluation of methods for estimating population pharmacokinetic parameters {II}. Biexponential model and experimental pharmacokinetic data},
	volume = {9},
	issn = {0090-466X},
	url = {http://link.springer.com/10.1007/BF01061030},
	doi = {10.1007/BF01061030},
	pages = {635--651},
	number = {5},
	journaltitle = {Journal of Pharmacokinetics and Biopharmaceutics},
	author = {Sheiner, Lewis B. and Beal, Stuart L.},
	urldate = {2020-08-20},
	date = {1981-10},
	langid = {english},
	file = {sheiner_beal_1981_evaluation_of_methods_for_estimating_population_pharmacokinetic_parameters_ii.pdf:/home/nathan/Dropbox/njames/zotero_sync/sheiner_beal_1981_evaluation_of_methods_for_estimating_population_pharmacokinetic_parameters_ii.pdf:application/pdf}
}

@book{muller_bayesian_2015,
	location = {Cham},
	title = {Bayesian nonparametric data analysis},
	isbn = {978-3-319-18967-3},
	series = {Springer series in statistics},
	pagetotal = {193},
	publisher = {Springer},
	author = {Müller, Peter and Quintana, Fernando Andrés and Jara, Alejandro and Hanson, Tim},
	date = {2015},
	note = {{OCLC}: 919835537},
	file = {müller_et_al_2015_bayesian_nonparametric_data_analysis.pdf:/home/nathan/Dropbox/njames/zotero_sync/müller_et_al_2015_bayesian_nonparametric_data_analysis.pdf:application/pdf}
}

@collection{hjort_bayesian_2010,
	location = {Cambridge, {UK} ; New York},
	title = {Bayesian nonparametrics},
	isbn = {978-0-521-51346-3},
	series = {Cambridge series in statistical and probabilistic mathematics},
	abstract = {"Bayesian nonparametrics works - theoretically, computationally. The theory provides highly flexible models whose complexity grows appropriately with the amount of data. Computational issues, though challenging, are no longer intractable. All that is needed is an entry point: this intelligent book is the perfect guide to what can seem a forbidding landscape. Tutorial chapters by Ghosal, Lijoi and Prünster, Teh and Jordan, and Dunson advance from theory, to basic models and hierarchical modeling, to applications and implementation, particularly in computer science and biostatistics. These are complemented by companion chapters by the editors and Griffin and Quintana, providing additional models, examining computational issues, identifying future growth areas, and giving links to related topics. This coherent text gives ready access both to underlying principles and to state-of-the-art practice. Specific examples are drawn from information retrieval, {NLP}, machine vision, computational biology, biostatistics, and bioinformatics"--Provided by publisher},
	pagetotal = {299},
	number = {28},
	publisher = {Cambridge University Press},
	editor = {Hjort, Nils Lid},
	date = {2010},
	note = {{OCLC}: ocn441945339},
	keywords = {Bayesian statistical decision theory, Nonparametric statistics}
}

@book{turkman_computational_2019,
	location = {Cambridge ; New York, {NY}},
	title = {Computational Bayesian statistics: an introduction},
	isbn = {978-1-108-48103-8 978-1-108-70374-1},
	series = {Institute of Mathematical Statistics textbooks},
	shorttitle = {Computational Bayesian statistics},
	number = {11},
	publisher = {Cambridge University Press},
	author = {Turkman, Maria Antónia Amaral and Paulino, Carlos Daniel and Müller, Peter},
	date = {2019},
	keywords = {Bayesian statistical decision theory, Textbooks}
}

@article{vozeh_population_1982,
	title = {Population pharmacokinetic parameters in patients treated with oral mexiletine},
	volume = {23},
	issn = {0031-6970, 1432-1041},
	url = {http://link.springer.com/10.1007/BF00605996},
	doi = {10.1007/BF00605996},
	abstract = {A new data analysis approach, {NONMEM}, proposed by Sheiner and Beal, has been employed to estimate the population pharmacokinetic parameters of oral mexiletine in patients treated for arrhythmias. 452 serum concentration measurements in 58 patients were available for analysis. 27 patients had congestive heart failure and 8 had abnormal liver function tests at the time of the study. The population averages of the pharmacokinetic parameters and their interindividual variability were: oral total body clearance (C1) 0.38 l/h/kg + 43\% (C.V.), apparent volume of distribution (Vd) 5.3 1/kg \_ 40\%, absorption rate constant 3.1 h -1 + 205\%, absorption time-lag 0.3 h. Congestive heart failure and sex did not show a significant effect on C1 and Vd; the number of patients with severe liver function impairment was too small for a definite conclusion. Normalizing C1 and Vd for body weight significantly decreased their interindividual variability. Based on these results, a dosage regimen is recommended which is expected to produce a "therapeutic" serum concentration (0.8-2 mg/1) in over 60\% of patients. Because of its unique features, which allow estimation of pharmacokinetic parameters and their variability from fragmentary patient data, the {NONMEM} system has great potential applicability to clinical pharmacokinetic studies.},
	pages = {445--451},
	number = {5},
	journaltitle = {Eur J Clin Pharmacol},
	author = {Vozeh, S. and Katz, G. and Steiner, V. and Follath, F.},
	urldate = {2020-08-26},
	date = {1982},
	langid = {english},
	file = {vozeh_et_al_1982_population_pharmacokinetic_parameters_in_patients_treated_with_oral_mexiletine.pdf:/home/nathan/Dropbox/njames/zotero_sync/vozeh_et_al_1982_population_pharmacokinetic_parameters_in_patients_treated_with_oral_mexiletine.pdf:application/pdf}
}

@article{grasela_evaluation_1986,
	title = {An evaluation of population pharmacokinetics in therapeutic trials. Part I. Comparison of methodologies},
	volume = {39},
	issn = {1532-6535},
	url = {http://ascpt.onlinelibrary.wiley.com/doi/10.1038/clpt.1986.107},
	doi = {10.1038/clpt.1986.107},
	abstract = {{NONMEM}, a computer program that uses the method of extended least‐squares analysis, has been advocated as a means of obtaining estimates of population pharmacokinetic parameters when only fragmentary...},
	pages = {605--612},
	number = {6},
	journaltitle = {Clinical Pharmacology \& Therapeutics},
	author = {Grasela, Thaddeus H. and Antai, Edward J. and Townsend, Raymond J. and Smith, Randall B.},
	urldate = {2020-08-27},
	date = {1986-06-01},
	langid = {english},
	note = {Publisher: John Wiley \& Sons, Ltd},
	file = {grasela_et_al_1986_an_evaluation_of_population_pharmacokinetics_in_therapeutic_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/grasela_et_al_1986_an_evaluation_of_population_pharmacokinetics_in_therapeutic_trials.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/ETVVRES8/login.html:text/html}
}

@article{grasela_evaluation_1987,
	title = {An evaluation of population pharmacokinetics in therapeutic trials. Part {II}. Detection of a drug‐drug interaction},
	volume = {42},
	issn = {1532-6535},
	url = {http://ascpt.onlinelibrary.wiley.com/doi/10.1038/clpt.1987.174},
	doi = {10.1038/clpt.1987.174},
	abstract = {The use of observational data, collected during the routine clinical care of patients, has been advocated as a means to obtain clinically relevant information regarding the pharmacokinetic parameters...},
	pages = {433--441},
	number = {4},
	journaltitle = {Clinical Pharmacology \& Therapeutics},
	author = {Grasela, Thaddeus H. and Antal, Edward J. and Ereshefsky, Larry and Wells, Barbara G. and Evans, R. Lee and Smith, Randall B.},
	urldate = {2020-08-27},
	date = {1987-10-01},
	langid = {english},
	note = {Publisher: John Wiley \& Sons, Ltd},
	file = {grasela_et_al_1987_an_evaluation_of_population_pharmacokinetics_in_therapeutic_trials.pdf:/home/nathan/Dropbox/njames/zotero_sync/grasela_et_al_1987_an_evaluation_of_population_pharmacokinetics_in_therapeutic_trials.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/8TR75FFL/login.html:text/html}
}

@article{mandema_building_1992,
	title = {Building population pharmacokineticpharmacodynamic models. I. Models for covariate effects},
	volume = {20},
	issn = {0090-466X},
	url = {http://link.springer.com/10.1007/BF01061469},
	doi = {10.1007/BF01061469},
	pages = {511--528},
	number = {5},
	journaltitle = {Journal of Pharmacokinetics and Biopharmaceutics},
	author = {Mandema, Jaap W. and Verotta, Davide and Sheiner, Lewis B.},
	urldate = {2020-08-27},
	date = {1992-10},
	langid = {english},
	file = {mandema_et_al_1992_building_population_pharmacokineticpharmacodynamic_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/mandema_et_al_1992_building_population_pharmacokineticpharmacodynamic_models.pdf:application/pdf}
}

@article{sheiner_population_1992,
	title = {Population Pharmacokinetics/Dynamics},
	volume = {32},
	pages = {185--209},
	number = {1},
	journaltitle = {Annual Review of Pharmacology and Toxicology},
	author = {Sheiner, L B and Ludden, T M},
	date = {1992},
	langid = {english},
	file = {sheiner_ludden_1992_population_pharmacokinetics-dynamics.pdf:/home/nathan/Dropbox/njames/zotero_sync/sheiner_ludden_1992_population_pharmacokinetics-dynamics.pdf:application/pdf}
}

@article{karlsson_importance_1993,
	title = {The importance of modeling interoccasion variability in population pharmacokinetic analyses},
	volume = {21},
	issn = {0090-466X},
	url = {http://link.springer.com/10.1007/BF01113502},
	doi = {10.1007/BF01113502},
	pages = {735--750},
	number = {6},
	journaltitle = {Journal of Pharmacokinetics and Biopharmaceutics},
	author = {Karlsson, M. O. and Sheiner, L. B.},
	urldate = {2020-08-27},
	date = {1993-12},
	langid = {english},
	file = {karlsson_sheiner_1993_the_importance_of_modeling_interoccasion_variability_in_population.pdf:/home/nathan/Dropbox/njames/zotero_sync/karlsson_sheiner_1993_the_importance_of_modeling_interoccasion_variability_in_population.pdf:application/pdf}
}

@article{wade_interaction_1994,
	title = {Interaction between structural, statistical, and covariate models in population pharmacokinetic analysis},
	volume = {22},
	issn = {0090-466X},
	url = {http://link.springer.com/10.1007/BF02353542},
	doi = {10.1007/BF02353542},
	pages = {165--177},
	number = {2},
	journaltitle = {Journal of Pharmacokinetics and Biopharmaceutics},
	author = {Wade, Janet R. and Beal, Stuart L. and Sambol, Nancy C.},
	urldate = {2020-08-27},
	date = {1994-04},
	langid = {english},
	file = {wade_et_al_1994_interaction_between_structural,_statistical,_and_covariate_models_in_population.pdf:/home/nathan/Dropbox/njames/zotero_sync/wade_et_al_1994_interaction_between_structural,_statistical,_and_covariate_models_in_population.pdf:application/pdf}
}

@article{bruno_population_1996,
	title = {A population pharmacokinetic model for docetaxel (Taxotere®): Model building and validation},
	volume = {24},
	issn = {0090-466X},
	url = {http://link.springer.com/10.1007/BF02353487},
	doi = {10.1007/BF02353487},
	shorttitle = {A population pharmacokinetic model for docetaxel (Taxotere®)},
	pages = {153--172},
	number = {2},
	journaltitle = {Journal of Pharmacokinetics and Biopharmaceutics},
	author = {Bruno, René and Vivier, Nicole and Vergniol, Jean Claude and De Phillips, Susan L. and Montay, Guy and Sheiner, Lewis B.},
	urldate = {2020-08-27},
	date = {1996-04},
	langid = {english},
	file = {bruno_et_al_1996_a_population_pharmacokinetic_model_for_docetaxel_(taxotere®).pdf:/home/nathan/Dropbox/njames/zotero_sync/bruno_et_al_1996_a_population_pharmacokinetic_model_for_docetaxel_(taxotere®).pdf:application/pdf}
}

@article{karlsson_assumption_nodate,
	title = {Assumption Testing in Population Pharmacokinetic Models: Illustrated with an Analysis of Moxonidine Data from Congestive Heart Failure Patients},
	pages = {40},
	author = {Karlsson, Mats O and Jonsson, E Niclas and Wiltse, Curtis G and Wade, Janet R},
	langid = {english},
	file = {karlsson_et_al_assumption_testing_in_population_pharmacokinetic_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/karlsson_et_al_assumption_testing_in_population_pharmacokinetic_models.pdf:application/pdf}
}

@online{noauthor_a1018828709196pdf_nodate,
	title = {A1018828709196.pdf},
	url = {https://link-springer-com.proxy.library.vanderbilt.edu/content/pdf/10.1023/A:1018828709196.pdf},
	urldate = {2020-08-27}
}

@article{bonate_effect_1999,
	title = {The Effect of Collinearity on Parameter Estimates in Nonlinear Mixed Effect Models},
	volume = {16},
	issn = {07248741},
	url = {http://link.springer.com/10.1023/A:1018828709196},
	doi = {10.1023/A:1018828709196},
	pages = {709--717},
	number = {5},
	journaltitle = {Pharmaceutical Research},
	author = {Bonate, Peter L.},
	urldate = {2020-08-27},
	date = {1999},
	file = {bonate_1999_the_effect_of_collinearity_on_parameter_estimates_in_nonlinear_mixed_effect.pdf:/home/nathan/Dropbox/njames/zotero_sync/bonate_1999_the_effect_of_collinearity_on_parameter_estimates_in_nonlinear_mixed_effect.pdf:application/pdf}
}

@article{hartford_consequences_2000,
	title = {Consequences of misspecifying assumptions in nonlinear mixed e ects models},
	abstract = {The nonlinear mixed e ects model provides a framework for inference in a number of applications, most notably pharmacokinetics and pharmacodynamics, but also in {HIV} and other disease dynamics and in a host of other longitudinal-data settings. In these models, to characterize population variation, individual-speciÿc parameters are modeled as functions of ÿxed e ects and mean-zero random e ects. A standard assumption is that of normality of the random e ects, but this assumption may not always be realistic, and, because the random e ects are not observed, it may be di cult to verify. An additional issue is specifying the form of the function relating individual-speciÿc parameters to ÿxed and random e ects. Again, because this relationship is not observed explicitly, it may be di cult to specify. Popular methods for ÿtting these models are predicated on the normality assumption, and past studies evaluating their performance have assumed that normality and the form of the model are correct speciÿcations. We investigate the consequences for population inferences using these methods when the normality assumption is inappropriate and=or the model is misspeciÿed. c 2000 Elsevier Science B.V. All rights reserved.},
	pages = {26},
	journaltitle = {Computational Statistics},
	author = {Hartford, Alan and Davidian, Marie},
	date = {2000},
	langid = {english},
	file = {hartford_davidian_2000_consequences_of_misspecifying_assumptions_in_nonlinear_mixed_e_ects_models.pdf:/home/nathan/Dropbox/njames/zotero_sync/hartford_davidian_2000_consequences_of_misspecifying_assumptions_in_nonlinear_mixed_e_ects_models.pdf:application/pdf}
}

@article{kowalski_design_2001,
	title = {Design evaluation for a population pharmacokinetic study using clinical trial simulations: a case study},
	volume = {20},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/1097-0258%2820010115%2920%3A1%3C75%3A%3AAID-SIM602%3E3.0.CO%3B2-C},
	doi = {10.1002/1097-0258(20010115)20:1<75::AID-SIM602>3.0.CO;2-C},
	shorttitle = {Design evaluation for a population pharmacokinetic study using clinical trial simulations},
	abstract = {Clinical trial simulations were conducted to assess power and sample size requirements for a population pharmacokinetic ({PK}) substudy of a phase {III} clinical trial. The simulations were based on a population {PK} model developed from phase I healthy volunteer data. A sparse sampling design was employed taking into account the practical considerations regarding the desire not to keep patients at the study sites for extended periods of time for blood sampling. It was expected that the sparse sampling design would not support fitting the same model developed in healthy volunteers due to the narrow range of sampling times. Therefore, a model with fewer parameters and variance components was fit to simulated data from the proposed design to assess the bias in the estimates of the population mean {PK} parameters and variance components. Results indicate that the proposed design employing the simple model can provide accurate mean estimates of oral drug clearance ({CL}) and the apparent steady-state volume of distribution (Vss). However, the simulation results also suggest that the size and power of the likelihood ratio test for subpopulation differences in {CL} are inflated when using the simple model. Copyright © 2001 John Wiley \& Sons, Ltd.},
	pages = {75--91},
	number = {1},
	journaltitle = {Statistics in Medicine},
	author = {Kowalski, Kenneth G. and Hutmacher, Matthew M.},
	urldate = {2020-08-27},
	date = {2001},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/1097-0258\%2820010115\%2920\%3A1\%3C75\%3A\%3AAID-{SIM}602\%3E3.0.{CO}\%3B2-C},
	file = {kowalski_hutmacher_2001_design_evaluation_for_a_population_pharmacokinetic_study_using_clinical_trial.pdf:/home/nathan/Dropbox/njames/zotero_sync/kowalski_hutmacher_2001_design_evaluation_for_a_population_pharmacokinetic_study_using_clinical_trial.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/832F4S5J/1097-0258(20010115)20175AID-SIM6023.0.html:text/html}
}

@article{lee_design_nodate,
	title = {Design and Power of A Population Pharmacokinetic Study},
	abstract = {Purpose. This paper investigated the influence of critical design factors on the power of a population pharmacokinetic ({PK}) study for identifying subpopulations that have different drug clearance than the typical population.
Methods. A study simulation approach was used for the power estimation. The design factors included the number of subjects, sampling scheme, and compliance.
Results. The false positive rates of incorrectly identifying a subpopulation were estimated for several scenarios. The false positive rates of the population {PK} study was relatively low, except when the numbers of subjects with full profiles and the subjects with troughs were distributed between populations in an unbalanced manner. The total number of subjects did not seem to have as much influence on study power as the number of subjects in the subpopulation, as long as the total number of subjects was significantly larger than the subpopulation. The variability of sampling time played an important role in both the statistical power and the accuracy of the estimated difference in clearance. Taking three samples provided greater power and better accuracy than taking two samples per subject. Taking only trough samples provided little power and poor estimation of clearance difference. Adding subjects with full profiles to a study with only trough samples taken in other subjects did not satisfactorily improve the clearance estimation. It was critical to account for dosing record in the population {PK} analysis to achieve appropriate power and accuracy. If the variability in dosing time was accounted for in the analysis, it improved the accuracy of the estimated difference in clearance. Missing dose administrations reduced the study power and resulted in deviation of estimated clearance difference.
Conclusions. The power of a study should be determined prospectively to ensure appropriate study design for specific study objectives.},
	pages = {8},
	author = {Lee, Peter I D},
	langid = {english},
	file = {lee_design_and_power_of_a_population_pharmacokinetic_study.pdf:/home/nathan/Dropbox/njames/zotero_sync/lee_design_and_power_of_a_population_pharmacokinetic_study.pdf:application/pdf}
}

@article{wahlby_assessment_nodate,
	title = {Assessment of Actual Significance Levels for Covariate Effects in {NONMEM}},
	pages = {22},
	author = {Wahlby, Ulrika and Jonsson, E Niclas and Karlsson, Mats O},
	langid = {english},
	file = {wahlby_et_al_assessment_of_actual_significance_levels_for_covariate_effects_in_nonmem.pdf:/home/nathan/Dropbox/njames/zotero_sync/wahlby_et_al_assessment_of_actual_significance_levels_for_covariate_effects_in_nonmem.pdf:application/pdf}
}

@article{wahlby_assessment_nodate-1,
	title = {Assessment of Type I Error Rates for the Statistical Sub-model in {NONMEM}},
	pages = {19},
	author = {Wahlby, Ulrika and Bouw, M Rene and Jonsson, E Niclas and Karlsson, Mats O},
	langid = {english},
	file = {wahlby_et_al_assessment_of_type_i_error_rates_for_the_statistical_sub-model_in_nonmem.pdf:/home/nathan/Dropbox/njames/zotero_sync/wahlby_et_al_assessment_of_type_i_error_rates_for_the_statistical_sub-model_in_nonmem.pdf:application/pdf}
}

@article{ette_model_2003,
	title = {Model Appropriateness and Population Pharmacokinetic Modeling},
	volume = {43},
	issn = {1552-4604},
	url = {http://accp1.onlinelibrary.wiley.com/doi/abs/10.1177/0091270003253624},
	doi = {10.1177/0091270003253624},
	abstract = {The purpose of this study was to define model appropriateness, identifying the individual elements thereof, and to set out a framework within which model appropriateness could be determined for population pharmacokinetic ({PPK}) models. Model appropriateness was defined by stating the problem to be solved, with the intended use of the model being the pivotal event. The elements of model appropriateness were identified with the type of model (descriptive vs. predictive) determining which elements of model appropriateness need to be executed. An example is presented to show how model appropriateness is determined for the optimal application of {PPK} models. It was determined that {PPK} models are developed to solve problems. Model appropriateness depends on identifying the problem, as well as stating the intended use of the model, and requires evaluation of the model for goodness of fit, reliability, and stability if intended for descriptive purposes; for predictive models, validation would be an additional requirement. Descriptive models are used to explain variability in the pharmacokinetics ({PK}) of a drug, while predictive models are developed to extrapolate beyond the immediate study population. For those models used for predictive purposes, strong assumptions are made about the relationship to the underlying population from which the data were collected. As an example of determining model appropriateness, a {PPK} model for 5-fluorocytosine was developed, using {NONMEM}, version {IV}. The model was evaluated and validated by the process of percentile bootstrapping. From the {PPK} model, the range of expected serum concentrations based on two widely used dosing methods (Sanford and the University of California at San Diego [{UCSD}]) was simulated (Pharsight Trial Designer software). These results indicated that the {UCSD} method performed well and has the advantage of recommending convenient dosing intervals. In conclusion, considering and applying the principles of model appropriateness to {PPK} models will result in models that can be applied for their intended use with confidence. Model appropriateness was efficiently established and determined to address the problem of comparing competing dosing strategies.},
	pages = {610--623},
	number = {6},
	journaltitle = {The Journal of Clinical Pharmacology},
	author = {Ette, Ene I. and Williams, Paul J. and Kim, Yong Ho and Lane, James R. and Liu, Mei-Jen and Capparelli, Edmund V.},
	urldate = {2020-08-27},
	date = {2003},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1177/0091270003253624},
	keywords = {bootstrapping, descriptive models, model appropriateness, Population pharmacokinetic models, predictive models},
	file = {ette_et_al_2003_model_appropriateness_and_population_pharmacokinetic_modeling.pdf:/home/nathan/Dropbox/njames/zotero_sync/ette_et_al_2003_model_appropriateness_and_population_pharmacokinetic_modeling.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/KKUC84QX/0091270003253624.html:text/html}
}

@article{bruno_population_2003,
	title = {Population pharmacokinetics and pharmacodynamics of enoxaparin in unstable angina and non-{ST}-segment elevation myocardial infarction},
	volume = {56},
	issn = {1365-2125},
	url = {http://bpspubs.onlinelibrary.wiley.com/doi/abs/10.1046/j.1365-2125.2003.01904.x},
	doi = {10.1046/j.1365-2125.2003.01904.x},
	abstract = {Aims A major concern with any antithrombotic therapy is an increase in the risk of haemorrhage. The aim of this study was to analyse population pharmacokinetics and pharmacokinetic/pharmacodynamic ({PK}/{PD}) relationships for enoxaparin in patients with unstable angina ({UA}) and non-{ST}-segment elevation myocardial infarction ({NSTEMI}), which may help predict risk of haemorrhage. Methods Anti-factor Xa (anti-Xa) activity was measured as marker of enoxaparin concentration in 448 patients receiving the drug as a single 30-mg intravenous bolus followed by 1.0 or 1.25 mg kg−1 subcutaneously twice a day. A population pharmacokinetic analysis was conducted and individual estimates of enoxaparin clearance and area under the curve were tested as prognostic factors for the occurrence of haemorrhagic episodes. Results Basic population {PK} parameters were an enoxaparin clearance of 0.733 l h−1[95\% confidence interval ({CI}) 0.698, 0.738], a distribution volume of 5.24 l (95\% {CI} 4.20, 6.28) and an elimination half-life of 5.0 h. Enoxaparin clearance was significantly related to patient weight and creatinine clearance, and was the only independent predictor of experiencing both all (10.7\%, P = 0.0013) and major (2.2\%, P = 0.0004) haemorrhagic events. A creatinine clearance of 30 ml min−1 was associated with a decrease in enoxaparin clearance of 27\% compared with that in a patient with a median creatinine clearance of 88 ml min−1, and was related to a 1.5- and 3.8-fold increase in the risk of ‘all’ and ‘major’ haemorrhagic episodes, respectively. Conclusions Enoxaparin clearance depends on body weight, and, therefore, weight-adjusted dosing is recommended to minimize interpatient variability in drug exposure and the risk of haemorrhage. The importance of an increased risk of haemorrhage with decreasing renal function must be weighed against the benefit of treatment with enoxaparin in patients with {UA} and {NSTEMI}.},
	pages = {407--414},
	number = {4},
	journaltitle = {British Journal of Clinical Pharmacology},
	author = {Bruno, René and Baille, Pascale and Retout, Sylvie and Vivier, Nicole and Veyrat‐Follet, Christine and Sanderink, Ger-Jan and Becker, Richard and Antman, Elliott M.},
	urldate = {2020-08-27},
	date = {2003},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1046/j.1365-2125.2003.01904.x},
	keywords = {population pharmacokinetics, acute coronary syndromes, angina, haemorrhage, myocardial infarction},
	file = {bruno_et_al_2003_population_pharmacokinetics_and_pharmacodynamics_of_enoxaparin_in_unstable.pdf:/home/nathan/Dropbox/njames/zotero_sync/bruno_et_al_2003_population_pharmacokinetics_and_pharmacodynamics_of_enoxaparin_in_unstable.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/52H2ITS3/j.1365-2125.2003.01904.html:text/html}
}

@article{rajagopalan_population_2003,
	title = {Population Pharmacokinetics of Ciprofloxacin in Pediatric Patients},
	volume = {43},
	issn = {1552-4604},
	url = {http://accp1.onlinelibrary.wiley.com/doi/abs/10.1177/0091270003254802},
	doi = {10.1177/0091270003254802},
	abstract = {The objective of this study was to characterize ciprofloxacin population pharmacokinetics in pediatric patients. A total of 150 pediatric patients (including 28 patients with cystic fibrosis [{CF}], ages 0.27–16.9 years) received ciprofloxacin by the oral and/or intravenous routes. Population pharmacokinetic analyses were performed with {NONMEM} software. Exponential error models were used to describe the interindividual variance in pharmacokinetic parameters, and the residual error model included both proportional and additive components. Based on principles of allometry, the patient's body weight was used as a covariate, along with appropriate allometric exponents, in the construction of the base model. Model building was accomplished by a stepwise forward inclusion procedure, and the final model was evaluated by multiple techniques, including bootstrap, leverage analysis, and cross-validation. With body weight included in the model (two compartments with first-order absorption), ciprofloxacin clearance was influenced by age, and the absorption rate constant was altered in {CF} patients. The final model is summarized as follows: {CL} (L/h) = 30.3 × ({WT}/70)0.75 × (1 + 0.045 [{AGE} −2.5]), {VC} (L) = 56.7 × ({WT}/70)1.0, {VP} (L) = 89.8 × ({WT}/70)1.0, Q (L/h) = 37.5 × ({WT}/70)0.75, Ka (1/h) = 1.27 × (1 + [−0.611 × {CF}]), absorption lag time = 0.35 hours, and bioavailability fraction = 61.1\%, where {WT} and {AGE} are the patient's body weight (kg) and age (years), respectively, and the variable {CF} equals 1 for {CF} patients and 0 for non-{CF} patients. The interpatient variability in pharmacokinetic parameters (percentage coefficient of variation [\%{CV}]) ranged from 22.5\% to 49.8\%. The residual variabilities (\%{CV}) for the oral and intravenous data were 40\% and 27\%, respectively. The shared additive residual variance component was small ({SD} = 0.04 mg/L). Model evaluation by the different methods indicated that the final model was robust and parameter estimates were precise. A small difference ({\textless} 6\%) was noted when the patient's age was not used in dose calculation. Therefore, in routine clinical use, for pediatric patients older than 3 months, ciprofloxacin dose may be calculated solely based on body weight.},
	pages = {698--710},
	number = {7},
	journaltitle = {The Journal of Clinical Pharmacology},
	author = {Rajagopalan, Prabhu and Gastonguay, Marc R.},
	urldate = {2020-08-27},
	date = {2003},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1177/0091270003254802},
	keywords = {pharmacokinetics, Ciprofloxacin, cystic fibrosis, pediatrics, urinary tract infection},
	file = {rajagopalan_gastonguay_2003_population_pharmacokinetics_of_ciprofloxacin_in_pediatric_patients.pdf:/home/nathan/Dropbox/njames/zotero_sync/rajagopalan_gastonguay_2003_population_pharmacokinetics_of_ciprofloxacin_in_pediatric_patients.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/IMAH6NES/0091270003254802.html:text/html}
}

@article{maitre_three-step_1991,
	title = {A three-step approach combining bayesian regression and {NONMEM} population analysis: Application to midazolam},
	volume = {19},
	issn = {0090-466X},
	url = {http://link.springer.com/10.1007/BF01061662},
	doi = {10.1007/BF01061662},
	shorttitle = {A three-step approach combining bayesian regression and {NONMEM} population analysis},
	pages = {377--384},
	number = {4},
	journaltitle = {Journal of Pharmacokinetics and Biopharmaceutics},
	author = {Maitre, P. O. and Bührer, M. and Thomson, D. and Stanski, D. R.},
	urldate = {2020-08-27},
	date = {1991-08},
	langid = {english},
	file = {maitre_et_al_1991_a_three-step_approach_combining_bayesian_regression_and_nonmem_population.pdf:/home/nathan/Dropbox/njames/zotero_sync/maitre_et_al_1991_a_three-step_approach_combining_bayesian_regression_and_nonmem_population.pdf:application/pdf}
}

@article{grasela_jr_neonatal_1985,
	title = {Neonatal Population Pharmacokinetics of Phenobarbital Derived from Routine Clinical Data},
	volume = {8},
	issn = {0379-8305, 2504-2505},
	url = {https://www.karger.com/Article/FullText/457062},
	doi = {10.1159/000457062},
	pages = {374--383},
	number = {6},
	journaltitle = {Dev Pharmacol Ther},
	author = {Grasela Jr., Thaddeus H. and Donn, Steven M.},
	urldate = {2020-08-28},
	date = {1985},
	langid = {english},
	file = {grasela_jr._donn_1985_neonatal_population_pharmacokinetics_of_phenobarbital_derived_from_routine.pdf:/home/nathan/Dropbox/njames/zotero_sync/grasela_jr._donn_1985_neonatal_population_pharmacokinetics_of_phenobarbital_derived_from_routine.pdf:application/pdf}
}

@article{nedelman_diagnostics_2007,
	title = {Diagnostics for confounding in {PK}/{PD} models for oxcarbazepine},
	volume = {26},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.2542},
	doi = {10.1002/sim.2542},
	abstract = {One type of pharmacokinetic/pharmacodynamic ({PK}/{PD}) relationship that is used to characterize the therapeutic action of a drug is the relationship between some univariate summary of the plasma-concentration-versus-time profile and the drug effect on a response outcome. Operationally, such a relationship may be observed in a large clinical trial where randomly sampled patients are randomized to different values of the concentration summary. If, under such conditions, the relationship between concentration and effect does not depend on the dose needed to attain the target concentration, such a relationship will be called a true {PK}/{PD} relationship. When the true {PK}/{PD} relationship is assessed as an object of estimation in a dose-controlled clinical trial (i.e. when dose is randomized), observed drug concentration is an outcome variable. The estimated {PK}/{PD} relationship between observed outcome and observed concentration, which we then refer to as the conventional {PK}/{PD} relationship, may be biased for the true {PK}/{PD} relationship. Because of this bias, the conventional relationship is called confounded for the true one. We show that diagnostics for confounding can be devised under reasonable assumptions. We then apply these diagnostics to {PK}/{PD} assessments of adults and children on oxcarbazepine adjunctive therapy. It was necessary to demonstrate the similarity of the true {PK}/{PD} relationships of adults and children on adjunctive therapy in order to support the approval of oxcarbazepine monotherapy in children by a bridging argument. Copyright © 2006 John Wiley \& Sons, Ltd.},
	pages = {290--308},
	number = {2},
	journaltitle = {Statistics in Medicine},
	author = {Nedelman, Jerry R. and Rubin, Donald B. and Sheiner, Lewis B.},
	urldate = {2020-08-31},
	date = {2007},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.2542},
	keywords = {instrumental variables, pharmacodynamics, pharmacokinetics, pediatric bridging, potential outcomes, Rubin's causal model, sensitivity analysis, two-stage least squares},
	file = {nedelman_et_al_2007_diagnostics_for_confounding_in_pk-pd_models_for_oxcarbazepine.pdf:/home/nathan/Dropbox/njames/zotero_sync/nedelman_et_al_2007_diagnostics_for_confounding_in_pk-pd_models_for_oxcarbazepine.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/KHFEHINH/sim.html:text/html}
}

@book{bonate_pharmacokinetic-pharmacodynamic_2011,
	location = {New York},
	edition = {2. ed},
	title = {Pharmacokinetic-pharmacodynamic modeling and simulation},
	isbn = {978-1-4419-9485-1 978-1-4419-9484-4},
	pagetotal = {618},
	publisher = {Springer},
	author = {Bonate, Peter L.},
	date = {2011},
	note = {{OCLC}: 748651873}
}

@article{lindstrom_nonlinear_1990,
	title = {Nonlinear Mixed Effects Models for Repeated Measures Data},
	volume = {46},
	issn = {0006341X},
	url = {https://www.jstor.org/stable/2532087?origin=crossref},
	doi = {10.2307/2532087},
	abstract = {We propose a general, nonlinear mixed effects model for repeated measures data and define estimators for its parameters. The proposed estimators are a natural combination of least squares estimators for nonlinear fixed effects models and maximum likelihood (or restricted maximum likelihood) estimators for linear mixed effects models. We implement Newton-Raphson estimation using previously developed computational methods for nonlinear fixed effects models and for linear mixed effects models. Two examples are presented and the connections between this work and recent work on generalized linear mixed effects models are discussed.},
	pages = {673},
	number = {3},
	journaltitle = {Biometrics},
	author = {Lindstrom, Mary J. and Bates, Douglas M.},
	urldate = {2020-08-31},
	date = {1990-09},
	langid = {english},
	file = {lindstrom_bates_1990_nonlinear_mixed_effects_models_for_repeated_measures_data.pdf:/home/nathan/Dropbox/njames/zotero_sync/lindstrom_bates_1990_nonlinear_mixed_effects_models_for_repeated_measures_data.pdf:application/pdf}
}

@article{dempster_maximum_1977,
	title = {Maximum Likelihood from Incomplete Data Via the \textit{{EM}} Algorithm},
	volume = {39},
	issn = {00359246},
	url = {http://doi.wiley.com/10.1111/j.2517-6161.1977.tb01600.x},
	doi = {10.1111/j.2517-6161.1977.tb01600.x},
	abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
	pages = {1--22},
	number = {1},
	journaltitle = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
	urldate = {2020-08-31},
	date = {1977-09},
	langid = {english},
	file = {dempster_et_al_1977_maximum_likelihood_from_incomplete_data_via_the_iem-i_algorithm.pdf:/home/nathan/Dropbox/njames/zotero_sync/dempster_et_al_1977_maximum_likelihood_from_incomplete_data_via_the_iem-i_algorithm.pdf:application/pdf}
}

@article{wahlby_comparison_2002,
	title = {Comparison of stepwise covariate model building strategies in population pharmacokinetic-pharmacodynamic analysis},
	volume = {4},
	issn = {1522-1059},
	url = {http://link.springer.com/10.1208/ps040427},
	doi = {10.1208/ps040427},
	abstract = {The aim of this study was to compare 2 stepwise covariate model-building strategies, frequently used in the analysis of pharmacokineticpharmacodynamic ({PK}-{PD}) data using nonlinear mixedeffects models, with respect to included covariates and predictive performance. In addition, the effects of stepwise regression on the estimated covariate coefficients were assessed. Using simulated and real {PK} data, covariate models were built applying (1) stepwise generalized additive models ({GAM}) for identifying potential covariates, followed by backward elimination in the computer program {NONMEM}, and (2) stepwise forward inclusion and backward elimination in {NONMEM}. Different versions of these procedures were tried (eg, treating different study occasions as separate individuals in the {GAM}, or fixing a part of the parameters when the {NONMEM} procedure was used). The final covariate models were compared, including their ability to predict a separate data set or their performance in crossvalidation. The bias in the estimated coefficients (selection bias) was assessed. The model-building procedures performed similarly in the data sets explored. No major differences in the resulting covariate models were seen, and the predictive performances overlapped. Therefore, the choice of model-building procedure in these examples could be based on other aspects such as analystand computer-time efficiency. There was a tendency to selection bias in the estimates, although this was small relative to the overall variability in the estimates. The predictive performances of the stepwise models were also reasonably good. Thus, selection bias seems to be a minor problem in this typical {PK} covariate analysis.},
	pages = {68--79},
	number = {4},
	journaltitle = {{AAPS} J},
	author = {Wählby, Ulrika and Jonsson, E. Niclas and Karlsson, Mats O.},
	urldate = {2020-09-04},
	date = {2002-12},
	langid = {english},
	file = {wählby_et_al_2002_comparison_of_stepwise_covariate_model_building_strategies_in_population.pdf:/home/nathan/Dropbox/njames/zotero_sync/wählby_et_al_2002_comparison_of_stepwise_covariate_model_building_strategies_in_population.pdf:application/pdf}
}

@article{sheiner_bayesian_1982,
	title = {Bayesian individualization of pharmacokinetics: Simple implementation and comparison with non-Bayesian methods},
	volume = {71},
	issn = {1520-6017},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/jps.2600711209},
	doi = {10.1002/jps.2600711209},
	shorttitle = {Bayesian individualization of pharmacokinetics},
	abstract = {One may attempt to individualize drug dosage by estimating an individual's pharmacokinetic parameters. Information useful for this purpose consists of certain population pharmacokinetic parameters (notably those describing the typical relationship between dosage and drug concentrations) and also measured drug concentrations from the individual of concern. Both types of information should be used. A (Bayesian) method that does so has been described in the pharmacokinetic literature. In this report an implementation of the Bayesian method that is readily adapted to a microcomputer is presented. Using simulated data it is compared with two other methods proposed by others, for estimating individual theophylline clearances. Both previously suggested methods are shown to be less precise than the Bayesian method: their typical error magnitudes are 20–70\% larger.},
	pages = {1344--1348},
	number = {12},
	journaltitle = {Journal of Pharmaceutical Sciences},
	author = {Sheiner, Lewis B. and Beal, Stuart L.},
	urldate = {2020-09-08},
	date = {1982},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/jps.2600711209},
	keywords = {Bayesian method—individualization of pharmacokinetics, Pharmacokinetics—Bayesian individualization, simple implementation and comparison with non-Bayesian methods, theophylline, Theophylline—Bayesian individualization of pharmacokinetics},
	file = {sheiner_beal_1982_bayesian_individualization_of_pharmacokinetics.pdf:/home/nathan/Dropbox/njames/zotero_sync/sheiner_beal_1982_bayesian_individualization_of_pharmacokinetics.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/TE9QAAGP/jps.html:text/html}
}

@article{sheiner_forecasting_1979,
	title = {Forecasting individual pharmacokinetics},
	volume = {26},
	issn = {1532-6535},
	url = {http://ascpt.onlinelibrary.wiley.com/doi/abs/10.1002/cpt1979263294},
	doi = {10.1002/cpt1979263294},
	abstract = {Often drug dosage may be chosen rationally by use of plasma concentration ({CP}) as the “therapeutic” end point. The ability to accurately forecast the {CP} resulting from a dosage regimen is central to choosing that regimen. Traditionally forecasting has been attempted only by accounting for known influences on pharmacokinetics, such as sex, age, and renal disease. One must also adjust for previously observed {CPs}. Herein, we discuss and explain an approach to both of these tasks, mainly focusing on the latter. The approach balances observed outcomes against prior expectations taking account of observation {CP} error. For digoxin, use of 1 measured {CP}, as opposed to none, improves forecast precision for future {CPs} by 40\% (decrement in variance of forecast error), and 2 {CPs} improve it by 67\%. There is also an increase in forecast accuracy (decrement in mean of forecast error) as the number of {CPs} used increases. After only 2, forecast accuracy and precision are as good as theoretically possible. Moreover, information from {CPs} is far more valuable for forecasting than that from observable patient features—sex, age, and the like; use of all the latter information does not improve accuracy and precision as much as only 1 {CP}.},
	pages = {294--305},
	number = {3},
	journaltitle = {Clinical Pharmacology \& Therapeutics},
	author = {Sheiner, Lewis B. and Beal, Stuart and Rosenberg, Barr and Marathe, Vinay V.},
	urldate = {2020-09-08},
	date = {1979},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpt1979263294},
	file = {sheiner_et_al_1979_forecasting_individual_pharmacokinetics.pdf:/home/nathan/Dropbox/njames/zotero_sync/sheiner_et_al_1979_forecasting_individual_pharmacokinetics.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/RR9VF746/cpt1979263294.html:text/html}
}

@article{lunn_automated_2008,
	title = {Automated covariate selection and Bayesian model averaging in population {PK}/{PD} models},
	volume = {35},
	issn = {1567-567X, 1573-8744},
	url = {http://link.springer.com/10.1007/s10928-007-9077-x},
	doi = {10.1007/s10928-007-9077-x},
	abstract = {We illustrate the use of ‘reversible jump’ {MCMC} to automate the process of covariate selection in population {PK}/{PD} analyses. The output from such an approach can be used not only to determine the ‘best’ covariate model for each parameter, but also to formally measure the spread of uncertainty across all possible models, and to average inferences across a range of ‘good’ models. We examine the substantive impact of such model averaging compared to conditioning inferences on the ‘best’ model alone, and conclude that clinically signiﬁcant differences between the two approaches can arise. The illustrative data that we consider pertain to the drug vancomycin in 59 neonates and infants, and all analyses are conducted using the {WinBUGS} software with newly developed ‘Jump’ interface installed.},
	pages = {85--100},
	number = {1},
	journaltitle = {J Pharmacokinet Pharmacodyn},
	author = {Lunn, David J.},
	urldate = {2020-09-09},
	date = {2008-02},
	langid = {english},
	file = {lunn_2008_automated_covariate_selection_and_bayesian_model_averaging_in_population_pk-pd.pdf:/home/nathan/Dropbox/njames/zotero_sync/lunn_2008_automated_covariate_selection_and_bayesian_model_averaging_in_population_pk-pd.pdf:application/pdf}
}

@article{hutmacher_covariate_2015,
	title = {Covariate selection in pharmacometric analyses: a review of methods: Covariate selection in pharmacometric analysis},
	volume = {79},
	issn = {03065251},
	url = {http://doi.wiley.com/10.1111/bcp.12451},
	doi = {10.1111/bcp.12451},
	shorttitle = {Covariate selection in pharmacometric analyses},
	pages = {132--147},
	number = {1},
	journaltitle = {Br J Clin Pharmacol},
	author = {Hutmacher, Matthew M. and Kowalski, Kenneth G.},
	urldate = {2020-09-09},
	date = {2015-01},
	langid = {english},
	file = {hutmacher_kowalski_2015_covariate_selection_in_pharmacometric_analyses.pdf:/home/nathan/Dropbox/njames/zotero_sync/hutmacher_kowalski_2015_covariate_selection_in_pharmacometric_analyses.pdf:application/pdf}
}

@article{byon_establishing_2013,
	title = {Establishing Best Practices and Guidance in Population Modeling: An Experience With an Internal Population Pharmacokinetic Analysis Guidance},
	volume = {2},
	issn = {2163-8306},
	url = {http://doi.wiley.com/10.1038/psp.2013.26},
	doi = {10.1038/psp.2013.26},
	shorttitle = {Establishing Best Practices and Guidance in Population Modeling},
	pages = {e51},
	number = {7},
	journaltitle = {{CPT}: pharmacomet. syst. pharmacol.},
	author = {Byon, W and Smith, M K and Chan, P and Tortorici, M A and Riley, S and Dai, H and Dong, J and Ruiz-Garcia, A and Sweeney, K and Cronenberger, C},
	urldate = {2020-09-09},
	date = {2013-07},
	langid = {english},
	file = {byon_et_al_2013_establishing_best_practices_and_guidance_in_population_modeling.pdf:/home/nathan/Dropbox/njames/zotero_sync/byon_et_al_2013_establishing_best_practices_and_guidance_in_population_modeling.pdf:application/pdf}
}

@article{ribbing_power_2004,
	title = {Power, Selection Bias and Predictive Performance of the Population Pharmacokinetic Covariate Model},
	volume = {31},
	issn = {1567-567X},
	url = {http://link.springer.com/10.1023/B:JOPA.0000034404.86036.72},
	doi = {10.1023/B:JOPA.0000034404.86036.72},
	pages = {109--134},
	number = {2},
	journaltitle = {J Pharmacokinet Pharmacodyn},
	author = {Ribbing, Jakob and Niclas Jonsson, E.},
	urldate = {2020-09-09},
	date = {2004-04},
	langid = {english},
	file = {ribbing_niclas_jonsson_2004_power,_selection_bias_and_predictive_performance_of_the_population.pdf:/home/nathan/Dropbox/njames/zotero_sync/ribbing_niclas_jonsson_2004_power,_selection_bias_and_predictive_performance_of_the_population.pdf:application/pdf}
}

@article{sherer_application_2012,
	title = {Application of a single-objective, hybrid genetic algorithm approach to pharmacokinetic model building},
	volume = {39},
	issn = {1567-567X, 1573-8744},
	url = {http://link.springer.com/10.1007/s10928-012-9258-0},
	doi = {10.1007/s10928-012-9258-0},
	pages = {393--414},
	number = {4},
	journaltitle = {J Pharmacokinet Pharmacodyn},
	author = {Sherer, Eric A. and Sale, Mark E. and Pollock, Bruce G. and Belani, Chandra P. and Egorin, Merrill J. and Ivy, Percy S. and Lieberman, Jeffrey A. and Manuck, Stephen B. and Marder, Stephen R. and Muldoon, Matthew F. and Scher, Howard I. and Solit, David B. and Bies, Robert R.},
	urldate = {2020-09-14},
	date = {2012-08},
	langid = {english},
	file = {sherer_et_al_2012_application_of_a_single-objective,_hybrid_genetic_algorithm_approach_to.pdf:/home/nathan/Dropbox/njames/zotero_sync/sherer_et_al_2012_application_of_a_single-objective,_hybrid_genetic_algorithm_approach_to.pdf:application/pdf}
}

@article{bies_genetic_2006,
	title = {A Genetic Algorithm-Based, Hybrid Machine Learning Approach to Model Selection},
	volume = {33},
	issn = {1567-567X, 1573-8744},
	url = {http://link.springer.com/10.1007/s10928-006-9004-6},
	doi = {10.1007/s10928-006-9004-6},
	pages = {195--221},
	number = {2},
	journaltitle = {J Pharmacokinet Pharmacodyn},
	author = {Bies, Robert R. and Muldoon, Matthew F. and Pollock, Bruce G. and Manuck, Steven and Smith, Gwenn and Sale, Mark E.},
	urldate = {2020-09-14},
	date = {2006-04},
	langid = {english},
	file = {bies_et_al_2006_a_genetic_algorithm-based,_hybrid_machine_learning_approach_to_model_selection.pdf:/home/nathan/Dropbox/njames/zotero_sync/bies_et_al_2006_a_genetic_algorithm-based,_hybrid_machine_learning_approach_to_model_selection.pdf:application/pdf}
}

@article{albert_bayesian_2020-1,
	title = {A Bayesian Redesign of the First Probability/Statistics Course},
	url = {http://arxiv.org/abs/2007.04180},
	abstract = {The traditional calculus-based introduction to statistical inference consists of a semester of probability followed by a semester of frequentist inference. Cobb (2015) challenges the statistical education community to rethink the undergraduate statistics curriculum. In particular, he suggests that we should focus on two goals: making fundamental concepts accessible and minimizing prerequisites to research. Using ﬁve underlying principles of Cobb, we describe a new calculusbased introduction to statistics based on simulation-based Bayesian computation.},
	journaltitle = {{arXiv}:2007.04180 [stat]},
	author = {Albert, Jim},
	urldate = {2020-09-14},
	date = {2020-07-08},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2007.04180},
	keywords = {Statistics - Other Statistics},
	file = {albert_2020_a_bayesian_redesign_of_the_first_probability-statistics_course.pdf:/home/nathan/Dropbox/njames/zotero_sync/albert_2020_a_bayesian_redesign_of_the_first_probability-statistics_course.pdf:application/pdf}
}

@article{lerner_build_nodate,
	title = {{BUILD} {YOUR} {OWN} {STATISTICS} {COURSE} {FOR} {STUDENTS} {IN} A {NON}-{QUANTITATIVE} {FIELD}},
	abstract = {Statistics courses are typically in mathematics or statistics departments or in social and natural sciences such as economics, political science, psychology, and biology. Here we discuss how to construct a statistics course for students in non-quantitative fields, with a goal of integrating the statistical material with students' substantive interests, using modern teaching methods to increase student involvement. We demonstrate with the example of an introductory applied statistics class at the University of Toronto's Centre for Jewish Studies.},
	pages = {12},
	author = {Lerner, Alexis and Gelman, Andrew},
	langid = {english},
	file = {lerner_gelman_build_your_own_statistics_course_for_students_in_a_non-quantitative_field.pdf:/home/nathan/Dropbox/njames/zotero_sync/lerner_gelman_build_your_own_statistics_course_for_students_in_a_non-quantitative_field.pdf:application/pdf}
}

@article{johnson_modelling_2005,
	title = {Modelling approaches to dose estimation in children},
	volume = {59},
	issn = {0306-5251, 1365-2125},
	url = {http://doi.wiley.com/10.1111/j.1365-2125.2005.02429.x},
	doi = {10.1111/j.1365-2125.2005.02429.x},
	pages = {663--669},
	number = {6},
	journaltitle = {Br J Clin Pharmacol},
	author = {Johnson, Trevor N.},
	urldate = {2020-09-15},
	date = {2005-06},
	langid = {english},
	file = {johnson_2005_modelling_approaches_to_dose_estimation_in_children.pdf:/home/nathan/Dropbox/njames/zotero_sync/johnson_2005_modelling_approaches_to_dose_estimation_in_children.pdf:application/pdf}
}

@article{choi_practical_2013,
	title = {Practical recommendations for population {PK} studies with sampling time errors},
	volume = {69},
	issn = {0031-6970, 1432-1041},
	url = {http://link.springer.com/10.1007/s00228-013-1576-7},
	doi = {10.1007/s00228-013-1576-7},
	abstract = {Purpose Population pharmacokinetic ({PK}) data collected from routine clinical practice offers a rich source of valuable information. However, in observational population {PK} data, accurate time information for blood samples is often missing, resulting in measurement errors ({ME}) in the sampling time variable. The goal of this study was to investigate the effects on model parameters when a scheduled time is used instead of the actual blood sampling time, and to propose {ME} correction methods.},
	pages = {2055--2064},
	number = {12},
	journaltitle = {Eur J Clin Pharmacol},
	author = {Choi, Leena and Crainiceanu, Ciprian M. and Caffo, Brian S.},
	urldate = {2020-09-15},
	date = {2013-12},
	langid = {english},
	file = {choi_et_al_2013_practical_recommendations_for_population_pk_studies_with_sampling_time_errors.pdf:/home/nathan/Dropbox/njames/zotero_sync/choi_et_al_2013_practical_recommendations_for_population_pk_studies_with_sampling_time_errors.pdf:application/pdf}
}

@article{brown_bayesian_2003,
	title = {A Bayesian Semiparametric Joint Hierarchical Model for Longitudinal and Survival Data},
	volume = {59},
	issn = {1541-0420},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/1541-0420.00028},
	doi = {10.1111/1541-0420.00028},
	abstract = {This article proposes a new semiparametric Bayesian hierarchical model for the joint modeling of longitudinal and survival data. We relax the distributional assumptions for the longitudinal model using Dirichlet process priors on the parameters defining the longitudinal model. The resulting posterior distribution of the longitudinal parameters is free of parametric constraints, resulting in more robust estimates. This type of approach is becoming increasingly essential in many applications, such as {HIV} and cancer vaccine trials, where patients' responses are highly diverse and may not be easily modeled with known distributions. An example will be presented from a clinical trial of a cancer vaccine where the survival outcome is time to recurrence of a tumor. Immunologic measures believed to be predictive of tumor recurrence were taken repeatedly during follow-up. We will present an analysis of this data using our new semiparametric Bayesian hierarchical joint modeling methodology to determine the association of these longitudinal immunologic measures with time to tumor recurrence.},
	pages = {221--228},
	number = {2},
	journaltitle = {Biometrics},
	author = {Brown, Elizabeth R. and Ibrahim, Joseph G.},
	urldate = {2020-09-16},
	date = {2003},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1541-0420.00028},
	keywords = {Dirichlet process, Joint longitudinal and survival model, Semiparametric Bayes},
	file = {brown_ibrahim_2003_a_bayesian_semiparametric_joint_hierarchical_model_for_longitudinal_and.pdf:/home/nathan/Dropbox/njames/zotero_sync/brown_ibrahim_2003_a_bayesian_semiparametric_joint_hierarchical_model_for_longitudinal_and.pdf:application/pdf;Snapshot:/home/nathan/.zotero/zotero/8wya1n1c.default/zotero/storage/ZSKMEFMM/1541-0420.html:text/html}
}

@article{blume_likelihood_2017,
	title = {Likelihood Based Study Designs for Time-to-Event Endpoints},
	url = {http://arxiv.org/abs/1711.01527},
	abstract = {Likelihood methods for measuring statistical evidence obey the likelihood principle and maintain excellent frequency properties. These methods lend themselves to sequential study designs because they measure the strength of statistical evidence in accumulating data without needing adjustments for the number of planned or unplanned examinations of data. However, sample size projections have, to date, only been developed for ﬁxed sample size designs. In this paper, we consider sequential study designs for time-to-event outcomes assuming likelihood methods will be used to monitor the strength of statistical evidence for eﬃcacy and futility. We develop sample size projections with the aim of controlling the probability of observing misleading evidence under the null and alternative hypotheses, and we show how eﬃcacy and futility considerations are managed in this context. We also consider relaxing the requirement of specifying the simple alternative hypothesis in advance of the study. Finally, we end with a comparative illustration of these methods in a phase {II} cancer clinical trial that previously was designed within a Bayesian framework.},
	journaltitle = {{arXiv}:1711.01527 [stat]},
	author = {Blume, Jeffrey D. and Choi, Leena},
	urldate = {2020-09-17},
	date = {2017-11-04},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1711.01527},
	keywords = {Statistics - Methodology},
	file = {blume_choi_2017_likelihood_based_study_designs_for_time-to-event_endpoints.pdf:/home/nathan/Dropbox/njames/zotero_sync/blume_choi_2017_likelihood_based_study_designs_for_time-to-event_endpoints.pdf:application/pdf}
}

@article{kass_statistical_2011,
	title = {Statistical Inference: The Big Picture},
	volume = {26},
	issn = {0883-4237},
	url = {http://projecteuclid.org/euclid.ss/1307626554},
	doi = {10.1214/10-STS337},
	shorttitle = {Statistical Inference},
	abstract = {Statistics has moved beyond the frequentist-Bayesian controversies of the past. Where does this leave our ability to interpret results? I suggest that a philosophy compatible with statistical practice, labelled here statistical pragmatism, serves as a foundation for inference. Statistical pragmatism is inclusive and emphasizes the assumptions that connect statistical models with observed data. I argue that introductory courses often mis-characterize the process of statistical inference and I propose an alternative “big picture” depiction.},
	pages = {1--9},
	number = {1},
	journaltitle = {Statist. Sci.},
	author = {Kass, Robert E.},
	urldate = {2020-09-20},
	date = {2011-02},
	langid = {english},
	file = {kass_2011_statistical_inference.pdf:/home/nathan/Dropbox/njames/zotero_sync/kass_2011_statistical_inference.pdf:application/pdf}
}

@incollection{neal_mcmc_2011,
	location = {New York},
	title = {{MCMC} using Hamiltonian Dynamics},
	isbn = {978-1-4200-7942-5},
	series = {Handbooks of Modern Statistical Methods},
	pages = {113--162},
	booktitle = {Handbook of Markov Chain Monte Carlo},
	publisher = {{CRC} Press, Taylor \& Francis Group},
	author = {Neal, Radford},
	editor = {Brooks, Steve and Gelman, Andrew and Jones, Galin L. and Meng, Xiao-Li},
	editorb = {Fitzmaurice, Garrett},
	editorbtype = {redactor},
	date = {2011},
	langid = {english}
}